import sys
import os
sys.path.append('../../')
sys.path.append('../../python_parser')
import json
import argparse
import warnings
import torch
from model import CodeBERT, GraphCodeBERT, CodeT5
from run import CodeBertTextDataset, GraphCodeBertTextDataset, CodeT5TextDataset
from utils import set_seed
from attacker import Attacker
from pso import PSOAttack
from transformers import (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, RobertaForMaskedLM,
                          T5Config, T5ForConditionalGeneration)
import fasttext
import fasttext.util
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.simplefilter(action='ignore', category=FutureWarning)


MODEL_CLASSES = {
    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer),
    'codet5': (T5Config, T5ForConditionalGeneration, RobertaTokenizer)
}


def main():
    parser = argparse.ArgumentParser()

    parser.add_argument("--eval_data_file", default=None, type=str,
                        help="An optional input evaluation data file to evaluate the perplexity on (a text file).")
    parser.add_argument('--seed', type=int, default=123456,
                        help="random seed for initialization")
    parser.add_argument("--cache_dir", default="", type=str,
                        help="Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)")
    parser.add_argument("--attack_random", default=0, type=int,
                        help="attack random.")
    parser.add_argument("--model_name", default="", type=str,
                        help="model type.")

    args = parser.parse_args()
    args.device = torch.device("cuda")
    args.output_dir = './saved_models'
    args.model_type = 'roberta'
    args.eval_batch_size = 64
    args.block_size = 512
    args.language_type = 'c'
    args.use_ga = True

    if args.model_name == 'codebert':
        args.tokenizer_name = 'microsoft/codebert-base-mlm'
        args.model_name_or_path = 'microsoft/codebert-base-mlm'
        args.base_model = 'microsoft/codebert-base-mlm'
    elif args.model_name == 'graphcodebert':
        args.code_length = 448
        args.data_flow_length = 64
        args.tokenizer_name = 'microsoft/graphcodebert-base'
        args.model_name_or_path = 'microsoft/graphcodebert-base'
        args.base_model = 'microsoft/graphcodebert-base'
    elif args.model_name == 'codet5':
        args.model_type = 'codet5'
        args.tokenizer_name = 'Salesforce/codet5-base-multi-sum'
        args.model_name_or_path = 'Salesforce/codet5-base-multi-sum'
        args.base_model = 'microsoft/codebert-base-mlm'

    set_seed(args.seed)
    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]
    config = config_class.from_pretrained(args.model_name_or_path, cache_dir=args.cache_dir if args.cache_dir else None)
    config.num_labels = 1
    tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name,
                                                do_lower_case=False,
                                                cache_dir=args.cache_dir if args.cache_dir else None)
    if args.block_size <= 0:
        args.block_size = tokenizer.max_len_single_sentence
    args.block_size = min(args.block_size, tokenizer.max_len_single_sentence)

    if args.model_name_or_path:
        model = model_class.from_pretrained(args.model_name_or_path,
                                            from_tf=bool('.ckpt' in args.model_name_or_path),
                                            config=config,
                                            cache_dir=args.cache_dir if args.cache_dir else None)    
    else:
        model = model_class(config)
    if args.model_name == 'codebert':
        model = CodeBERT(model, config, tokenizer, args)
        eval_dataset = CodeBertTextDataset(tokenizer, args, args.eval_data_file)
    elif args.model_name == 'graphcodebert':
        model = GraphCodeBERT(model, config, tokenizer, args)
        eval_dataset = GraphCodeBertTextDataset(tokenizer, args, args.eval_data_file)
    elif args.model_name == 'codet5':
        model = CodeT5(model, config, tokenizer, args)
        eval_dataset = CodeT5TextDataset(tokenizer, args, args.eval_data_file)

    checkpoint_prefix = 'checkpoint-best-acc/%s_model.bin' % args.model_name
    output_dir = os.path.join(args.output_dir, '{}'.format(checkpoint_prefix))
    if os.path.exists(output_dir):
        model.load_state_dict(torch.load(output_dir))
    model.to(args.device)

    codebert_mlm = RobertaForMaskedLM.from_pretrained(args.base_model)
    codebert_mlm.to(args.device)
    tokenizer_mlm = RobertaTokenizer.from_pretrained(args.base_model)
    fasttext_model = fasttext.load_model('./saved_models/fasttext_model.bin')

    source_codes = []   
    generated_substitutions = []
    with open(args.eval_data_file) as f:
        for line in f:
            js=json.loads(line.strip())
            # code = ' '.join(js['func'].split())
            code = js['func']
            source_codes.append(code)
            generated_substitutions.append(js['substitutes'])
    assert(len(source_codes) == len(eval_dataset) == len(generated_substitutions))
    print(len(eval_dataset), len(source_codes))

    # attacker = Attacker(args, model, tokenizer, tokenizer_mlm, codebert_mlm, fasttext_model, generated_substitutions)
    # TODO pop_size待确定
    attacker = PSOAttack(args, model, tokenizer, tokenizer_mlm, codebert_mlm, fasttext_model, generated_substitutions, 20, 20)
    # attacker = PSOAttack(args, model, tokenizer, tokenizer_mlm, codebert_mlm, fasttext_model, generated_substitutions)

    # source_codes = []
    # with open(args.eval_data_file) as f:
    #     for line in f:
    #         js = json.loads(line.strip())
    #         code = js['func']
    #         source_codes.append(code)
    #         generated_substitutions.append(js['substitutes'])
    # print(len(eval_dataset), len(source_codes))

    success_attack = 0
    total_cnt = 0
    for index, example in enumerate(eval_dataset):
        # if not index==49:
        #     continue
        code = source_codes[index]
        print("测试: ", index)
        is_success, final_code, min_gap_prob = attacker.attack(
            index,
            example,
            code
        )
        if is_success >= -1:
            total_cnt += 1
            if is_success >= 1:
                success_attack += 1
            if total_cnt == 0:
                continue
            print("Success rate: %.2f%%" % ((1.0 * success_attack / total_cnt) * 100))
            print("Successful items count: ", success_attack)
            print("Total count: ", total_cnt)
            print("Index: ", index)
            print()
        else:
            print("Attack failed! return code: ", is_success)
    
        
if __name__ == '__main__':
    main()
    """
    CUDA_VISIBLE_DEVICES=0 python test.py --eval_data_file=../dataset/test_subs_0_400.jsonl --model_name=codebert --seed=12345 2>&1 | tee psoTest.log
    CUDA_VISIBLE_DEVICES=0 python test.py --eval_data_file=../dataset/test_subs_0_400.jsonl --model_name=codebert --seed=12345 2>&1 | tee psoTest_outofindex.log
    CUDA_VISIBLE_DEVICES=0 python test.py --eval_data_file=../dataset/test_subs_0_400.jsonl --model_name=codebert --seed=12345 2>&1 | tee psoTest_changestructure.log
    """