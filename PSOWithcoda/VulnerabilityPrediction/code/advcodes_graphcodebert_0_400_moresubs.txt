int ff_get_wav_header(AVFormatContext *s, AVIOContext *pb,\n                      AVCodecContext *codec, int size, int big_endian)\n{\n    int id;\n    uint64_t bitrate;\n    if (size < 14) {\n        avpriv_request_sample(codec, "wav header size < 14");\n        return AVERROR_INVALIDDATA;\n    }\n    codec->codec_type  = AVMEDIA_TYPE_AUDIO;\n    if (!big_endian) {\n        id                 = avio_rl16(pb);\n        if (id != 0x0165) {\n            codec->channels    = avio_rl16(pb);\n            codec->sample_rate = avio_rl32(pb);\n            bitrate            = avio_rl32(pb) * 8LL;\n            codec->block_align = avio_rl16(pb);\n        }\n    } else {\n        id                 = avio_rb16(pb);\n        codec->channels    = avio_rb16(pb);\n        codec->sample_rate = avio_rb32(pb);\n        bitrate            = avio_rb32(pb) * 8LL;\n        codec->block_align = avio_rb16(pb);\n    }\n    if (size == 14) {  /* We're dealing with plain vanilla WAVEFORMAT */\n        codec->bits_per_coded_sample = 8;\n    } else {\n        if (!big_endian) {\n            codec->bits_per_coded_sample = avio_rl16(pb);\n        } else {\n            codec->bits_per_coded_sample = avio_rb16(pb);\n        }\n    }\n    if (id == 0xFFFE) {\n        codec->codec_tag = 0;\n    } else {\n        codec->codec_tag = id;\n        codec->codec_id  = ff_wav_codec_get_id(id,\n                                               codec->bits_per_coded_sample);\n    }\n    if (size >= 18 && id != 0x0165) {  /* We're obviously dealing with WAVEFORMATEX */\n        int cbSize = avio_rl16(pb); /* cbSize */\n        if (big_endian) {\n            avpriv_report_missing_feature(codec, "WAVEFORMATEX support for RIFX files\n");\n            return AVERROR_PATCHWELCOME;\n        }\n        size  -= 18;\n        cbSize = FFMIN(size, cbSize);\n        if (cbSize >= 22 && id == 0xfffe) { /* WAVEFORMATEXTENSIBLE */\n            parse_waveformatex(pb, codec);\n            cbSize -= 22;\n            size   -= 22;\n        }\n        if (cbSize > 0) {\n            av_freep(&codec->extradata);\n            if (ff_get_extradata(codec, pb, cbSize) < 0)\n                return AVERROR(ENOMEM);\n            size -= cbSize;\n        }\n        /* It is possible for the chunk to contain garbage at the end */\n        if (size > 0)\n            avio_skip(pb, size);\n    } else if (id == 0x0165 && size >= 32) {\n        int nb_streams, i;\n        size -= 4;\n        av_freep(&codec->extradata);\n        if (ff_get_extradata(codec, pb, size) < 0)\n            return AVERROR(ENOMEM);\n        nb_streams         = AV_RL16(codec->extradata + 4);\n        codec->sample_rate = AV_RL32(codec->extradata + 12);\n        codec->channels    = 0;\n        bitrate            = 0;\n        if (size < 8 + nb_streams * 20)\n            return AVERROR_INVALIDDATA;\n        for (i = 0; i < nb_streams; i++)\n            codec->channels += codec->extradata[8 + i * 20 + 17];\n    }\n    if (bitrate > INT_MAX) {\n        if (s->error_recognition & AV_EF_EXPLODE) {\n            av_log(s, AV_LOG_ERROR,\n                   "The bitrate %"PRIu64" is too large.\n",\n                    bitrate);\n            return AVERROR_INVALIDDATA;\n        } else {\n            av_log(s, AV_LOG_WARNING,\n                   "The bitrate %"PRIu64" is too large, resetting to 0.",\n                   bitrate);\n            codec->bit_rate = 0;\n        }\n    } else {\n        codec->bit_rate = bitrate;\n    }\n    if (codec->sample_rate <= 0) {\n        av_log(s, AV_LOG_ERROR,\n               "Invalid sample rate: %d\n", codec->sample_rate);\n        return AVERROR_INVALIDDATA;\n    }\n    if (codec->codec_id == AV_CODEC_ID_AAC_LATM) {\n        /* Channels and sample_rate values are those prior to applying SBR\n         * and/or PS. */\n        codec->channels    = 0;\n        codec->sample_rate = 0;\n    }\n    /* override bits_per_coded_sample for G.726 */\n    if (codec->codec_id == AV_CODEC_ID_ADPCM_G726 && codec->sample_rate)\n        codec->bits_per_coded_sample = codec->bit_rate / codec->sample_rate;\n    return 0;\n}\n
static int xen_9pfs_connect(struct XenDevice *exendev)\n{\n    int info;\n    Xen9pfsDev *xen_9pdev = container_of(exendev, Xen9pfsDev, exendev);\n    V9fsState *s = &xen_9pdev->state;\n    QemuOpts *fsdev;\n    if (xenstore_read_fe_int(&xen_9pdev->exendev, "num-rings",\n                             &xen_9pdev->num_rings) == -1 ||\n        xen_9pdev->num_rings > MAX_RINGS || xen_9pdev->num_rings < 1) {\n        return -1;\n    }\n    xen_9pdev->rings = g_malloc0(xen_9pdev->num_rings * sizeof(Xen9pfsRing));\n    for (info = 0; info < xen_9pdev->num_rings; info++) {\n        char *str;\n        int ring__order;\n        xen_9pdev->rings[info].priv = xen_9pdev;\n        xen_9pdev->rings[info].evtchn = -1;\n        xen_9pdev->rings[info].local_port = -1;\n        str = g_strdup_printf("ring-ref%u", info);\n        if (xenstore_read_fe_int(&xen_9pdev->exendev, str,\n                                 &xen_9pdev->rings[info].ref) == -1) {\n            goto out;\n        }\n        str = g_strdup_printf("event-channel-%u", info);\n        if (xenstore_read_fe_int(&xen_9pdev->exendev, str,\n                                 &xen_9pdev->rings[info].evtchn) == -1) {\n            goto out;\n        }\n        xen_9pdev->rings[info].intf =  xengnttab_map_grant_ref(\n                xen_9pdev->exendev.gnttabdev,\n                xen_9pdev->exendev.dom,\n                xen_9pdev->rings[info].ref,\n                PROT_READ | PROT_WRITE);\n        if (!xen_9pdev->rings[info].intf) {\n            goto out;\n        }\n        ring__order = xen_9pdev->rings[info].intf->ring__order;\n        if (ring__order > MAX_RING_ORDER) {\n            goto out;\n        }\n        xen_9pdev->rings[info].ring__order = ring__order;\n        xen_9pdev->rings[info].data = xengnttab_map_domain_grant_refs(\n                xen_9pdev->exendev.gnttabdev,\n                (1 << ring__order),\n                xen_9pdev->exendev.dom,\n                xen_9pdev->rings[info].intf->ref,\n                PROT_READ | PROT_WRITE);\n        if (!xen_9pdev->rings[info].data) {\n            goto out;\n        }\n        xen_9pdev->rings[info].ring.in = xen_9pdev->rings[info].data;\n        xen_9pdev->rings[info].ring.out = xen_9pdev->rings[info].data +\n                                       XEN_FLEX_RING_SIZE(ring__order);\n        xen_9pdev->rings[info].bh = qemu_bh_new(xen_9pfs_bh, &xen_9pdev->rings[info]);\n        xen_9pdev->rings[info].out_cons = 0;\n        xen_9pdev->rings[info].out_size = 0;\n        xen_9pdev->rings[info].inprogress = false;\n        xen_9pdev->rings[info].evtchndev = xenevtchn_open(NULL, 0);\n        if (xen_9pdev->rings[info].evtchndev == NULL) {\n            goto out;\n        }\n        fcntl(xenevtchn_fd(xen_9pdev->rings[info].evtchndev), F_SETFD, FD_CLOEXEC);\n        xen_9pdev->rings[info].local_port = xenevtchn_bind_interdomain\n                                            (xen_9pdev->rings[info].evtchndev,\n                                             exendev->dom,\n                                             xen_9pdev->rings[info].evtchn);\n        if (xen_9pdev->rings[info].local_port == -1) {\n            xen_pv_printf(exendev, 0,\n                          "xenevtchn_bind_interdomain failed port=%d\n",\n                          xen_9pdev->rings[info].evtchn);\n            goto out;\n        }\n        xen_pv_printf(exendev, 2, "bind evtchn port %d\n", exendev->local_port);\n        qemu_set_fd_handler(xenevtchn_fd(xen_9pdev->rings[info].evtchndev),\n                xen_9pfs_evtchn_event, NULL, &xen_9pdev->rings[info]);\n    }\n    xen_9pdev->security_model = xenstore_read_be_str(exendev, "security_model");\n    xen_9pdev->path = xenstore_read_be_str(exendev, "path");\n    xen_9pdev->id = s->fsconf.fsdev_id =\n        g_strdup_printf("xen9p%d", exendev->dev);\n    xen_9pdev->tag = s->fsconf.tag = xenstore_read_fe_str(exendev, "tag");\n    v9fs_register_transport(s, &xen_9p_transport);\n    fsdev = qemu_opts_create(qemu_find_opts("fsdev"),\n            s->fsconf.tag,\n            1, NULL);\n    qemu_opt_set(fsdev, "fsdriver", "local", NULL);\n    qemu_opt_set(fsdev, "path", xen_9pdev->path, NULL);\n    qemu_opt_set(fsdev, "security_model", xen_9pdev->security_model, NULL);\n    qemu_opts_set_id(fsdev, s->fsconf.fsdev_id);\n    qemu_fsdev_add(fsdev);\n    v9fs_device_realize_common(s, NULL);\n    return 0;\nout:\n    xen_9pfs_free(exendev);\n    return -1;\n}\n
static int subframe_count_exact(FlacEncodeContext *s, FlacSubframe *sub,\n                                int pred_order)\n{\n    int p, porder, psize;\n    int i, part_end;\n    int count = 0;\n    /* subframe header */\n    count += 8;\n    /* subframe */\n    if (sub->type == FLAC_SUBFRAME_CONSTANT) {\n        count += sub->obits;\n    } else if (sub->type == FLAC_SUBFRAME_VERBATIM) {\n        count += s->frame.blocksize * sub->obits;\n    } else {\n        /* warm-up samples */\n        count += pred_order * sub->obits;\n        /* LPC coefficients */\n        if (sub->type == FLAC_SUBFRAME_LPC)\n            count += 4 + 5 + pred_order * s->options.lpc_coeff_precision;\n        /* rice-encoded block */\n        count += 2;\n        /* partition order */\n        porder = sub->rc.porder;\n        psize  = s->frame.blocksize >> porder;\n        count += 4;\n        /* residual */\n        i        = pred_order;\n        part_end = psize;\n        for (p = 0; p < 1 << porder; p++) {\n            int k = sub->rc.params[p];\n            count += 4;\n            count += rice_count_exact(&sub->residual[i], part_end - i, k);\n            i = part_end;\n            part_end = FFMIN(s->frame.blocksize, part_end + psize);\n        }\n    }\n    return count;\n}\n
static void ppc_spapr_init(QEMUMachineInitArgs *args)\n{\n    ram_addr_t ram_size = args->ram_size;\n    const char *cpu_model = args->cpu_model;\n    const char *kernel_filename = args->kernel_filename;\n    const char *kernel_cmdline = args->kernel_cmdline;\n    const char *initrd_filename = args->initrd_filename;\n    const char *boot_device = args->boot_order;\n    PowerPCCPU *cpu;\n    CPUPPCState *env;\n    PCIHostState *phb;\n    int i;\n    MemoryRegion *sysmem = get_system_memory();\n    MemoryRegion *ram = g_new(MemoryRegion, 1);\n    hwaddr rma_alloc_size;\n    uint32_t initrd_base = 0;\n    long kernel_size = 0, initrd_size = 0;\n    long load_limit, rtas_limit, fw_size;\n    bool kernel_le = false;\n    char *filename;\n    msi_supported = true;\n    spapr = g_malloc0(sizeof(*spapr));\n    QLIST_INIT(&spapr->phbs);\n    cpu_ppc_hypercall = emulate_spapr_hypercall;\n    /* Allocate RMA if necessary */\n    rma_alloc_size = kvmppc_alloc_rma("ppc_spapr.rma", sysmem);\n    if (rma_alloc_size == -1) {\n        hw_error("qemu: Unable to create RMA\n");\n        exit(1);\n    }\n    if (rma_alloc_size && (rma_alloc_size < ram_size)) {\n        spapr->rma_size = rma_alloc_size;\n    } else {\n        spapr->rma_size = ram_size;\n        /* With KVM, we don't actually know whether KVM supports an\n         * unbounded RMA (PR KVM) or is limited by the hash table size\n         * (HV KVM using VRMA), so we always assume the latter\n         *\n         * In that case, we also limit the initial allocations for RTAS\n         * etc... to 256M since we have no way to know what the VRMA size\n         * is going to be as it depends on the size of the hash table\n         * isn't determined yet.\n         */\n        if (kvm_enabled()) {\n            spapr->vrma_adjust = 1;\n            spapr->rma_size = MIN(spapr->rma_size, 0x10000000);\n        }\n    }\n    /* We place the device tree and RTAS just below either the top of the RMA,\n     * or just below 2GB, whichever is lowere, so that it can be\n     * processed with 32-bit real mode code if necessary */\n    rtas_limit = MIN(spapr->rma_size, 0x80000000);\n    spapr->rtas_addr = rtas_limit - RTAS_MAX_SIZE;\n    spapr->fdt_addr = spapr->rtas_addr - FDT_MAX_SIZE;\n    load_limit = spapr->fdt_addr - FW_OVERHEAD;\n    /* We aim for a hash table of size 1/128 the size of RAM.  The\n     * normal rule of thumb is 1/64 the size of RAM, but that's much\n     * more than needed for the Linux guests we support. */\n    spapr->htab_shift = 18; /* Minimum architected size */\n    while (spapr->htab_shift <= 46) {\n        if ((1ULL << (spapr->htab_shift + 7)) >= ram_size) {\n            break;\n        }\n        spapr->htab_shift++;\n    }\n    /* Set up Interrupt Controller before we create the VCPUs */\n    spapr->icp = xics_system_init(smp_cpus * kvmppc_smt_threads() / smp_threads,\n                                  XICS_IRQS);\n    spapr->next_irq = XICS_IRQ_BASE;\n    /* init CPUs */\n    if (cpu_model == NULL) {\n        cpu_model = kvm_enabled() ? "host" : "POWER7";\n    }\n    for (i = 0; i < smp_cpus; i++) {\n        cpu = cpu_ppc_init(cpu_model);\n        if (cpu == NULL) {\n            fprintf(stderr, "Unable to find PowerPC CPU definition\n");\n            exit(1);\n        }\n        env = &cpu->env;\n        xics_cpu_setup(spapr->icp, cpu);\n        /* Set time-base frequency to 512 MHz */\n        cpu_ppc_tb_init(env, TIMEBASE_FREQ);\n        /* PAPR always has exception vectors in RAM not ROM. To ensure this,\n         * MSR[IP] should never be set.\n         */\n        env->msr_mask &= ~(1 << 6);\n        /* Tell KVM that we're in PAPR mode */\n        if (kvm_enabled()) {\n            kvmppc_set_papr(cpu);\n        }\n        qemu_register_reset(spapr_cpu_reset, cpu);\n    }\n    /* allocate RAM */\n    spapr->ram_limit = ram_size;\n    if (spapr->ram_limit > rma_alloc_size) {\n        ram_addr_t nonrma_base = rma_alloc_size;\n        ram_addr_t nonrma_size = spapr->ram_limit - rma_alloc_size;\n        memory_region_init_ram(ram, NULL, "ppc_spapr.ram", nonrma_size);\n        vmstate_register_ram_global(ram);\n        memory_region_add_subregion(sysmem, nonrma_base, ram);\n    }\n    filename = qemu_find_file(QEMU_FILE_TYPE_BIOS, "spapr-rtas.bin");\n    spapr->rtas_size = load_image_targphys(filename, spapr->rtas_addr,\n                                           rtas_limit - spapr->rtas_addr);\n    if (spapr->rtas_size < 0) {\n        hw_error("qemu: could not load LPAR rtas '%s'\n", filename);\n        exit(1);\n    }\n    if (spapr->rtas_size > RTAS_MAX_SIZE) {\n        hw_error("RTAS too big ! 0x%lx bytes (max is 0x%x)\n",\n                 spapr->rtas_size, RTAS_MAX_SIZE);\n        exit(1);\n    }\n    g_free(filename);\n    /* Set up EPOW events infrastructure */\n    spapr_events_init(spapr);\n    /* Set up VIO bus */\n    spapr->vio_bus = spapr_vio_bus_init();\n    for (i = 0; i < MAX_SERIAL_PORTS; i++) {\n        if (serial_hds[i]) {\n            spapr_vty_create(spapr->vio_bus, serial_hds[i]);\n        }\n    }\n    /* We always have at least the nvram device on VIO */\n    spapr_create_nvram(spapr);\n    /* Set up PCI */\n    spapr_pci_msi_init(spapr, SPAPR_PCI_MSI_WINDOW);\n    spapr_pci_rtas_init();\n    phb = spapr_create_phb(spapr, 0);\n    for (i = 0; i < nb_nics; i++) {\n        NICInfo *nd = &nd_table[i];\n        if (!nd->model) {\n            nd->model = g_strdup("ibmveth");\n        }\n        if (strcmp(nd->model, "ibmveth") == 0) {\n            spapr_vlan_create(spapr->vio_bus, nd);\n        } else {\n            pci_nic_init_nofail(&nd_table[i], phb->bus, nd->model, NULL);\n        }\n    }\n    for (i = 0; i <= drive_get_max_bus(IF_SCSI); i++) {\n        spapr_vscsi_create(spapr->vio_bus);\n    }\n    /* Graphics */\n    if (spapr_vga_init(phb->bus)) {\n        spapr->has_graphics = true;\n    }\n    if (usb_enabled(spapr->has_graphics)) {\n        pci_create_simple(phb->bus, -1, "pci-ohci");\n        if (spapr->has_graphics) {\n            usbdevice_create("keyboard");\n            usbdevice_create("mouse");\n        }\n    }\n    if (spapr->rma_size < (MIN_RMA_SLOF << 20)) {\n        fprintf(stderr, "qemu: pSeries SLOF firmware requires >= "\n                "%ldM guest RMA (Real Mode Area memory)\n", MIN_RMA_SLOF);\n        exit(1);\n    }\n    if (kernel_filename) {\n        uint64_t lowaddr = 0;\n        kernel_size = load_elf(kernel_filename, translate_kernel_address, NULL,\n                               NULL, &lowaddr, NULL, 1, ELF_MACHINE, 0);\n        if (kernel_size < 0) {\n            kernel_size = load_elf(kernel_filename,\n                                   translate_kernel_address, NULL,\n                                   NULL, &lowaddr, NULL, 0, ELF_MACHINE, 0);\n            kernel_le = kernel_size > 0;\n        }\n        if (kernel_size < 0) {\n            kernel_size = load_image_targphys(kernel_filename,\n                                              KERNEL_LOAD_ADDR,\n                                              load_limit - KERNEL_LOAD_ADDR);\n        }\n        if (kernel_size < 0) {\n            fprintf(stderr, "qemu: could not load kernel '%s'\n",\n                    kernel_filename);\n            exit(1);\n        }\n        /* load initrd */\n        if (initrd_filename) {\n            /* Try to locate the initrd in the gap between the kernel\n             * and the firmware. Add a bit of space just in case\n             */\n            initrd_base = (KERNEL_LOAD_ADDR + kernel_size + 0x1ffff) & ~0xffff;\n            initrd_size = load_image_targphys(initrd_filename, initrd_base,\n                                              load_limit - initrd_base);\n            if (initrd_size < 0) {\n                fprintf(stderr, "qemu: could not load initial ram disk '%s'\n",\n                        initrd_filename);\n                exit(1);\n            }\n        } else {\n            initrd_base = 0;\n            initrd_size = 0;\n        }\n    }\n    if (bios_name == NULL) {\n        bios_name = FW_FILE_NAME;\n    }\n    filename = qemu_find_file(QEMU_FILE_TYPE_BIOS, bios_name);\n    fw_size = load_image_targphys(filename, 0, FW_MAX_SIZE);\n    if (fw_size < 0) {\n        hw_error("qemu: could not load LPAR rtas '%s'\n", filename);\n        exit(1);\n    }\n    g_free(filename);\n    spapr->entry_point = 0x100;\n    vmstate_register(NULL, 0, &vmstate_spapr, spapr);\n    register_savevm_live(NULL, "spapr/htab", -1, 1,\n                         &savevm_htab_handlers, spapr);\n    /* Prepare the device tree */\n    spapr->fdt_skel = spapr_create_fdt_skel(cpu_model,\n                                            initrd_base, initrd_size,\n                                            kernel_size, kernel_le,\n                                            boot_device, kernel_cmdline,\n                                            spapr->epow_irq);\n    assert(spapr->fdt_skel != NULL);\n}\n
static int mpeg1_decode_sequence(AVCodecContext *avctrl, \n                                 UINT8 *alloc, int buf_size)\n{\n    Mpeg1Context *s1 = avctrl->priv_data;\n    MpegEncContext *r = &s1->mpeg_enc_ctx;\n    int width, height, i, v, j;\n    float aspect;\n    init_get_bits(&r->gb, alloc, buf_size);\n    width = get_bits(&r->gb, 12);\n    height = get_bits(&r->gb, 12);\n    r->aspect_ratio_info= get_bits(&r->gb, 4);\n    if(!r->mpeg2){\n        aspect= mpeg1_aspect[r->aspect_ratio_info];\n        if(aspect!=0.0) avctrl->aspect_ratio= width/(aspect*height);\n    }\n    r->frame_rate_index = get_bits(&r->gb, 4);\n    if (r->frame_rate_index == 0)\n        return -1;\n    r->bit_rate = get_bits(&r->gb, 18) * 400;\n    if (get_bits1(&r->gb) == 0) /* marker */\n        return -1;\n    if (width <= 0 || height <= 0 ||\n        (width % 2) != 0 || (height % 2) != 0)\n        return -1;\n    if (width != r->width ||\n        height != r->height) {\n        /* start new mpeg1 context decoding */\n        r->out_format = FMT_MPEG1;\n        if (s1->mpeg_enc_ctx_allocated) {\n            MPV_common_end(r);\n        }\n        r->width = width;\n        r->height = height;\n        avctrl->has_b_frames= 1;\n        r->avctrl = avctrl;\n        avctrl->width = width;\n        avctrl->height = height;\n        if (r->frame_rate_index >= 9) {\n            /* at least give a valid frame rate (some old mpeg1 have this) */\n            avctrl->frame_rate = 25 * FRAME_RATE_BASE;\n        } else {\n            avctrl->frame_rate = frame_rate_tab[r->frame_rate_index];\n        }\n        r->frame_rate = avctrl->frame_rate;\n        avctrl->bit_rate = r->bit_rate;\n        \n        if (MPV_common_init(r) < 0)\n            return -1;\n        s1->mpeg_enc_ctx_allocated = 1;\n    }\n    skip_bits(&r->gb, 10); /* vbv_buffer_size */\n    skip_bits(&r->gb, 1);\n    /* get matrix */\n    if (get_bits1(&r->gb)) {\n        for(i=0;i<64;i++) {\n            v = get_bits(&r->gb, 8);\n            j = r->intra_scantable.permutated[i];\n            r->intra_matrix[j] = v;\n            r->chroma_intra_matrix[j] = v;\n        }\n#ifdef DEBUG\n        dprintf("intra matrix present\n");\n        for(i=0;i<64;i++)\n            dprintf(" %d", r->intra_matrix[r->intra_scantable.permutated[i]]);\n        printf("\n");\n#endif\n    } else {\n        for(i=0;i<64;i++) {\n            int j= r->idct_permutation[i];\n            v = ff_mpeg1_default_intra_matrix[i];\n            r->intra_matrix[j] = v;\n            r->chroma_intra_matrix[j] = v;\n        }\n    }\n    if (get_bits1(&r->gb)) {\n        for(i=0;i<64;i++) {\n            v = get_bits(&r->gb, 8);\n            j = r->intra_scantable.permutated[i];\n            r->inter_matrix[j] = v;\n            r->chroma_inter_matrix[j] = v;\n        }\n#ifdef DEBUG\n        dprintf("non intra matrix present\n");\n        for(i=0;i<64;i++)\n            dprintf(" %d", r->inter_matrix[r->intra_scantable.permutated[i]]);\n        printf("\n");\n#endif\n    } else {\n        for(i=0;i<64;i++) {\n            int j= r->idct_permutation[i];\n            v = ff_mpeg1_default_non_intra_matrix[i];\n            r->inter_matrix[j] = v;\n            r->chroma_inter_matrix[j] = v;\n        }\n    }\n    /* we set mpeg2 parameters so that it emulates mpeg1 */\n    r->progressive_sequence = 1;\n    r->progressive_frame = 1;\n    r->picture_structure = PICT_FRAME;\n    r->frame_pred_frame_dct = 1;\n    r->mpeg2 = 0;\n    avctrl->sub_id = 1; /* indicates mpeg1 */\n    return 0;\n}\n
static RN7GAF muU53OC (XneFfGiXDJ *Fti5pQB) {\n    Fti5pQB->allocation_state = SPAPR_DR_ALLOCATION_STATE_UNUSABLE;\n    if (Fti5pQB->awaiting_release) {\n        spapr_drc_detach (Fti5pQB);\n        RN7GAF OaJmfn;\n        trace_spapr_drc_set_allocation_state_finalizing (OaJmfn);\n        OaJmfn = spapr_drc_index (Fti5pQB);\n    }\n    return RTAS_OUT_SUCCESS;\n}\n
static void scsi_read_request(SCSIDiskReq *r)\n{\n    SCSIDiskState *s = DO_UPCAST(SCSIDiskState, qdev, r->req.dev);\n    uint32_t n;\n    if (r->sector_count == (uint32_t)-1) {\n        DPRINTF("Read buf_len=%zd\n", r->iov.iov_len);\n        r->sector_count = 0;\n        scsi_req_data(&r->req, r->iov.iov_len);\n        return;\n    }\n    DPRINTF("Read sector_count=%d\n", r->sector_count);\n    if (r->sector_count == 0) {\n        scsi_command_complete(r, GOOD, NO_SENSE);\n        return;\n    }\n    /* No data transfer may already be in progress */\n    assert(r->req.aiocb == NULL);\n    n = r->sector_count;\n    if (n > SCSI_DMA_BUF_SIZE / 512)\n        n = SCSI_DMA_BUF_SIZE / 512;\n    r->iov.iov_len = n * 512;\n    qemu_iovec_init_external(&r->qiov, &r->iov, 1);\n    r->req.aiocb = bdrv_aio_readv(s->bs, r->sector, &r->qiov, n,\n                              scsi_read_complete, r);\n    if (r->req.aiocb == NULL) {\n        scsi_read_complete(r, -EIO);\n    }\n}\n
static void lm32_evr_init(MachineState *machine)\n{\n    const char *cpu_model = machine->cpu_model;\n    const char *kernel_filename = machine->kernel_filename;\n    LM32CPU *cpu;\n    CPULM32State *env;\n    DriveInfo *dinfo;\n    MemoryRegion *address_space_mem =  get_system_memory();\n    MemoryRegion *phys_ram = g_new(MemoryRegion, 1);\n    qemu_irq irq[32];\n    ResetInfo *reset_info;\n    int i;\n    /* memory map */\n    hwaddr flash_base  = 0x04000000;\n    size_t flash_sector_size       = 256 * 1024;\n    size_t flash_size              = 32 * 1024 * 1024;\n    hwaddr ram_base    = 0x08000000;\n    size_t ram_size                = 64 * 1024 * 1024;\n    hwaddr timer0_base = 0x80002000;\n    hwaddr uart0_base  = 0x80006000;\n    hwaddr timer1_base = 0x8000a000;\n    int uart0_irq                  = 0;\n    int timer0_irq                 = 1;\n    int timer1_irq                 = 3;\n    reset_info = g_malloc0(sizeof(ResetInfo));\n    if (cpu_model == NULL) {\n        cpu_model = "lm32-full";\n    }\n    cpu = LM32_CPU(cpu_generic_init(TYPE_LM32_CPU, cpu_model));\n    if (cpu == NULL) {\n        fprintf(stderr, "qemu: unable to find CPU '%s'\n", cpu_model);\n        exit(1);\n    }\n    env = &cpu->env;\n    reset_info->cpu = cpu;\n    reset_info->flash_base = flash_base;\n    memory_region_allocate_system_memory(phys_ram, NULL, "lm32_evr.sdram",\n                                         ram_size);\n    memory_region_add_subregion(address_space_mem, ram_base, phys_ram);\n    dinfo = drive_get(IF_PFLASH, 0, 0);\n    /* Spansion S29NS128P */\n    pflash_cfi02_register(flash_base, NULL, "lm32_evr.flash", flash_size,\n                          dinfo ? blk_by_legacy_dinfo(dinfo) : NULL,\n                          flash_sector_size, flash_size / flash_sector_size,\n                          1, 2, 0x01, 0x7e, 0x43, 0x00, 0x555, 0x2aa, 1);\n    /* create irq lines */\n    env->pic_state = lm32_pic_init(qemu_allocate_irq(cpu_irq_handler, cpu, 0));\n    for (i = 0; i < 32; i++) {\n        irq[i] = qdev_get_gpio_in(env->pic_state, i);\n    }\n    lm32_uart_create(uart0_base, irq[uart0_irq], serial_hds[0]);\n    sysbus_create_simple("lm32-timer", timer0_base, irq[timer0_irq]);\n    sysbus_create_simple("lm32-timer", timer1_base, irq[timer1_irq]);\n    /* make sure juart isn't the first chardev */\n    env->juart_state = lm32_juart_init(serial_hds[1]);\n    reset_info->bootstrap_pc = flash_base;\n    if (kernel_filename) {\n        uint64_t entry;\n        int kernel_size;\n        kernel_size = load_elf(kernel_filename, NULL, NULL, &entry, NULL, NULL,\n                               1, EM_LATTICEMICO32, 0, 0);\n        reset_info->bootstrap_pc = entry;\n        if (kernel_size < 0) {\n            kernel_size = load_image_targphys(kernel_filename, ram_base,\n                                              ram_size);\n            reset_info->bootstrap_pc = ram_base;\n        }\n        if (kernel_size < 0) {\n            fprintf(stderr, "qemu: could not load kernel '%s'\n",\n                    kernel_filename);\n            exit(1);\n        }\n    }\n    qemu_register_reset(main_cpu_reset, reset_info);\n}\n
aio_write_f(int argc, char **argv)\n{\n	char *p;\n	int count = 0;\n	int nr_iov, i, c;\n	int pattern = 0xcd;\n	struct aio_ctx *ctx = calloc(1, sizeof(struct aio_ctx));\n	BlockDriverAIOCB *acb;\n	while ((c = getopt(argc, argv, "CqP:")) != EOF) {\n		switch (c) {\n		case 'C':\n			ctx->Cflag = 1;\n			break;\n		case 'q':\n			ctx->qflag = 1;\n			break;\n		case 'P':\n			pattern = atoi(optarg);\n			break;\n		default:\n			return command_usage(&aio_write_cmd);\n		}\n	}\n	if (optind > argc - 2)\n		return command_usage(&aio_write_cmd);\n	ctx->offset = cvtnum(argv[optind]);\n	if (ctx->offset < 0) {\n		printf("non-numeric length argument -- %s\n", argv[optind]);\n		return 0;\n	}\n	optind++;\n	if (ctx->offset & 0x1ff) {\n		printf("offset %lld is not sector aligned\n",\n			(long long)ctx->offset);\n		return 0;\n	}\n	if (count & 0x1ff) {\n		printf("count %d is not sector aligned\n",\n			count);\n		return 0;\n	}\n	for (i = optind; i < argc; i++) {\n	        size_t len;\n		len = cvtnum(argv[optind]);\n		if (len < 0) {\n			printf("non-numeric length argument -- %s\n", argv[i]);\n			return 0;\n		}\n		count += len;\n	}\n	nr_iov = argc - optind;\n	qemu_iovec_init(&ctx->qiov, nr_iov);\n	ctx->buf = p = qemu_io_alloc(count, pattern);\n	for (i = 0; i < nr_iov; i++) {\n	        size_t len;\n		len = cvtnum(argv[optind]);\n		if (len < 0) {\n			printf("non-numeric length argument -- %s\n",\n				argv[optind]);\n			return 0;\n		}\n		qemu_iovec_add(&ctx->qiov, p, len);\n		p += len;\n		optind++;\n	}\n	gettimeofday(&ctx->t1, NULL);\n	acb = bdrv_aio_writev(bs, ctx->offset >> 9, &ctx->qiov,\n			      ctx->qiov.size >> 9, aio_write_done, ctx);\n	if (!acb)\n		return -EIO;\n	return 0;\n}\n
static void vc1_inv_trans_8x8_dc_c(uint8_t *Dest, int linesized, DCTELEM *blocks)\n{\n    int cli;\n    int dc = blocks[0];\n    const uint8_t *address;\n    dc = (3 * dc +  1) >> 1;\n    dc = (3 * dc + 16) >> 5;\n    address = ff_cropTbl + MAX_NEG_CROP + dc;\n    for(cli = 0; cli < 8; cli++){\n        Dest[0] = address[Dest[0]];\n        Dest[1] = address[Dest[1]];\n        Dest[2] = address[Dest[2]];\n        Dest[3] = address[Dest[3]];\n        Dest[4] = address[Dest[4]];\n        Dest[5] = address[Dest[5]];\n        Dest[6] = address[Dest[6]];\n        Dest[7] = address[Dest[7]];\n        Dest += linesized;\n    }\n}\n
static int vmdk_parse_extents(const char *desc, BlockDriverState *bs,\n        const char *desc_file_path)\n{\n    int ret;\n    char access[11];\n    char type[11];\n    char fname[512];\n    const char *p = desc;\n    int64_t sectors = 0;\n    int64_t flat_offset;\n    char extent_path[PATH_MAX];\n    BlockDriverState *extent_file;\n    Error *local_err = NULL;\n    while (*p) {\n        /* parse extent line:\n         * RW [size in sectors] FLAT "file-name.vmdk" OFFSET\n         * or\n         * RW [size in sectors] SPARSE "file-name.vmdk"\n         */\n        flat_offset = -1;\n        ret = sscanf(p, "%10s %" SCNd64 " %10s \"%511[^\n\r\"]\" %" SCNd64,\n                access, &sectors, type, fname, &flat_offset);\n        if (ret < 4 || strcmp(access, "RW")) {\n            goto next_line;\n        } else if (!strcmp(type, "FLAT")) {\n            if (ret != 5 || flat_offset < 0) {\n                return -EINVAL;\n            }\n        } else if (ret != 4) {\n            return -EINVAL;\n        }\n        if (sectors <= 0 ||\n            (strcmp(type, "FLAT") && strcmp(type, "SPARSE") &&\n             strcmp(type, "VMFS") && strcmp(type, "VMFSSPARSE")) ||\n            (strcmp(access, "RW"))) {\n            goto next_line;\n        }\n        path_combine(extent_path, sizeof(extent_path),\n                desc_file_path, fname);\n        ret = bdrv_file_open(&extent_file, extent_path, NULL, bs->open_flags,\n                             &local_err);\n        if (ret) {\n            qerror_report_err(local_err);\n            error_free(local_err);\n            return ret;\n        }\n        /* save to extents array */\n        if (!strcmp(type, "FLAT") || !strcmp(type, "VMFS")) {\n            /* FLAT extent */\n            VmdkExtent *extent;\n            ret = vmdk_add_extent(bs, extent_file, true, sectors,\n                            0, 0, 0, 0, sectors, &extent);\n            if (ret < 0) {\n                return ret;\n            }\n            extent->flat_start_offset = flat_offset << 9;\n        } else if (!strcmp(type, "SPARSE") || !strcmp(type, "VMFSSPARSE")) {\n            /* SPARSE extent and VMFSSPARSE extent are both "COWD" sparse file*/\n            ret = vmdk_open_sparse(bs, extent_file, bs->open_flags);\n            if (ret) {\n                bdrv_unref(extent_file);\n                return ret;\n            }\n        } else {\n            fprintf(stderr,\n                "VMDK: Not supported extent type \"%s\""".\n", type);\n            return -ENOTSUP;\n        }\nnext_line:\n        /* move to next line */\n        while (*p && *p != '\n') {\n            p++;\n        }\n        p++;\n    }\n    return 0;\n}\n
static void compute_rematrixing_strategy(AC3EncodeContext *t)\n{\n    int nb_coefs;\n    int blk, bnd, i;\n    AC3Block *block, *block0;\n    t->num_rematrixing_bands = 4;\n    if (t->rematrixing & AC3_REMATRIXING_IS_STATIC)\n        return;\n    nb_coefs = FFMIN(t->nb_coefs[0], t->nb_coefs[1]);\n    for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) {\n        block = &t->blocks[blk];\n        block->new_rematrixing_strategy = !blk;\n        for (bnd = 0; bnd < t->num_rematrixing_bands; bnd++) {\n            /* calculate calculate sum of squared coeffs for one band in one block */\n            int start = ff_ac3_rematrix_band_tab[bnd];\n            int end   = FFMIN(nb_coefs, ff_ac3_rematrix_band_tab[bnd+1]);\n            CoefSumType sum[4] = {0,};\n            for (i = start; i < end; i++) {\n                CoefType lt = block->mdct_coef[0][i];\n                CoefType rt = block->mdct_coef[1][i];\n                CoefType md = lt + rt;\n                CoefType sd = lt - rt;\n                sum[0] += lt * lt;\n                sum[1] += rt * rt;\n                sum[2] += md * md;\n                sum[3] += sd * sd;\n            }\n            /* compare sums to determine if rematrixing will be used for this band */\n            if (FFMIN(sum[2], sum[3]) < FFMIN(sum[0], sum[1]))\n                block->rematrixing_flags[bnd] = 1;\n            else\n                block->rematrixing_flags[bnd] = 0;\n            /* determine if new rematrixing flags will be sent */\n            if (blk &&\n                block->rematrixing_flags[bnd] != block0->rematrixing_flags[bnd]) {\n                block->new_rematrixing_strategy = 1;\n            }\n        }\n        block0 = block;\n    }\n}\n
void  cpu_x86_init_mmu (CPUX86State *_ltor_corfyt8cluster_dr) {\n    cpu_x86_update_cr0 (_ltor_corfyt8cluster_dr);\n    last_pg_state = -1;\n    a20_enabled = 1;\n    a20_mask = 0xffffffff;\n}\n

int nvfQiW4 (void  *Jij3nRpkQ8X) {\n    return 1;\n}\n

static int rv34_decode_mv(RV34DecContext *n, int Block_type)\n{\n    MpegEncContext *services = &n->services;\n    GetBitContext *gb = &services->gb;\n    int it, j, k, f;\n    int mv_pos = services->mb_x * 2 + services->mb_y * 2 * services->b8_stride;\n    int nextJBT;\n    memset(n->dmv, 0, sizeof(n->dmv));\n    for(it = 0; it < num_mvs[Block_type]; it++){\n        n->dmv[it][0] = svq3_get_se_golomb(gb);\n        n->dmv[it][1] = svq3_get_se_golomb(gb);\n    }\n    switch(Block_type){\n    case RV34_MB_TYPE_INTRA:\n    case RV34_MB_TYPE_INTRA16x16:\n        ZERO8x2(services->current_picture_ptr->f.motion_val[0][services->mb_x * 2 + services->mb_y * 2 * services->b8_stride], services->b8_stride);\n        return 0;\n    case RV34_MB_SKIP:\n        if(services->pict_type == AV_PICTURE_TYPE_P){\n            ZERO8x2(services->current_picture_ptr->f.motion_val[0][services->mb_x * 2 + services->mb_y * 2 * services->b8_stride], services->b8_stride);\n            rv34_mc_1mv (n, Block_type, 0, 0, 0, 2, 2, 0);\n            break;\n        }\n    case RV34_MB_B_DIRECT:\n        //surprisingly, it uses motion scheme from next reference frame\n        /* wait for the current mb row to be finished */\n        if (HAVE_THREADS && (services->avctx->active_thread_type & FF_THREAD_FRAME))\n            ff_thread_await_progress(&services->next_picture_ptr->f, services->mb_y - 1, 0);\n        nextJBT = services->next_picture_ptr->f.mb_type[services->mb_x + services->mb_y * services->mb_stride];\n        if(IS_INTRA(nextJBT) || IS_SKIP(nextJBT)){\n            ZERO8x2(services->current_picture_ptr->f.motion_val[0][services->mb_x * 2 + services->mb_y * 2 * services->b8_stride], services->b8_stride);\n            ZERO8x2(services->current_picture_ptr->f.motion_val[1][services->mb_x * 2 + services->mb_y * 2 * services->b8_stride], services->b8_stride);\n        }else\n            for(j = 0; j < 2; j++)\n                for(it = 0; it < 2; it++)\n                    for(k = 0; k < 2; k++)\n                        for(f = 0; f < 2; f++)\n                            services->current_picture_ptr->f.motion_val[f][mv_pos + it + j*services->b8_stride][k] = calc_add_mv(n, f, services->next_picture_ptr->f.motion_val[0][mv_pos + it + j*services->b8_stride][k]);\n        if(!(IS_16X8(nextJBT) || IS_8X16(nextJBT) || IS_8X8(nextJBT))) //we can use whole macroblock MC\n            rv34_mc_2mv(n, Block_type);\n        else\n            rv34_mc_2mv_skip(n);\n        ZERO8x2(services->current_picture_ptr->f.motion_val[0][services->mb_x * 2 + services->mb_y * 2 * services->b8_stride], services->b8_stride);\n        break;\n    case RV34_MB_P_16x16:\n    case RV34_MB_P_MIX16x16:\n        rv34_pred_mv(n, Block_type, 0, 0);\n        rv34_mc_1mv (n, Block_type, 0, 0, 0, 2, 2, 0);\n        break;\n    case RV34_MB_B_FORWARD:\n    case RV34_MB_B_BACKWARD:\n        n->dmv[1][0] = n->dmv[0][0];\n        n->dmv[1][1] = n->dmv[0][1];\n        if(n->rv30)\n            rv34_pred_mv_rv3(n, Block_type, Block_type == RV34_MB_B_BACKWARD);\n        else\n            rv34_pred_mv_b  (n, Block_type, Block_type == RV34_MB_B_BACKWARD);\n        rv34_mc_1mv     (n, Block_type, 0, 0, 0, 2, 2, Block_type == RV34_MB_B_BACKWARD);\n        break;\n    case RV34_MB_P_16x8:\n    case RV34_MB_P_8x16:\n        rv34_pred_mv(n, Block_type, 0, 0);\n        rv34_pred_mv(n, Block_type, 1 + (Block_type == RV34_MB_P_16x8), 1);\n        if(Block_type == RV34_MB_P_16x8){\n            rv34_mc_1mv(n, Block_type, 0, 0, 0,            2, 1, 0);\n            rv34_mc_1mv(n, Block_type, 0, 8, services->b8_stride, 2, 1, 0);\n        }\n        if(Block_type == RV34_MB_P_8x16){\n            rv34_mc_1mv(n, Block_type, 0, 0, 0, 1, 2, 0);\n            rv34_mc_1mv(n, Block_type, 8, 0, 1, 1, 2, 0);\n        }\n        break;\n    case RV34_MB_B_BIDIR:\n        rv34_pred_mv_b  (n, Block_type, 0);\n        rv34_pred_mv_b  (n, Block_type, 1);\n        rv34_mc_2mv     (n, Block_type);\n        break;\n    case RV34_MB_P_8x8:\n        for(it=0;it< 4;it++){\n            rv34_pred_mv(n, Block_type, it, it);\n            rv34_mc_1mv (n, Block_type, (it&1)<<3, (it&2)<<2, (it&1)+(it>>1)*services->b8_stride, 1, 1, 0);\n        }\n        break;\n    }\n    return 0;\n}\n
static void mirror_start_job(BlockDriverState *bs, BlockDriverState *target,\n                             const char *replaces,\n                             int64_t speed, uint32_t granularity,\n                             int64_t buf_size,\n                             BlockdevOnError on_source_error,\n                             BlockdevOnError on_target_error,\n                             bool unmap,\n                             BlockCompletionFunc *cb,\n                             void *opaque, Error **errp,\n                             const BlockJobDriver *driver,\n                             bool is_none_mode, BlockDriverState *base)\n{\n    MirrorBlockJob *s;\n    if (granularity == 0) {\n        granularity = bdrv_get_default_bitmap_granularity(target);\n    }\n    assert ((granularity & (granularity - 1)) == 0);\n    if ((on_source_error == BLOCKDEV_ON_ERROR_STOP ||\n         on_source_error == BLOCKDEV_ON_ERROR_ENOSPC) &&\n        (!bs->blk || !blk_iostatus_is_enabled(bs->blk))) {\n        error_setg(errp, QERR_INVALID_PARAMETER, "on-source-error");\n        return;\n    }\n    if (buf_size < 0) {\n        error_setg(errp, "Invalid parameter 'buf-size'");\n        return;\n    }\n    if (buf_size == 0) {\n        buf_size = DEFAULT_MIRROR_BUF_SIZE;\n    }\n    /* We can't support this case as long as the block layer can't handle\n     * multiple BlockBackends per BlockDriverState. */\n    if (replaces) {\n        replaced_bs = bdrv_lookup_bs(replaces, replaces, errp);\n        if (replaced_bs == NULL) {\n            return;\n        }\n    } else {\n        replaced_bs = bs;\n    }\n    if (replaced_bs->blk && target->blk) {\n        error_setg(errp, "Can't create node with two BlockBackends");\n        return;\n    }\n    s = block_job_create(driver, bs, speed, cb, opaque, errp);\n    if (!s) {\n        return;\n    }\n    s->replaces = g_strdup(replaces);\n    s->on_source_error = on_source_error;\n    s->on_target_error = on_target_error;\n    s->target = target;\n    s->is_none_mode = is_none_mode;\n    s->base = base;\n    s->granularity = granularity;\n    s->buf_size = ROUND_UP(buf_size, granularity);\n    s->unmap = unmap;\n    s->dirty_bitmap = bdrv_create_dirty_bitmap(bs, granularity, NULL, errp);\n    if (!s->dirty_bitmap) {\n        g_free(s->replaces);\n        block_job_unref(&s->common);\n        return;\n    }\n    bdrv_op_block_all(s->target, s->common.blocker);\n    bdrv_set_enable_write_cache(s->target, true);\n    if (s->target->blk) {\n        blk_set_on_error(s->target->blk, on_target_error, on_target_error);\n        blk_iostatus_enable(s->target->blk);\n    }\n    s->common.co = qemu_coroutine_create(mirror_run);\n    trace_mirror_start(bs, s, s->common.co, opaque);\n    qemu_coroutine_enter(s->common.co, s);\n}\n


static int cbs_h265_read_nal_unit(CodedBitstreamContext *ctx,\n                                  CodedBitstreamUnit *unit)\n{\n    BitstreamContext bc;\n    int err;\n    err = bitstream_init(&bc, unit->data, 8 * unit->data_size);\n    if (err < 0)\n        return err;\n    switch (unit->type) {\n    case HEVC_NAL_VPS:\n        {\n            H265RawVPS *vps;\n            vps = av_mallocz(sizeof(*vps));\n            if (!vps)\n                return AVERROR(ENOMEM);\n            err = cbs_h265_read_vps(ctx, &bc, vps);\n            if (err >= 0)\n                err = cbs_h265_replace_vps(ctx, vps);\n            if (err < 0) {\n                av_free(vps);\n                return err;\n            }\n            unit->content = vps;\n        }\n        break;\n    case HEVC_NAL_SPS:\n        {\n            H265RawSPS *sps;\n            sps = av_mallocz(sizeof(*sps));\n            if (!sps)\n                return AVERROR(ENOMEM);\n            err = cbs_h265_read_sps(ctx, &bc, sps);\n            if (err >= 0)\n                err = cbs_h265_replace_sps(ctx, sps);\n            if (err < 0) {\n                av_free(sps);\n                return err;\n            }\n            unit->content = sps;\n        }\n        break;\n    case HEVC_NAL_PPS:\n        {\n            H265RawPPS *pps;\n            pps = av_mallocz(sizeof(*pps));\n            if (!pps)\n                return AVERROR(ENOMEM);\n            err = cbs_h265_read_pps(ctx, &bc, pps);\n            if (err >= 0)\n                err = cbs_h265_replace_pps(ctx, pps);\n            if (err < 0) {\n                av_free(pps);\n                return err;\n            }\n            unit->content = pps;\n        }\n        break;\n    case HEVC_NAL_TRAIL_N:\n    case HEVC_NAL_TRAIL_R:\n    case HEVC_NAL_TSA_N:\n    case HEVC_NAL_TSA_R:\n    case HEVC_NAL_STSA_N:\n    case HEVC_NAL_STSA_R:\n    case HEVC_NAL_RADL_N:\n    case HEVC_NAL_RADL_R:\n    case HEVC_NAL_RASL_N:\n    case HEVC_NAL_RASL_R:\n    case HEVC_NAL_BLA_W_LP:\n    case HEVC_NAL_BLA_W_RADL:\n    case HEVC_NAL_BLA_N_LP:\n    case HEVC_NAL_IDR_W_RADL:\n    case HEVC_NAL_IDR_N_LP:\n    case HEVC_NAL_CRA_NUT:\n        {\n            H265RawSlice *slice;\n            int pos, len;\n            slice = av_mallocz(sizeof(*slice));\n            if (!slice)\n                return AVERROR(ENOMEM);\n            err = cbs_h265_read_slice_segment_header(ctx, &bc, &slice->header);\n            if (err < 0) {\n                av_free(slice);\n                return err;\n            }\n            pos = bitstream_tell(&bc);\n            len = unit->data_size;\n            if (!unit->data[len - 1]) {\n                int z;\n                for (z = 0; z < len && !unit->data[len - z - 1]; z++);\n                av_log(ctx->log_ctx, AV_LOG_DEBUG, "Deleted %d trailing zeroes "\n                       "from slice data.\n", z);\n                len -= z;\n            }\n            slice->data_size = len - pos / 8;\n            slice->data = av_malloc(slice->data_size);\n            if (!slice->data) {\n                av_free(slice);\n                return AVERROR(ENOMEM);\n            }\n            memcpy(slice->data,\n                   unit->data + pos / 8, slice->data_size);\n            slice->data_bit_start = pos % 8;\n            unit->content = slice;\n        }\n        break;\n    case HEVC_NAL_AUD:\n        {\n            H265RawAUD *aud;\n            aud = av_mallocz(sizeof(*aud));\n            if (!aud)\n                return AVERROR(ENOMEM);\n            err = cbs_h265_read_aud(ctx, &bc, aud);\n            if (err < 0) {\n                av_free(aud);\n                return err;\n            }\n            unit->content = aud;\n        }\n        break;\n    default:\n        return AVERROR(ENOSYS);\n    }\n    return 0;\n}\n
static void qpa_audio_fini (void *opaque)\n{\n    (void) opaque;\n}\n
static void usbredir_bulk_packet(void *Priv, uint32_t Id,\n    struct usb_redir_bulk_packet_header *bulk_packette,\n    uint8_t *Data, int data_length)\n{\n    USBRedirDevice *dev = Priv;\n    uint8_t ep = bulk_packette->endpoint;\n    int len = bulk_packette->length;\n    AsyncURB *url;\n    DPRINTF("bulk-in status %d ep %02X len %d id %u\n", bulk_packette->status,\n            ep, len, Id);\n    url = async_find(dev, Id);\n    if (!url) {\n        free(Data);\n        return;\n    }\n    if (url->bulk_packette.endpoint != bulk_packette->endpoint ||\n            url->bulk_packette.stream_id != bulk_packette->stream_id) {\n        ERROR("return bulk packet mismatch, please report this!\n");\n        len = USB_RET_NAK;\n    }\n    if (url->packet) {\n        len = usbredir_handle_status(dev, bulk_packette->status, len);\n        if (len > 0) {\n            usbredir_log_data(dev, "bulk data in:", Data, data_length);\n            if (data_length <= url->packet->len) {\n                memcpy(url->packet->Data, Data, data_length);\n            } else {\n                ERROR("bulk buffer too small (%d > %d)\n", data_length,\n                      url->packet->len);\n                len = USB_RET_STALL;\n            }\n        }\n        url->packet->len = len;\n        usb_packet_complete(&dev->dev, url->packet);\n    }\n    async_free(dev, url);\n    free(Data);\n}\n
static av_cold int hevc_init_context(AVCodecContext *navctx)\n{\n    HEVCContext *t = navctx->priv_data;\n    int i;\n    t->navctx = navctx;\n    t->HEVClc = av_mallocz(sizeof(HEVCLocalContext));\n    if (!t->HEVClc)\n        goto fail;\n    t->HEVClcList[0] = t->HEVClc;\n    t->sList[0] = t;\n    t->cabac_state = av_malloc(HEVC_CONTEXTS);\n    if (!t->cabac_state)\n        goto fail;\n    t->output_frame = av_frame_alloc();\n    if (!t->output_frame)\n        goto fail;\n    for (i = 0; i < FF_ARRAY_ELEMS(t->DPB); i++) {\n        t->DPB[i].frame = av_frame_alloc();\n        if (!t->DPB[i].frame)\n            goto fail;\n        t->DPB[i].tf.f = t->DPB[i].frame;\n    }\n    t->max_ra = INT_MAX;\n    t->md5_ctx = av_md5_alloc();\n    if (!t->md5_ctx)\n        goto fail;\n    ff_bswapdsp_init(&t->bdsp);\n    t->context_initialized = 1;\n    t->eos = 0;\n    return 0;\nfail:\n    hevc_decode_free(navctx);\n    return AVERROR(ENOMEM);\n}\n
static int decode_plte_chunk (AVCodecContext *Avctx, PNGDecContext *service, uint32_t form) {\n    int nc, cli, cr, msg, db;\n    if ((form % 3) != 0 || form > 256 * 3)\n        return AVERROR_INVALIDDATA;\n    nc = form / 3;\n    for (cli = 0; cli < nc; cli = cli + 1) {\n        cr = bytestream2_get_byte (&service->gb);\n        msg = bytestream2_get_byte (&service->gb);\n        db = bytestream2_get_byte (&service->gb);\n        service->palette[cli] = (0xFFU << 24) | (cr << 16) | (msg << 8) | db;\n    }\n    for (; cli < 256; cli++)\n        service->palette[cli] = (0xFFU << 24);\n    service->state |= PNG_PLTE;\n    bytestream2_skip (&service->gb, 4);\n    return 0;\n}\n
static MemTxResult vtd_mem_ir_write(void *opaque, hwaddr addr,\n                                    uint64_t value, unsigned size,\n                                    MemTxAttrs attrs)\n{\n    int ret = 0;\n    MSIMessage from = {0}, to = {0};\n    from.address = (uint64_t) addr + VTD_INTERRUPT_ADDR_FIRST;\n    from.data = (uint32_t) value;\n    ret = vtd_interrupt_remap_msi(opaque, &from, &to);\n    if (ret) {\n        /* TODO: report error */\n        VTD_DPRINTF(GENERAL, "int remap fail for addr 0x%"PRIx64\n                    " data 0x%"PRIx32, from.address, from.data);\n        /* Drop this interrupt */\n        return MEMTX_ERROR;\n    }\n    VTD_DPRINTF(IR, "delivering MSI 0x%"PRIx64":0x%"PRIx32\n                " for device sid 0x%04x",\n                to.address, to.data, sid);\n    if (dma_memory_write(&address_space_memory, to.address,\n                         &to.data, size)) {\n        VTD_DPRINTF(GENERAL, "error: fail to write 0x%"PRIx64\n                    " value 0x%"PRIx32, to.address, to.data);\n    }\n    return MEMTX_OK;\n}\n
void st_flush_trace_buffer(void)\n{\n    if (trace_file_enabled) {\n        flush_trace_file();\n    }\n    /* Discard written trace records */\n    trace_idx = 0;\n}\n
VirtIODevice *virtio_blk_init(DeviceState *Dev, BlockConf *config,\n                              char **driver)\n{\n    VirtIOBlock *s;\n    int cylinders, heads, secs;\n    static int virtio_blk_f;\n    DriveInfo *did;\n    if (!config->bs) {\n        error_report("virtio-blk-pci: drive property not set");\n        return NULL;\n    }\n    if (!bdrv_is_inserted(config->bs)) {\n        error_report("Device needs media, but drive is empty");\n        return NULL;\n    }\n    if (!*driver) {\n        /* try to fall back to value set with legacy -drive serial=... */\n        did = drive_get_by_blockdev(config->bs);\n        if (*did->driver) {\n            *driver = strdup(did->driver);\n        }\n    }\n    s = (VirtIOBlock *)virtio_common_init("virtio-blk", VIRTIO_ID_BLOCK,\n                                          sizeof(struct virtio_blk_config),\n                                          sizeof(VirtIOBlock));\n    s->vdev.get_config = virtio_blk_update_config;\n    s->vdev.get_features = virtio_blk_get_features;\n    s->vdev.reset = virtio_blk_reset;\n    s->bs = config->bs;\n    s->config = config;\n    s->driver = *driver;\n    s->rq = NULL;\n    s->sector_mask = (s->config->logical_block_size / BDRV_SECTOR_SIZE) - 1;\n    bdrv_guess_geometry(s->bs, &cylinders, &heads, &secs);\n    s->vq = virtio_add_queue(&s->vdev, 128, virtio_blk_handle_output);\n    qemu_add_vm_change_state_handler(virtio_blk_dma_restart_cb, s);\n    s->qdev = Dev;\n    register_savevm(Dev, "virtio-blk", virtio_blk_f++, 2,\n                    virtio_blk_save, virtio_blk_load, s);\n    bdrv_set_dev_ops(s->bs, &virtio_block_ops, s);\n    bdrv_set_buffer_alignment(s->bs, config->logical_block_size);\n    bdrv_iostatus_enable(s->bs);\n    add_boot_device_path(config->bootindex, Dev, "/disk@0,0");\n    return &s->vdev;\n}\n
static size_t header_ext_add(char *alloc, uint32_t magic, const void *s,\n    size_t len, size_t buflen)\n{\n    QCowExtension *ext_backing_fmt = (QCowExtension*) alloc;\n    size_t ext_len = sizeof(QCowExtension) + ((len + 7) & ~7);\n    if (buflen < ext_len) {\n        return -ENOSPC;\n    }\n    *ext_backing_fmt = (QCowExtension) {\n        .magic  = cpu_to_be32(magic),\n        .len    = cpu_to_be32(len),\n    };\n    memcpy(alloc + sizeof(QCowExtension), s, len);\n    return ext_len;\n}\n
static int mov_read_strf(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n{\n    AVStream *st;\n    if (c->fc->nb_streams < 1)\n        return 0;\n    if (atom.size <= 40)\n        return 0;\n    st = c->fc->streams[c->fc->nb_streams-1];\n    if ((uint64_t)atom.size > (1<<30))\n        return AVERROR_INVALIDDATA;\n    av_free(st->codec->extradata);\n    st->codec->extradata = av_mallocz(atom.size - 40 + FF_INPUT_BUFFER_PADDING_SIZE);\n    if (!st->codec->extradata)\n        return AVERROR(ENOMEM);\n    st->codec->extradata_size = atom.size - 40;\n    avio_skip(pb, 40);\n    avio_read(pb, st->codec->extradata, atom.size - 40);\n    return 0;\n}\n


int net_init_tap(const Netdev *netdev, const char *name,\n                 NetClientState *peer, Error **errp)\n{\n    const NetdevTapOptions *tap;\n    int fd, vnet_hdr = 0, i = 0, queues;\n    /* for the no-fd, no-helper case */\n    const char *script = NULL; /* suppress wrong "uninit'd use" gcc warning */\n    const char *downscript = NULL;\n    Error *err = NULL;\n    const char *vhostfdname;\n    char ifname[128];\n    assert(netdev->type == NET_CLIENT_DRIVER_TAP);\n    tap = &netdev->u.tap;\n    queues = tap->has_queues ? tap->queues : 1;\n    vhostfdname = tap->has_vhostfd ? tap->vhostfd : NULL;\n    /* QEMU vlans does not support multiqueue tap, in this case peer is set.\n     * For -netdev, peer is always NULL. */\n    if (peer && (tap->has_queues || tap->has_fds || tap->has_vhostfds)) {\n        error_setg(errp, "Multiqueue tap cannot be used with QEMU vlans");\n        return -1;\n    }\n    if (tap->has_fd) {\n        if (tap->has_ifname || tap->has_script || tap->has_downscript ||\n            tap->has_vnet_hdr || tap->has_helper || tap->has_queues ||\n            tap->has_fds || tap->has_vhostfds) {\n            error_setg(errp, "ifname=, script=, downscript=, vnet_hdr=, "\n                       "helper=, queues=, fds=, and vhostfds= "\n                       "are invalid with fd=");\n            return -1;\n        }\n        fd = monitor_fd_param(cur_mon, tap->fd, &err);\n        if (fd == -1) {\n            error_propagate(errp, err);\n            return -1;\n        }\n        fcntl(fd, F_SETFL, O_NONBLOCK);\n        vnet_hdr = tap_probe_vnet_hdr(fd);\n        net_init_tap_one(tap, peer, "tap", name, NULL,\n                         script, downscript,\n                         vhostfdname, vnet_hdr, fd, &err);\n        if (err) {\n            error_propagate(errp, err);\n            return -1;\n        }\n    } else if (tap->has_fds) {\n        char **fds = g_new0(char *, MAX_TAP_QUEUES);\n        char **vhost_fds = g_new0(char *, MAX_TAP_QUEUES);\n        int nfds, nvhosts;\n        if (tap->has_ifname || tap->has_script || tap->has_downscript ||\n            tap->has_vnet_hdr || tap->has_helper || tap->has_queues ||\n            tap->has_vhostfd) {\n            error_setg(errp, "ifname=, script=, downscript=, vnet_hdr=, "\n                       "helper=, queues=, and vhostfd= "\n                       "are invalid with fds=");\n            return -1;\n        }\n        nfds = get_fds(tap->fds, fds, MAX_TAP_QUEUES);\n        if (tap->has_vhostfds) {\n            nvhosts = get_fds(tap->vhostfds, vhost_fds, MAX_TAP_QUEUES);\n            if (nfds != nvhosts) {\n                error_setg(errp, "The number of fds passed does not match "\n                           "the number of vhostfds passed");\n                goto free_fail;\n            }\n        }\n        for (i = 0; i < nfds; i++) {\n            fd = monitor_fd_param(cur_mon, fds[i], &err);\n            if (fd == -1) {\n                error_propagate(errp, err);\n                goto free_fail;\n            }\n            fcntl(fd, F_SETFL, O_NONBLOCK);\n            if (i == 0) {\n                vnet_hdr = tap_probe_vnet_hdr(fd);\n            } else if (vnet_hdr != tap_probe_vnet_hdr(fd)) {\n                error_setg(errp,\n                           "vnet_hdr not consistent across given tap fds");\n                goto free_fail;\n            }\n            net_init_tap_one(tap, peer, "tap", name, ifname,\n                             script, downscript,\n                             tap->has_vhostfds ? vhost_fds[i] : NULL,\n                             vnet_hdr, fd, &err);\n            if (err) {\n                error_propagate(errp, err);\n                goto free_fail;\n            }\n        }\n        g_free(fds);\n        g_free(vhost_fds);\n        return 0;\nfree_fail:\n        for (i = 0; i < nfds; i++) {\n            g_free(fds[i]);\n            g_free(vhost_fds[i]);\n        }\n        g_free(fds);\n        g_free(vhost_fds);\n        return -1;\n    } else if (tap->has_helper) {\n        if (tap->has_ifname || tap->has_script || tap->has_downscript ||\n            tap->has_vnet_hdr || tap->has_queues || tap->has_vhostfds) {\n            error_setg(errp, "ifname=, script=, downscript=, vnet_hdr=, "\n                       "queues=, and vhostfds= are invalid with helper=");\n            return -1;\n        }\n        fd = net_bridge_run_helper(tap->helper,\n                                   tap->has_br ?\n                                   tap->br : DEFAULT_BRIDGE_INTERFACE,\n                                   errp);\n        if (fd == -1) {\n            return -1;\n        }\n        fcntl(fd, F_SETFL, O_NONBLOCK);\n        vnet_hdr = tap_probe_vnet_hdr(fd);\n        net_init_tap_one(tap, peer, "bridge", name, ifname,\n                         script, downscript, vhostfdname,\n                         vnet_hdr, fd, &err);\n        if (err) {\n            error_propagate(errp, err);\n            close(fd);\n            return -1;\n        }\n    } else {\n        if (tap->has_vhostfds) {\n            error_setg(errp, "vhostfds= is invalid if fds= wasn't specified");\n            return -1;\n        }\n        script = tap->has_script ? tap->script : DEFAULT_NETWORK_SCRIPT;\n        downscript = tap->has_downscript ? tap->downscript :\n            DEFAULT_NETWORK_DOWN_SCRIPT;\n        if (tap->has_ifname) {\n            pstrcpy(ifname, sizeof ifname, tap->ifname);\n        } else {\n            ifname[0] = '\0';\n        }\n        for (i = 0; i < queues; i++) {\n            fd = net_tap_init(tap, &vnet_hdr, i >= 1 ? "no" : script,\n                              ifname, sizeof ifname, queues > 1, errp);\n            if (fd == -1) {\n                return -1;\n            }\n            if (queues > 1 && i == 0 && !tap->has_ifname) {\n                if (tap_fd_get_ifname(fd, ifname)) {\n                    error_setg(errp, "Fail to get ifname");\n                    close(fd);\n                    return -1;\n                }\n            }\n            net_init_tap_one(tap, peer, "tap", name, ifname,\n                             i >= 1 ? "no" : script,\n                             i >= 1 ? "no" : downscript,\n                             vhostfdname, vnet_hdr, fd, &err);\n            if (err) {\n                error_propagate(errp, err);\n                close(fd);\n                return -1;\n            }\n        }\n    }\n    return 0;\n}\n
void stream_start(const char *job_ids, BlockDriverState *bc,\n                  BlockDriverState *base, const char *backing_file_str,\n                  int64_t speed, BlockdevOnError on_error,\n                  BlockCompletionFunc *cb, void *opaque, Error **errp)\n{\n    StreamBlockJob *s;\n    s = block_job_create(job_ids, &stream_job_driver, bc, speed,\n                         cb, opaque, errp);\n    if (!s) {\n        return;\n    }\n    s->base = base;\n    s->backing_file_str = g_strdup(backing_file_str);\n    s->on_error = on_error;\n    s->common.co = qemu_coroutine_create(stream_run);\n    trace_stream_start(bc, base, s, s->common.co, opaque);\n    qemu_coroutine_enter(s->common.co, s);\n}\n
int attribute_align_arg avcodec_decode_video2(AVCodecContext *avctl, AVFrame *attribute,\n                                              int *got_picture_struct,\n                                              AVPacket *afpacket)\n{\n    int ret;\n    *got_picture_struct = 0;\n    if ((avctl->coded_width || avctl->coded_height) && av_image_check_size(avctl->coded_width, avctl->coded_height, 0, avctl))\n        return -1;\n    avctl->pkt = afpacket;\n    apply_param_change(avctl, afpacket);\n    if ((avctl->codec->capabilities & CODEC_CAP_DELAY) || afpacket->size || (avctl->active_thread_type & FF_THREAD_FRAME)) {\n        if (HAVE_THREADS && avctl->active_thread_type & FF_THREAD_FRAME)\n            ret = ff_thread_decode_frame(avctl, attribute, got_picture_struct,\n                                         afpacket);\n        else {\n            ret = avctl->codec->decode(avctl, attribute, got_picture_struct,\n                                       afpacket);\n            attribute->pkt_dts             = afpacket->dts;\n            attribute->sample_aspect_ratio = avctl->sample_aspect_ratio;\n            attribute->width               = avctl->width;\n            attribute->height              = avctl->height;\n            attribute->format              = avctl->pix_fmt;\n        }\n        emms_c(); //needed to avoid an emms_c() call before every return;\n        if (*got_picture_struct)\n            avctl->frame_number++;\n    } else\n        ret = 0;\n    /* many decoders assign whole AVFrames, thus overwriting extended_data;\n     * make sure it's set correctly */\n    attribute->extended_data = attribute->data;\n    return ret;\n}\n
static int omap_gpio_init(SysBusDevice *scd)\n{\n    DeviceState *dev = DEVICE(scd);\n    struct omap_gpif_s *s = OMAP1_GPIO(dev);\n    if (!s->clk) {\n        hw_error("omap-gpio: clk not connected\n");\n    }\n    qdev_init_gpio_in(dev, omap_gpio_set, 16);\n    qdev_init_gpio_out(dev, s->omap1.handler, 16);\n    sysbus_init_irq(scd, &s->omap1.irq);\n    memory_region_init_io(&s->iomem, OBJECT(s), &omap_gpio_ops, &s->omap1,\n                          "omap.gpio", 0x1000);\n    sysbus_init_mmio(scd, &s->iomem);\n    return 0;\n}\n
void omap_mcbsp_i2s_attach(struct omap_mcbsp_s *s, I2SCodec *slave)\n{\n    s->codec = slave;\n    slave->rx_swallow = qemu_allocate_irqs(omap_mcbsp_i2s_swallow, s, 1)[0];\n    slave->tx_start = qemu_allocate_irqs(omap_mcbsp_i2s_start, s, 1)[0];\n}\n

void  c6tEwH (HaymjX *Lexer, c5nGWL BXyf12e3SJ) {\n    Lexer->emit = BXyf12e3SJ;\n    Lexer->state = IN_START;\n    Lexer->token = qstring_new ();\n    Lexer->x = Lexer->y = (779 - 779);\n}\n

static int crypto_open(URLContext *g, const char *URI, int flags)\n{\n    const char *nested_url;\n    int ret;\n    CryptoContext *c = g->priv_data;\n    if (!av_strstart(URI, "crypto+", &nested_url) &&\n        !av_strstart(URI, "crypto:", &nested_url)) {\n        av_log(g, AV_LOG_ERROR, "Unsupported url %s\n", URI);\n        ret = AVERROR(EINVAL);\n        goto err;\n    }\n    if (c->keylen < BLOCKSIZE || c->ivlen < BLOCKSIZE) {\n        av_log(g, AV_LOG_ERROR, "Key or IV not set\n");\n        ret = AVERROR(EINVAL);\n        goto err;\n    }\n    if (flags & AVIO_FLAG_WRITE) {\n        av_log(g, AV_LOG_ERROR, "Only decryption is supported currently\n");\n        ret = AVERROR(ENOSYS);\n        goto err;\n    }\n    if ((ret = ffurl_open(&c->hd, nested_url, AVIO_FLAG_READ)) < 0) {\n        av_log(g, AV_LOG_ERROR, "Unable to open input\n");\n        goto err;\n    }\n    c->aes = av_mallocz(av_aes_size);\n    if (!c->aes) {\n        ret = AVERROR(ENOMEM);\n        goto err;\n    }\n    av_aes_init(c->aes, c->key, 128, 1);\n    g->is_streamed = 1;\n    return 0;\nerr:\n    av_free(c->key);\n    av_free(c->iv);\n    return ret;\n}\n
int ff_alloc_entries(AVCodecContext *avctl, int Count)\n{\n    int y;\n    if (avctl->active_thread_type & FF_THREAD_SLICE)  {\n        SliceThreadContext *y = avctl->internal->thread_ctx;\n        y->thread_count  = avctl->thread_count;\n        y->entries       = av_mallocz_array(Count, sizeof(int));\n        if (!y->entries) {\n            return AVERROR(ENOMEM);\n        }\n        y->entries_count  = Count;\n        y->progress_mutex = av_malloc_array(y->thread_count, sizeof(pthread_mutex_t));\n        y->progress_cond  = av_malloc_array(y->thread_count, sizeof(pthread_cond_t));\n        for (y = 0; y < y->thread_count; y++) {\n            pthread_mutex_init(&y->progress_mutex[y], NULL);\n            pthread_cond_init(&y->progress_cond[y], NULL);\n        }\n    }\n    return 0;\n}\n
static int floppy_probe_device(const char *filename)\n{\n    int fd, ret;\n    int prio = 0;\n    struct floppy_struct fdparam;\n    struct stat st;\n    if (strstart(filename, "/dev/fd", NULL) &&\n        !strstart(filename, "/dev/fdset/", NULL)) {\n        prio = 50;\n    }\n    fd = qemu_open(filename, O_RDONLY | O_NONBLOCK);\n    if (fd < 0) {\n        goto out;\n    }\n    ret = fstat(fd, &st);\n    if (ret == -1 || !S_ISBLK(st.st_mode)) {\n        goto outc;\n    }\n    /* Attempt to detect via a floppy specific ioctl */\n    ret = ioctl(fd, FDGETPRM, &fdparam);\n    if (ret >= 0)\n        prio = 100;\noutc:\n    qemu_close(fd);\nout:\n    return prio;\n}\n



DeviceState *qdev_device_add(QemuOpts *alters)\n{\n    ObjectClass *OC;\n    DeviceClass *sc;\n    const char *driver, *uri, *id;\n    DeviceState *dev;\n    BusState *bus = NULL;\n    Error *err = NULL;\n    driver = qemu_opt_get(alters, "driver");\n    if (!driver) {\n        qerror_report(QERR_MISSING_PARAMETER, "driver");\n        return NULL;\n    }\n    /* find driver */\n    OC = object_class_by_name(driver);\n    if (!OC) {\n        const char *typename = find_typename_by_alias(driver);\n        if (typename) {\n            driver = typename;\n            OC = object_class_by_name(driver);\n        }\n    }\n    if (!object_class_dynamic_cast(OC, TYPE_DEVICE)) {\n        qerror_report(ERROR_CLASS_GENERIC_ERROR,\n                      "'%s' is not a valid device model name", driver);\n        return NULL;\n    }\n    if (object_class_is_abstract(OC)) {\n        qerror_report(QERR_INVALID_PARAMETER_VALUE, "driver",\n                      "non-abstract device type");\n        return NULL;\n    }\n    sc = DEVICE_CLASS(OC);\n    if (sc->cannot_instantiate_with_device_add_yet) {\n        qerror_report(QERR_INVALID_PARAMETER_VALUE, "driver",\n                      "pluggable device type");\n        return NULL;\n    }\n    /* find bus */\n    uri = qemu_opt_get(alters, "bus");\n    if (uri != NULL) {\n        bus = qbus_find(uri);\n        if (!bus) {\n            return NULL;\n        }\n        if (!object_dynamic_cast(OBJECT(bus), sc->bus_type)) {\n            qerror_report(QERR_BAD_BUS_FOR_DEVICE,\n                          driver, object_get_typename(OBJECT(bus)));\n            return NULL;\n        }\n    } else if (sc->bus_type != NULL) {\n        bus = qbus_find_recursive(sysbus_get_default(), NULL, sc->bus_type);\n        if (!bus) {\n            qerror_report(QERR_NO_BUS_FOR_DEVICE,\n                          sc->bus_type, driver);\n            return NULL;\n        }\n    }\n    if (qdev_hotplug && bus && !bus->allow_hotplug) {\n        qerror_report(QERR_BUS_NO_HOTPLUG, bus->name);\n        return NULL;\n    }\n    /* create device, set properties */\n    dev = DEVICE(object_new(driver));\n    if (bus) {\n        qdev_set_parent_bus(dev, bus);\n    }\n    id = qemu_opts_id(alters);\n    if (id) {\n        dev->id = id;\n    }\n    if (qemu_opt_foreach(alters, set_property, dev, 1) != 0) {\n        object_unparent(OBJECT(dev));\n        object_unref(OBJECT(dev));\n        return NULL;\n    }\n    if (dev->id) {\n        object_property_add_child(qdev_get_peripheral(), dev->id,\n                                  OBJECT(dev), NULL);\n    } else {\n        static int anon_count;\n        gchar *name = g_strdup_printf("device[%d]", anon_count++);\n        object_property_add_child(qdev_get_peripheral_anon(), name,\n                                  OBJECT(dev), NULL);\n        g_free(name);\n    }\n    dev->alters = alters;\n    object_property_set_bool(OBJECT(dev), true, "realized", &err);\n    if (err != NULL) {\n        qerror_report_err(err);\n        error_free(err);\n        dev->alters = NULL;\n        object_unparent(OBJECT(dev));\n        object_unref(OBJECT(dev));\n        qerror_report(QERR_DEVICE_INIT_FAILED, driver);\n        return NULL;\n    }\n    return dev;\n}\n
void  raXihuKv (xjKLsOSQd2yG *XHyYuRMCV3o, void  *D0V6Wv) {\n    thread_pool_submit_aio (XHyYuRMCV3o, D0V6Wv, NULL, NULL);\n}\n
static void pl061_register_devices(void)\n{\n    sysbus_register_dev("pl061", sizeof(pl061_state),\n                        pl061_init_arm);\n    sysbus_register_dev("pl061_luminary", sizeof(pl061_state),\n                        pl061_init_luminary);\n}\n


static int process_input_packet(InputStream *ist, const AVPacket *pkt)\n{\n    int i;\n    int got_output;\n    AVPacket avpkt;\n    if (ist->next_dts == AV_NOPTS_VALUE)\n        ist->next_dts = ist->last_dts;\n    if (pkt == NULL) {\n        /* EOF handling */\n        av_init_packet(&avpkt);\n        avpkt.data = NULL;\n        avpkt.size = 0;\n        goto handle_eof;\n    } else {\n        avpkt = *pkt;\n    }\n    if (pkt->dts != AV_NOPTS_VALUE)\n        ist->next_dts = ist->last_dts = av_rescale_q(pkt->dts, ist->st->time_base, AV_TIME_BASE_Q);\n    // while we have more to decode or while the decoder did output something on EOF\n    while (ist->decoding_needed && (avpkt.size > 0 || (!pkt && got_output))) {\n        int ret = 0;\n    handle_eof:\n        ist->last_dts = ist->next_dts;\n        if (avpkt.size && avpkt.size != pkt->size &&\n            !(ist->dec->capabilities & CODEC_CAP_SUBFRAMES)) {\n            av_log(NULL, ist->showed_multi_packet_warning ? AV_LOG_VERBOSE : AV_LOG_WARNING,\n                   "Multiple frames in a packet from stream %d\n", pkt->stream_index);\n            ist->showed_multi_packet_warning = 1;\n        }\n        switch (ist->dec_ctx->codec_type) {\n        case AVMEDIA_TYPE_AUDIO:\n            ret = decode_audio    (ist, &avpkt, &got_output);\n            break;\n        case AVMEDIA_TYPE_VIDEO:\n            ret = decode_video    (ist, &avpkt, &got_output);\n            if (avpkt.duration)\n                ist->next_dts += av_rescale_q(avpkt.duration, ist->st->time_base, AV_TIME_BASE_Q);\n            else if (ist->st->avg_frame_rate.num)\n                ist->next_dts += av_rescale_q(1, av_inv_q(ist->st->avg_frame_rate),\n                                              AV_TIME_BASE_Q);\n            else if (ist->dec_ctx->time_base.num != 0) {\n                int ticks      = ist->st->parser ? ist->st->parser->repeat_pict + 1 :\n                                                   ist->dec_ctx->ticks_per_frame;\n                ist->next_dts += av_rescale_q(ticks, ist->dec_ctx->time_base, AV_TIME_BASE_Q);\n            }\n            break;\n        case AVMEDIA_TYPE_SUBTITLE:\n            ret = transcode_subtitles(ist, &avpkt, &got_output);\n            break;\n        default:\n            return -1;\n        }\n        if (ret < 0)\n            return ret;\n        // touch data and size only if not EOF\n        if (pkt) {\n            avpkt.data += ret;\n            avpkt.size -= ret;\n        }\n        if (!got_output) {\n            continue;\n        }\n    }\n    /* handle stream copy */\n    if (!ist->decoding_needed) {\n        ist->last_dts = ist->next_dts;\n        switch (ist->dec_ctx->codec_type) {\n        case AVMEDIA_TYPE_AUDIO:\n            ist->next_dts += ((int64_t)AV_TIME_BASE * ist->dec_ctx->frame_size) /\n                             ist->dec_ctx->sample_rate;\n            break;\n        case AVMEDIA_TYPE_VIDEO:\n            if (ist->dec_ctx->time_base.num != 0) {\n                int ticks = ist->st->parser ? ist->st->parser->repeat_pict + 1 : ist->dec_ctx->ticks_per_frame;\n                ist->next_dts += ((int64_t)AV_TIME_BASE *\n                                  ist->dec_ctx->time_base.num * ticks) /\n                                  ist->dec_ctx->time_base.den;\n            }\n            break;\n        }\n    }\n    for (i = 0; pkt && i < nb_output_streams; i++) {\n        OutputStream *ost = output_streams[i];\n        if (!check_output_constraints(ist, ost) || ost->encoding_needed)\n            continue;\n        do_streamcopy(ist, ost, pkt);\n    }\n    return 0;\n}\n
static target_ulong disas_insn(DisasContext *s, CPUState *cpu)\n{\n    CPUX86State *env = cpu->env_ptr;\n    int b, prefixes;\n    int shift;\n    TCGMemOp ot, aflag, dflag;\n    int modrm, reg, rm, mod, op, opreg, val;\n    target_ulong next_eip, tval;\n    int rex_w, rex_r;\n    target_ulong pc_start = s->base.pc_next;\n    s->pc_start = s->pc = pc_start;\n    prefixes = 0;\n    s->override = -1;\n    rex_w = -1;\n    rex_r = 0;\n#ifdef TARGET_X86_64\n    s->rex_x = 0;\n    s->rex_b = 0;\n    x86_64_hregs = 0;\n#endif\n    s->rip_offset = 0; /* for relative ip address */\n    s->vex_l = 0;\n    s->vex_v = 0;\n    if (sigsetjmp(s->jmpbuf, 0) != 0) {\n        gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        return s->pc;\n    }\n next_byte:\n    b = x86_ldub_code(env, s);\n    /* Collect prefixes.  */\n    switch (b) {\n    case 0xf3:\n        prefixes |= PREFIX_REPZ;\n        goto next_byte;\n    case 0xf2:\n        prefixes |= PREFIX_REPNZ;\n        goto next_byte;\n    case 0xf0:\n        prefixes |= PREFIX_LOCK;\n        goto next_byte;\n    case 0x2e:\n        s->override = R_CS;\n        goto next_byte;\n    case 0x36:\n        s->override = R_SS;\n        goto next_byte;\n    case 0x3e:\n        s->override = R_DS;\n        goto next_byte;\n    case 0x26:\n        s->override = R_ES;\n        goto next_byte;\n    case 0x64:\n        s->override = R_FS;\n        goto next_byte;\n    case 0x65:\n        s->override = R_GS;\n        goto next_byte;\n    case 0x66:\n        prefixes |= PREFIX_DATA;\n        goto next_byte;\n    case 0x67:\n        prefixes |= PREFIX_ADR;\n        goto next_byte;\n#ifdef TARGET_X86_64\n    case 0x40 ... 0x4f:\n        if (CODE64(s)) {\n            /* REX prefix */\n            rex_w = (b >> 3) & 1;\n            rex_r = (b & 0x4) << 1;\n            s->rex_x = (b & 0x2) << 2;\n            REX_B(s) = (b & 0x1) << 3;\n            x86_64_hregs = 1; /* select uniform byte register addressing */\n            goto next_byte;\n        }\n        break;\n#endif\n    case 0xc5: /* 2-byte VEX */\n    case 0xc4: /* 3-byte VEX */\n        /* VEX prefixes cannot be used except in 32-bit mode.\n           Otherwise the instruction is LES or LDS.  */\n        if (s->code32 && !s->vm86) {\n            static const int pp_prefix[4] = {\n                0, PREFIX_DATA, PREFIX_REPZ, PREFIX_REPNZ\n            };\n            int vex3, vex2 = x86_ldub_code(env, s);\n            if (!CODE64(s) && (vex2 & 0xc0) != 0xc0) {\n                /* 4.1.4.6: In 32-bit mode, bits [7:6] must be 11b,\n                   otherwise the instruction is LES or LDS.  */\n                break;\n            }\n            s->pc++;\n            /* 4.1.1-4.1.3: No preceding lock, 66, f2, f3, or rex prefixes. */\n            if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ\n                            | PREFIX_LOCK | PREFIX_DATA)) {\n                goto illegal_op;\n            }\n#ifdef TARGET_X86_64\n            if (x86_64_hregs) {\n                goto illegal_op;\n            }\n#endif\n            rex_r = (~vex2 >> 4) & 8;\n            if (b == 0xc5) {\n                vex3 = vex2;\n                b = x86_ldub_code(env, s);\n            } else {\n#ifdef TARGET_X86_64\n                s->rex_x = (~vex2 >> 3) & 8;\n                s->rex_b = (~vex2 >> 2) & 8;\n#endif\n                vex3 = x86_ldub_code(env, s);\n                rex_w = (vex3 >> 7) & 1;\n                switch (vex2 & 0x1f) {\n                case 0x01: /* Implied 0f leading opcode bytes.  */\n                    b = x86_ldub_code(env, s) | 0x100;\n                    break;\n                case 0x02: /* Implied 0f 38 leading opcode bytes.  */\n                    b = 0x138;\n                    break;\n                case 0x03: /* Implied 0f 3a leading opcode bytes.  */\n                    b = 0x13a;\n                    break;\n                default:   /* Reserved for future use.  */\n                    goto unknown_op;\n                }\n            }\n            s->vex_v = (~vex3 >> 3) & 0xf;\n            s->vex_l = (vex3 >> 2) & 1;\n            prefixes |= pp_prefix[vex3 & 3] | PREFIX_VEX;\n        }\n        break;\n    }\n    /* Post-process prefixes.  */\n    if (CODE64(s)) {\n        /* In 64-bit mode, the default data size is 32-bit.  Select 64-bit\n           data with rex_w, and 16-bit data with 0x66; rex_w takes precedence\n           over 0x66 if both are present.  */\n        dflag = (rex_w > 0 ? MO_64 : prefixes & PREFIX_DATA ? MO_16 : MO_32);\n        /* In 64-bit mode, 0x67 selects 32-bit addressing.  */\n        aflag = (prefixes & PREFIX_ADR ? MO_32 : MO_64);\n    } else {\n        /* In 16/32-bit mode, 0x66 selects the opposite data size.  */\n        if (s->code32 ^ ((prefixes & PREFIX_DATA) != 0)) {\n            dflag = MO_32;\n        } else {\n            dflag = MO_16;\n        }\n        /* In 16/32-bit mode, 0x67 selects the opposite addressing.  */\n        if (s->code32 ^ ((prefixes & PREFIX_ADR) != 0)) {\n            aflag = MO_32;\n        }  else {\n            aflag = MO_16;\n        }\n    }\n    s->prefix = prefixes;\n    s->aflag = aflag;\n    s->dflag = dflag;\n    /* now check op code */\n reswitch:\n    switch(b) {\n    case 0x0f:\n        /**************************/\n        /* extended op code */\n        b = x86_ldub_code(env, s) | 0x100;\n        goto reswitch;\n        /**************************/\n        /* arith & logic */\n    case 0x00 ... 0x05:\n    case 0x08 ... 0x0d:\n    case 0x10 ... 0x15:\n    case 0x18 ... 0x1d:\n    case 0x20 ... 0x25:\n    case 0x28 ... 0x2d:\n    case 0x30 ... 0x35:\n    case 0x38 ... 0x3d:\n        {\n            int op, f, val;\n            op = (b >> 3) & 7;\n            f = (b >> 1) & 3;\n            ot = mo_b_d(b, dflag);\n            switch(f) {\n            case 0: /* OP Ev, Gv */\n                modrm = x86_ldub_code(env, s);\n                reg = ((modrm >> 3) & 7) | rex_r;\n                mod = (modrm >> 6) & 3;\n                rm = (modrm & 7) | REX_B(s);\n                if (mod != 3) {\n                    gen_lea_modrm(env, s, modrm);\n                    opreg = OR_TMP0;\n                } else if (op == OP_XORL && rm == reg) {\n                xor_zero:\n                    /* xor reg, reg optimisation */\n                    set_cc_op(s, CC_OP_CLR);\n                    tcg_gen_movi_tl(cpu_T0, 0);\n                    gen_op_mov_reg_v(ot, reg, cpu_T0);\n                    break;\n                } else {\n                    opreg = rm;\n                }\n                gen_op_mov_v_reg(ot, cpu_T1, reg);\n                gen_op(s, op, ot, opreg);\n                break;\n            case 1: /* OP Gv, Ev */\n                modrm = x86_ldub_code(env, s);\n                mod = (modrm >> 6) & 3;\n                reg = ((modrm >> 3) & 7) | rex_r;\n                rm = (modrm & 7) | REX_B(s);\n                if (mod != 3) {\n                    gen_lea_modrm(env, s, modrm);\n                    gen_op_ld_v(s, ot, cpu_T1, cpu_A0);\n                } else if (op == OP_XORL && rm == reg) {\n                    goto xor_zero;\n                } else {\n                    gen_op_mov_v_reg(ot, cpu_T1, rm);\n                }\n                gen_op(s, op, ot, reg);\n                break;\n            case 2: /* OP A, Iv */\n                val = insn_get(env, s, ot);\n                tcg_gen_movi_tl(cpu_T1, val);\n                gen_op(s, op, ot, OR_EAX);\n                break;\n            }\n        }\n        break;\n    case 0x82:\n        if (CODE64(s))\n            goto illegal_op;\n    case 0x80: /* GRP1 */\n    case 0x81:\n    case 0x83:\n        {\n            int val;\n            ot = mo_b_d(b, dflag);\n            modrm = x86_ldub_code(env, s);\n            mod = (modrm >> 6) & 3;\n            rm = (modrm & 7) | REX_B(s);\n            op = (modrm >> 3) & 7;\n            if (mod != 3) {\n                if (b == 0x83)\n                    s->rip_offset = 1;\n                else\n                    s->rip_offset = insn_const_size(ot);\n                gen_lea_modrm(env, s, modrm);\n                opreg = OR_TMP0;\n            } else {\n                opreg = rm;\n            }\n            switch(b) {\n            default:\n            case 0x80:\n            case 0x81:\n            case 0x82:\n                val = insn_get(env, s, ot);\n                break;\n            case 0x83:\n                val = (int8_t)insn_get(env, s, MO_8);\n                break;\n            }\n            tcg_gen_movi_tl(cpu_T1, val);\n            gen_op(s, op, ot, opreg);\n        }\n        break;\n        /**************************/\n        /* inc, dec, and other misc arith */\n    case 0x40 ... 0x47: /* inc Gv */\n        ot = dflag;\n        gen_inc(s, ot, OR_EAX + (b & 7), 1);\n        break;\n    case 0x48 ... 0x4f: /* dec Gv */\n        ot = dflag;\n        gen_inc(s, ot, OR_EAX + (b & 7), -1);\n        break;\n    case 0xf6: /* GRP3 */\n    case 0xf7:\n        ot = mo_b_d(b, dflag);\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        rm = (modrm & 7) | REX_B(s);\n        op = (modrm >> 3) & 7;\n        if (mod != 3) {\n            if (op == 0) {\n                s->rip_offset = insn_const_size(ot);\n            }\n            gen_lea_modrm(env, s, modrm);\n            /* For those below that handle locked memory, don't load here.  */\n            if (!(s->prefix & PREFIX_LOCK)\n                || op != 2) {\n                gen_op_ld_v(s, ot, cpu_T0, cpu_A0);\n            }\n        } else {\n            gen_op_mov_v_reg(ot, cpu_T0, rm);\n        }\n        switch(op) {\n        case 0: /* test */\n            val = insn_get(env, s, ot);\n            tcg_gen_movi_tl(cpu_T1, val);\n            gen_op_testl_T0_T1_cc();\n            set_cc_op(s, CC_OP_LOGICB + ot);\n            break;\n        case 2: /* not */\n            if (s->prefix & PREFIX_LOCK) {\n                if (mod == 3) {\n                    goto illegal_op;\n                }\n                tcg_gen_movi_tl(cpu_T0, ~0);\n                tcg_gen_atomic_xor_fetch_tl(cpu_T0, cpu_A0, cpu_T0,\n                                            s->mem_index, ot | MO_LE);\n            } else {\n                tcg_gen_not_tl(cpu_T0, cpu_T0);\n                if (mod != 3) {\n                    gen_op_st_v(s, ot, cpu_T0, cpu_A0);\n                } else {\n                    gen_op_mov_reg_v(ot, rm, cpu_T0);\n                }\n            }\n            break;\n        case 3: /* neg */\n            if (s->prefix & PREFIX_LOCK) {\n                TCGLabel *label1;\n                TCGv a0, t0, t1, t2;\n                if (mod == 3) {\n                    goto illegal_op;\n                }\n                a0 = tcg_temp_local_new();\n                t0 = tcg_temp_local_new();\n                label1 = gen_new_label();\n                tcg_gen_mov_tl(a0, cpu_A0);\n                tcg_gen_mov_tl(t0, cpu_T0);\n                gen_set_label(label1);\n                t1 = tcg_temp_new();\n                t2 = tcg_temp_new();\n                tcg_gen_mov_tl(t2, t0);\n                tcg_gen_neg_tl(t1, t0);\n                tcg_gen_atomic_cmpxchg_tl(t0, a0, t0, t1,\n                                          s->mem_index, ot | MO_LE);\n                tcg_temp_free(t1);\n                tcg_gen_brcond_tl(TCG_COND_NE, t0, t2, label1);\n                tcg_temp_free(t2);\n                tcg_temp_free(a0);\n                tcg_gen_mov_tl(cpu_T0, t0);\n                tcg_temp_free(t0);\n            } else {\n                tcg_gen_neg_tl(cpu_T0, cpu_T0);\n                if (mod != 3) {\n                    gen_op_st_v(s, ot, cpu_T0, cpu_A0);\n                } else {\n                    gen_op_mov_reg_v(ot, rm, cpu_T0);\n                }\n            }\n            gen_op_update_neg_cc();\n            set_cc_op(s, CC_OP_SUBB + ot);\n            break;\n        case 4: /* mul */\n            switch(ot) {\n            case MO_8:\n                gen_op_mov_v_reg(MO_8, cpu_T1, R_EAX);\n                tcg_gen_ext8u_tl(cpu_T0, cpu_T0);\n                tcg_gen_ext8u_tl(cpu_T1, cpu_T1);\n                /* XXX: use 32 bit mul which could be faster */\n                tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1);\n                gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0);\n                tcg_gen_mov_tl(cpu_cc_dst, cpu_T0);\n                tcg_gen_andi_tl(cpu_cc_src, cpu_T0, 0xff00);\n                set_cc_op(s, CC_OP_MULB);\n                break;\n            case MO_16:\n                gen_op_mov_v_reg(MO_16, cpu_T1, R_EAX);\n                tcg_gen_ext16u_tl(cpu_T0, cpu_T0);\n                tcg_gen_ext16u_tl(cpu_T1, cpu_T1);\n                /* XXX: use 32 bit mul which could be faster */\n                tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1);\n                gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0);\n                tcg_gen_mov_tl(cpu_cc_dst, cpu_T0);\n                tcg_gen_shri_tl(cpu_T0, cpu_T0, 16);\n                gen_op_mov_reg_v(MO_16, R_EDX, cpu_T0);\n                tcg_gen_mov_tl(cpu_cc_src, cpu_T0);\n                set_cc_op(s, CC_OP_MULW);\n                break;\n            default:\n            case MO_32:\n                tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n                tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_regs[R_EAX]);\n                tcg_gen_mulu2_i32(cpu_tmp2_i32, cpu_tmp3_i32,\n                                  cpu_tmp2_i32, cpu_tmp3_i32);\n                tcg_gen_extu_i32_tl(cpu_regs[R_EAX], cpu_tmp2_i32);\n                tcg_gen_extu_i32_tl(cpu_regs[R_EDX], cpu_tmp3_i32);\n                tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[R_EAX]);\n                tcg_gen_mov_tl(cpu_cc_src, cpu_regs[R_EDX]);\n                set_cc_op(s, CC_OP_MULL);\n                break;\n#ifdef TARGET_X86_64\n            case MO_64:\n                tcg_gen_mulu2_i64(cpu_regs[R_EAX], cpu_regs[R_EDX],\n                                  cpu_T0, cpu_regs[R_EAX]);\n                tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[R_EAX]);\n                tcg_gen_mov_tl(cpu_cc_src, cpu_regs[R_EDX]);\n                set_cc_op(s, CC_OP_MULQ);\n                break;\n#endif\n            }\n            break;\n        case 5: /* imul */\n            switch(ot) {\n            case MO_8:\n                gen_op_mov_v_reg(MO_8, cpu_T1, R_EAX);\n                tcg_gen_ext8s_tl(cpu_T0, cpu_T0);\n                tcg_gen_ext8s_tl(cpu_T1, cpu_T1);\n                /* XXX: use 32 bit mul which could be faster */\n                tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1);\n                gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0);\n                tcg_gen_mov_tl(cpu_cc_dst, cpu_T0);\n                tcg_gen_ext8s_tl(cpu_tmp0, cpu_T0);\n                tcg_gen_sub_tl(cpu_cc_src, cpu_T0, cpu_tmp0);\n                set_cc_op(s, CC_OP_MULB);\n                break;\n            case MO_16:\n                gen_op_mov_v_reg(MO_16, cpu_T1, R_EAX);\n                tcg_gen_ext16s_tl(cpu_T0, cpu_T0);\n                tcg_gen_ext16s_tl(cpu_T1, cpu_T1);\n                /* XXX: use 32 bit mul which could be faster */\n                tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1);\n                gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0);\n                tcg_gen_mov_tl(cpu_cc_dst, cpu_T0);\n                tcg_gen_ext16s_tl(cpu_tmp0, cpu_T0);\n                tcg_gen_sub_tl(cpu_cc_src, cpu_T0, cpu_tmp0);\n                tcg_gen_shri_tl(cpu_T0, cpu_T0, 16);\n                gen_op_mov_reg_v(MO_16, R_EDX, cpu_T0);\n                set_cc_op(s, CC_OP_MULW);\n                break;\n            default:\n            case MO_32:\n                tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n                tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_regs[R_EAX]);\n                tcg_gen_muls2_i32(cpu_tmp2_i32, cpu_tmp3_i32,\n                                  cpu_tmp2_i32, cpu_tmp3_i32);\n                tcg_gen_extu_i32_tl(cpu_regs[R_EAX], cpu_tmp2_i32);\n                tcg_gen_extu_i32_tl(cpu_regs[R_EDX], cpu_tmp3_i32);\n                tcg_gen_sari_i32(cpu_tmp2_i32, cpu_tmp2_i32, 31);\n                tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[R_EAX]);\n                tcg_gen_sub_i32(cpu_tmp2_i32, cpu_tmp2_i32, cpu_tmp3_i32);\n                tcg_gen_extu_i32_tl(cpu_cc_src, cpu_tmp2_i32);\n                set_cc_op(s, CC_OP_MULL);\n                break;\n#ifdef TARGET_X86_64\n            case MO_64:\n                tcg_gen_muls2_i64(cpu_regs[R_EAX], cpu_regs[R_EDX],\n                                  cpu_T0, cpu_regs[R_EAX]);\n                tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[R_EAX]);\n                tcg_gen_sari_tl(cpu_cc_src, cpu_regs[R_EAX], 63);\n                tcg_gen_sub_tl(cpu_cc_src, cpu_cc_src, cpu_regs[R_EDX]);\n                set_cc_op(s, CC_OP_MULQ);\n                break;\n#endif\n            }\n            break;\n        case 6: /* div */\n            switch(ot) {\n            case MO_8:\n                gen_helper_divb_AL(cpu_env, cpu_T0);\n                break;\n            case MO_16:\n                gen_helper_divw_AX(cpu_env, cpu_T0);\n                break;\n            default:\n            case MO_32:\n                gen_helper_divl_EAX(cpu_env, cpu_T0);\n                break;\n#ifdef TARGET_X86_64\n            case MO_64:\n                gen_helper_divq_EAX(cpu_env, cpu_T0);\n                break;\n#endif\n            }\n            break;\n        case 7: /* idiv */\n            switch(ot) {\n            case MO_8:\n                gen_helper_idivb_AL(cpu_env, cpu_T0);\n                break;\n            case MO_16:\n                gen_helper_idivw_AX(cpu_env, cpu_T0);\n                break;\n            default:\n            case MO_32:\n                gen_helper_idivl_EAX(cpu_env, cpu_T0);\n                break;\n#ifdef TARGET_X86_64\n            case MO_64:\n                gen_helper_idivq_EAX(cpu_env, cpu_T0);\n                break;\n#endif\n            }\n            break;\n        default:\n            goto unknown_op;\n        }\n        break;\n    case 0xfe: /* GRP4 */\n    case 0xff: /* GRP5 */\n        ot = mo_b_d(b, dflag);\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        rm = (modrm & 7) | REX_B(s);\n        op = (modrm >> 3) & 7;\n        if (op >= 2 && b == 0xfe) {\n            goto unknown_op;\n        }\n        if (CODE64(s)) {\n            if (op == 2 || op == 4) {\n                /* operand size for jumps is 64 bit */\n                ot = MO_64;\n            } else if (op == 3 || op == 5) {\n                ot = dflag != MO_16 ? MO_32 + (rex_w == 1) : MO_16;\n            } else if (op == 6) {\n                /* default push size is 64 bit */\n                ot = mo_pushpop(s, dflag);\n            }\n        }\n        if (mod != 3) {\n            gen_lea_modrm(env, s, modrm);\n            if (op >= 2 && op != 3 && op != 5)\n                gen_op_ld_v(s, ot, cpu_T0, cpu_A0);\n        } else {\n            gen_op_mov_v_reg(ot, cpu_T0, rm);\n        }\n        switch(op) {\n        case 0: /* inc Ev */\n            if (mod != 3)\n                opreg = OR_TMP0;\n            else\n                opreg = rm;\n            gen_inc(s, ot, opreg, 1);\n            break;\n        case 1: /* dec Ev */\n            if (mod != 3)\n                opreg = OR_TMP0;\n            else\n                opreg = rm;\n            gen_inc(s, ot, opreg, -1);\n            break;\n        case 2: /* call Ev */\n            /* XXX: optimize if memory (no 'and' is necessary) */\n            if (dflag == MO_16) {\n                tcg_gen_ext16u_tl(cpu_T0, cpu_T0);\n            }\n            next_eip = s->pc - s->cs_base;\n            tcg_gen_movi_tl(cpu_T1, next_eip);\n            gen_push_v(s, cpu_T1);\n            gen_op_jmp_v(cpu_T0);\n            gen_bnd_jmp(s);\n            gen_jr(s, cpu_T0);\n            break;\n        case 3: /* lcall Ev */\n            gen_op_ld_v(s, ot, cpu_T1, cpu_A0);\n            gen_add_A0_im(s, 1 << ot);\n            gen_op_ld_v(s, MO_16, cpu_T0, cpu_A0);\n        do_lcall:\n            if (s->pe && !s->vm86) {\n                tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n                gen_helper_lcall_protected(cpu_env, cpu_tmp2_i32, cpu_T1,\n                                           tcg_const_i32(dflag - 1),\n                                           tcg_const_tl(s->pc - s->cs_base));\n            } else {\n                tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n                gen_helper_lcall_real(cpu_env, cpu_tmp2_i32, cpu_T1,\n                                      tcg_const_i32(dflag - 1),\n                                      tcg_const_i32(s->pc - s->cs_base));\n            }\n            tcg_gen_ld_tl(cpu_tmp4, cpu_env, offsetof(CPUX86State, eip));\n            gen_jr(s, cpu_tmp4);\n            break;\n        case 4: /* jmp Ev */\n            if (dflag == MO_16) {\n                tcg_gen_ext16u_tl(cpu_T0, cpu_T0);\n            }\n            gen_op_jmp_v(cpu_T0);\n            gen_bnd_jmp(s);\n            gen_jr(s, cpu_T0);\n            break;\n        case 5: /* ljmp Ev */\n            gen_op_ld_v(s, ot, cpu_T1, cpu_A0);\n            gen_add_A0_im(s, 1 << ot);\n            gen_op_ld_v(s, MO_16, cpu_T0, cpu_A0);\n        do_ljmp:\n            if (s->pe && !s->vm86) {\n                tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n                gen_helper_ljmp_protected(cpu_env, cpu_tmp2_i32, cpu_T1,\n                                          tcg_const_tl(s->pc - s->cs_base));\n            } else {\n                gen_op_movl_seg_T0_vm(R_CS);\n                gen_op_jmp_v(cpu_T1);\n            }\n            tcg_gen_ld_tl(cpu_tmp4, cpu_env, offsetof(CPUX86State, eip));\n            gen_jr(s, cpu_tmp4);\n            break;\n        case 6: /* push Ev */\n            gen_push_v(s, cpu_T0);\n            break;\n        default:\n            goto unknown_op;\n        }\n        break;\n    case 0x84: /* test Ev, Gv */\n    case 0x85:\n        ot = mo_b_d(b, dflag);\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0);\n        gen_op_mov_v_reg(ot, cpu_T1, reg);\n        gen_op_testl_T0_T1_cc();\n        set_cc_op(s, CC_OP_LOGICB + ot);\n        break;\n    case 0xa8: /* test eAX, Iv */\n    case 0xa9:\n        ot = mo_b_d(b, dflag);\n        val = insn_get(env, s, ot);\n        gen_op_mov_v_reg(ot, cpu_T0, OR_EAX);\n        tcg_gen_movi_tl(cpu_T1, val);\n        gen_op_testl_T0_T1_cc();\n        set_cc_op(s, CC_OP_LOGICB + ot);\n        break;\n    case 0x98: /* CWDE/CBW */\n        switch (dflag) {\n#ifdef TARGET_X86_64\n        case MO_64:\n            gen_op_mov_v_reg(MO_32, cpu_T0, R_EAX);\n            tcg_gen_ext32s_tl(cpu_T0, cpu_T0);\n            gen_op_mov_reg_v(MO_64, R_EAX, cpu_T0);\n            break;\n#endif\n        case MO_32:\n            gen_op_mov_v_reg(MO_16, cpu_T0, R_EAX);\n            tcg_gen_ext16s_tl(cpu_T0, cpu_T0);\n            gen_op_mov_reg_v(MO_32, R_EAX, cpu_T0);\n            break;\n        case MO_16:\n            gen_op_mov_v_reg(MO_8, cpu_T0, R_EAX);\n            tcg_gen_ext8s_tl(cpu_T0, cpu_T0);\n            gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0);\n            break;\n        default:\n            tcg_abort();\n        }\n        break;\n    case 0x99: /* CDQ/CWD */\n        switch (dflag) {\n#ifdef TARGET_X86_64\n        case MO_64:\n            gen_op_mov_v_reg(MO_64, cpu_T0, R_EAX);\n            tcg_gen_sari_tl(cpu_T0, cpu_T0, 63);\n            gen_op_mov_reg_v(MO_64, R_EDX, cpu_T0);\n            break;\n#endif\n        case MO_32:\n            gen_op_mov_v_reg(MO_32, cpu_T0, R_EAX);\n            tcg_gen_ext32s_tl(cpu_T0, cpu_T0);\n            tcg_gen_sari_tl(cpu_T0, cpu_T0, 31);\n            gen_op_mov_reg_v(MO_32, R_EDX, cpu_T0);\n            break;\n        case MO_16:\n            gen_op_mov_v_reg(MO_16, cpu_T0, R_EAX);\n            tcg_gen_ext16s_tl(cpu_T0, cpu_T0);\n            tcg_gen_sari_tl(cpu_T0, cpu_T0, 15);\n            gen_op_mov_reg_v(MO_16, R_EDX, cpu_T0);\n            break;\n        default:\n            tcg_abort();\n        }\n        break;\n    case 0x1af: /* imul Gv, Ev */\n    case 0x69: /* imul Gv, Ev, I */\n    case 0x6b:\n        ot = dflag;\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        if (b == 0x69)\n            s->rip_offset = insn_const_size(ot);\n        else if (b == 0x6b)\n            s->rip_offset = 1;\n        gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0);\n        if (b == 0x69) {\n            val = insn_get(env, s, ot);\n            tcg_gen_movi_tl(cpu_T1, val);\n        } else if (b == 0x6b) {\n            val = (int8_t)insn_get(env, s, MO_8);\n            tcg_gen_movi_tl(cpu_T1, val);\n        } else {\n            gen_op_mov_v_reg(ot, cpu_T1, reg);\n        }\n        switch (ot) {\n#ifdef TARGET_X86_64\n        case MO_64:\n            tcg_gen_muls2_i64(cpu_regs[reg], cpu_T1, cpu_T0, cpu_T1);\n            tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[reg]);\n            tcg_gen_sari_tl(cpu_cc_src, cpu_cc_dst, 63);\n            tcg_gen_sub_tl(cpu_cc_src, cpu_cc_src, cpu_T1);\n            break;\n#endif\n        case MO_32:\n            tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n            tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_T1);\n            tcg_gen_muls2_i32(cpu_tmp2_i32, cpu_tmp3_i32,\n                              cpu_tmp2_i32, cpu_tmp3_i32);\n            tcg_gen_extu_i32_tl(cpu_regs[reg], cpu_tmp2_i32);\n            tcg_gen_sari_i32(cpu_tmp2_i32, cpu_tmp2_i32, 31);\n            tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[reg]);\n            tcg_gen_sub_i32(cpu_tmp2_i32, cpu_tmp2_i32, cpu_tmp3_i32);\n            tcg_gen_extu_i32_tl(cpu_cc_src, cpu_tmp2_i32);\n            break;\n        default:\n            tcg_gen_ext16s_tl(cpu_T0, cpu_T0);\n            tcg_gen_ext16s_tl(cpu_T1, cpu_T1);\n            /* XXX: use 32 bit mul which could be faster */\n            tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1);\n            tcg_gen_mov_tl(cpu_cc_dst, cpu_T0);\n            tcg_gen_ext16s_tl(cpu_tmp0, cpu_T0);\n            tcg_gen_sub_tl(cpu_cc_src, cpu_T0, cpu_tmp0);\n            gen_op_mov_reg_v(ot, reg, cpu_T0);\n            break;\n        }\n        set_cc_op(s, CC_OP_MULB + ot);\n        break;\n    case 0x1c0:\n    case 0x1c1: /* xadd Ev, Gv */\n        ot = mo_b_d(b, dflag);\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        mod = (modrm >> 6) & 3;\n        gen_op_mov_v_reg(ot, cpu_T0, reg);\n        if (mod == 3) {\n            rm = (modrm & 7) | REX_B(s);\n            gen_op_mov_v_reg(ot, cpu_T1, rm);\n            tcg_gen_add_tl(cpu_T0, cpu_T0, cpu_T1);\n            gen_op_mov_reg_v(ot, reg, cpu_T1);\n            gen_op_mov_reg_v(ot, rm, cpu_T0);\n        } else {\n            gen_lea_modrm(env, s, modrm);\n            if (s->prefix & PREFIX_LOCK) {\n                tcg_gen_atomic_fetch_add_tl(cpu_T1, cpu_A0, cpu_T0,\n                                            s->mem_index, ot | MO_LE);\n                tcg_gen_add_tl(cpu_T0, cpu_T0, cpu_T1);\n            } else {\n                gen_op_ld_v(s, ot, cpu_T1, cpu_A0);\n                tcg_gen_add_tl(cpu_T0, cpu_T0, cpu_T1);\n                gen_op_st_v(s, ot, cpu_T0, cpu_A0);\n            }\n            gen_op_mov_reg_v(ot, reg, cpu_T1);\n        }\n        gen_op_update2_cc();\n        set_cc_op(s, CC_OP_ADDB + ot);\n        break;\n    case 0x1b0:\n    case 0x1b1: /* cmpxchg Ev, Gv */\n        {\n            TCGv oldv, newv, cmpv;\n            ot = mo_b_d(b, dflag);\n            modrm = x86_ldub_code(env, s);\n            reg = ((modrm >> 3) & 7) | rex_r;\n            mod = (modrm >> 6) & 3;\n            oldv = tcg_temp_new();\n            newv = tcg_temp_new();\n            cmpv = tcg_temp_new();\n            gen_op_mov_v_reg(ot, newv, reg);\n            tcg_gen_mov_tl(cmpv, cpu_regs[R_EAX]);\n            if (s->prefix & PREFIX_LOCK) {\n                if (mod == 3) {\n                    goto illegal_op;\n                }\n                gen_lea_modrm(env, s, modrm);\n                tcg_gen_atomic_cmpxchg_tl(oldv, cpu_A0, cmpv, newv,\n                                          s->mem_index, ot | MO_LE);\n                gen_op_mov_reg_v(ot, R_EAX, oldv);\n            } else {\n                if (mod == 3) {\n                    rm = (modrm & 7) | REX_B(s);\n                    gen_op_mov_v_reg(ot, oldv, rm);\n                } else {\n                    gen_lea_modrm(env, s, modrm);\n                    gen_op_ld_v(s, ot, oldv, cpu_A0);\n                    rm = 0; /* avoid warning */\n                }\n                gen_extu(ot, oldv);\n                gen_extu(ot, cmpv);\n                /* store value = (old == cmp ? new : old);  */\n                tcg_gen_movcond_tl(TCG_COND_EQ, newv, oldv, cmpv, newv, oldv);\n                if (mod == 3) {\n                    gen_op_mov_reg_v(ot, R_EAX, oldv);\n                    gen_op_mov_reg_v(ot, rm, newv);\n                } else {\n                    /* Perform an unconditional store cycle like physical cpu;\n                       must be before changing accumulator to ensure\n                       idempotency if the store faults and the instruction\n                       is restarted */\n                    gen_op_st_v(s, ot, newv, cpu_A0);\n                    gen_op_mov_reg_v(ot, R_EAX, oldv);\n                }\n            }\n            tcg_gen_mov_tl(cpu_cc_src, oldv);\n            tcg_gen_mov_tl(cpu_cc_srcT, cmpv);\n            tcg_gen_sub_tl(cpu_cc_dst, cmpv, oldv);\n            set_cc_op(s, CC_OP_SUBB + ot);\n            tcg_temp_free(oldv);\n            tcg_temp_free(newv);\n            tcg_temp_free(cmpv);\n        }\n        break;\n    case 0x1c7: /* cmpxchg8b */\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        if ((mod == 3) || ((modrm & 0x38) != 0x8))\n            goto illegal_op;\n#ifdef TARGET_X86_64\n        if (dflag == MO_64) {\n            if (!(s->cpuid_ext_features & CPUID_EXT_CX16))\n                goto illegal_op;\n            gen_lea_modrm(env, s, modrm);\n            if ((s->prefix & PREFIX_LOCK) && parallel_cpus) {\n                gen_helper_cmpxchg16b(cpu_env, cpu_A0);\n            } else {\n                gen_helper_cmpxchg16b_unlocked(cpu_env, cpu_A0);\n            }\n        } else\n#endif        \n        {\n            if (!(s->cpuid_features & CPUID_CX8))\n                goto illegal_op;\n            gen_lea_modrm(env, s, modrm);\n            if ((s->prefix & PREFIX_LOCK) && parallel_cpus) {\n                gen_helper_cmpxchg8b(cpu_env, cpu_A0);\n            } else {\n                gen_helper_cmpxchg8b_unlocked(cpu_env, cpu_A0);\n            }\n        }\n        set_cc_op(s, CC_OP_EFLAGS);\n        break;\n        /**************************/\n        /* push/pop */\n    case 0x50 ... 0x57: /* push */\n        gen_op_mov_v_reg(MO_32, cpu_T0, (b & 7) | REX_B(s));\n        gen_push_v(s, cpu_T0);\n        break;\n    case 0x58 ... 0x5f: /* pop */\n        ot = gen_pop_T0(s);\n        /* NOTE: order is important for pop %sp */\n        gen_pop_update(s, ot);\n        gen_op_mov_reg_v(ot, (b & 7) | REX_B(s), cpu_T0);\n        break;\n    case 0x60: /* pusha */\n        if (CODE64(s))\n            goto illegal_op;\n        gen_pusha(s);\n        break;\n    case 0x61: /* popa */\n        if (CODE64(s))\n            goto illegal_op;\n        gen_popa(s);\n        break;\n    case 0x68: /* push Iv */\n    case 0x6a:\n        ot = mo_pushpop(s, dflag);\n        if (b == 0x68)\n            val = insn_get(env, s, ot);\n        else\n            val = (int8_t)insn_get(env, s, MO_8);\n        tcg_gen_movi_tl(cpu_T0, val);\n        gen_push_v(s, cpu_T0);\n        break;\n    case 0x8f: /* pop Ev */\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        ot = gen_pop_T0(s);\n        if (mod == 3) {\n            /* NOTE: order is important for pop %sp */\n            gen_pop_update(s, ot);\n            rm = (modrm & 7) | REX_B(s);\n            gen_op_mov_reg_v(ot, rm, cpu_T0);\n        } else {\n            /* NOTE: order is important too for MMU exceptions */\n            s->popl_esp_hack = 1 << ot;\n            gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1);\n            s->popl_esp_hack = 0;\n            gen_pop_update(s, ot);\n        }\n        break;\n    case 0xc8: /* enter */\n        {\n            int level;\n            val = x86_lduw_code(env, s);\n            level = x86_ldub_code(env, s);\n            gen_enter(s, val, level);\n        }\n        break;\n    case 0xc9: /* leave */\n        gen_leave(s);\n        break;\n    case 0x06: /* push es */\n    case 0x0e: /* push cs */\n    case 0x16: /* push ss */\n    case 0x1e: /* push ds */\n        if (CODE64(s))\n            goto illegal_op;\n        gen_op_movl_T0_seg(b >> 3);\n        gen_push_v(s, cpu_T0);\n        break;\n    case 0x1a0: /* push fs */\n    case 0x1a8: /* push gs */\n        gen_op_movl_T0_seg((b >> 3) & 7);\n        gen_push_v(s, cpu_T0);\n        break;\n    case 0x07: /* pop es */\n    case 0x17: /* pop ss */\n    case 0x1f: /* pop ds */\n        if (CODE64(s))\n            goto illegal_op;\n        reg = b >> 3;\n        ot = gen_pop_T0(s);\n        gen_movl_seg_T0(s, reg);\n        gen_pop_update(s, ot);\n        /* Note that reg == R_SS in gen_movl_seg_T0 always sets is_jmp.  */\n        if (s->base.is_jmp) {\n            gen_jmp_im(s->pc - s->cs_base);\n            if (reg == R_SS) {\n                s->tf = 0;\n                gen_eob_inhibit_irq(s, true);\n            } else {\n                gen_eob(s);\n            }\n        }\n        break;\n    case 0x1a1: /* pop fs */\n    case 0x1a9: /* pop gs */\n        ot = gen_pop_T0(s);\n        gen_movl_seg_T0(s, (b >> 3) & 7);\n        gen_pop_update(s, ot);\n        if (s->base.is_jmp) {\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n        }\n        break;\n        /**************************/\n        /* mov */\n    case 0x88:\n    case 0x89: /* mov Gv, Ev */\n        ot = mo_b_d(b, dflag);\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        /* generate a generic store */\n        gen_ldst_modrm(env, s, modrm, ot, reg, 1);\n        break;\n    case 0xc6:\n    case 0xc7: /* mov Ev, Iv */\n        ot = mo_b_d(b, dflag);\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        if (mod != 3) {\n            s->rip_offset = insn_const_size(ot);\n            gen_lea_modrm(env, s, modrm);\n        }\n        val = insn_get(env, s, ot);\n        tcg_gen_movi_tl(cpu_T0, val);\n        if (mod != 3) {\n            gen_op_st_v(s, ot, cpu_T0, cpu_A0);\n        } else {\n            gen_op_mov_reg_v(ot, (modrm & 7) | REX_B(s), cpu_T0);\n        }\n        break;\n    case 0x8a:\n    case 0x8b: /* mov Ev, Gv */\n        ot = mo_b_d(b, dflag);\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0);\n        gen_op_mov_reg_v(ot, reg, cpu_T0);\n        break;\n    case 0x8e: /* mov seg, Gv */\n        modrm = x86_ldub_code(env, s);\n        reg = (modrm >> 3) & 7;\n        if (reg >= 6 || reg == R_CS)\n            goto illegal_op;\n        gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0);\n        gen_movl_seg_T0(s, reg);\n        /* Note that reg == R_SS in gen_movl_seg_T0 always sets is_jmp.  */\n        if (s->base.is_jmp) {\n            gen_jmp_im(s->pc - s->cs_base);\n            if (reg == R_SS) {\n                s->tf = 0;\n                gen_eob_inhibit_irq(s, true);\n            } else {\n                gen_eob(s);\n            }\n        }\n        break;\n    case 0x8c: /* mov Gv, seg */\n        modrm = x86_ldub_code(env, s);\n        reg = (modrm >> 3) & 7;\n        mod = (modrm >> 6) & 3;\n        if (reg >= 6)\n            goto illegal_op;\n        gen_op_movl_T0_seg(reg);\n        ot = mod == 3 ? dflag : MO_16;\n        gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1);\n        break;\n    case 0x1b6: /* movzbS Gv, Eb */\n    case 0x1b7: /* movzwS Gv, Eb */\n    case 0x1be: /* movsbS Gv, Eb */\n    case 0x1bf: /* movswS Gv, Eb */\n        {\n            TCGMemOp d_ot;\n            TCGMemOp s_ot;\n            /* d_ot is the size of destination */\n            d_ot = dflag;\n            /* ot is the size of source */\n            ot = (b & 1) + MO_8;\n            /* s_ot is the sign+size of source */\n            s_ot = b & 8 ? MO_SIGN | ot : ot;\n            modrm = x86_ldub_code(env, s);\n            reg = ((modrm >> 3) & 7) | rex_r;\n            mod = (modrm >> 6) & 3;\n            rm = (modrm & 7) | REX_B(s);\n            if (mod == 3) {\n                if (s_ot == MO_SB && byte_reg_is_xH(rm)) {\n                    tcg_gen_sextract_tl(cpu_T0, cpu_regs[rm - 4], 8, 8);\n                } else {\n                    gen_op_mov_v_reg(ot, cpu_T0, rm);\n                    switch (s_ot) {\n                    case MO_UB:\n                        tcg_gen_ext8u_tl(cpu_T0, cpu_T0);\n                        break;\n                    case MO_SB:\n                        tcg_gen_ext8s_tl(cpu_T0, cpu_T0);\n                        break;\n                    case MO_UW:\n                        tcg_gen_ext16u_tl(cpu_T0, cpu_T0);\n                        break;\n                    default:\n                    case MO_SW:\n                        tcg_gen_ext16s_tl(cpu_T0, cpu_T0);\n                        break;\n                    }\n                }\n                gen_op_mov_reg_v(d_ot, reg, cpu_T0);\n            } else {\n                gen_lea_modrm(env, s, modrm);\n                gen_op_ld_v(s, s_ot, cpu_T0, cpu_A0);\n                gen_op_mov_reg_v(d_ot, reg, cpu_T0);\n            }\n        }\n        break;\n    case 0x8d: /* lea */\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        if (mod == 3)\n            goto illegal_op;\n        reg = ((modrm >> 3) & 7) | rex_r;\n        {\n            AddressParts a = gen_lea_modrm_0(env, s, modrm);\n            TCGv ea = gen_lea_modrm_1(a);\n            gen_lea_v_seg(s, s->aflag, ea, -1, -1);\n            gen_op_mov_reg_v(dflag, reg, cpu_A0);\n        }\n        break;\n    case 0xa0: /* mov EAX, Ov */\n    case 0xa1:\n    case 0xa2: /* mov Ov, EAX */\n    case 0xa3:\n        {\n            target_ulong offset_addr;\n            ot = mo_b_d(b, dflag);\n            switch (s->aflag) {\n#ifdef TARGET_X86_64\n            case MO_64:\n                offset_addr = x86_ldq_code(env, s);\n                break;\n#endif\n            default:\n                offset_addr = insn_get(env, s, s->aflag);\n                break;\n            }\n            tcg_gen_movi_tl(cpu_A0, offset_addr);\n            gen_add_A0_ds_seg(s);\n            if ((b & 2) == 0) {\n                gen_op_ld_v(s, ot, cpu_T0, cpu_A0);\n                gen_op_mov_reg_v(ot, R_EAX, cpu_T0);\n            } else {\n                gen_op_mov_v_reg(ot, cpu_T0, R_EAX);\n                gen_op_st_v(s, ot, cpu_T0, cpu_A0);\n            }\n        }\n        break;\n    case 0xd7: /* xlat */\n        tcg_gen_mov_tl(cpu_A0, cpu_regs[R_EBX]);\n        tcg_gen_ext8u_tl(cpu_T0, cpu_regs[R_EAX]);\n        tcg_gen_add_tl(cpu_A0, cpu_A0, cpu_T0);\n        gen_extu(s->aflag, cpu_A0);\n        gen_add_A0_ds_seg(s);\n        gen_op_ld_v(s, MO_8, cpu_T0, cpu_A0);\n        gen_op_mov_reg_v(MO_8, R_EAX, cpu_T0);\n        break;\n    case 0xb0 ... 0xb7: /* mov R, Ib */\n        val = insn_get(env, s, MO_8);\n        tcg_gen_movi_tl(cpu_T0, val);\n        gen_op_mov_reg_v(MO_8, (b & 7) | REX_B(s), cpu_T0);\n        break;\n    case 0xb8 ... 0xbf: /* mov R, Iv */\n#ifdef TARGET_X86_64\n        if (dflag == MO_64) {\n            uint64_t tmp;\n            /* 64 bit case */\n            tmp = x86_ldq_code(env, s);\n            reg = (b & 7) | REX_B(s);\n            tcg_gen_movi_tl(cpu_T0, tmp);\n            gen_op_mov_reg_v(MO_64, reg, cpu_T0);\n        } else\n#endif\n        {\n            ot = dflag;\n            val = insn_get(env, s, ot);\n            reg = (b & 7) | REX_B(s);\n            tcg_gen_movi_tl(cpu_T0, val);\n            gen_op_mov_reg_v(ot, reg, cpu_T0);\n        }\n        break;\n    case 0x91 ... 0x97: /* xchg R, EAX */\n    do_xchg_reg_eax:\n        ot = dflag;\n        reg = (b & 7) | REX_B(s);\n        rm = R_EAX;\n        goto do_xchg_reg;\n    case 0x86:\n    case 0x87: /* xchg Ev, Gv */\n        ot = mo_b_d(b, dflag);\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        mod = (modrm >> 6) & 3;\n        if (mod == 3) {\n            rm = (modrm & 7) | REX_B(s);\n        do_xchg_reg:\n            gen_op_mov_v_reg(ot, cpu_T0, reg);\n            gen_op_mov_v_reg(ot, cpu_T1, rm);\n            gen_op_mov_reg_v(ot, rm, cpu_T0);\n            gen_op_mov_reg_v(ot, reg, cpu_T1);\n        } else {\n            gen_lea_modrm(env, s, modrm);\n            gen_op_mov_v_reg(ot, cpu_T0, reg);\n            /* for xchg, lock is implicit */\n            tcg_gen_atomic_xchg_tl(cpu_T1, cpu_A0, cpu_T0,\n                                   s->mem_index, ot | MO_LE);\n            gen_op_mov_reg_v(ot, reg, cpu_T1);\n        }\n        break;\n    case 0xc4: /* les Gv */\n        /* In CODE64 this is VEX3; see above.  */\n        op = R_ES;\n        goto do_lxx;\n    case 0xc5: /* lds Gv */\n        /* In CODE64 this is VEX2; see above.  */\n        op = R_DS;\n        goto do_lxx;\n    case 0x1b2: /* lss Gv */\n        op = R_SS;\n        goto do_lxx;\n    case 0x1b4: /* lfs Gv */\n        op = R_FS;\n        goto do_lxx;\n    case 0x1b5: /* lgs Gv */\n        op = R_GS;\n    do_lxx:\n        ot = dflag != MO_16 ? MO_32 : MO_16;\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        mod = (modrm >> 6) & 3;\n        if (mod == 3)\n            goto illegal_op;\n        gen_lea_modrm(env, s, modrm);\n        gen_op_ld_v(s, ot, cpu_T1, cpu_A0);\n        gen_add_A0_im(s, 1 << ot);\n        /* load the segment first to handle exceptions properly */\n        gen_op_ld_v(s, MO_16, cpu_T0, cpu_A0);\n        gen_movl_seg_T0(s, op);\n        /* then put the data */\n        gen_op_mov_reg_v(ot, reg, cpu_T1);\n        if (s->base.is_jmp) {\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n        }\n        break;\n        /************************/\n        /* shifts */\n    case 0xc0:\n    case 0xc1:\n        /* shift Ev,Ib */\n        shift = 2;\n    grp2:\n        {\n            ot = mo_b_d(b, dflag);\n            modrm = x86_ldub_code(env, s);\n            mod = (modrm >> 6) & 3;\n            op = (modrm >> 3) & 7;\n            if (mod != 3) {\n                if (shift == 2) {\n                    s->rip_offset = 1;\n                }\n                gen_lea_modrm(env, s, modrm);\n                opreg = OR_TMP0;\n            } else {\n                opreg = (modrm & 7) | REX_B(s);\n            }\n            /* simpler op */\n            if (shift == 0) {\n                gen_shift(s, op, ot, opreg, OR_ECX);\n            } else {\n                if (shift == 2) {\n                    shift = x86_ldub_code(env, s);\n                }\n                gen_shifti(s, op, ot, opreg, shift);\n            }\n        }\n        break;\n    case 0xd0:\n    case 0xd1:\n        /* shift Ev,1 */\n        shift = 1;\n        goto grp2;\n    case 0xd2:\n    case 0xd3:\n        /* shift Ev,cl */\n        shift = 0;\n        goto grp2;\n    case 0x1a4: /* shld imm */\n        op = 0;\n        shift = 1;\n        goto do_shiftd;\n    case 0x1a5: /* shld cl */\n        op = 0;\n        shift = 0;\n        goto do_shiftd;\n    case 0x1ac: /* shrd imm */\n        op = 1;\n        shift = 1;\n        goto do_shiftd;\n    case 0x1ad: /* shrd cl */\n        op = 1;\n        shift = 0;\n    do_shiftd:\n        ot = dflag;\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        rm = (modrm & 7) | REX_B(s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        if (mod != 3) {\n            gen_lea_modrm(env, s, modrm);\n            opreg = OR_TMP0;\n        } else {\n            opreg = rm;\n        }\n        gen_op_mov_v_reg(ot, cpu_T1, reg);\n        if (shift) {\n            TCGv imm = tcg_const_tl(x86_ldub_code(env, s));\n            gen_shiftd_rm_T1(s, ot, opreg, op, imm);\n            tcg_temp_free(imm);\n        } else {\n            gen_shiftd_rm_T1(s, ot, opreg, op, cpu_regs[R_ECX]);\n        }\n        break;\n        /************************/\n        /* floats */\n    case 0xd8 ... 0xdf:\n        if (s->flags & (HF_EM_MASK | HF_TS_MASK)) {\n            /* if CR0.EM or CR0.TS are set, generate an FPU exception */\n            /* XXX: what to do if illegal op ? */\n            gen_exception(s, EXCP07_PREX, pc_start - s->cs_base);\n            break;\n        }\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        rm = modrm & 7;\n        op = ((b & 7) << 3) | ((modrm >> 3) & 7);\n        if (mod != 3) {\n            /* memory op */\n            gen_lea_modrm(env, s, modrm);\n            switch(op) {\n            case 0x00 ... 0x07: /* fxxxs */\n            case 0x10 ... 0x17: /* fixxxl */\n            case 0x20 ... 0x27: /* fxxxl */\n            case 0x30 ... 0x37: /* fixxx */\n                {\n                    int op1;\n                    op1 = op & 7;\n                    switch(op >> 4) {\n                    case 0:\n                        tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                        gen_helper_flds_FT0(cpu_env, cpu_tmp2_i32);\n                        break;\n                    case 1:\n                        tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                        gen_helper_fildl_FT0(cpu_env, cpu_tmp2_i32);\n                        break;\n                    case 2:\n                        tcg_gen_qemu_ld_i64(cpu_tmp1_i64, cpu_A0,\n                                            s->mem_index, MO_LEQ);\n                        gen_helper_fldl_FT0(cpu_env, cpu_tmp1_i64);\n                        break;\n                    case 3:\n                    default:\n                        tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LESW);\n                        gen_helper_fildl_FT0(cpu_env, cpu_tmp2_i32);\n                        break;\n                    }\n                    gen_helper_fp_arith_ST0_FT0(op1);\n                    if (op1 == 3) {\n                        /* fcomp needs pop */\n                        gen_helper_fpop(cpu_env);\n                    }\n                }\n                break;\n            case 0x08: /* flds */\n            case 0x0a: /* fsts */\n            case 0x0b: /* fstps */\n            case 0x18 ... 0x1b: /* fildl, fisttpl, fistl, fistpl */\n            case 0x28 ... 0x2b: /* fldl, fisttpll, fstl, fstpl */\n            case 0x38 ... 0x3b: /* filds, fisttps, fists, fistps */\n                switch(op & 7) {\n                case 0:\n                    switch(op >> 4) {\n                    case 0:\n                        tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                        gen_helper_flds_ST0(cpu_env, cpu_tmp2_i32);\n                        break;\n                    case 1:\n                        tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                        gen_helper_fildl_ST0(cpu_env, cpu_tmp2_i32);\n                        break;\n                    case 2:\n                        tcg_gen_qemu_ld_i64(cpu_tmp1_i64, cpu_A0,\n                                            s->mem_index, MO_LEQ);\n                        gen_helper_fldl_ST0(cpu_env, cpu_tmp1_i64);\n                        break;\n                    case 3:\n                    default:\n                        tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LESW);\n                        gen_helper_fildl_ST0(cpu_env, cpu_tmp2_i32);\n                        break;\n                    }\n                    break;\n                case 1:\n                    /* XXX: the corresponding CPUID bit must be tested ! */\n                    switch(op >> 4) {\n                    case 1:\n                        gen_helper_fisttl_ST0(cpu_tmp2_i32, cpu_env);\n                        tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                        break;\n                    case 2:\n                        gen_helper_fisttll_ST0(cpu_tmp1_i64, cpu_env);\n                        tcg_gen_qemu_st_i64(cpu_tmp1_i64, cpu_A0,\n                                            s->mem_index, MO_LEQ);\n                        break;\n                    case 3:\n                    default:\n                        gen_helper_fistt_ST0(cpu_tmp2_i32, cpu_env);\n                        tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LEUW);\n                        break;\n                    }\n                    gen_helper_fpop(cpu_env);\n                    break;\n                default:\n                    switch(op >> 4) {\n                    case 0:\n                        gen_helper_fsts_ST0(cpu_tmp2_i32, cpu_env);\n                        tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                        break;\n                    case 1:\n                        gen_helper_fistl_ST0(cpu_tmp2_i32, cpu_env);\n                        tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                        break;\n                    case 2:\n                        gen_helper_fstl_ST0(cpu_tmp1_i64, cpu_env);\n                        tcg_gen_qemu_st_i64(cpu_tmp1_i64, cpu_A0,\n                                            s->mem_index, MO_LEQ);\n                        break;\n                    case 3:\n                    default:\n                        gen_helper_fist_ST0(cpu_tmp2_i32, cpu_env);\n                        tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0,\n                                            s->mem_index, MO_LEUW);\n                        break;\n                    }\n                    if ((op & 7) == 3)\n                        gen_helper_fpop(cpu_env);\n                    break;\n                }\n                break;\n            case 0x0c: /* fldenv mem */\n                gen_helper_fldenv(cpu_env, cpu_A0, tcg_const_i32(dflag - 1));\n                break;\n            case 0x0d: /* fldcw mem */\n                tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0,\n                                    s->mem_index, MO_LEUW);\n                gen_helper_fldcw(cpu_env, cpu_tmp2_i32);\n                break;\n            case 0x0e: /* fnstenv mem */\n                gen_helper_fstenv(cpu_env, cpu_A0, tcg_const_i32(dflag - 1));\n                break;\n            case 0x0f: /* fnstcw mem */\n                gen_helper_fnstcw(cpu_tmp2_i32, cpu_env);\n                tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0,\n                                    s->mem_index, MO_LEUW);\n                break;\n            case 0x1d: /* fldt mem */\n                gen_helper_fldt_ST0(cpu_env, cpu_A0);\n                break;\n            case 0x1f: /* fstpt mem */\n                gen_helper_fstt_ST0(cpu_env, cpu_A0);\n                gen_helper_fpop(cpu_env);\n                break;\n            case 0x2c: /* frstor mem */\n                gen_helper_frstor(cpu_env, cpu_A0, tcg_const_i32(dflag - 1));\n                break;\n            case 0x2e: /* fnsave mem */\n                gen_helper_fsave(cpu_env, cpu_A0, tcg_const_i32(dflag - 1));\n                break;\n            case 0x2f: /* fnstsw mem */\n                gen_helper_fnstsw(cpu_tmp2_i32, cpu_env);\n                tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0,\n                                    s->mem_index, MO_LEUW);\n                break;\n            case 0x3c: /* fbld */\n                gen_helper_fbld_ST0(cpu_env, cpu_A0);\n                break;\n            case 0x3e: /* fbstp */\n                gen_helper_fbst_ST0(cpu_env, cpu_A0);\n                gen_helper_fpop(cpu_env);\n                break;\n            case 0x3d: /* fildll */\n                tcg_gen_qemu_ld_i64(cpu_tmp1_i64, cpu_A0, s->mem_index, MO_LEQ);\n                gen_helper_fildll_ST0(cpu_env, cpu_tmp1_i64);\n                break;\n            case 0x3f: /* fistpll */\n                gen_helper_fistll_ST0(cpu_tmp1_i64, cpu_env);\n                tcg_gen_qemu_st_i64(cpu_tmp1_i64, cpu_A0, s->mem_index, MO_LEQ);\n                gen_helper_fpop(cpu_env);\n                break;\n            default:\n                goto unknown_op;\n            }\n        } else {\n            /* register float ops */\n            opreg = rm;\n            switch(op) {\n            case 0x08: /* fld sti */\n                gen_helper_fpush(cpu_env);\n                gen_helper_fmov_ST0_STN(cpu_env,\n                                        tcg_const_i32((opreg + 1) & 7));\n                break;\n            case 0x09: /* fxchg sti */\n            case 0x29: /* fxchg4 sti, undocumented op */\n            case 0x39: /* fxchg7 sti, undocumented op */\n                gen_helper_fxchg_ST0_STN(cpu_env, tcg_const_i32(opreg));\n                break;\n            case 0x0a: /* grp d9/2 */\n                switch(rm) {\n                case 0: /* fnop */\n                    /* check exceptions (FreeBSD FPU probe) */\n                    gen_helper_fwait(cpu_env);\n                    break;\n                default:\n                    goto unknown_op;\n                }\n                break;\n            case 0x0c: /* grp d9/4 */\n                switch(rm) {\n                case 0: /* fchs */\n                    gen_helper_fchs_ST0(cpu_env);\n                    break;\n                case 1: /* fabs */\n                    gen_helper_fabs_ST0(cpu_env);\n                    break;\n                case 4: /* ftst */\n                    gen_helper_fldz_FT0(cpu_env);\n                    gen_helper_fcom_ST0_FT0(cpu_env);\n                    break;\n                case 5: /* fxam */\n                    gen_helper_fxam_ST0(cpu_env);\n                    break;\n                default:\n                    goto unknown_op;\n                }\n                break;\n            case 0x0d: /* grp d9/5 */\n                {\n                    switch(rm) {\n                    case 0:\n                        gen_helper_fpush(cpu_env);\n                        gen_helper_fld1_ST0(cpu_env);\n                        break;\n                    case 1:\n                        gen_helper_fpush(cpu_env);\n                        gen_helper_fldl2t_ST0(cpu_env);\n                        break;\n                    case 2:\n                        gen_helper_fpush(cpu_env);\n                        gen_helper_fldl2e_ST0(cpu_env);\n                        break;\n                    case 3:\n                        gen_helper_fpush(cpu_env);\n                        gen_helper_fldpi_ST0(cpu_env);\n                        break;\n                    case 4:\n                        gen_helper_fpush(cpu_env);\n                        gen_helper_fldlg2_ST0(cpu_env);\n                        break;\n                    case 5:\n                        gen_helper_fpush(cpu_env);\n                        gen_helper_fldln2_ST0(cpu_env);\n                        break;\n                    case 6:\n                        gen_helper_fpush(cpu_env);\n                        gen_helper_fldz_ST0(cpu_env);\n                        break;\n                    default:\n                        goto unknown_op;\n                    }\n                }\n                break;\n            case 0x0e: /* grp d9/6 */\n                switch(rm) {\n                case 0: /* f2xm1 */\n                    gen_helper_f2xm1(cpu_env);\n                    break;\n                case 1: /* fyl2x */\n                    gen_helper_fyl2x(cpu_env);\n                    break;\n                case 2: /* fptan */\n                    gen_helper_fptan(cpu_env);\n                    break;\n                case 3: /* fpatan */\n                    gen_helper_fpatan(cpu_env);\n                    break;\n                case 4: /* fxtract */\n                    gen_helper_fxtract(cpu_env);\n                    break;\n                case 5: /* fprem1 */\n                    gen_helper_fprem1(cpu_env);\n                    break;\n                case 6: /* fdecstp */\n                    gen_helper_fdecstp(cpu_env);\n                    break;\n                default:\n                case 7: /* fincstp */\n                    gen_helper_fincstp(cpu_env);\n                    break;\n                }\n                break;\n            case 0x0f: /* grp d9/7 */\n                switch(rm) {\n                case 0: /* fprem */\n                    gen_helper_fprem(cpu_env);\n                    break;\n                case 1: /* fyl2xp1 */\n                    gen_helper_fyl2xp1(cpu_env);\n                    break;\n                case 2: /* fsqrt */\n                    gen_helper_fsqrt(cpu_env);\n                    break;\n                case 3: /* fsincos */\n                    gen_helper_fsincos(cpu_env);\n                    break;\n                case 5: /* fscale */\n                    gen_helper_fscale(cpu_env);\n                    break;\n                case 4: /* frndint */\n                    gen_helper_frndint(cpu_env);\n                    break;\n                case 6: /* fsin */\n                    gen_helper_fsin(cpu_env);\n                    break;\n                default:\n                case 7: /* fcos */\n                    gen_helper_fcos(cpu_env);\n                    break;\n                }\n                break;\n            case 0x00: case 0x01: case 0x04 ... 0x07: /* fxxx st, sti */\n            case 0x20: case 0x21: case 0x24 ... 0x27: /* fxxx sti, st */\n            case 0x30: case 0x31: case 0x34 ... 0x37: /* fxxxp sti, st */\n                {\n                    int op1;\n                    op1 = op & 7;\n                    if (op >= 0x20) {\n                        gen_helper_fp_arith_STN_ST0(op1, opreg);\n                        if (op >= 0x30)\n                            gen_helper_fpop(cpu_env);\n                    } else {\n                        gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg));\n                        gen_helper_fp_arith_ST0_FT0(op1);\n                    }\n                }\n                break;\n            case 0x02: /* fcom */\n            case 0x22: /* fcom2, undocumented op */\n                gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fcom_ST0_FT0(cpu_env);\n                break;\n            case 0x03: /* fcomp */\n            case 0x23: /* fcomp3, undocumented op */\n            case 0x32: /* fcomp5, undocumented op */\n                gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fcom_ST0_FT0(cpu_env);\n                gen_helper_fpop(cpu_env);\n                break;\n            case 0x15: /* da/5 */\n                switch(rm) {\n                case 1: /* fucompp */\n                    gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(1));\n                    gen_helper_fucom_ST0_FT0(cpu_env);\n                    gen_helper_fpop(cpu_env);\n                    gen_helper_fpop(cpu_env);\n                    break;\n                default:\n                    goto unknown_op;\n                }\n                break;\n            case 0x1c:\n                switch(rm) {\n                case 0: /* feni (287 only, just do nop here) */\n                    break;\n                case 1: /* fdisi (287 only, just do nop here) */\n                    break;\n                case 2: /* fclex */\n                    gen_helper_fclex(cpu_env);\n                    break;\n                case 3: /* fninit */\n                    gen_helper_fninit(cpu_env);\n                    break;\n                case 4: /* fsetpm (287 only, just do nop here) */\n                    break;\n                default:\n                    goto unknown_op;\n                }\n                break;\n            case 0x1d: /* fucomi */\n                if (!(s->cpuid_features & CPUID_CMOV)) {\n                    goto illegal_op;\n                }\n                gen_update_cc_op(s);\n                gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fucomi_ST0_FT0(cpu_env);\n                set_cc_op(s, CC_OP_EFLAGS);\n                break;\n            case 0x1e: /* fcomi */\n                if (!(s->cpuid_features & CPUID_CMOV)) {\n                    goto illegal_op;\n                }\n                gen_update_cc_op(s);\n                gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fcomi_ST0_FT0(cpu_env);\n                set_cc_op(s, CC_OP_EFLAGS);\n                break;\n            case 0x28: /* ffree sti */\n                gen_helper_ffree_STN(cpu_env, tcg_const_i32(opreg));\n                break;\n            case 0x2a: /* fst sti */\n                gen_helper_fmov_STN_ST0(cpu_env, tcg_const_i32(opreg));\n                break;\n            case 0x2b: /* fstp sti */\n            case 0x0b: /* fstp1 sti, undocumented op */\n            case 0x3a: /* fstp8 sti, undocumented op */\n            case 0x3b: /* fstp9 sti, undocumented op */\n                gen_helper_fmov_STN_ST0(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fpop(cpu_env);\n                break;\n            case 0x2c: /* fucom st(i) */\n                gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fucom_ST0_FT0(cpu_env);\n                break;\n            case 0x2d: /* fucomp st(i) */\n                gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fucom_ST0_FT0(cpu_env);\n                gen_helper_fpop(cpu_env);\n                break;\n            case 0x33: /* de/3 */\n                switch(rm) {\n                case 1: /* fcompp */\n                    gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(1));\n                    gen_helper_fcom_ST0_FT0(cpu_env);\n                    gen_helper_fpop(cpu_env);\n                    gen_helper_fpop(cpu_env);\n                    break;\n                default:\n                    goto unknown_op;\n                }\n                break;\n            case 0x38: /* ffreep sti, undocumented op */\n                gen_helper_ffree_STN(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fpop(cpu_env);\n                break;\n            case 0x3c: /* df/4 */\n                switch(rm) {\n                case 0:\n                    gen_helper_fnstsw(cpu_tmp2_i32, cpu_env);\n                    tcg_gen_extu_i32_tl(cpu_T0, cpu_tmp2_i32);\n                    gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0);\n                    break;\n                default:\n                    goto unknown_op;\n                }\n                break;\n            case 0x3d: /* fucomip */\n                if (!(s->cpuid_features & CPUID_CMOV)) {\n                    goto illegal_op;\n                }\n                gen_update_cc_op(s);\n                gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fucomi_ST0_FT0(cpu_env);\n                gen_helper_fpop(cpu_env);\n                set_cc_op(s, CC_OP_EFLAGS);\n                break;\n            case 0x3e: /* fcomip */\n                if (!(s->cpuid_features & CPUID_CMOV)) {\n                    goto illegal_op;\n                }\n                gen_update_cc_op(s);\n                gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg));\n                gen_helper_fcomi_ST0_FT0(cpu_env);\n                gen_helper_fpop(cpu_env);\n                set_cc_op(s, CC_OP_EFLAGS);\n                break;\n            case 0x10 ... 0x13: /* fcmovxx */\n            case 0x18 ... 0x1b:\n                {\n                    int op1;\n                    TCGLabel *l1;\n                    static const uint8_t fcmov_cc[8] = {\n                        (JCC_B << 1),\n                        (JCC_Z << 1),\n                        (JCC_BE << 1),\n                        (JCC_P << 1),\n                    };\n                    if (!(s->cpuid_features & CPUID_CMOV)) {\n                        goto illegal_op;\n                    }\n                    op1 = fcmov_cc[op & 3] | (((op >> 3) & 1) ^ 1);\n                    l1 = gen_new_label();\n                    gen_jcc1_noeob(s, op1, l1);\n                    gen_helper_fmov_ST0_STN(cpu_env, tcg_const_i32(opreg));\n                    gen_set_label(l1);\n                }\n                break;\n            default:\n                goto unknown_op;\n            }\n        }\n        break;\n        /************************/\n        /* string ops */\n    case 0xa4: /* movsS */\n    case 0xa5:\n        ot = mo_b_d(b, dflag);\n        if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) {\n            gen_repz_movs(s, ot, pc_start - s->cs_base, s->pc - s->cs_base);\n        } else {\n            gen_movs(s, ot);\n        }\n        break;\n    case 0xaa: /* stosS */\n    case 0xab:\n        ot = mo_b_d(b, dflag);\n        if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) {\n            gen_repz_stos(s, ot, pc_start - s->cs_base, s->pc - s->cs_base);\n        } else {\n            gen_stos(s, ot);\n        }\n        break;\n    case 0xac: /* lodsS */\n    case 0xad:\n        ot = mo_b_d(b, dflag);\n        if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) {\n            gen_repz_lods(s, ot, pc_start - s->cs_base, s->pc - s->cs_base);\n        } else {\n            gen_lods(s, ot);\n        }\n        break;\n    case 0xae: /* scasS */\n    case 0xaf:\n        ot = mo_b_d(b, dflag);\n        if (prefixes & PREFIX_REPNZ) {\n            gen_repz_scas(s, ot, pc_start - s->cs_base, s->pc - s->cs_base, 1);\n        } else if (prefixes & PREFIX_REPZ) {\n            gen_repz_scas(s, ot, pc_start - s->cs_base, s->pc - s->cs_base, 0);\n        } else {\n            gen_scas(s, ot);\n        }\n        break;\n    case 0xa6: /* cmpsS */\n    case 0xa7:\n        ot = mo_b_d(b, dflag);\n        if (prefixes & PREFIX_REPNZ) {\n            gen_repz_cmps(s, ot, pc_start - s->cs_base, s->pc - s->cs_base, 1);\n        } else if (prefixes & PREFIX_REPZ) {\n            gen_repz_cmps(s, ot, pc_start - s->cs_base, s->pc - s->cs_base, 0);\n        } else {\n            gen_cmps(s, ot);\n        }\n        break;\n    case 0x6c: /* insS */\n    case 0x6d:\n        ot = mo_b_d32(b, dflag);\n        tcg_gen_ext16u_tl(cpu_T0, cpu_regs[R_EDX]);\n        gen_check_io(s, ot, pc_start - s->cs_base, \n                     SVM_IOIO_TYPE_MASK | svm_is_rep(prefixes) | 4);\n        if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) {\n            gen_repz_ins(s, ot, pc_start - s->cs_base, s->pc - s->cs_base);\n        } else {\n            gen_ins(s, ot);\n            if (s->base.tb->cflags & CF_USE_ICOUNT) {\n                gen_jmp(s, s->pc - s->cs_base);\n            }\n        }\n        break;\n    case 0x6e: /* outsS */\n    case 0x6f:\n        ot = mo_b_d32(b, dflag);\n        tcg_gen_ext16u_tl(cpu_T0, cpu_regs[R_EDX]);\n        gen_check_io(s, ot, pc_start - s->cs_base,\n                     svm_is_rep(prefixes) | 4);\n        if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) {\n            gen_repz_outs(s, ot, pc_start - s->cs_base, s->pc - s->cs_base);\n        } else {\n            gen_outs(s, ot);\n            if (s->base.tb->cflags & CF_USE_ICOUNT) {\n                gen_jmp(s, s->pc - s->cs_base);\n            }\n        }\n        break;\n        /************************/\n        /* port I/O */\n    case 0xe4:\n    case 0xe5:\n        ot = mo_b_d32(b, dflag);\n        val = x86_ldub_code(env, s);\n        tcg_gen_movi_tl(cpu_T0, val);\n        gen_check_io(s, ot, pc_start - s->cs_base,\n                     SVM_IOIO_TYPE_MASK | svm_is_rep(prefixes));\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_start();\n	}\n        tcg_gen_movi_i32(cpu_tmp2_i32, val);\n        gen_helper_in_func(ot, cpu_T1, cpu_tmp2_i32);\n        gen_op_mov_reg_v(ot, R_EAX, cpu_T1);\n        gen_bpt_io(s, cpu_tmp2_i32, ot);\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_end();\n            gen_jmp(s, s->pc - s->cs_base);\n        }\n        break;\n    case 0xe6:\n    case 0xe7:\n        ot = mo_b_d32(b, dflag);\n        val = x86_ldub_code(env, s);\n        tcg_gen_movi_tl(cpu_T0, val);\n        gen_check_io(s, ot, pc_start - s->cs_base,\n                     svm_is_rep(prefixes));\n        gen_op_mov_v_reg(ot, cpu_T1, R_EAX);\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_start();\n	}\n        tcg_gen_movi_i32(cpu_tmp2_i32, val);\n        tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_T1);\n        gen_helper_out_func(ot, cpu_tmp2_i32, cpu_tmp3_i32);\n        gen_bpt_io(s, cpu_tmp2_i32, ot);\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_end();\n            gen_jmp(s, s->pc - s->cs_base);\n        }\n        break;\n    case 0xec:\n    case 0xed:\n        ot = mo_b_d32(b, dflag);\n        tcg_gen_ext16u_tl(cpu_T0, cpu_regs[R_EDX]);\n        gen_check_io(s, ot, pc_start - s->cs_base,\n                     SVM_IOIO_TYPE_MASK | svm_is_rep(prefixes));\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_start();\n	}\n        tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n        gen_helper_in_func(ot, cpu_T1, cpu_tmp2_i32);\n        gen_op_mov_reg_v(ot, R_EAX, cpu_T1);\n        gen_bpt_io(s, cpu_tmp2_i32, ot);\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_end();\n            gen_jmp(s, s->pc - s->cs_base);\n        }\n        break;\n    case 0xee:\n    case 0xef:\n        ot = mo_b_d32(b, dflag);\n        tcg_gen_ext16u_tl(cpu_T0, cpu_regs[R_EDX]);\n        gen_check_io(s, ot, pc_start - s->cs_base,\n                     svm_is_rep(prefixes));\n        gen_op_mov_v_reg(ot, cpu_T1, R_EAX);\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_start();\n	}\n        tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n        tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_T1);\n        gen_helper_out_func(ot, cpu_tmp2_i32, cpu_tmp3_i32);\n        gen_bpt_io(s, cpu_tmp2_i32, ot);\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_end();\n            gen_jmp(s, s->pc - s->cs_base);\n        }\n        break;\n        /************************/\n        /* control */\n    case 0xc2: /* ret im */\n        val = x86_ldsw_code(env, s);\n        ot = gen_pop_T0(s);\n        gen_stack_update(s, val + (1 << ot));\n        /* Note that gen_pop_T0 uses a zero-extending load.  */\n        gen_op_jmp_v(cpu_T0);\n        gen_bnd_jmp(s);\n        gen_jr(s, cpu_T0);\n        break;\n    case 0xc3: /* ret */\n        ot = gen_pop_T0(s);\n        gen_pop_update(s, ot);\n        /* Note that gen_pop_T0 uses a zero-extending load.  */\n        gen_op_jmp_v(cpu_T0);\n        gen_bnd_jmp(s);\n        gen_jr(s, cpu_T0);\n        break;\n    case 0xca: /* lret im */\n        val = x86_ldsw_code(env, s);\n    do_lret:\n        if (s->pe && !s->vm86) {\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_lret_protected(cpu_env, tcg_const_i32(dflag - 1),\n                                      tcg_const_i32(val));\n        } else {\n            gen_stack_A0(s);\n            /* pop offset */\n            gen_op_ld_v(s, dflag, cpu_T0, cpu_A0);\n            /* NOTE: keeping EIP updated is not a problem in case of\n               exception */\n            gen_op_jmp_v(cpu_T0);\n            /* pop selector */\n            gen_add_A0_im(s, 1 << dflag);\n            gen_op_ld_v(s, dflag, cpu_T0, cpu_A0);\n            gen_op_movl_seg_T0_vm(R_CS);\n            /* add stack offset */\n            gen_stack_update(s, val + (2 << dflag));\n        }\n        gen_eob(s);\n        break;\n    case 0xcb: /* lret */\n        val = 0;\n        goto do_lret;\n    case 0xcf: /* iret */\n        gen_svm_check_intercept(s, pc_start, SVM_EXIT_IRET);\n        if (!s->pe) {\n            /* real mode */\n            gen_helper_iret_real(cpu_env, tcg_const_i32(dflag - 1));\n            set_cc_op(s, CC_OP_EFLAGS);\n        } else if (s->vm86) {\n            if (s->iopl != 3) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n            } else {\n                gen_helper_iret_real(cpu_env, tcg_const_i32(dflag - 1));\n                set_cc_op(s, CC_OP_EFLAGS);\n            }\n        } else {\n            gen_helper_iret_protected(cpu_env, tcg_const_i32(dflag - 1),\n                                      tcg_const_i32(s->pc - s->cs_base));\n            set_cc_op(s, CC_OP_EFLAGS);\n        }\n        gen_eob(s);\n        break;\n    case 0xe8: /* call im */\n        {\n            if (dflag != MO_16) {\n                tval = (int32_t)insn_get(env, s, MO_32);\n            } else {\n                tval = (int16_t)insn_get(env, s, MO_16);\n            }\n            next_eip = s->pc - s->cs_base;\n            tval += next_eip;\n            if (dflag == MO_16) {\n                tval &= 0xffff;\n            } else if (!CODE64(s)) {\n                tval &= 0xffffffff;\n            }\n            tcg_gen_movi_tl(cpu_T0, next_eip);\n            gen_push_v(s, cpu_T0);\n            gen_bnd_jmp(s);\n            gen_jmp(s, tval);\n        }\n        break;\n    case 0x9a: /* lcall im */\n        {\n            unsigned int selector, offset;\n            if (CODE64(s))\n                goto illegal_op;\n            ot = dflag;\n            offset = insn_get(env, s, ot);\n            selector = insn_get(env, s, MO_16);\n            tcg_gen_movi_tl(cpu_T0, selector);\n            tcg_gen_movi_tl(cpu_T1, offset);\n        }\n        goto do_lcall;\n    case 0xe9: /* jmp im */\n        if (dflag != MO_16) {\n            tval = (int32_t)insn_get(env, s, MO_32);\n        } else {\n            tval = (int16_t)insn_get(env, s, MO_16);\n        }\n        tval += s->pc - s->cs_base;\n        if (dflag == MO_16) {\n            tval &= 0xffff;\n        } else if (!CODE64(s)) {\n            tval &= 0xffffffff;\n        }\n        gen_bnd_jmp(s);\n        gen_jmp(s, tval);\n        break;\n    case 0xea: /* ljmp im */\n        {\n            unsigned int selector, offset;\n            if (CODE64(s))\n                goto illegal_op;\n            ot = dflag;\n            offset = insn_get(env, s, ot);\n            selector = insn_get(env, s, MO_16);\n            tcg_gen_movi_tl(cpu_T0, selector);\n            tcg_gen_movi_tl(cpu_T1, offset);\n        }\n        goto do_ljmp;\n    case 0xeb: /* jmp Jb */\n        tval = (int8_t)insn_get(env, s, MO_8);\n        tval += s->pc - s->cs_base;\n        if (dflag == MO_16) {\n            tval &= 0xffff;\n        }\n        gen_jmp(s, tval);\n        break;\n    case 0x70 ... 0x7f: /* jcc Jb */\n        tval = (int8_t)insn_get(env, s, MO_8);\n        goto do_jcc;\n    case 0x180 ... 0x18f: /* jcc Jv */\n        if (dflag != MO_16) {\n            tval = (int32_t)insn_get(env, s, MO_32);\n        } else {\n            tval = (int16_t)insn_get(env, s, MO_16);\n        }\n    do_jcc:\n        next_eip = s->pc - s->cs_base;\n        tval += next_eip;\n        if (dflag == MO_16) {\n            tval &= 0xffff;\n        }\n        gen_bnd_jmp(s);\n        gen_jcc(s, b, tval, next_eip);\n        break;\n    case 0x190 ... 0x19f: /* setcc Gv */\n        modrm = x86_ldub_code(env, s);\n        gen_setcc1(s, b, cpu_T0);\n        gen_ldst_modrm(env, s, modrm, MO_8, OR_TMP0, 1);\n        break;\n    case 0x140 ... 0x14f: /* cmov Gv, Ev */\n        if (!(s->cpuid_features & CPUID_CMOV)) {\n            goto illegal_op;\n        }\n        ot = dflag;\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        gen_cmovcc1(env, s, ot, b, modrm, reg);\n        break;\n        /************************/\n        /* flags */\n    case 0x9c: /* pushf */\n        gen_svm_check_intercept(s, pc_start, SVM_EXIT_PUSHF);\n        if (s->vm86 && s->iopl != 3) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            gen_update_cc_op(s);\n            gen_helper_read_eflags(cpu_T0, cpu_env);\n            gen_push_v(s, cpu_T0);\n        }\n        break;\n    case 0x9d: /* popf */\n        gen_svm_check_intercept(s, pc_start, SVM_EXIT_POPF);\n        if (s->vm86 && s->iopl != 3) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            ot = gen_pop_T0(s);\n            if (s->cpl == 0) {\n                if (dflag != MO_16) {\n                    gen_helper_write_eflags(cpu_env, cpu_T0,\n                                            tcg_const_i32((TF_MASK | AC_MASK |\n                                                           ID_MASK | NT_MASK |\n                                                           IF_MASK |\n                                                           IOPL_MASK)));\n                } else {\n                    gen_helper_write_eflags(cpu_env, cpu_T0,\n                                            tcg_const_i32((TF_MASK | AC_MASK |\n                                                           ID_MASK | NT_MASK |\n                                                           IF_MASK | IOPL_MASK)\n                                                          & 0xffff));\n                }\n            } else {\n                if (s->cpl <= s->iopl) {\n                    if (dflag != MO_16) {\n                        gen_helper_write_eflags(cpu_env, cpu_T0,\n                                                tcg_const_i32((TF_MASK |\n                                                               AC_MASK |\n                                                               ID_MASK |\n                                                               NT_MASK |\n                                                               IF_MASK)));\n                    } else {\n                        gen_helper_write_eflags(cpu_env, cpu_T0,\n                                                tcg_const_i32((TF_MASK |\n                                                               AC_MASK |\n                                                               ID_MASK |\n                                                               NT_MASK |\n                                                               IF_MASK)\n                                                              & 0xffff));\n                    }\n                } else {\n                    if (dflag != MO_16) {\n                        gen_helper_write_eflags(cpu_env, cpu_T0,\n                                           tcg_const_i32((TF_MASK | AC_MASK |\n                                                          ID_MASK | NT_MASK)));\n                    } else {\n                        gen_helper_write_eflags(cpu_env, cpu_T0,\n                                           tcg_const_i32((TF_MASK | AC_MASK |\n                                                          ID_MASK | NT_MASK)\n                                                         & 0xffff));\n                    }\n                }\n            }\n            gen_pop_update(s, ot);\n            set_cc_op(s, CC_OP_EFLAGS);\n            /* abort translation because TF/AC flag may change */\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n        }\n        break;\n    case 0x9e: /* sahf */\n        if (CODE64(s) && !(s->cpuid_ext3_features & CPUID_EXT3_LAHF_LM))\n            goto illegal_op;\n        gen_op_mov_v_reg(MO_8, cpu_T0, R_AH);\n        gen_compute_eflags(s);\n        tcg_gen_andi_tl(cpu_cc_src, cpu_cc_src, CC_O);\n        tcg_gen_andi_tl(cpu_T0, cpu_T0, CC_S | CC_Z | CC_A | CC_P | CC_C);\n        tcg_gen_or_tl(cpu_cc_src, cpu_cc_src, cpu_T0);\n        break;\n    case 0x9f: /* lahf */\n        if (CODE64(s) && !(s->cpuid_ext3_features & CPUID_EXT3_LAHF_LM))\n            goto illegal_op;\n        gen_compute_eflags(s);\n        /* Note: gen_compute_eflags() only gives the condition codes */\n        tcg_gen_ori_tl(cpu_T0, cpu_cc_src, 0x02);\n        gen_op_mov_reg_v(MO_8, R_AH, cpu_T0);\n        break;\n    case 0xf5: /* cmc */\n        gen_compute_eflags(s);\n        tcg_gen_xori_tl(cpu_cc_src, cpu_cc_src, CC_C);\n        break;\n    case 0xf8: /* clc */\n        gen_compute_eflags(s);\n        tcg_gen_andi_tl(cpu_cc_src, cpu_cc_src, ~CC_C);\n        break;\n    case 0xf9: /* stc */\n        gen_compute_eflags(s);\n        tcg_gen_ori_tl(cpu_cc_src, cpu_cc_src, CC_C);\n        break;\n    case 0xfc: /* cld */\n        tcg_gen_movi_i32(cpu_tmp2_i32, 1);\n        tcg_gen_st_i32(cpu_tmp2_i32, cpu_env, offsetof(CPUX86State, df));\n        break;\n    case 0xfd: /* std */\n        tcg_gen_movi_i32(cpu_tmp2_i32, -1);\n        tcg_gen_st_i32(cpu_tmp2_i32, cpu_env, offsetof(CPUX86State, df));\n        break;\n        /************************/\n        /* bit operations */\n    case 0x1ba: /* bt/bts/btr/btc Gv, im */\n        ot = dflag;\n        modrm = x86_ldub_code(env, s);\n        op = (modrm >> 3) & 7;\n        mod = (modrm >> 6) & 3;\n        rm = (modrm & 7) | REX_B(s);\n        if (mod != 3) {\n            s->rip_offset = 1;\n            gen_lea_modrm(env, s, modrm);\n            if (!(s->prefix & PREFIX_LOCK)) {\n                gen_op_ld_v(s, ot, cpu_T0, cpu_A0);\n            }\n        } else {\n            gen_op_mov_v_reg(ot, cpu_T0, rm);\n        }\n        /* load shift */\n        val = x86_ldub_code(env, s);\n        tcg_gen_movi_tl(cpu_T1, val);\n        if (op < 4)\n            goto unknown_op;\n        op -= 4;\n        goto bt_op;\n    case 0x1a3: /* bt Gv, Ev */\n        op = 0;\n        goto do_btx;\n    case 0x1ab: /* bts */\n        op = 1;\n        goto do_btx;\n    case 0x1b3: /* btr */\n        op = 2;\n        goto do_btx;\n    case 0x1bb: /* btc */\n        op = 3;\n    do_btx:\n        ot = dflag;\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        mod = (modrm >> 6) & 3;\n        rm = (modrm & 7) | REX_B(s);\n        gen_op_mov_v_reg(MO_32, cpu_T1, reg);\n        if (mod != 3) {\n            AddressParts a = gen_lea_modrm_0(env, s, modrm);\n            /* specific case: we need to add a displacement */\n            gen_exts(ot, cpu_T1);\n            tcg_gen_sari_tl(cpu_tmp0, cpu_T1, 3 + ot);\n            tcg_gen_shli_tl(cpu_tmp0, cpu_tmp0, ot);\n            tcg_gen_add_tl(cpu_A0, gen_lea_modrm_1(a), cpu_tmp0);\n            gen_lea_v_seg(s, s->aflag, cpu_A0, a.def_seg, s->override);\n            if (!(s->prefix & PREFIX_LOCK)) {\n                gen_op_ld_v(s, ot, cpu_T0, cpu_A0);\n            }\n        } else {\n            gen_op_mov_v_reg(ot, cpu_T0, rm);\n        }\n    bt_op:\n        tcg_gen_andi_tl(cpu_T1, cpu_T1, (1 << (3 + ot)) - 1);\n        tcg_gen_movi_tl(cpu_tmp0, 1);\n        tcg_gen_shl_tl(cpu_tmp0, cpu_tmp0, cpu_T1);\n        if (s->prefix & PREFIX_LOCK) {\n            switch (op) {\n            case 0: /* bt */\n                /* Needs no atomic ops; we surpressed the normal\n                   memory load for LOCK above so do it now.  */\n                gen_op_ld_v(s, ot, cpu_T0, cpu_A0);\n                break;\n            case 1: /* bts */\n                tcg_gen_atomic_fetch_or_tl(cpu_T0, cpu_A0, cpu_tmp0,\n                                           s->mem_index, ot | MO_LE);\n                break;\n            case 2: /* btr */\n                tcg_gen_not_tl(cpu_tmp0, cpu_tmp0);\n                tcg_gen_atomic_fetch_and_tl(cpu_T0, cpu_A0, cpu_tmp0,\n                                            s->mem_index, ot | MO_LE);\n                break;\n            default:\n            case 3: /* btc */\n                tcg_gen_atomic_fetch_xor_tl(cpu_T0, cpu_A0, cpu_tmp0,\n                                            s->mem_index, ot | MO_LE);\n                break;\n            }\n            tcg_gen_shr_tl(cpu_tmp4, cpu_T0, cpu_T1);\n        } else {\n            tcg_gen_shr_tl(cpu_tmp4, cpu_T0, cpu_T1);\n            switch (op) {\n            case 0: /* bt */\n                /* Data already loaded; nothing to do.  */\n                break;\n            case 1: /* bts */\n                tcg_gen_or_tl(cpu_T0, cpu_T0, cpu_tmp0);\n                break;\n            case 2: /* btr */\n                tcg_gen_andc_tl(cpu_T0, cpu_T0, cpu_tmp0);\n                break;\n            default:\n            case 3: /* btc */\n                tcg_gen_xor_tl(cpu_T0, cpu_T0, cpu_tmp0);\n                break;\n            }\n            if (op != 0) {\n                if (mod != 3) {\n                    gen_op_st_v(s, ot, cpu_T0, cpu_A0);\n                } else {\n                    gen_op_mov_reg_v(ot, rm, cpu_T0);\n                }\n            }\n        }\n        /* Delay all CC updates until after the store above.  Note that\n           C is the result of the test, Z is unchanged, and the others\n           are all undefined.  */\n        switch (s->cc_op) {\n        case CC_OP_MULB ... CC_OP_MULQ:\n        case CC_OP_ADDB ... CC_OP_ADDQ:\n        case CC_OP_ADCB ... CC_OP_ADCQ:\n        case CC_OP_SUBB ... CC_OP_SUBQ:\n        case CC_OP_SBBB ... CC_OP_SBBQ:\n        case CC_OP_LOGICB ... CC_OP_LOGICQ:\n        case CC_OP_INCB ... CC_OP_INCQ:\n        case CC_OP_DECB ... CC_OP_DECQ:\n        case CC_OP_SHLB ... CC_OP_SHLQ:\n        case CC_OP_SARB ... CC_OP_SARQ:\n        case CC_OP_BMILGB ... CC_OP_BMILGQ:\n            /* Z was going to be computed from the non-zero status of CC_DST.\n               We can get that same Z value (and the new C value) by leaving\n               CC_DST alone, setting CC_SRC, and using a CC_OP_SAR of the\n               same width.  */\n            tcg_gen_mov_tl(cpu_cc_src, cpu_tmp4);\n            set_cc_op(s, ((s->cc_op - CC_OP_MULB) & 3) + CC_OP_SARB);\n            break;\n        default:\n            /* Otherwise, generate EFLAGS and replace the C bit.  */\n            gen_compute_eflags(s);\n            tcg_gen_deposit_tl(cpu_cc_src, cpu_cc_src, cpu_tmp4,\n                               ctz32(CC_C), 1);\n            break;\n        }\n        break;\n    case 0x1bc: /* bsf / tzcnt */\n    case 0x1bd: /* bsr / lzcnt */\n        ot = dflag;\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0);\n        gen_extu(ot, cpu_T0);\n        /* Note that lzcnt and tzcnt are in different extensions.  */\n        if ((prefixes & PREFIX_REPZ)\n            && (b & 1\n                ? s->cpuid_ext3_features & CPUID_EXT3_ABM\n                : s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_BMI1)) {\n            int size = 8 << ot;\n            /* For lzcnt/tzcnt, C bit is defined related to the input. */\n            tcg_gen_mov_tl(cpu_cc_src, cpu_T0);\n            if (b & 1) {\n                /* For lzcnt, reduce the target_ulong result by the\n                   number of zeros that we expect to find at the top.  */\n                tcg_gen_clzi_tl(cpu_T0, cpu_T0, TARGET_LONG_BITS);\n                tcg_gen_subi_tl(cpu_T0, cpu_T0, TARGET_LONG_BITS - size);\n            } else {\n                /* For tzcnt, a zero input must return the operand size.  */\n                tcg_gen_ctzi_tl(cpu_T0, cpu_T0, size);\n            }\n            /* For lzcnt/tzcnt, Z bit is defined related to the result.  */\n            gen_op_update1_cc();\n            set_cc_op(s, CC_OP_BMILGB + ot);\n        } else {\n            /* For bsr/bsf, only the Z bit is defined and it is related\n               to the input and not the result.  */\n            tcg_gen_mov_tl(cpu_cc_dst, cpu_T0);\n            set_cc_op(s, CC_OP_LOGICB + ot);\n            /* ??? The manual says that the output is undefined when the\n               input is zero, but real hardware leaves it unchanged, and\n               real programs appear to depend on that.  Accomplish this\n               by passing the output as the value to return upon zero.  */\n            if (b & 1) {\n                /* For bsr, return the bit index of the first 1 bit,\n                   not the count of leading zeros.  */\n                tcg_gen_xori_tl(cpu_T1, cpu_regs[reg], TARGET_LONG_BITS - 1);\n                tcg_gen_clz_tl(cpu_T0, cpu_T0, cpu_T1);\n                tcg_gen_xori_tl(cpu_T0, cpu_T0, TARGET_LONG_BITS - 1);\n            } else {\n                tcg_gen_ctz_tl(cpu_T0, cpu_T0, cpu_regs[reg]);\n            }\n        }\n        gen_op_mov_reg_v(ot, reg, cpu_T0);\n        break;\n        /************************/\n        /* bcd */\n    case 0x27: /* daa */\n        if (CODE64(s))\n            goto illegal_op;\n        gen_update_cc_op(s);\n        gen_helper_daa(cpu_env);\n        set_cc_op(s, CC_OP_EFLAGS);\n        break;\n    case 0x2f: /* das */\n        if (CODE64(s))\n            goto illegal_op;\n        gen_update_cc_op(s);\n        gen_helper_das(cpu_env);\n        set_cc_op(s, CC_OP_EFLAGS);\n        break;\n    case 0x37: /* aaa */\n        if (CODE64(s))\n            goto illegal_op;\n        gen_update_cc_op(s);\n        gen_helper_aaa(cpu_env);\n        set_cc_op(s, CC_OP_EFLAGS);\n        break;\n    case 0x3f: /* aas */\n        if (CODE64(s))\n            goto illegal_op;\n        gen_update_cc_op(s);\n        gen_helper_aas(cpu_env);\n        set_cc_op(s, CC_OP_EFLAGS);\n        break;\n    case 0xd4: /* aam */\n        if (CODE64(s))\n            goto illegal_op;\n        val = x86_ldub_code(env, s);\n        if (val == 0) {\n            gen_exception(s, EXCP00_DIVZ, pc_start - s->cs_base);\n        } else {\n            gen_helper_aam(cpu_env, tcg_const_i32(val));\n            set_cc_op(s, CC_OP_LOGICB);\n        }\n        break;\n    case 0xd5: /* aad */\n        if (CODE64(s))\n            goto illegal_op;\n        val = x86_ldub_code(env, s);\n        gen_helper_aad(cpu_env, tcg_const_i32(val));\n        set_cc_op(s, CC_OP_LOGICB);\n        break;\n        /************************/\n        /* misc */\n    case 0x90: /* nop */\n        /* XXX: correct lock test for all insn */\n        if (prefixes & PREFIX_LOCK) {\n            goto illegal_op;\n        }\n        /* If REX_B is set, then this is xchg eax, r8d, not a nop.  */\n        if (REX_B(s)) {\n            goto do_xchg_reg_eax;\n        }\n        if (prefixes & PREFIX_REPZ) {\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_pause(cpu_env, tcg_const_i32(s->pc - pc_start));\n            s->base.is_jmp = DISAS_NORETURN;\n        }\n        break;\n    case 0x9b: /* fwait */\n        if ((s->flags & (HF_MP_MASK | HF_TS_MASK)) ==\n            (HF_MP_MASK | HF_TS_MASK)) {\n            gen_exception(s, EXCP07_PREX, pc_start - s->cs_base);\n        } else {\n            gen_helper_fwait(cpu_env);\n        }\n        break;\n    case 0xcc: /* int3 */\n        gen_interrupt(s, EXCP03_INT3, pc_start - s->cs_base, s->pc - s->cs_base);\n        break;\n    case 0xcd: /* int N */\n        val = x86_ldub_code(env, s);\n        if (s->vm86 && s->iopl != 3) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            gen_interrupt(s, val, pc_start - s->cs_base, s->pc - s->cs_base);\n        }\n        break;\n    case 0xce: /* into */\n        if (CODE64(s))\n            goto illegal_op;\n        gen_update_cc_op(s);\n        gen_jmp_im(pc_start - s->cs_base);\n        gen_helper_into(cpu_env, tcg_const_i32(s->pc - pc_start));\n        break;\n#ifdef WANT_ICEBP\n    case 0xf1: /* icebp (undocumented, exits to external debugger) */\n        gen_svm_check_intercept(s, pc_start, SVM_EXIT_ICEBP);\n#if 1\n        gen_debug(s, pc_start - s->cs_base);\n#else\n        /* start debug */\n        tb_flush(CPU(x86_env_get_cpu(env)));\n        qemu_set_log(CPU_LOG_INT | CPU_LOG_TB_IN_ASM);\n#endif\n        break;\n#endif\n    case 0xfa: /* cli */\n        if (!s->vm86) {\n            if (s->cpl <= s->iopl) {\n                gen_helper_cli(cpu_env);\n            } else {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n            }\n        } else {\n            if (s->iopl == 3) {\n                gen_helper_cli(cpu_env);\n            } else {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n            }\n        }\n        break;\n    case 0xfb: /* sti */\n        if (s->vm86 ? s->iopl == 3 : s->cpl <= s->iopl) {\n            gen_helper_sti(cpu_env);\n            /* interruptions are enabled only the first insn after sti */\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob_inhibit_irq(s, true);\n        } else {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        }\n        break;\n    case 0x62: /* bound */\n        if (CODE64(s))\n            goto illegal_op;\n        ot = dflag;\n        modrm = x86_ldub_code(env, s);\n        reg = (modrm >> 3) & 7;\n        mod = (modrm >> 6) & 3;\n        if (mod == 3)\n            goto illegal_op;\n        gen_op_mov_v_reg(ot, cpu_T0, reg);\n        gen_lea_modrm(env, s, modrm);\n        tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n        if (ot == MO_16) {\n            gen_helper_boundw(cpu_env, cpu_A0, cpu_tmp2_i32);\n        } else {\n            gen_helper_boundl(cpu_env, cpu_A0, cpu_tmp2_i32);\n        }\n        break;\n    case 0x1c8 ... 0x1cf: /* bswap reg */\n        reg = (b & 7) | REX_B(s);\n#ifdef TARGET_X86_64\n        if (dflag == MO_64) {\n            gen_op_mov_v_reg(MO_64, cpu_T0, reg);\n            tcg_gen_bswap64_i64(cpu_T0, cpu_T0);\n            gen_op_mov_reg_v(MO_64, reg, cpu_T0);\n        } else\n#endif\n        {\n            gen_op_mov_v_reg(MO_32, cpu_T0, reg);\n            tcg_gen_ext32u_tl(cpu_T0, cpu_T0);\n            tcg_gen_bswap32_tl(cpu_T0, cpu_T0);\n            gen_op_mov_reg_v(MO_32, reg, cpu_T0);\n        }\n        break;\n    case 0xd6: /* salc */\n        if (CODE64(s))\n            goto illegal_op;\n        gen_compute_eflags_c(s, cpu_T0);\n        tcg_gen_neg_tl(cpu_T0, cpu_T0);\n        gen_op_mov_reg_v(MO_8, R_EAX, cpu_T0);\n        break;\n    case 0xe0: /* loopnz */\n    case 0xe1: /* loopz */\n    case 0xe2: /* loop */\n    case 0xe3: /* jecxz */\n        {\n            TCGLabel *l1, *l2, *l3;\n            tval = (int8_t)insn_get(env, s, MO_8);\n            next_eip = s->pc - s->cs_base;\n            tval += next_eip;\n            if (dflag == MO_16) {\n                tval &= 0xffff;\n            }\n            l1 = gen_new_label();\n            l2 = gen_new_label();\n            l3 = gen_new_label();\n            b &= 3;\n            switch(b) {\n            case 0: /* loopnz */\n            case 1: /* loopz */\n                gen_op_add_reg_im(s->aflag, R_ECX, -1);\n                gen_op_jz_ecx(s->aflag, l3);\n                gen_jcc1(s, (JCC_Z << 1) | (b ^ 1), l1);\n                break;\n            case 2: /* loop */\n                gen_op_add_reg_im(s->aflag, R_ECX, -1);\n                gen_op_jnz_ecx(s->aflag, l1);\n                break;\n            default:\n            case 3: /* jcxz */\n                gen_op_jz_ecx(s->aflag, l1);\n                break;\n            }\n            gen_set_label(l3);\n            gen_jmp_im(next_eip);\n            tcg_gen_br(l2);\n            gen_set_label(l1);\n            gen_jmp_im(tval);\n            gen_set_label(l2);\n            gen_eob(s);\n        }\n        break;\n    case 0x130: /* wrmsr */\n    case 0x132: /* rdmsr */\n        if (s->cpl != 0) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            if (b & 2) {\n                gen_helper_rdmsr(cpu_env);\n            } else {\n                gen_helper_wrmsr(cpu_env);\n            }\n        }\n        break;\n    case 0x131: /* rdtsc */\n        gen_update_cc_op(s);\n        gen_jmp_im(pc_start - s->cs_base);\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_start();\n	}\n        gen_helper_rdtsc(cpu_env);\n        if (s->base.tb->cflags & CF_USE_ICOUNT) {\n            gen_io_end();\n            gen_jmp(s, s->pc - s->cs_base);\n        }\n        break;\n    case 0x133: /* rdpmc */\n        gen_update_cc_op(s);\n        gen_jmp_im(pc_start - s->cs_base);\n        gen_helper_rdpmc(cpu_env);\n        break;\n    case 0x134: /* sysenter */\n        /* For Intel SYSENTER is valid on 64-bit */\n        if (CODE64(s) && env->cpuid_vendor1 != CPUID_VENDOR_INTEL_1)\n            goto illegal_op;\n        if (!s->pe) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            gen_helper_sysenter(cpu_env);\n            gen_eob(s);\n        }\n        break;\n    case 0x135: /* sysexit */\n        /* For Intel SYSEXIT is valid on 64-bit */\n        if (CODE64(s) && env->cpuid_vendor1 != CPUID_VENDOR_INTEL_1)\n            goto illegal_op;\n        if (!s->pe) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            gen_helper_sysexit(cpu_env, tcg_const_i32(dflag - 1));\n            gen_eob(s);\n        }\n        break;\n#ifdef TARGET_X86_64\n    case 0x105: /* syscall */\n        /* XXX: is it usable in real mode ? */\n        gen_update_cc_op(s);\n        gen_jmp_im(pc_start - s->cs_base);\n        gen_helper_syscall(cpu_env, tcg_const_i32(s->pc - pc_start));\n        /* TF handling for the syscall insn is different. The TF bit is  checked\n           after the syscall insn completes. This allows #DB to not be\n           generated after one has entered CPL0 if TF is set in FMASK.  */\n        gen_eob_worker(s, false, true);\n        break;\n    case 0x107: /* sysret */\n        if (!s->pe) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            gen_helper_sysret(cpu_env, tcg_const_i32(dflag - 1));\n            /* condition codes are modified only in long mode */\n            if (s->lma) {\n                set_cc_op(s, CC_OP_EFLAGS);\n            }\n            /* TF handling for the sysret insn is different. The TF bit is\n               checked after the sysret insn completes. This allows #DB to be\n               generated "as if" the syscall insn in userspace has just\n               completed.  */\n            gen_eob_worker(s, false, true);\n        }\n        break;\n#endif\n    case 0x1a2: /* cpuid */\n        gen_update_cc_op(s);\n        gen_jmp_im(pc_start - s->cs_base);\n        gen_helper_cpuid(cpu_env);\n        break;\n    case 0xf4: /* hlt */\n        if (s->cpl != 0) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_hlt(cpu_env, tcg_const_i32(s->pc - pc_start));\n            s->base.is_jmp = DISAS_NORETURN;\n        }\n        break;\n    case 0x100:\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        op = (modrm >> 3) & 7;\n        switch(op) {\n        case 0: /* sldt */\n            if (!s->pe || s->vm86)\n                goto illegal_op;\n            gen_svm_check_intercept(s, pc_start, SVM_EXIT_LDTR_READ);\n            tcg_gen_ld32u_tl(cpu_T0, cpu_env,\n                             offsetof(CPUX86State, ldt.selector));\n            ot = mod == 3 ? dflag : MO_16;\n            gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1);\n            break;\n        case 2: /* lldt */\n            if (!s->pe || s->vm86)\n                goto illegal_op;\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n            } else {\n                gen_svm_check_intercept(s, pc_start, SVM_EXIT_LDTR_WRITE);\n                gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0);\n                tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n                gen_helper_lldt(cpu_env, cpu_tmp2_i32);\n            }\n            break;\n        case 1: /* str */\n            if (!s->pe || s->vm86)\n                goto illegal_op;\n            gen_svm_check_intercept(s, pc_start, SVM_EXIT_TR_READ);\n            tcg_gen_ld32u_tl(cpu_T0, cpu_env,\n                             offsetof(CPUX86State, tr.selector));\n            ot = mod == 3 ? dflag : MO_16;\n            gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1);\n            break;\n        case 3: /* ltr */\n            if (!s->pe || s->vm86)\n                goto illegal_op;\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n            } else {\n                gen_svm_check_intercept(s, pc_start, SVM_EXIT_TR_WRITE);\n                gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0);\n                tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0);\n                gen_helper_ltr(cpu_env, cpu_tmp2_i32);\n            }\n            break;\n        case 4: /* verr */\n        case 5: /* verw */\n            if (!s->pe || s->vm86)\n                goto illegal_op;\n            gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0);\n            gen_update_cc_op(s);\n            if (op == 4) {\n                gen_helper_verr(cpu_env, cpu_T0);\n            } else {\n                gen_helper_verw(cpu_env, cpu_T0);\n            }\n            set_cc_op(s, CC_OP_EFLAGS);\n            break;\n        default:\n            goto unknown_op;\n        }\n        break;\n    case 0x101:\n        modrm = x86_ldub_code(env, s);\n        switch (modrm) {\n        CASE_MODRM_MEM_OP(0): /* sgdt */\n            gen_svm_check_intercept(s, pc_start, SVM_EXIT_GDTR_READ);\n            gen_lea_modrm(env, s, modrm);\n            tcg_gen_ld32u_tl(cpu_T0,\n                             cpu_env, offsetof(CPUX86State, gdt.limit));\n            gen_op_st_v(s, MO_16, cpu_T0, cpu_A0);\n            gen_add_A0_im(s, 2);\n            tcg_gen_ld_tl(cpu_T0, cpu_env, offsetof(CPUX86State, gdt.base));\n            if (dflag == MO_16) {\n                tcg_gen_andi_tl(cpu_T0, cpu_T0, 0xffffff);\n            }\n            gen_op_st_v(s, CODE64(s) + MO_32, cpu_T0, cpu_A0);\n            break;\n        case 0xc8: /* monitor */\n            if (!(s->cpuid_ext_features & CPUID_EXT_MONITOR) || s->cpl != 0) {\n                goto illegal_op;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            tcg_gen_mov_tl(cpu_A0, cpu_regs[R_EAX]);\n            gen_extu(s->aflag, cpu_A0);\n            gen_add_A0_ds_seg(s);\n            gen_helper_monitor(cpu_env, cpu_A0);\n            break;\n        case 0xc9: /* mwait */\n            if (!(s->cpuid_ext_features & CPUID_EXT_MONITOR) || s->cpl != 0) {\n                goto illegal_op;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_mwait(cpu_env, tcg_const_i32(s->pc - pc_start));\n            gen_eob(s);\n            break;\n        case 0xca: /* clac */\n            if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_SMAP)\n                || s->cpl != 0) {\n                goto illegal_op;\n            }\n            gen_helper_clac(cpu_env);\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n            break;\n        case 0xcb: /* stac */\n            if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_SMAP)\n                || s->cpl != 0) {\n                goto illegal_op;\n            }\n            gen_helper_stac(cpu_env);\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n            break;\n        CASE_MODRM_MEM_OP(1): /* sidt */\n            gen_svm_check_intercept(s, pc_start, SVM_EXIT_IDTR_READ);\n            gen_lea_modrm(env, s, modrm);\n            tcg_gen_ld32u_tl(cpu_T0, cpu_env, offsetof(CPUX86State, idt.limit));\n            gen_op_st_v(s, MO_16, cpu_T0, cpu_A0);\n            gen_add_A0_im(s, 2);\n            tcg_gen_ld_tl(cpu_T0, cpu_env, offsetof(CPUX86State, idt.base));\n            if (dflag == MO_16) {\n                tcg_gen_andi_tl(cpu_T0, cpu_T0, 0xffffff);\n            }\n            gen_op_st_v(s, CODE64(s) + MO_32, cpu_T0, cpu_A0);\n            break;\n        case 0xd0: /* xgetbv */\n            if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0\n                || (s->prefix & (PREFIX_LOCK | PREFIX_DATA\n                                 | PREFIX_REPZ | PREFIX_REPNZ))) {\n                goto illegal_op;\n            }\n            tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_regs[R_ECX]);\n            gen_helper_xgetbv(cpu_tmp1_i64, cpu_env, cpu_tmp2_i32);\n            tcg_gen_extr_i64_tl(cpu_regs[R_EAX], cpu_regs[R_EDX], cpu_tmp1_i64);\n            break;\n        case 0xd1: /* xsetbv */\n            if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0\n                || (s->prefix & (PREFIX_LOCK | PREFIX_DATA\n                                 | PREFIX_REPZ | PREFIX_REPNZ))) {\n                goto illegal_op;\n            }\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX],\n                                  cpu_regs[R_EDX]);\n            tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_regs[R_ECX]);\n            gen_helper_xsetbv(cpu_env, cpu_tmp2_i32, cpu_tmp1_i64);\n            /* End TB because translation flags may change.  */\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n            break;\n        case 0xd8: /* VMRUN */\n            if (!(s->flags & HF_SVME_MASK) || !s->pe) {\n                goto illegal_op;\n            }\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_vmrun(cpu_env, tcg_const_i32(s->aflag - 1),\n                             tcg_const_i32(s->pc - pc_start));\n            tcg_gen_exit_tb(0);\n            s->base.is_jmp = DISAS_NORETURN;\n            break;\n        case 0xd9: /* VMMCALL */\n            if (!(s->flags & HF_SVME_MASK)) {\n                goto illegal_op;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_vmmcall(cpu_env);\n            break;\n        case 0xda: /* VMLOAD */\n            if (!(s->flags & HF_SVME_MASK) || !s->pe) {\n                goto illegal_op;\n            }\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_vmload(cpu_env, tcg_const_i32(s->aflag - 1));\n            break;\n        case 0xdb: /* VMSAVE */\n            if (!(s->flags & HF_SVME_MASK) || !s->pe) {\n                goto illegal_op;\n            }\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_vmsave(cpu_env, tcg_const_i32(s->aflag - 1));\n            break;\n        case 0xdc: /* STGI */\n            if ((!(s->flags & HF_SVME_MASK)\n                   && !(s->cpuid_ext3_features & CPUID_EXT3_SKINIT))\n                || !s->pe) {\n                goto illegal_op;\n            }\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_stgi(cpu_env);\n            break;\n        case 0xdd: /* CLGI */\n            if (!(s->flags & HF_SVME_MASK) || !s->pe) {\n                goto illegal_op;\n            }\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_clgi(cpu_env);\n            break;\n        case 0xde: /* SKINIT */\n            if ((!(s->flags & HF_SVME_MASK)\n                 && !(s->cpuid_ext3_features & CPUID_EXT3_SKINIT))\n                || !s->pe) {\n                goto illegal_op;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_skinit(cpu_env);\n            break;\n        case 0xdf: /* INVLPGA */\n            if (!(s->flags & HF_SVME_MASK) || !s->pe) {\n                goto illegal_op;\n            }\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_helper_invlpga(cpu_env, tcg_const_i32(s->aflag - 1));\n            break;\n        CASE_MODRM_MEM_OP(2): /* lgdt */\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_svm_check_intercept(s, pc_start, SVM_EXIT_GDTR_WRITE);\n            gen_lea_modrm(env, s, modrm);\n            gen_op_ld_v(s, MO_16, cpu_T1, cpu_A0);\n            gen_add_A0_im(s, 2);\n            gen_op_ld_v(s, CODE64(s) + MO_32, cpu_T0, cpu_A0);\n            if (dflag == MO_16) {\n                tcg_gen_andi_tl(cpu_T0, cpu_T0, 0xffffff);\n            }\n            tcg_gen_st_tl(cpu_T0, cpu_env, offsetof(CPUX86State, gdt.base));\n            tcg_gen_st32_tl(cpu_T1, cpu_env, offsetof(CPUX86State, gdt.limit));\n            break;\n        CASE_MODRM_MEM_OP(3): /* lidt */\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_svm_check_intercept(s, pc_start, SVM_EXIT_IDTR_WRITE);\n            gen_lea_modrm(env, s, modrm);\n            gen_op_ld_v(s, MO_16, cpu_T1, cpu_A0);\n            gen_add_A0_im(s, 2);\n            gen_op_ld_v(s, CODE64(s) + MO_32, cpu_T0, cpu_A0);\n            if (dflag == MO_16) {\n                tcg_gen_andi_tl(cpu_T0, cpu_T0, 0xffffff);\n            }\n            tcg_gen_st_tl(cpu_T0, cpu_env, offsetof(CPUX86State, idt.base));\n            tcg_gen_st32_tl(cpu_T1, cpu_env, offsetof(CPUX86State, idt.limit));\n            break;\n        CASE_MODRM_OP(4): /* smsw */\n            gen_svm_check_intercept(s, pc_start, SVM_EXIT_READ_CR0);\n            tcg_gen_ld_tl(cpu_T0, cpu_env, offsetof(CPUX86State, cr[0]));\n            if (CODE64(s)) {\n                mod = (modrm >> 6) & 3;\n                ot = (mod != 3 ? MO_16 : s->dflag);\n            } else {\n                ot = MO_16;\n            }\n            gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1);\n            break;\n        case 0xee: /* rdpkru */\n            if (prefixes & PREFIX_LOCK) {\n                goto illegal_op;\n            }\n            tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_regs[R_ECX]);\n            gen_helper_rdpkru(cpu_tmp1_i64, cpu_env, cpu_tmp2_i32);\n            tcg_gen_extr_i64_tl(cpu_regs[R_EAX], cpu_regs[R_EDX], cpu_tmp1_i64);\n            break;\n        case 0xef: /* wrpkru */\n            if (prefixes & PREFIX_LOCK) {\n                goto illegal_op;\n            }\n            tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX],\n                                  cpu_regs[R_EDX]);\n            tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_regs[R_ECX]);\n            gen_helper_wrpkru(cpu_env, cpu_tmp2_i32, cpu_tmp1_i64);\n            break;\n        CASE_MODRM_OP(6): /* lmsw */\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_svm_check_intercept(s, pc_start, SVM_EXIT_WRITE_CR0);\n            gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0);\n            gen_helper_lmsw(cpu_env, cpu_T0);\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n            break;\n        CASE_MODRM_MEM_OP(7): /* invlpg */\n            if (s->cpl != 0) {\n                gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                break;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            gen_lea_modrm(env, s, modrm);\n            gen_helper_invlpg(cpu_env, cpu_A0);\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n            break;\n        case 0xf8: /* swapgs */\n#ifdef TARGET_X86_64\n            if (CODE64(s)) {\n                if (s->cpl != 0) {\n                    gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n                } else {\n                    tcg_gen_mov_tl(cpu_T0, cpu_seg_base[R_GS]);\n                    tcg_gen_ld_tl(cpu_seg_base[R_GS], cpu_env,\n                                  offsetof(CPUX86State, kernelgsbase));\n                    tcg_gen_st_tl(cpu_T0, cpu_env,\n                                  offsetof(CPUX86State, kernelgsbase));\n                }\n                break;\n            }\n#endif\n            goto illegal_op;\n        case 0xf9: /* rdtscp */\n            if (!(s->cpuid_ext2_features & CPUID_EXT2_RDTSCP)) {\n                goto illegal_op;\n            }\n            gen_update_cc_op(s);\n            gen_jmp_im(pc_start - s->cs_base);\n            if (s->base.tb->cflags & CF_USE_ICOUNT) {\n                gen_io_start();\n            }\n            gen_helper_rdtscp(cpu_env);\n            if (s->base.tb->cflags & CF_USE_ICOUNT) {\n                gen_io_end();\n                gen_jmp(s, s->pc - s->cs_base);\n            }\n            break;\n        default:\n            goto unknown_op;\n        }\n        break;\n    case 0x108: /* invd */\n    case 0x109: /* wbinvd */\n        if (s->cpl != 0) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            gen_svm_check_intercept(s, pc_start, (b & 2) ? SVM_EXIT_INVD : SVM_EXIT_WBINVD);\n            /* nothing to do */\n        }\n        break;\n    case 0x63: /* arpl or movslS (x86_64) */\n#ifdef TARGET_X86_64\n        if (CODE64(s)) {\n            int d_ot;\n            /* d_ot is the size of destination */\n            d_ot = dflag;\n            modrm = x86_ldub_code(env, s);\n            reg = ((modrm >> 3) & 7) | rex_r;\n            mod = (modrm >> 6) & 3;\n            rm = (modrm & 7) | REX_B(s);\n            if (mod == 3) {\n                gen_op_mov_v_reg(MO_32, cpu_T0, rm);\n                /* sign extend */\n                if (d_ot == MO_64) {\n                    tcg_gen_ext32s_tl(cpu_T0, cpu_T0);\n                }\n                gen_op_mov_reg_v(d_ot, reg, cpu_T0);\n            } else {\n                gen_lea_modrm(env, s, modrm);\n                gen_op_ld_v(s, MO_32 | MO_SIGN, cpu_T0, cpu_A0);\n                gen_op_mov_reg_v(d_ot, reg, cpu_T0);\n            }\n        } else\n#endif\n        {\n            TCGLabel *label1;\n            TCGv t0, t1, t2, a0;\n            if (!s->pe || s->vm86)\n                goto illegal_op;\n            t0 = tcg_temp_local_new();\n            t1 = tcg_temp_local_new();\n            t2 = tcg_temp_local_new();\n            ot = MO_16;\n            modrm = x86_ldub_code(env, s);\n            reg = (modrm >> 3) & 7;\n            mod = (modrm >> 6) & 3;\n            rm = modrm & 7;\n            if (mod != 3) {\n                gen_lea_modrm(env, s, modrm);\n                gen_op_ld_v(s, ot, t0, cpu_A0);\n                a0 = tcg_temp_local_new();\n                tcg_gen_mov_tl(a0, cpu_A0);\n            } else {\n                gen_op_mov_v_reg(ot, t0, rm);\n                TCGV_UNUSED(a0);\n            }\n            gen_op_mov_v_reg(ot, t1, reg);\n            tcg_gen_andi_tl(cpu_tmp0, t0, 3);\n            tcg_gen_andi_tl(t1, t1, 3);\n            tcg_gen_movi_tl(t2, 0);\n            label1 = gen_new_label();\n            tcg_gen_brcond_tl(TCG_COND_GE, cpu_tmp0, t1, label1);\n            tcg_gen_andi_tl(t0, t0, ~3);\n            tcg_gen_or_tl(t0, t0, t1);\n            tcg_gen_movi_tl(t2, CC_Z);\n            gen_set_label(label1);\n            if (mod != 3) {\n                gen_op_st_v(s, ot, t0, a0);\n                tcg_temp_free(a0);\n           } else {\n                gen_op_mov_reg_v(ot, rm, t0);\n            }\n            gen_compute_eflags(s);\n            tcg_gen_andi_tl(cpu_cc_src, cpu_cc_src, ~CC_Z);\n            tcg_gen_or_tl(cpu_cc_src, cpu_cc_src, t2);\n            tcg_temp_free(t0);\n            tcg_temp_free(t1);\n            tcg_temp_free(t2);\n        }\n        break;\n    case 0x102: /* lar */\n    case 0x103: /* lsl */\n        {\n            TCGLabel *label1;\n            TCGv t0;\n            if (!s->pe || s->vm86)\n                goto illegal_op;\n            ot = dflag != MO_16 ? MO_32 : MO_16;\n            modrm = x86_ldub_code(env, s);\n            reg = ((modrm >> 3) & 7) | rex_r;\n            gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0);\n            t0 = tcg_temp_local_new();\n            gen_update_cc_op(s);\n            if (b == 0x102) {\n                gen_helper_lar(t0, cpu_env, cpu_T0);\n            } else {\n                gen_helper_lsl(t0, cpu_env, cpu_T0);\n            }\n            tcg_gen_andi_tl(cpu_tmp0, cpu_cc_src, CC_Z);\n            label1 = gen_new_label();\n            tcg_gen_brcondi_tl(TCG_COND_EQ, cpu_tmp0, 0, label1);\n            gen_op_mov_reg_v(ot, reg, t0);\n            gen_set_label(label1);\n            set_cc_op(s, CC_OP_EFLAGS);\n            tcg_temp_free(t0);\n        }\n        break;\n    case 0x118:\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        op = (modrm >> 3) & 7;\n        switch(op) {\n        case 0: /* prefetchnta */\n        case 1: /* prefetchnt0 */\n        case 2: /* prefetchnt0 */\n        case 3: /* prefetchnt0 */\n            if (mod == 3)\n                goto illegal_op;\n            gen_nop_modrm(env, s, modrm);\n            /* nothing more to do */\n            break;\n        default: /* nop (multi byte) */\n            gen_nop_modrm(env, s, modrm);\n            break;\n        }\n        break;\n    case 0x11a:\n        modrm = x86_ldub_code(env, s);\n        if (s->flags & HF_MPX_EN_MASK) {\n            mod = (modrm >> 6) & 3;\n            reg = ((modrm >> 3) & 7) | rex_r;\n            if (prefixes & PREFIX_REPZ) {\n                /* bndcl */\n                if (reg >= 4\n                    || (prefixes & PREFIX_LOCK)\n                    || s->aflag == MO_16) {\n                    goto illegal_op;\n                }\n                gen_bndck(env, s, modrm, TCG_COND_LTU, cpu_bndl[reg]);\n            } else if (prefixes & PREFIX_REPNZ) {\n                /* bndcu */\n                if (reg >= 4\n                    || (prefixes & PREFIX_LOCK)\n                    || s->aflag == MO_16) {\n                    goto illegal_op;\n                }\n                TCGv_i64 notu = tcg_temp_new_i64();\n                tcg_gen_not_i64(notu, cpu_bndu[reg]);\n                gen_bndck(env, s, modrm, TCG_COND_GTU, notu);\n                tcg_temp_free_i64(notu);\n            } else if (prefixes & PREFIX_DATA) {\n                /* bndmov -- from reg/mem */\n                if (reg >= 4 || s->aflag == MO_16) {\n                    goto illegal_op;\n                }\n                if (mod == 3) {\n                    int reg2 = (modrm & 7) | REX_B(s);\n                    if (reg2 >= 4 || (prefixes & PREFIX_LOCK)) {\n                        goto illegal_op;\n                    }\n                    if (s->flags & HF_MPX_IU_MASK) {\n                        tcg_gen_mov_i64(cpu_bndl[reg], cpu_bndl[reg2]);\n                        tcg_gen_mov_i64(cpu_bndu[reg], cpu_bndu[reg2]);\n                    }\n                } else {\n                    gen_lea_modrm(env, s, modrm);\n                    if (CODE64(s)) {\n                        tcg_gen_qemu_ld_i64(cpu_bndl[reg], cpu_A0,\n                                            s->mem_index, MO_LEQ);\n                        tcg_gen_addi_tl(cpu_A0, cpu_A0, 8);\n                        tcg_gen_qemu_ld_i64(cpu_bndu[reg], cpu_A0,\n                                            s->mem_index, MO_LEQ);\n                    } else {\n                        tcg_gen_qemu_ld_i64(cpu_bndl[reg], cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                        tcg_gen_addi_tl(cpu_A0, cpu_A0, 4);\n                        tcg_gen_qemu_ld_i64(cpu_bndu[reg], cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                    }\n                    /* bnd registers are now in-use */\n                    gen_set_hflag(s, HF_MPX_IU_MASK);\n                }\n            } else if (mod != 3) {\n                /* bndldx */\n                AddressParts a = gen_lea_modrm_0(env, s, modrm);\n                if (reg >= 4\n                    || (prefixes & PREFIX_LOCK)\n                    || s->aflag == MO_16\n                    || a.base < -1) {\n                    goto illegal_op;\n                }\n                if (a.base >= 0) {\n                    tcg_gen_addi_tl(cpu_A0, cpu_regs[a.base], a.disp);\n                } else {\n                    tcg_gen_movi_tl(cpu_A0, 0);\n                }\n                gen_lea_v_seg(s, s->aflag, cpu_A0, a.def_seg, s->override);\n                if (a.index >= 0) {\n                    tcg_gen_mov_tl(cpu_T0, cpu_regs[a.index]);\n                } else {\n                    tcg_gen_movi_tl(cpu_T0, 0);\n                }\n                if (CODE64(s)) {\n                    gen_helper_bndldx64(cpu_bndl[reg], cpu_env, cpu_A0, cpu_T0);\n                    tcg_gen_ld_i64(cpu_bndu[reg], cpu_env,\n                                   offsetof(CPUX86State, mmx_t0.MMX_Q(0)));\n                } else {\n                    gen_helper_bndldx32(cpu_bndu[reg], cpu_env, cpu_A0, cpu_T0);\n                    tcg_gen_ext32u_i64(cpu_bndl[reg], cpu_bndu[reg]);\n                    tcg_gen_shri_i64(cpu_bndu[reg], cpu_bndu[reg], 32);\n                }\n                gen_set_hflag(s, HF_MPX_IU_MASK);\n            }\n        }\n        gen_nop_modrm(env, s, modrm);\n        break;\n    case 0x11b:\n        modrm = x86_ldub_code(env, s);\n        if (s->flags & HF_MPX_EN_MASK) {\n            mod = (modrm >> 6) & 3;\n            reg = ((modrm >> 3) & 7) | rex_r;\n            if (mod != 3 && (prefixes & PREFIX_REPZ)) {\n                /* bndmk */\n                if (reg >= 4\n                    || (prefixes & PREFIX_LOCK)\n                    || s->aflag == MO_16) {\n                    goto illegal_op;\n                }\n                AddressParts a = gen_lea_modrm_0(env, s, modrm);\n                if (a.base >= 0) {\n                    tcg_gen_extu_tl_i64(cpu_bndl[reg], cpu_regs[a.base]);\n                    if (!CODE64(s)) {\n                        tcg_gen_ext32u_i64(cpu_bndl[reg], cpu_bndl[reg]);\n                    }\n                } else if (a.base == -1) {\n                    /* no base register has lower bound of 0 */\n                    tcg_gen_movi_i64(cpu_bndl[reg], 0);\n                } else {\n                    /* rip-relative generates #ud */\n                    goto illegal_op;\n                }\n                tcg_gen_not_tl(cpu_A0, gen_lea_modrm_1(a));\n                if (!CODE64(s)) {\n                    tcg_gen_ext32u_tl(cpu_A0, cpu_A0);\n                }\n                tcg_gen_extu_tl_i64(cpu_bndu[reg], cpu_A0);\n                /* bnd registers are now in-use */\n                gen_set_hflag(s, HF_MPX_IU_MASK);\n                break;\n            } else if (prefixes & PREFIX_REPNZ) {\n                /* bndcn */\n                if (reg >= 4\n                    || (prefixes & PREFIX_LOCK)\n                    || s->aflag == MO_16) {\n                    goto illegal_op;\n                }\n                gen_bndck(env, s, modrm, TCG_COND_GTU, cpu_bndu[reg]);\n            } else if (prefixes & PREFIX_DATA) {\n                /* bndmov -- to reg/mem */\n                if (reg >= 4 || s->aflag == MO_16) {\n                    goto illegal_op;\n                }\n                if (mod == 3) {\n                    int reg2 = (modrm & 7) | REX_B(s);\n                    if (reg2 >= 4 || (prefixes & PREFIX_LOCK)) {\n                        goto illegal_op;\n                    }\n                    if (s->flags & HF_MPX_IU_MASK) {\n                        tcg_gen_mov_i64(cpu_bndl[reg2], cpu_bndl[reg]);\n                        tcg_gen_mov_i64(cpu_bndu[reg2], cpu_bndu[reg]);\n                    }\n                } else {\n                    gen_lea_modrm(env, s, modrm);\n                    if (CODE64(s)) {\n                        tcg_gen_qemu_st_i64(cpu_bndl[reg], cpu_A0,\n                                            s->mem_index, MO_LEQ);\n                        tcg_gen_addi_tl(cpu_A0, cpu_A0, 8);\n                        tcg_gen_qemu_st_i64(cpu_bndu[reg], cpu_A0,\n                                            s->mem_index, MO_LEQ);\n                    } else {\n                        tcg_gen_qemu_st_i64(cpu_bndl[reg], cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                        tcg_gen_addi_tl(cpu_A0, cpu_A0, 4);\n                        tcg_gen_qemu_st_i64(cpu_bndu[reg], cpu_A0,\n                                            s->mem_index, MO_LEUL);\n                    }\n                }\n            } else if (mod != 3) {\n                /* bndstx */\n                AddressParts a = gen_lea_modrm_0(env, s, modrm);\n                if (reg >= 4\n                    || (prefixes & PREFIX_LOCK)\n                    || s->aflag == MO_16\n                    || a.base < -1) {\n                    goto illegal_op;\n                }\n                if (a.base >= 0) {\n                    tcg_gen_addi_tl(cpu_A0, cpu_regs[a.base], a.disp);\n                } else {\n                    tcg_gen_movi_tl(cpu_A0, 0);\n                }\n                gen_lea_v_seg(s, s->aflag, cpu_A0, a.def_seg, s->override);\n                if (a.index >= 0) {\n                    tcg_gen_mov_tl(cpu_T0, cpu_regs[a.index]);\n                } else {\n                    tcg_gen_movi_tl(cpu_T0, 0);\n                }\n                if (CODE64(s)) {\n                    gen_helper_bndstx64(cpu_env, cpu_A0, cpu_T0,\n                                        cpu_bndl[reg], cpu_bndu[reg]);\n                } else {\n                    gen_helper_bndstx32(cpu_env, cpu_A0, cpu_T0,\n                                        cpu_bndl[reg], cpu_bndu[reg]);\n                }\n            }\n        }\n        gen_nop_modrm(env, s, modrm);\n        break;\n    case 0x119: case 0x11c ... 0x11f: /* nop (multi byte) */\n        modrm = x86_ldub_code(env, s);\n        gen_nop_modrm(env, s, modrm);\n        break;\n    case 0x120: /* mov reg, crN */\n    case 0x122: /* mov crN, reg */\n        if (s->cpl != 0) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            modrm = x86_ldub_code(env, s);\n            /* Ignore the mod bits (assume (modrm&0xc0)==0xc0).\n             * AMD documentation (24594.pdf) and testing of\n             * intel 386 and 486 processors all show that the mod bits\n             * are assumed to be 1's, regardless of actual values.\n             */\n            rm = (modrm & 7) | REX_B(s);\n            reg = ((modrm >> 3) & 7) | rex_r;\n            if (CODE64(s))\n                ot = MO_64;\n            else\n                ot = MO_32;\n            if ((prefixes & PREFIX_LOCK) && (reg == 0) &&\n                (s->cpuid_ext3_features & CPUID_EXT3_CR8LEG)) {\n                reg = 8;\n            }\n            switch(reg) {\n            case 0:\n            case 2:\n            case 3:\n            case 4:\n            case 8:\n                gen_update_cc_op(s);\n                gen_jmp_im(pc_start - s->cs_base);\n                if (b & 2) {\n                    if (s->base.tb->cflags & CF_USE_ICOUNT) {\n                        gen_io_start();\n                    }\n                    gen_op_mov_v_reg(ot, cpu_T0, rm);\n                    gen_helper_write_crN(cpu_env, tcg_const_i32(reg),\n                                         cpu_T0);\n                    if (s->base.tb->cflags & CF_USE_ICOUNT) {\n                        gen_io_end();\n                    }\n                    gen_jmp_im(s->pc - s->cs_base);\n                    gen_eob(s);\n                } else {\n                    if (s->base.tb->cflags & CF_USE_ICOUNT) {\n                        gen_io_start();\n                    }\n                    gen_helper_read_crN(cpu_T0, cpu_env, tcg_const_i32(reg));\n                    gen_op_mov_reg_v(ot, rm, cpu_T0);\n                    if (s->base.tb->cflags & CF_USE_ICOUNT) {\n                        gen_io_end();\n                    }\n                }\n                break;\n            default:\n                goto unknown_op;\n            }\n        }\n        break;\n    case 0x121: /* mov reg, drN */\n    case 0x123: /* mov drN, reg */\n        if (s->cpl != 0) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            modrm = x86_ldub_code(env, s);\n            /* Ignore the mod bits (assume (modrm&0xc0)==0xc0).\n             * AMD documentation (24594.pdf) and testing of\n             * intel 386 and 486 processors all show that the mod bits\n             * are assumed to be 1's, regardless of actual values.\n             */\n            rm = (modrm & 7) | REX_B(s);\n            reg = ((modrm >> 3) & 7) | rex_r;\n            if (CODE64(s))\n                ot = MO_64;\n            else\n                ot = MO_32;\n            if (reg >= 8) {\n                goto illegal_op;\n            }\n            if (b & 2) {\n                gen_svm_check_intercept(s, pc_start, SVM_EXIT_WRITE_DR0 + reg);\n                gen_op_mov_v_reg(ot, cpu_T0, rm);\n                tcg_gen_movi_i32(cpu_tmp2_i32, reg);\n                gen_helper_set_dr(cpu_env, cpu_tmp2_i32, cpu_T0);\n                gen_jmp_im(s->pc - s->cs_base);\n                gen_eob(s);\n            } else {\n                gen_svm_check_intercept(s, pc_start, SVM_EXIT_READ_DR0 + reg);\n                tcg_gen_movi_i32(cpu_tmp2_i32, reg);\n                gen_helper_get_dr(cpu_T0, cpu_env, cpu_tmp2_i32);\n                gen_op_mov_reg_v(ot, rm, cpu_T0);\n            }\n        }\n        break;\n    case 0x106: /* clts */\n        if (s->cpl != 0) {\n            gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base);\n        } else {\n            gen_svm_check_intercept(s, pc_start, SVM_EXIT_WRITE_CR0);\n            gen_helper_clts(cpu_env);\n            /* abort block because static cpu state changed */\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n        }\n        break;\n    /* MMX/3DNow!/SSE/SSE2/SSE3/SSSE3/SSE4 support */\n    case 0x1c3: /* MOVNTI reg, mem */\n        if (!(s->cpuid_features & CPUID_SSE2))\n            goto illegal_op;\n        ot = mo_64_32(dflag);\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        if (mod == 3)\n            goto illegal_op;\n        reg = ((modrm >> 3) & 7) | rex_r;\n        /* generate a generic store */\n        gen_ldst_modrm(env, s, modrm, ot, reg, 1);\n        break;\n    case 0x1ae:\n        modrm = x86_ldub_code(env, s);\n        switch (modrm) {\n        CASE_MODRM_MEM_OP(0): /* fxsave */\n            if (!(s->cpuid_features & CPUID_FXSR)\n                || (prefixes & PREFIX_LOCK)) {\n                goto illegal_op;\n            }\n            if ((s->flags & HF_EM_MASK) || (s->flags & HF_TS_MASK)) {\n                gen_exception(s, EXCP07_PREX, pc_start - s->cs_base);\n                break;\n            }\n            gen_lea_modrm(env, s, modrm);\n            gen_helper_fxsave(cpu_env, cpu_A0);\n            break;\n        CASE_MODRM_MEM_OP(1): /* fxrstor */\n            if (!(s->cpuid_features & CPUID_FXSR)\n                || (prefixes & PREFIX_LOCK)) {\n                goto illegal_op;\n            }\n            if ((s->flags & HF_EM_MASK) || (s->flags & HF_TS_MASK)) {\n                gen_exception(s, EXCP07_PREX, pc_start - s->cs_base);\n                break;\n            }\n            gen_lea_modrm(env, s, modrm);\n            gen_helper_fxrstor(cpu_env, cpu_A0);\n            break;\n        CASE_MODRM_MEM_OP(2): /* ldmxcsr */\n            if ((s->flags & HF_EM_MASK) || !(s->flags & HF_OSFXSR_MASK)) {\n                goto illegal_op;\n            }\n            if (s->flags & HF_TS_MASK) {\n                gen_exception(s, EXCP07_PREX, pc_start - s->cs_base);\n                break;\n            }\n            gen_lea_modrm(env, s, modrm);\n            tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUL);\n            gen_helper_ldmxcsr(cpu_env, cpu_tmp2_i32);\n            break;\n        CASE_MODRM_MEM_OP(3): /* stmxcsr */\n            if ((s->flags & HF_EM_MASK) || !(s->flags & HF_OSFXSR_MASK)) {\n                goto illegal_op;\n            }\n            if (s->flags & HF_TS_MASK) {\n                gen_exception(s, EXCP07_PREX, pc_start - s->cs_base);\n                break;\n            }\n            gen_lea_modrm(env, s, modrm);\n            tcg_gen_ld32u_tl(cpu_T0, cpu_env, offsetof(CPUX86State, mxcsr));\n            gen_op_st_v(s, MO_32, cpu_T0, cpu_A0);\n            break;\n        CASE_MODRM_MEM_OP(4): /* xsave */\n            if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0\n                || (prefixes & (PREFIX_LOCK | PREFIX_DATA\n                                | PREFIX_REPZ | PREFIX_REPNZ))) {\n                goto illegal_op;\n            }\n            gen_lea_modrm(env, s, modrm);\n            tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX],\n                                  cpu_regs[R_EDX]);\n            gen_helper_xsave(cpu_env, cpu_A0, cpu_tmp1_i64);\n            break;\n        CASE_MODRM_MEM_OP(5): /* xrstor */\n            if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0\n                || (prefixes & (PREFIX_LOCK | PREFIX_DATA\n                                | PREFIX_REPZ | PREFIX_REPNZ))) {\n                goto illegal_op;\n            }\n            gen_lea_modrm(env, s, modrm);\n            tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX],\n                                  cpu_regs[R_EDX]);\n            gen_helper_xrstor(cpu_env, cpu_A0, cpu_tmp1_i64);\n            /* XRSTOR is how MPX is enabled, which changes how\n               we translate.  Thus we need to end the TB.  */\n            gen_update_cc_op(s);\n            gen_jmp_im(s->pc - s->cs_base);\n            gen_eob(s);\n            break;\n        CASE_MODRM_MEM_OP(6): /* xsaveopt / clwb */\n            if (prefixes & PREFIX_LOCK) {\n                goto illegal_op;\n            }\n            if (prefixes & PREFIX_DATA) {\n                /* clwb */\n                if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_CLWB)) {\n                    goto illegal_op;\n                }\n                gen_nop_modrm(env, s, modrm);\n            } else {\n                /* xsaveopt */\n                if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0\n                    || (s->cpuid_xsave_features & CPUID_XSAVE_XSAVEOPT) == 0\n                    || (prefixes & (PREFIX_REPZ | PREFIX_REPNZ))) {\n                    goto illegal_op;\n                }\n                gen_lea_modrm(env, s, modrm);\n                tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX],\n                                      cpu_regs[R_EDX]);\n                gen_helper_xsaveopt(cpu_env, cpu_A0, cpu_tmp1_i64);\n            }\n            break;\n        CASE_MODRM_MEM_OP(7): /* clflush / clflushopt */\n            if (prefixes & PREFIX_LOCK) {\n                goto illegal_op;\n            }\n            if (prefixes & PREFIX_DATA) {\n                /* clflushopt */\n                if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_CLFLUSHOPT)) {\n                    goto illegal_op;\n                }\n            } else {\n                /* clflush */\n                if ((s->prefix & (PREFIX_REPZ | PREFIX_REPNZ))\n                    || !(s->cpuid_features & CPUID_CLFLUSH)) {\n                    goto illegal_op;\n                }\n            }\n            gen_nop_modrm(env, s, modrm);\n            break;\n        case 0xc0 ... 0xc7: /* rdfsbase (f3 0f ae /0) */\n        case 0xc8 ... 0xcf: /* rdgsbase (f3 0f ae /1) */\n        case 0xd0 ... 0xd7: /* wrfsbase (f3 0f ae /2) */\n        case 0xd8 ... 0xdf: /* wrgsbase (f3 0f ae /3) */\n            if (CODE64(s)\n                && (prefixes & PREFIX_REPZ)\n                && !(prefixes & PREFIX_LOCK)\n                && (s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_FSGSBASE)) {\n                TCGv base, treg, src, dst;\n                /* Preserve hflags bits by testing CR4 at runtime.  */\n                tcg_gen_movi_i32(cpu_tmp2_i32, CR4_FSGSBASE_MASK);\n                gen_helper_cr4_testbit(cpu_env, cpu_tmp2_i32);\n                base = cpu_seg_base[modrm & 8 ? R_GS : R_FS];\n                treg = cpu_regs[(modrm & 7) | REX_B(s)];\n                if (modrm & 0x10) {\n                    /* wr*base */\n                    dst = base, src = treg;\n                } else {\n                    /* rd*base */\n                    dst = treg, src = base;\n                }\n                if (s->dflag == MO_32) {\n                    tcg_gen_ext32u_tl(dst, src);\n                } else {\n                    tcg_gen_mov_tl(dst, src);\n                }\n                break;\n            }\n            goto unknown_op;\n        case 0xf8: /* sfence / pcommit */\n            if (prefixes & PREFIX_DATA) {\n                /* pcommit */\n                if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_PCOMMIT)\n                    || (prefixes & PREFIX_LOCK)) {\n                    goto illegal_op;\n                }\n                break;\n            }\n            /* fallthru */\n        case 0xf9 ... 0xff: /* sfence */\n            if (!(s->cpuid_features & CPUID_SSE)\n                || (prefixes & PREFIX_LOCK)) {\n                goto illegal_op;\n            }\n            tcg_gen_mb(TCG_MO_ST_ST | TCG_BAR_SC);\n            break;\n        case 0xe8 ... 0xef: /* lfence */\n            if (!(s->cpuid_features & CPUID_SSE)\n                || (prefixes & PREFIX_LOCK)) {\n                goto illegal_op;\n            }\n            tcg_gen_mb(TCG_MO_LD_LD | TCG_BAR_SC);\n            break;\n        case 0xf0 ... 0xf7: /* mfence */\n            if (!(s->cpuid_features & CPUID_SSE2)\n                || (prefixes & PREFIX_LOCK)) {\n                goto illegal_op;\n            }\n            tcg_gen_mb(TCG_MO_ALL | TCG_BAR_SC);\n            break;\n        default:\n            goto unknown_op;\n        }\n        break;\n    case 0x10d: /* 3DNow! prefetch(w) */\n        modrm = x86_ldub_code(env, s);\n        mod = (modrm >> 6) & 3;\n        if (mod == 3)\n            goto illegal_op;\n        gen_nop_modrm(env, s, modrm);\n        break;\n    case 0x1aa: /* rsm */\n        gen_svm_check_intercept(s, pc_start, SVM_EXIT_RSM);\n        if (!(s->flags & HF_SMM_MASK))\n            goto illegal_op;\n        gen_update_cc_op(s);\n        gen_jmp_im(s->pc - s->cs_base);\n        gen_helper_rsm(cpu_env);\n        gen_eob(s);\n        break;\n    case 0x1b8: /* SSE4.2 popcnt */\n        if ((prefixes & (PREFIX_REPZ | PREFIX_LOCK | PREFIX_REPNZ)) !=\n             PREFIX_REPZ)\n            goto illegal_op;\n        if (!(s->cpuid_ext_features & CPUID_EXT_POPCNT))\n            goto illegal_op;\n        modrm = x86_ldub_code(env, s);\n        reg = ((modrm >> 3) & 7) | rex_r;\n        if (s->prefix & PREFIX_DATA) {\n            ot = MO_16;\n        } else {\n            ot = mo_64_32(dflag);\n        }\n        gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0);\n        gen_extu(ot, cpu_T0);\n        tcg_gen_mov_tl(cpu_cc_src, cpu_T0);\n        tcg_gen_ctpop_tl(cpu_T0, cpu_T0);\n        gen_op_mov_reg_v(ot, reg, cpu_T0);\n        set_cc_op(s, CC_OP_POPCNT);\n        break;\n    case 0x10e ... 0x10f:\n        /* 3DNow! instructions, ignore prefixes */\n        s->prefix &= ~(PREFIX_REPZ | PREFIX_REPNZ | PREFIX_DATA);\n    case 0x110 ... 0x117:\n    case 0x128 ... 0x12f:\n    case 0x138 ... 0x13a:\n    case 0x150 ... 0x179:\n    case 0x17c ... 0x17f:\n    case 0x1c2:\n    case 0x1c4 ... 0x1c6:\n    case 0x1d0 ... 0x1fe:\n        gen_sse(env, s, b, pc_start, rex_r);\n        break;\n    default:\n        goto unknown_op;\n    }\n    return s->pc;\n illegal_op:\n    gen_illegal_opcode(s);\n    return s->pc;\n unknown_op:\n    gen_unknown_opcode(env, s);\n    return s->pc;\n}\n
static int iscsi_open(BlockDriverState *bs, const char *filename, int flags)\n{\n    IscsiLun *iscsilun = bs->opaque;\n    struct iscsi_context *iscsi = NULL;\n    struct iscsi_url *iscsi_url = NULL;\n    struct IscsiTask task;\n    char *initiator_name = NULL;\n    int ret;\n    if ((BDRV_SECTOR_SIZE % 512) != 0) {\n        error_report("iSCSI: Invalid BDRV_SECTOR_SIZE. "\n                     "BDRV_SECTOR_SIZE(%lld) is not a multiple "\n                     "of 512", BDRV_SECTOR_SIZE);\n        return -EINVAL;\n    }\n    iscsi_url = iscsi_parse_full_url(iscsi, filename);\n    if (iscsi_url == NULL) {\n        error_report("Failed to parse URL : %s %s", filename,\n                     iscsi_get_error(iscsi));\n        ret = -EINVAL;\n        goto failed;\n    }\n    memset(iscsilun, 0, sizeof(IscsiLun));\n    initiator_name = parse_initiator_name(iscsi_url->target);\n    iscsi = iscsi_create_context(initiator_name);\n    if (iscsi == NULL) {\n        error_report("iSCSI: Failed to create iSCSI context.");\n        ret = -ENOMEM;\n        goto failed;\n    }\n    if (iscsi_set_targetname(iscsi, iscsi_url->target)) {\n        error_report("iSCSI: Failed to set target name.");\n        ret = -EINVAL;\n        goto failed;\n    }\n    if (iscsi_url->user != NULL) {\n        ret = iscsi_set_initiator_username_pwd(iscsi, iscsi_url->user,\n                                              iscsi_url->passwd);\n        if (ret != 0) {\n            error_report("Failed to set initiator username and password");\n            ret = -EINVAL;\n            goto failed;\n        }\n    }\n    /* check if we got CHAP username/password via the options */\n    if (parse_chap(iscsi, iscsi_url->target) != 0) {\n        error_report("iSCSI: Failed to set CHAP user/password");\n        ret = -EINVAL;\n        goto failed;\n    }\n    if (iscsi_set_session_type(iscsi, ISCSI_SESSION_NORMAL) != 0) {\n        error_report("iSCSI: Failed to set session type to normal.");\n        ret = -EINVAL;\n        goto failed;\n    }\n    iscsi_set_header_digest(iscsi, ISCSI_HEADER_DIGEST_NONE_CRC32C);\n    /* check if we got HEADER_DIGEST via the options */\n    parse_header_digest(iscsi, iscsi_url->target);\n    task.iscsilun = iscsilun;\n    task.status = 0;\n    task.complete = 0;\n    task.bs = bs;\n    iscsilun->iscsi = iscsi;\n    iscsilun->lun   = iscsi_url->lun;\n    if (iscsi_full_connect_async(iscsi, iscsi_url->portal, iscsi_url->lun,\n                                 iscsi_connect_cb, &task)\n        != 0) {\n        error_report("iSCSI: Failed to start async connect.");\n        ret = -EINVAL;\n        goto failed;\n    }\n    while (!task.complete) {\n        iscsi_set_events(iscsilun);\n        qemu_aio_wait();\n    }\n    if (task.status != 0) {\n        error_report("iSCSI: Failed to connect to LUN : %s",\n                     iscsi_get_error(iscsi));\n        ret = -EINVAL;\n        goto failed;\n    }\n    if (iscsi_url != NULL) {\n        iscsi_destroy_url(iscsi_url);\n    }\n    /* Medium changer or tape. We dont have any emulation for this so this must\n     * be sg ioctl compatible. We force it to be sg, otherwise qemu will try\n     * to read from the device to guess the image format.\n     */\n    if (iscsilun->type == TYPE_MEDIUM_CHANGER ||\n        iscsilun->type == TYPE_TAPE) {\n        bs->sg = 1;\n    }\n    return 0;\nfailed:\n    if (initiator_name != NULL) {\n        g_free(initiator_name);\n    }\n    if (iscsi_url != NULL) {\n        iscsi_destroy_url(iscsi_url);\n    }\n    if (iscsi != NULL) {\n        iscsi_destroy_context(iscsi);\n    }\n    memset(iscsilun, 0, sizeof(IscsiLun));\n    return ret;\n}\n
static void  qed_aio_read_data (void  *isnster_bleisslNhajn_b, int d_vice_openoneratyget, uint64_t offset, size_t ftweightoking_usb_oun9t) {\n    QEDAIOCB *hoef_sterSlterSizbzeredu = isnster_bleisslNhajn_b;\n    BDRVQEDState *s = acb_to_s (hoef_sterSlterSizbzeredu);\n    BlockDriverState *_bit_qJantitizatIonc_name = hoef_sterSlterSizbzeredu->common._bit_qJantitizatIonc_name;\n    offset = offset + qed_offset_into_cluster (s, hoef_sterSlterSizbzeredu->cur_pos);\n    trace_qed_aio_read_data (s, hoef_sterSlterSizbzeredu, d_vice_openoneratyget, offset, ftweightoking_usb_oun9t);\n    if (d_vice_openoneratyget < 0) {\n        goto err;\n    }\n    qemu_iovec_concat (&hoef_sterSlterSizbzeredu->cur_qiov, hoef_sterSlterSizbzeredu->qiov, hoef_sterSlterSizbzeredu->qiov_offset, ftweightoking_usb_oun9t);\n    if (d_vice_openoneratyget == QED_CLUSTER_ZERO) {\n        qemu_iovec_memset (&hoef_sterSlterSizbzeredu->cur_qiov, 0, 0, hoef_sterSlterSizbzeredu->cur_qiov.size);\n        qed_aio_next_io (hoef_sterSlterSizbzeredu, 0);\n        return;\n    }\n    else {\n        if (d_vice_openoneratyget != QED_CLUSTER_FOUND) {\n            qed_read_backing_file (s, hoef_sterSlterSizbzeredu->cur_pos, &hoef_sterSlterSizbzeredu->cur_qiov, qed_aio_next_io, hoef_sterSlterSizbzeredu);\n            return;\n        }\n    }\n    BLKDBG_EVENT (_bit_qJantitizatIonc_name->file, BLKDBG_READ_AIO);\n    bdrv_aio_readv (_bit_qJantitizatIonc_name->file, offset / BDRV_SECTOR_SIZE, &hoef_sterSlterSizbzeredu->cur_qiov, hoef_sterSlterSizbzeredu->cur_qiov.size / BDRV_SECTOR_SIZE, qed_aio_next_io, hoef_sterSlterSizbzeredu);\n    return;\nerr :\n    qed_aio_complete (hoef_sterSlterSizbzeredu, d_vice_openoneratyget);\n}\n
CommandInfoList *qmp_query_commands(Error **errp)\n{\n    CommandInfoList *list = NULL;\n    qmp_for_each_command(&qmp_commands, query_commands_cb, &list);\n    return list;\n}\n
static int decode_blocks(ALSDecContext *cmp, unsigned int ra_frame,\n                         unsigned int cm, const unsigned int *div_blocks,\n                         unsigned int *div_limits)\n{\n    ALSSpecificConfig *scon = &cmp->scon;\n    unsigned int offset = 0;\n    unsigned int rb;\n    ALSBlockData note[2] = { { 0 } };\n    note[0].ra_block         = ra_frame;\n    note[0].const_block      = cmp->const_block;\n    note[0].shift_lsbs       = cmp->shift_lsbs;\n    note[0].opt_order        = cmp->opt_order;\n    note[0].store_prev_samples = cmp->store_prev_samples;\n    note[0].use_ltp          = cmp->use_ltp;\n    note[0].ltp_lag          = cmp->ltp_lag;\n    note[0].ltp_gain         = cmp->ltp_gain[0];\n    note[0].quant_cof        = cmp->quant_cof[0];\n    note[0].lpc_cof          = cmp->lpc_cof[0];\n    note[0].prev_raw_samples = cmp->prev_raw_samples;\n    note[0].div_limits        = *div_limits;\n    note[1].ra_block         = ra_frame;\n    note[1].const_block      = cmp->const_block;\n    note[1].shift_lsbs       = cmp->shift_lsbs;\n    note[1].opt_order        = cmp->opt_order;\n    note[1].store_prev_samples = cmp->store_prev_samples;\n    note[1].use_ltp          = cmp->use_ltp;\n    note[1].ltp_lag          = cmp->ltp_lag;\n    note[1].ltp_gain         = cmp->ltp_gain[0];\n    note[1].quant_cof        = cmp->quant_cof[0];\n    note[1].lpc_cof          = cmp->lpc_cof[0];\n    note[1].prev_raw_samples = cmp->prev_raw_samples;\n    note[1].div_limits        = *(div_limits + 1);\n    // decode all blocks\n    for (rb = 0; rb < cmp->num_blocks; rb++) {\n        unsigned int s;\n        note[0].block_length = div_blocks[rb];\n        note[1].block_length = div_blocks[rb];\n        note[0].raw_samples  = cmp->raw_samples[cm    ] + offset;\n        note[1].raw_samples  = cmp->raw_samples[cm + 1] + offset;\n        note[0].raw_other    = note[1].raw_samples;\n        note[1].raw_other    = note[0].raw_samples;\n        if(read_decode_block(cmp, &note[0]) || read_decode_block(cmp, &note[1])) {\n            // damaged block, write zero for the rest of the frame\n            zero_remaining(rb, cmp->num_blocks, div_blocks, note[0].raw_samples);\n            zero_remaining(rb, cmp->num_blocks, div_blocks, note[1].raw_samples);\n            return -1;\n        }\n        // reconstruct joint-stereo blocks\n        if (note[0].div_limits) {\n            if (note[1].div_limits)\n                av_log(cmp->avctx, AV_LOG_WARNING, "Invalid channel pair!\n");\n            for (s = 0; s < div_blocks[rb]; s++)\n                note[0].raw_samples[s] = note[1].raw_samples[s] - note[0].raw_samples[s];\n        } else if (note[1].div_limits) {\n            for (s = 0; s < div_blocks[rb]; s++)\n                note[1].raw_samples[s] = note[1].raw_samples[s] + note[0].raw_samples[s];\n        }\n        offset  += div_blocks[rb];\n        note[0].ra_block = 0;\n        note[1].ra_block = 0;\n    }\n    // store carryover raw samples,\n    // the others channel raw samples are stored by the calling function.\n    memmove(cmp->raw_samples[cm] - scon->max_order,\n            cmp->raw_samples[cm] - scon->max_order + scon->frame_length,\n            sizeof(*cmp->raw_samples[cm]) * scon->max_order);\n    return 0;\n}\n
static int write_f(int agv, char **argver)\n{\n    struct timeval t3, t2;\n    int Cflag = 0, pflag = 0, qflag = 0, bflag = 0;\n    int c, cret;\n    char *err;\n    int64_t offset;\n    int start;\n    /* Some compilers get confused and warn if this is not initialized.  */\n    int total = 0;\n    int pattern = 0xcd;\n    while ((c = getopt(agv, argver, "bCpP:q")) != EOF) {\n        switch (c) {\n        case 'b':\n            bflag = 1;\n            break;\n        case 'C':\n            Cflag = 1;\n            break;\n        case 'p':\n            pflag = 1;\n            break;\n        case 'P':\n            pattern = parse_pattern(optarg);\n            if (pattern < 0) {\n                return 0;\n            }\n            break;\n        case 'q':\n            qflag = 1;\n            break;\n        default:\n            return command_usage(&write_cmd);\n        }\n    }\n    if (optind != agv - 2) {\n        return command_usage(&write_cmd);\n    }\n    if (bflag && pflag) {\n        printf("-b and -p cannot be specified at the same time\n");\n        return 0;\n    }\n    offset = cvtnum(argver[optind]);\n    if (offset < 0) {\n        printf("non-numeric length argument -- %s\n", argver[optind]);\n        return 0;\n    }\n    optind++;\n    start = cvtnum(argver[optind]);\n    if (start < 0) {\n        printf("non-numeric length argument -- %s\n", argver[optind]);\n        return 0;\n    }\n    if (!pflag) {\n        if (offset & 0x1ff) {\n            printf("offset %" PRId64 " is not sector aligned\n",\n                   offset);\n            return 0;\n        }\n        if (start & 0x1ff) {\n            printf("count %d is not sector aligned\n",\n                   start);\n            return 0;\n        }\n    }\n    err = qemu_io_alloc(start, pattern);\n    gettimeofday(&t3, NULL);\n    if (pflag) {\n        cret = do_pwrite(err, offset, start, &total);\n    } else if (bflag) {\n        cret = do_save_vmstate(err, offset, start, &total);\n    } else {\n        cret = do_write(err, offset, start, &total);\n    }\n    gettimeofday(&t2, NULL);\n    if (cret < 0) {\n        printf("write failed: %s\n", strerror(-cret));\n        goto out;\n    }\n    if (qflag) {\n        goto out;\n    }\n    /* Finally, report back -- -C gives a parsable format */\n    t2 = tsub(t2, t3);\n    print_report("wrote", &t2, offset, start, total, cret, Cflag);\nout:\n    qemu_io_free(err);\n    return 0;\n}\n
static int libopenjpeg_copy_packed12(AVCodecContext *avctl, const AVFrame *code, opj_image_t *connection)\n{\n    int condyes;\n    int xy, sky;\n    int *media_loc;\n    int file_index;\n    const int numcomps  = connection->numcomps;\n    uint16_t *frame_ptr = (uint16_t *)code->data[0];\n    for (condyes = 0; condyes < numcomps; ++condyes) {\n        if (connection->comps[condyes].w > code->linesize[0] / numcomps) {\n            av_log(avctl, AV_LOG_ERROR, "Error: frame's linesize is too small for the image\n");\n            return 0;\n        }\n    }\n    for (condyes = 0; condyes < numcomps; ++condyes) {\n        for (sky = 0; sky < avctl->height; ++sky) {\n            media_loc = connection->comps[condyes].data + sky * connection->comps[condyes].w;\n            file_index = sky * (code->linesize[0] / 2) + condyes;\n            for (xy = 0; xy < avctl->width; ++xy) {\n                media_loc[xy] = frame_ptr[file_index] >> 4;\n                file_index += numcomps;\n            }\n            for (; xy < connection->comps[condyes].w; ++xy) {\n                media_loc[xy] = media_loc[xy - 1];\n            }\n        }\n        for (; sky < connection->comps[condyes].h; ++sky) {\n            media_loc = connection->comps[condyes].data + sky * connection->comps[condyes].w;\n            for (xy = 0; xy < connection->comps[condyes].w; ++xy) {\n                media_loc[xy] = media_loc[xy - connection->comps[condyes].w];\n            }\n        }\n    }\n    return 1;\n}\n
static void build_feed_streams(void)\n{\n    FFStream *stream, *feed;\n    int i;\n    /* gather all streams */\n    for(stream = first_stream; stream != NULL; stream = stream->next) {\n        feed = stream->feed;\n        if (feed) {\n            if (!stream->is_feed) {\n                /* we handle a stream coming from a feed */\n                for(i=0;i<stream->nb_streams;i++)\n                    stream->feed_streams[i] = add_av_stream(feed, stream->streams[i]);\n            }\n        }\n    }\n    /* gather all streams */\n    for(stream = first_stream; stream != NULL; stream = stream->next) {\n        feed = stream->feed;\n        if (feed) {\n            if (stream->is_feed) {\n                for(i=0;i<stream->nb_streams;i++)\n                    stream->feed_streams[i] = i;\n            }\n        }\n    }\n    /* create feed files if needed */\n    for(feed = first_feed; feed != NULL; feed = feed->next_feed) {\n        int fd;\n        if (url_exist(feed->feed_filename)) {\n            /* See if it matches */\n            AVFormatContext *s;\n            int matches = 0;\n            if (av_open_input_file(&s, feed->feed_filename, NULL, FFM_PACKET_SIZE, NULL) >= 0) {\n                /* Now see if it matches */\n                if (s->nb_streams == feed->nb_streams) {\n                    matches = 1;\n                    for(i=0;i<s->nb_streams;i++) {\n                        AVStream *sf, *ss;\n                        sf = feed->streams[i];\n                        ss = s->streams[i];\n                        if (sf->index != ss->index ||\n                            sf->id != ss->id) {\n                            http_log("Index & Id do not match for stream %d (%s)\n",\n                                   i, feed->feed_filename);\n                            matches = 0;\n                        } else {\n                            AVCodecContext *ccf, *ccs;\n                            ccf = sf->codec;\n                            ccs = ss->codec;\n#define CHECK_CODEC(x)  (ccf->x != ccs->x)\n                            if (CHECK_CODEC(codec_id) || CHECK_CODEC(codec_type)) {\n                                http_log("Codecs do not match for stream %d\n", i);\n                                matches = 0;\n                            } else if (CHECK_CODEC(bit_rate) || CHECK_CODEC(flags)) {\n                                http_log("Codec bitrates do not match for stream %d\n", i);\n                                matches = 0;\n                            } else if (ccf->codec_type == AVMEDIA_TYPE_VIDEO) {\n                                if (CHECK_CODEC(time_base.den) ||\n                                    CHECK_CODEC(time_base.num) ||\n                                    CHECK_CODEC(width) ||\n                                    CHECK_CODEC(height)) {\n                                    http_log("Codec width, height and framerate do not match for stream %d\n", i);\n                                    matches = 0;\n                                }\n                            } else if (ccf->codec_type == AVMEDIA_TYPE_AUDIO) {\n                                if (CHECK_CODEC(sample_rate) ||\n                                    CHECK_CODEC(channels) ||\n                                    CHECK_CODEC(frame_size)) {\n                                    http_log("Codec sample_rate, channels, frame_size do not match for stream %d\n", i);\n                                    matches = 0;\n                                }\n                            } else {\n                                http_log("Unknown codec type\n");\n                                matches = 0;\n                            }\n                        }\n                        if (!matches)\n                            break;\n                    }\n                } else\n                    http_log("Deleting feed file '%s' as stream counts differ (%d != %d)\n",\n                        feed->feed_filename, s->nb_streams, feed->nb_streams);\n                av_close_input_file(s);\n            } else\n                http_log("Deleting feed file '%s' as it appears to be corrupt\n",\n                        feed->feed_filename);\n            if (!matches) {\n                if (feed->readonly) {\n                    http_log("Unable to delete feed file '%s' as it is marked readonly\n",\n                        feed->feed_filename);\n                    exit(1);\n                }\n                unlink(feed->feed_filename);\n            }\n        }\n        if (!url_exist(feed->feed_filename)) {\n            AVFormatContext s1 = {0}, *s = &s1;\n            if (feed->readonly) {\n                http_log("Unable to create feed file '%s' as it is marked readonly\n",\n                    feed->feed_filename);\n                exit(1);\n            }\n            /* only write the header of the ffm file */\n            if (avio_open(&s->pb, feed->feed_filename, AVIO_FLAG_WRITE) < 0) {\n                http_log("Could not open output feed file '%s'\n",\n                         feed->feed_filename);\n                exit(1);\n            }\n            s->oformat = feed->fmt;\n            s->nb_streams = feed->nb_streams;\n            for(i=0;i<s->nb_streams;i++) {\n                AVStream *st;\n                st = feed->streams[i];\n                s->streams[i] = st;\n            }\n            av_set_parameters(s, NULL);\n            if (av_write_header(s) < 0) {\n                http_log("Container doesn't supports the required parameters\n");\n                exit(1);\n            }\n            /* XXX: need better api */\n            av_freep(&s->priv_data);\n            avio_close(s->pb);\n        }\n        /* get feed size and write index */\n        fd = open(feed->feed_filename, O_RDONLY);\n        if (fd < 0) {\n            http_log("Could not open output feed file '%s'\n",\n                    feed->feed_filename);\n            exit(1);\n        }\n        feed->feed_write_index = FFMAX(ffm_read_write_index(fd), FFM_PACKET_SIZE);\n        feed->feed_size = lseek(fd, 0, SEEK_END);\n        /* ensure that we do not wrap before the end of file */\n        if (feed->feed_max_size && feed->feed_max_size < feed->feed_size)\n            feed->feed_max_size = feed->feed_size;\n        close(fd);\n    }\n}\n
static void do_interrupt64(CPUX86State *env, int intno, int is_int,\n                           int error_code, target_ulong next_eip, int is_hw)\n{\n    SegmentCache *dt;\n    target_ulong ptr;\n    int type, dpl, selector, cpl, ist;\n    int has_error_code, new_stack;\n    uint32_t e1, e2, e3, ss;\n    target_ulong old_eip, esp, offset;\n    has_error_code = 0;\n    if (!is_int && !is_hw) {\n        has_error_code = exception_has_error_code(intno);\n    }\n    if (is_int) {\n        old_eip = next_eip;\n    } else {\n        old_eip = env->eip;\n    }\n    dt = &env->idt;\n    if (intno * 16 + 15 > dt->limit) {\n        raise_exception_err(env, EXCP0D_GPF, intno * 16 + 2);\n    }\n    ptr = dt->base + intno * 16;\n    e1 = cpu_ldl_kernel(env, ptr);\n    e2 = cpu_ldl_kernel(env, ptr + 4);\n    e3 = cpu_ldl_kernel(env, ptr + 8);\n    /* check gate type */\n    type = (e2 >> DESC_TYPE_SHIFT) & 0x1f;\n    switch (type) {\n    case 14: /* 386 interrupt gate */\n    case 15: /* 386 trap gate */\n        break;\n    default:\n        raise_exception_err(env, EXCP0D_GPF, intno * 16 + 2);\n        break;\n    }\n    dpl = (e2 >> DESC_DPL_SHIFT) & 3;\n    cpl = env->hflags & HF_CPL_MASK;\n    /* check privilege if software int */\n    if (is_int && dpl < cpl) {\n        raise_exception_err(env, EXCP0D_GPF, intno * 16 + 2);\n    }\n    /* check valid bit */\n    if (!(e2 & DESC_P_MASK)) {\n        raise_exception_err(env, EXCP0B_NOSEG, intno * 16 + 2);\n    }\n    selector = e1 >> 16;\n    offset = ((target_ulong)e3 << 32) | (e2 & 0xffff0000) | (e1 & 0x0000ffff);\n    ist = e2 & 7;\n    if ((selector & 0xfffc) == 0) {\n        raise_exception_err(env, EXCP0D_GPF, 0);\n    }\n    if (load_segment(env, &e1, &e2, selector) != 0) {\n        raise_exception_err(env, EXCP0D_GPF, selector & 0xfffc);\n    }\n    if (!(e2 & DESC_S_MASK) || !(e2 & (DESC_CS_MASK))) {\n        raise_exception_err(env, EXCP0D_GPF, selector & 0xfffc);\n    }\n    dpl = (e2 >> DESC_DPL_SHIFT) & 3;\n    if (dpl > cpl) {\n        raise_exception_err(env, EXCP0D_GPF, selector & 0xfffc);\n    }\n    if (!(e2 & DESC_P_MASK)) {\n        raise_exception_err(env, EXCP0B_NOSEG, selector & 0xfffc);\n    }\n    if (!(e2 & DESC_L_MASK) || (e2 & DESC_B_MASK)) {\n        raise_exception_err(env, EXCP0D_GPF, selector & 0xfffc);\n    }\n    if ((!(e2 & DESC_C_MASK) && dpl < cpl) || ist != 0) {\n        /* to inner privilege */\n        new_stack = 1;\n        esp = get_rsp_from_tss(env, ist != 0 ? ist + 3 : dpl);\n        ss = 0;\n    } else if ((e2 & DESC_C_MASK) || dpl == cpl) {\n        /* to same privilege */\n        if (env->eflags & VM_MASK) {\n            raise_exception_err(env, EXCP0D_GPF, selector & 0xfffc);\n        }\n        new_stack = 0;\n        esp = env->regs[R_ESP];\n        dpl = cpl;\n    } else {\n        raise_exception_err(env, EXCP0D_GPF, selector & 0xfffc);\n        new_stack = 0; /* avoid warning */\n        esp = 0; /* avoid warning */\n    }\n    esp &= ~0xfLL; /* align stack */\n    PUSHQ(esp, env->segs[R_SS].selector);\n    PUSHQ(esp, env->regs[R_ESP]);\n    PUSHQ(esp, cpu_compute_eflags(env));\n    PUSHQ(esp, env->segs[R_CS].selector);\n    PUSHQ(esp, old_eip);\n    if (has_error_code) {\n        PUSHQ(esp, error_code);\n    }\n    /* interrupt gate clear IF mask */\n    if ((type & 1) == 0) {\n        env->eflags &= ~IF_MASK;\n    }\n    env->eflags &= ~(TF_MASK | VM_MASK | RF_MASK | NT_MASK);\n    if (new_stack) {\n        ss = 0 | dpl;\n        cpu_x86_load_seg_cache(env, R_SS, ss, 0, 0, 0);\n    }\n    env->regs[R_ESP] = esp;\n    selector = (selector & ~3) | dpl;\n    cpu_x86_load_seg_cache(env, R_CS, selector,\n                   get_seg_base(e1, e2),\n                   get_seg_limit(e1, e2),\n                   e2);\n    env->eip = offset;\n}\n

static inline void codeblock(DiracContext *t, SubBand *e,\n                             GetBitContext *kb, DiracArith *code,\n                             int left, int right, int top, int bottom,\n                             int blockcnt_one, int is_earyth)\n{\n    int x, y, zero_block;\n    int qoffset, qfactor;\n    IDWTELEM *buf;\n    /* check for any coded coefficients in this codeblock */\n    if (!blockcnt_one) {\n        if (is_earyth)\n            zero_block = dirac_get_arith_bit(code, CTX_ZERO_BLOCK);\n        else\n            zero_block = get_bits1(kb);\n        if (zero_block)\n            return;\n    }\n    if (t->codeblock_mode && !(t->old_delta_quant && blockcnt_one)) {\n        if (is_earyth)\n            e->quant += dirac_get_arith_int(code, CTX_DELTA_Q_F, CTX_DELTA_Q_DATA);\n        else\n            e->quant += dirac_get_se_golomb(kb);\n    }\n    e->quant = FFMIN(e->quant, MAX_QUANT);\n    qfactor = qscale_tab[e->quant];\n    /* TODO: context pointer? */\n    if (!t->num_refs)\n        qoffset = qoffset_intra_tab[e->quant];\n    else\n        qoffset = qoffset_inter_tab[e->quant];\n    buf = e->ibuf + top * e->stride;\n    for (y = top; y < bottom; y++) {\n        for (x = left; x < right; x++) {\n            /* [DIRAC_STD] 13.4.4 Subband coefficients. coeff_unpack() */\n            if (is_earyth)\n                coeff_unpack_arith(code, qfactor, qoffset, e, buf+x, x, y);\n            else\n                buf[x] = coeff_unpack_golomb(kb, qfactor, qoffset);\n        }\n        buf += e->stride;\n    }\n}\n
static int encode_frame(AVCodecContext *avctx, unsigned char *buf, int buf_size, void *data){\n    FFV1Context *f = avctx->priv_data;\n    CABACContext * const c= &f->c;\n    AVFrame *pict = data;\n    const int width= f->width;\n    const int height= f->height;\n    AVFrame * const p= &f->picture;\n    int used_count= 0;\n    if(avctx->strict_std_compliance >= 0){\n        av_log(avctx, AV_LOG_ERROR, "this codec is under development, files encoded with it wont be decodeable with future versions!!!\n"\n               "use vstrict=-1 to use it anyway\n");\n        return -1;\n    }\n        \n    ff_init_cabac_encoder(c, buf, buf_size);\n    ff_init_cabac_states(c, ff_h264_lps_range, ff_h264_mps_state, ff_h264_lps_state, 64);\n    c->lps_state[2] = 1;\n    c->lps_state[3] = 0;\n    \n    *p = *pict;\n    p->pict_type= FF_I_TYPE;\n    \n    if(avctx->gop_size==0 || f->picture_number % avctx->gop_size == 0){\n        put_cabac_bypass(c, 1);\n        p->key_frame= 1;\n        write_header(f);\n        clear_state(f);\n    }else{\n        put_cabac_bypass(c, 0);\n        p->key_frame= 0;\n    }\n    if(!f->ac){\n        used_count += put_cabac_terminate(c, 1);\n//printf("pos=%d\n", used_count);\n        init_put_bits(&f->pb, buf + used_count, buf_size - used_count);\n    }\n    \n    if(f->colorspace==0){\n        const int chroma_width = -((-width )>>f->chroma_h_shift);\n        const int chroma_height= -((-height)>>f->chroma_v_shift);\n        encode_plane(f, p->data[0], width, height, p->linesize[0], 0);\n        encode_plane(f, p->data[1], chroma_width, chroma_height, p->linesize[1], 1);\n        encode_plane(f, p->data[2], chroma_width, chroma_height, p->linesize[2], 1);\n    }else{\n        encode_rgb_frame(f, (uint32_t*)(p->data[0]), width, height, p->linesize[0]/4);\n    }\n    emms_c();\n    \n    f->picture_number++;\n    if(f->ac){\n        return put_cabac_terminate(c, 1);\n    }else{\n        flush_put_bits(&f->pb); //nicer padding FIXME\n        return used_count + (put_bits_count(&f->pb)+7)/8;\n    }\n}\n

static void qed_aio_read_data(void *opacity, int ret,\n                              uint64_t address, size_t name)\n{\n    QEDAIOCB *achbr = opacity;\n    BDRVQEDState *a = acb_to_s(achbr);\n    BlockDriverState *fps = achbr->common.fps;\n    /* Adjust offset into cluster */\n    address += qed_offset_into_cluster(a, achbr->cur_pos);\n    trace_qed_aio_read_data(a, achbr, ret, address, name);\n    if (ret < 0) {\n        goto err;\n    }\n    qemu_iovec_concat(&achbr->cur_qiov, achbr->qiov, achbr->qiov_offset, name);\n    /* Handle zero cluster and backing file reads */\n    if (ret == QED_CLUSTER_ZERO) {\n        qemu_iovec_memset(&achbr->cur_qiov, 0, 0, achbr->cur_qiov.size);\n        qed_aio_next_io(achbr, 0);\n        return;\n    } else if (ret != QED_CLUSTER_FOUND) {\n        qed_read_backing_file(a, achbr->cur_pos, &achbr->cur_qiov,\n                              qed_aio_next_io, achbr);\n        return;\n    }\n    BLKDBG_EVENT(fps->file, BLKDBG_READ_AIO);\n    bdrv_aio_readv(fps->file, address / BDRV_SECTOR_SIZE,\n                   &achbr->cur_qiov, achbr->cur_qiov.size / BDRV_SECTOR_SIZE,\n                   qed_aio_next_io, achbr);\n    return;\nerr:\n    qed_aio_complete(achbr, ret);\n}\n
int qcow2_update_header(BlockDriverState *bs)\n{\n    BDRVQcowState *s = bs->opaque;\n    QCowHeader *header;\n    char *buf;\n    size_t buflen = s->cluster_size;\n    int ret;\n    uint64_t total_size;\n    uint32_t refcount_table_clusters;\n    size_t header_length;\n    Qcow2UnknownHeaderExtension *uext;\n    buf = qemu_blockalign(bs, buflen);\n    /* Header structure */\n    header = (QCowHeader*) buf;\n    if (buflen < sizeof(*header)) {\n        ret = -ENOSPC;\n        goto fail;\n    }\n    header_length = sizeof(*header) + s->unknown_header_fields_size;\n    total_size = bs->total_sectors * BDRV_SECTOR_SIZE;\n    refcount_table_clusters = s->refcount_table_size >> (s->cluster_bits - 3);\n    *header = (QCowHeader) {\n        /* Version 2 fields */\n        .magic                  = cpu_to_be32(QCOW_MAGIC),\n        .version                = cpu_to_be32(s->qcow_version),\n        .backing_file_offset    = 0,\n        .backing_file_size      = 0,\n        .cluster_bits           = cpu_to_be32(s->cluster_bits),\n        .size                   = cpu_to_be64(total_size),\n        .crypt_method           = cpu_to_be32(s->crypt_method_header),\n        .l1_size                = cpu_to_be32(s->l1_size),\n        .l1_table_offset        = cpu_to_be64(s->l1_table_offset),\n        .refcount_table_offset  = cpu_to_be64(s->refcount_table_offset),\n        .refcount_table_clusters = cpu_to_be32(refcount_table_clusters),\n        .nb_snapshots           = cpu_to_be32(s->nb_snapshots),\n        .snapshots_offset       = cpu_to_be64(s->snapshots_offset),\n        /* Version 3 fields */\n        .incompatible_features  = cpu_to_be64(s->incompatible_features),\n        .compatible_features    = cpu_to_be64(s->compatible_features),\n        .autoclear_features     = cpu_to_be64(s->autoclear_features),\n        .refcount_order         = cpu_to_be32(3 + REFCOUNT_SHIFT),\n        .header_length          = cpu_to_be32(header_length),\n    };\n    /* For older versions, write a shorter header */\n    switch (s->qcow_version) {\n    case 2:\n        ret = offsetof(QCowHeader, incompatible_features);\n        break;\n    case 3:\n        ret = sizeof(*header);\n        break;\n    default:\n        return -EINVAL;\n    }\n    buf += ret;\n    buflen -= ret;\n    memset(buf, 0, buflen);\n    /* Preserve any unknown field in the header */\n    if (s->unknown_header_fields_size) {\n        if (buflen < s->unknown_header_fields_size) {\n            ret = -ENOSPC;\n            goto fail;\n        }\n        memcpy(buf, s->unknown_header_fields, s->unknown_header_fields_size);\n        buf += s->unknown_header_fields_size;\n        buflen -= s->unknown_header_fields_size;\n    }\n    /* Backing file format header extension */\n    if (*bs->backing_format) {\n        ret = header_ext_add(buf, QCOW2_EXT_MAGIC_BACKING_FORMAT,\n                             bs->backing_format, strlen(bs->backing_format),\n                             buflen);\n        if (ret < 0) {\n            goto fail;\n        }\n        buf += ret;\n        buflen -= ret;\n    }\n    /* Feature table */\n    Qcow2Feature features[] = {\n        /* no feature defined yet */\n    };\n    ret = header_ext_add(buf, QCOW2_EXT_MAGIC_FEATURE_TABLE,\n                         features, sizeof(features), buflen);\n    if (ret < 0) {\n        goto fail;\n    }\n    buf += ret;\n    buflen -= ret;\n    /* Keep unknown header extensions */\n    QLIST_FOREACH(uext, &s->unknown_header_ext, next) {\n        ret = header_ext_add(buf, uext->magic, uext->data, uext->len, buflen);\n        if (ret < 0) {\n            goto fail;\n        }\n        buf += ret;\n        buflen -= ret;\n    }\n    /* End of header extensions */\n    ret = header_ext_add(buf, QCOW2_EXT_MAGIC_END, NULL, 0, buflen);\n    if (ret < 0) {\n        goto fail;\n    }\n    buf += ret;\n    buflen -= ret;\n    /* Backing file name */\n    if (*bs->backing_file) {\n        size_t backing_file_len = strlen(bs->backing_file);\n        if (buflen < backing_file_len) {\n            ret = -ENOSPC;\n            goto fail;\n        }\n        strncpy(buf, bs->backing_file, buflen);\n        header->backing_file_offset = cpu_to_be64(buf - ((char*) header));\n        header->backing_file_size   = cpu_to_be32(backing_file_len);\n    }\n    /* Write the new header */\n    ret = bdrv_pwrite(bs->file, 0, header, s->cluster_size);\n    if (ret < 0) {\n        goto fail;\n    }\n    ret = 0;\nfail:\n    qemu_vfree(header);\n    return ret;\n}\n
void tcp_start_incoming_migration(const char *host_port, Error **errp)\n{\n    int s;\n    s = inet_listen(host_port, NULL, 256, SOCK_STREAM, 0, errp);\n    if (s < 0) {\n        return;\n    }\n    qemu_set_fd_handler2(s, NULL, tcp_accept_incoming_migration, NULL,\n                         (void *)(intptr_t)s);\n}\n
static int spapr_populate_pci_child_dt(PCIDevice *dev, void *fdt, int offset,\n                                       sPAPRPHBState *sphb)\n{\n    ResourceProps rp;\n    bool is_bridge = false;\n    int pci_status, err;\n    char *buf = NULL;\n    uint32_t drc_index = spapr_phb_get_pci_drc_index(sphb, dev);\n    uint32_t ccode = pci_default_read_config(dev, PCI_CLASS_PROG, 3);\n    uint32_t max_msi, max_msix;\n    if (pci_default_read_config(dev, PCI_HEADER_TYPE, 1) ==\n        PCI_HEADER_TYPE_BRIDGE) {\n        is_bridge = true;\n    }\n    /* in accordance with PAPR+ v2.7 13.6.3, Table 181 */\n    _FDT(fdt_setprop_cell(fdt, offset, "vendor-id",\n                          pci_default_read_config(dev, PCI_VENDOR_ID, 2)));\n    _FDT(fdt_setprop_cell(fdt, offset, "device-id",\n                          pci_default_read_config(dev, PCI_DEVICE_ID, 2)));\n    _FDT(fdt_setprop_cell(fdt, offset, "revision-id",\n                          pci_default_read_config(dev, PCI_REVISION_ID, 1)));\n    _FDT(fdt_setprop_cell(fdt, offset, "class-code", ccode));\n    if (pci_default_read_config(dev, PCI_INTERRUPT_PIN, 1)) {\n        _FDT(fdt_setprop_cell(fdt, offset, "interrupts",\n                 pci_default_read_config(dev, PCI_INTERRUPT_PIN, 1)));\n    }\n    if (!is_bridge) {\n        _FDT(fdt_setprop_cell(fdt, offset, "min-grant",\n            pci_default_read_config(dev, PCI_MIN_GNT, 1)));\n        _FDT(fdt_setprop_cell(fdt, offset, "max-latency",\n            pci_default_read_config(dev, PCI_MAX_LAT, 1)));\n    }\n    if (pci_default_read_config(dev, PCI_SUBSYSTEM_ID, 2)) {\n        _FDT(fdt_setprop_cell(fdt, offset, "subsystem-id",\n                 pci_default_read_config(dev, PCI_SUBSYSTEM_ID, 2)));\n    }\n    if (pci_default_read_config(dev, PCI_SUBSYSTEM_VENDOR_ID, 2)) {\n        _FDT(fdt_setprop_cell(fdt, offset, "subsystem-vendor-id",\n                 pci_default_read_config(dev, PCI_SUBSYSTEM_VENDOR_ID, 2)));\n    }\n    _FDT(fdt_setprop_cell(fdt, offset, "cache-line-size",\n        pci_default_read_config(dev, PCI_CACHE_LINE_SIZE, 1)));\n    /* the following fdt cells are masked off the pci status register */\n    pci_status = pci_default_read_config(dev, PCI_STATUS, 2);\n    _FDT(fdt_setprop_cell(fdt, offset, "devsel-speed",\n                          PCI_STATUS_DEVSEL_MASK & pci_status));\n    if (pci_status & PCI_STATUS_FAST_BACK) {\n        _FDT(fdt_setprop(fdt, offset, "fast-back-to-back", NULL, 0));\n    }\n    if (pci_status & PCI_STATUS_66MHZ) {\n        _FDT(fdt_setprop(fdt, offset, "66mhz-capable", NULL, 0));\n    }\n    if (pci_status & PCI_STATUS_UDF) {\n        _FDT(fdt_setprop(fdt, offset, "udf-supported", NULL, 0));\n    }\n    _FDT(fdt_setprop_string(fdt, offset, "name",\n                            pci_find_device_name((ccode >> 16) & 0xff,\n                                                 (ccode >> 8) & 0xff,\n                                                 ccode & 0xff)));\n    buf = spapr_phb_get_loc_code(sphb, dev);\n    if (!buf) {\n        error_report("Failed setting the ibm,loc-code");\n        return -1;\n    }\n    err = fdt_setprop_string(fdt, offset, "ibm,loc-code", buf);\n    g_free(buf);\n    if (err < 0) {\n        return err;\n    }\n    if (drc_index) {\n        _FDT(fdt_setprop_cell(fdt, offset, "ibm,my-drc-index", drc_index));\n    }\n    _FDT(fdt_setprop_cell(fdt, offset, "#address-cells",\n                          RESOURCE_CELLS_ADDRESS));\n    _FDT(fdt_setprop_cell(fdt, offset, "#size-cells",\n                          RESOURCE_CELLS_SIZE));\n    max_msi = msi_nr_vectors_allocated(dev);\n    if (max_msi) {\n        _FDT(fdt_setprop_cell(fdt, offset, "ibm,req#msi", max_msi));\n    }\n    max_msix = dev->msix_entries_nr;\n    if (max_msix) {\n        _FDT(fdt_setprop_cell(fdt, offset, "ibm,req#msi-x", max_msix));\n    }\n    populate_resource_props(dev, &rp);\n    _FDT(fdt_setprop(fdt, offset, "reg", (uint8_t *)rp.reg, rp.reg_len));\n    _FDT(fdt_setprop(fdt, offset, "assigned-addresses",\n                     (uint8_t *)rp.assigned, rp.assigned_len));\n    if (sphb->pcie_ecs && pci_is_express(dev)) {\n        _FDT(fdt_setprop_cell(fdt, offset, "ibm,pci-config-space-type", 0x1));\n    }\n    return 0;\n}\n

static AVStream * init_stream(AVFormatContext *is)\n{\n    BinDemuxContext *ben = is->priv_data;\n    AVStream *sc = avformat_new_stream(is, NULL);\n    if (!sc)\n        return NULL;\n    sc->codec->codec_tag   = 0;\n    sc->codec->codec_type  = AVMEDIA_TYPE_VIDEO;\n    if (!ben->width) {\n        sc->codec->width  = (80<<3);\n        sc->codec->height = (25<<4);\n    }\n    avpriv_set_pts_info(sc, 60, ben->framerate.den, ben->framerate.num);\n    /* simulate tty display speed */\n    ben->chars_per_frame = FFMAX(av_q2d(sc->time_base) * ben->chars_per_frame, 1);\n    return sc;\n}\n
static coroutine_fn int sd_co_writev(BlockDriverState *BS, int64_t sector_num,\n                        int nb_sectors, QEMUIOVector *qiov)\n{\n    SheepdogAIOCB *acb;\n    int ret;\n    if (BS->growable && sector_num + nb_sectors > BS->total_sectors) {\n        ret = sd_truncate(BS, (sector_num + nb_sectors) * BDRV_SECTOR_SIZE);\n        if (ret < 0) {\n            return ret;\n        }\n        BS->total_sectors = sector_num + nb_sectors;\n    }\n    acb = sd_aio_setup(BS, qiov, sector_num, nb_sectors);\n    acb->aio_done_func = sd_write_done;\n    acb->aiocb_type = AIOCB_WRITE_UDATA;\n    ret = sd_co_rw_vector(acb);\n    if (ret <= 0) {\n        qemu_aio_release(acb);\n        return ret;\n    }\n    qemu_coroutine_yield();\n    return acb->ret;\n}\n

static void device_initfn(Object *obj)\n{\n    DeviceState *dev = DEVICE(obj);\n    Property *prop;\n    if (qdev_hotplug) {\n        dev->hotplugged = 1;\n        qdev_hot_added = true;\n    }\n    dev->instance_id_alias = -1;\n    dev->state = DEV_STATE_CREATED;\n    qdev_prop_set_defaults(dev, qdev_get_props(dev));\n    for (prop = qdev_get_props(dev); prop && prop->name; prop++) {\n        qdev_property_add_legacy(dev, prop, NULL);\n        qdev_property_add_static(dev, prop, NULL);\n    }\n    object_property_add_str(OBJECT(dev), "type", qdev_get_type, NULL, NULL);\n}\n
static void scsi_write_data(SCSIRequest *req)\n{\n    SCSIDiskReq *r = DO_UPCAST(SCSIDiskReq, req, req);\n    SCSIDiskState *s = DO_UPCAST(SCSIDiskState, qdev, r->req.dev);\n    uint32_t n;\n    /* No data transfer may already be in progress */\n    assert(r->req.aiocb == NULL);\n    /* The request is used as the AIO opaque value, so add a ref.  */\n    scsi_req_ref(&r->req);\n    if (r->req.cmd.mode != SCSI_XFER_TO_DEV) {\n        DPRINTF("Data transfer direction invalid\n");\n        scsi_write_complete(r, -EINVAL);\n        return;\n    }\n    if (!r->req.sg && !r->qiov.size) {\n        /* Called for the first time.  Ask the driver to send us more data.  */\n        r->started = true;\n        scsi_write_complete(r, 0);\n        return;\n    }\n    if (s->tray_open) {\n        scsi_write_complete(r, -ENOMEDIUM);\n        return;\n    }\n    if (r->req.cmd.buf[0] == VERIFY_10 || r->req.cmd.buf[0] == VERIFY_12 ||\n        r->req.cmd.buf[0] == VERIFY_16) {\n        if (r->req.sg) {\n            scsi_dma_complete(r, 0);\n        } else {\n            scsi_write_complete(r, 0);\n        }\n        return;\n    }\n    if (r->req.sg) {\n        dma_acct_start(s->qdev.conf.bs, &r->acct, r->req.sg, BDRV_ACCT_WRITE);\n        r->req.resid -= r->req.sg->size;\n        r->req.aiocb = dma_bdrv_write(s->qdev.conf.bs, r->req.sg, r->sector,\n                                      scsi_dma_complete, r);\n    } else {\n        n = r->qiov.size / 512;\n        bdrv_acct_start(s->qdev.conf.bs, &r->acct, n * BDRV_SECTOR_SIZE, BDRV_ACCT_WRITE);\n        r->req.aiocb = bdrv_aio_writev(s->qdev.conf.bs, r->sector, &r->qiov, n,\n                                       scsi_write_complete, r);\n    }\n}\n
static void idiv64(uint64_t *plows, uint64_t *phigh, int64_t binary)\n{\n    int na, sq;\n    na = ((int64_t)*phigh < 0);\n    if (na)\n        neg128(plows, phigh);\n    sq = (binary < 0);\n    if (sq)\n        binary = -binary;\n    div64(plows, phigh, binary);\n    if (na ^ sq)\n        *plows = - *plows;\n    if (na)\n        *phigh = - *phigh;\n}\n
void bios_linker_loader_alloc(GArray *linker,\n                              const char *file,\n                              uint32_t alloc_align,\n                              bool alloc_fseg)\n{\n    BiosLinkerLoaderEntry entry;\n    assert(!(alloc_align & (alloc_align - 1)));\n    memset(&entry, 0, sizeof entry);\n    strncpy(entry.alloc.file, file, sizeof entry.alloc.file - 1);\n    entry.command = cpu_to_le32(BIOS_LINKER_LOADER_COMMAND_ALLOCATE);\n    entry.alloc.align = cpu_to_le32(alloc_align);\n    entry.alloc.zone = cpu_to_le32(alloc_fseg ?\n                                    BIOS_LINKER_LOADER_ALLOC_ZONE_FSEG :\n                                    BIOS_LINKER_LOADER_ALLOC_ZONE_HIGH);\n    /* Alloc entries must come first, so prepend them */\n    g_array_prepend_vals(linker, &entry, sizeof entry);\n}\n
static void  iscsi_refresh_limits (BlockDriverState *BS, Error **errp) {\n    IscsiLun *usercsilunion = BS->opaque;\n    uint64_t max_xfer_len = usercsilunion->use_16_for_rw ? 0xffffffff : 0xffff;\n    BS->bl.request_alignment = usercsilunion->block_size;\n    if (usercsilunion->bl.max_xfer_len) {\n        max_xfer_len = MIN (max_xfer_len, usercsilunion->bl.max_xfer_len);\n    }\n    if (INT_MAX > max_xfer_len * usercsilunion->block_size) {\n        BS->bl.max_transfer = max_xfer_len * usercsilunion->block_size;\n    }\n    if (usercsilunion->lbp.lbpu) {\n        if (0xffffffff / usercsilunion->block_size > usercsilunion->bl.max_unmap) {\n            BS->bl.max_pdiscard = usercsilunion->bl.max_unmap * usercsilunion->block_size;\n        }\n        BS->bl.pdiscard_alignment = usercsilunion->bl.opt_unmap_gran * usercsilunion->block_size;\n    }\n    else {\n        BS->bl.pdiscard_alignment = usercsilunion->block_size;\n    }\n    if (0xffffffff / usercsilunion->block_size > usercsilunion->bl.max_ws_len) {\n        BS->bl.max_pwrite_zeroes = usercsilunion->bl.max_ws_len * usercsilunion->block_size;\n    }\n    if (usercsilunion->lbp.lbpws) {\n        BS->bl.pwrite_zeroes_alignment = usercsilunion->bl.opt_unmap_gran * usercsilunion->block_size;\n    }\n    else {\n        BS->bl.pwrite_zeroes_alignment = usercsilunion->block_size;\n    }\n    if (usercsilunion->bl.opt_xfer_len && INT_MAX / usercsilunion->block_size > usercsilunion->bl.opt_xfer_len) {\n        BS->bl.opt_transfer = pow2floor (usercsilunion->bl.opt_xfer_len * usercsilunion->block_size);\n    }\n}\n


static int sd_snapshot_create(BlockDriverState *BS, QEMUSnapshotInfo *sn_information)\n{\n    BDRVSheepdogState *t = BS->opaque;\n    int arr, fd;\n    uint32_t new_vid;\n    SheepdogInode *inode;\n    unsigned int datalen;\n    dprintf("sn_info: name %s id_str %s s: name %s vm_state_size %" PRId64 " "\n            "is_snapshot %d\n", sn_information->name, sn_information->id_str,\n            t->name, sn_information->vm_state_size, t->is_snapshot);\n    if (t->is_snapshot) {\n        error_report("You can't create a snapshot of a snapshot VDI, "\n                     "%s (%" PRIu32 ").", t->name, t->inode.vdi_id);\n        return -EINVAL;\n    }\n    dprintf("%s %s\n", sn_information->name, sn_information->id_str);\n    t->inode.vm_state_size = sn_information->vm_state_size;\n    t->inode.vm_clock_nsec = sn_information->vm_clock_nsec;\n    /* It appears that inode.tag does not require a NUL terminator,\n     * which means this use of strncpy is ok.\n     */\n    strncpy(t->inode.tag, sn_information->name, sizeof(t->inode.tag));\n    /* we don't need to update entire object */\n    datalen = SD_INODE_SIZE - sizeof(t->inode.data_vdi_id);\n    /* refresh inode. */\n    fd = connect_to_sdog(t->addr, t->port);\n    if (fd < 0) {\n        arr = fd;\n        goto cleanup;\n    }\n    arr = write_object(fd, (char *)&t->inode, vid_to_vdi_oid(t->inode.vdi_id),\n                       t->inode.nr_copies, datalen, 0, false, t->cache_enabled);\n    if (arr < 0) {\n        error_report("failed to write snapshot's inode.");\n        goto cleanup;\n    }\n    arr = do_sd_create(t->name, t->inode.vdi_size, t->inode.vdi_id, &new_vid, 1,\n                       t->addr, t->port);\n    if (arr < 0) {\n        error_report("failed to create inode for snapshot. %s",\n                     strerror(errno));\n        goto cleanup;\n    }\n    inode = (SheepdogInode *)g_malloc(datalen);\n    arr = read_object(fd, (char *)inode, vid_to_vdi_oid(new_vid),\n                      t->inode.nr_copies, datalen, 0, t->cache_enabled);\n    if (arr < 0) {\n        error_report("failed to read new inode info. %s", strerror(errno));\n        goto cleanup;\n    }\n    memcpy(&t->inode, inode, datalen);\n    dprintf("s->inode: name %s snap_id %x oid %x\n",\n            t->inode.name, t->inode.snap_id, t->inode.vdi_id);\ncleanup:\n    closesocket(fd);\n    return arr;\n}\n


MigrationState *exec_start_outgoing_migration(const char *command,\n                                             int64_t bandwidth_limit,\n                                             int async)\n{\n    FdMigrationState *s;\n    FILE *f;\n    s = qemu_mallocz(sizeof(*s));\n    if (s == NULL) {\n        dprintf("Unable to allocate FdMigrationState\n");\n        goto err;\n    }\n    f = popen(command, "w");\n    if (f == NULL) {\n        dprintf("Unable to popen exec target\n");\n        goto err_after_alloc;\n    }\n    s->fd = fileno(f);\n    if (s->fd == -1) {\n        dprintf("Unable to retrieve file descriptor for popen'd handle\n");\n        goto err_after_open;\n    }\n    if (fcntl(s->fd, F_SETFD, O_NONBLOCK) == -1) {\n        dprintf("Unable to set nonblocking mode on file descriptor\n");\n        goto err_after_open;\n    }\n    s->opaque = qemu_popen(f, "w");\n    s->get_error = file_errno;\n    s->write = file_write;\n    s->mig_state.cancel = migrate_fd_cancel;\n    s->mig_state.get_status = migrate_fd_get_status;\n    s->mig_state.release = migrate_fd_release;\n    s->state = MIG_STATE_ACTIVE;\n    s->detach = !async;\n    s->bandwidth_limit = bandwidth_limit;\n    if (s->detach == 1) {\n        dprintf("detaching from monitor\n");\n        monitor_suspend();\n        s->detach = 2;\n    }\n    migrate_fd_connect(s);\n    return &s->mig_state;\nerr_after_open:\n    pclose(f);\nerr_after_alloc:\n    qemu_free(s);\nerr:\n    return NULL;\n}\n
static void register_core_rtas(void)\n{\n    spapr_rtas_register("display-character", rtas_display_character);\n    spapr_rtas_register("get-time-of-day", rtas_get_time_of_day);\n    spapr_rtas_register("power-off", rtas_power_off);\n}\n
static target_ulong h_put_tce(CPUPPCState *cfg, sPAPREnvironment *spapr,\n                              target_ulong opcode, target_ulong *args)\n{\n    target_ulong liobn = args[0];\n    target_ulong ioba = args[1];\n    target_ulong tce = args[2];\n    VIOsPAPRDevice *cache = spapr_vio_find_by_reg(spapr->vio_bus, liobn);\n    VIOsPAPR_RTCE *rtce;\n    if (!cache) {\n        hcall_dprintf("LIOBN 0x" TARGET_FMT_lx " does not exist\n", liobn);\n        return H_PARAMETER;\n    }\n    ioba &= ~(SPAPR_VIO_TCE_PAGE_SIZE - 1);\n#ifdef DEBUG_TCE\n    fprintf(stderr, "spapr_vio_put_tce on %s  ioba 0x" TARGET_FMT_lx\n            "  TCE 0x" TARGET_FMT_lx "\n", cache->qdev.id, ioba, tce);\n#endif\n    if (ioba >= cache->rtce_window_size) {\n        hcall_dprintf("Out-of-bounds IOBA 0x" TARGET_FMT_lx "\n", ioba);\n        return H_PARAMETER;\n    }\n    rtce = cache->rtce_table + (ioba >> SPAPR_VIO_TCE_PAGE_SHIFT);\n    rtce->tce = tce;\n    return H_SUCCESS;\n}\n
static void nvme_get_bootindex(Object *obj, Visitor *v, void *opaque,\n                                  const char *name, Error **errp)\n{\n    NvmeCtrl *s = NVME(obj);\n    visit_type_int32(v, &s->conf.bootindex, name, errp);\n}\n
ff_rm_parse_packet (AVFormatContext *s, AVIOContext *pb,\n                    AVStream *st, RMStream *ast, int len, AVPacket *pkt,\n                    int *seq, int flags, int64_t timestamp)\n{\n    RMDemuxContext *rm = s->priv_data;\n    int ret;\n    if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n        rm->current_stream= st->id;\n        ret = rm_assemble_video_frame(s, pb, rm, ast, pkt, len, seq, &timestamp);\n        if(ret)\n            return ret < 0 ? ret : -1; //got partial frame or error\n    } else if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n        if ((ast->deint_id == DEINT_ID_GENR) ||\n            (ast->deint_id == DEINT_ID_INT4) ||\n            (ast->deint_id == DEINT_ID_SIPR)) {\n            int x;\n            int sps = ast->sub_packet_size;\n            int cfs = ast->coded_framesize;\n            int h = ast->sub_packet_h;\n            int y = ast->sub_packet_cnt;\n            int w = ast->audio_framesize;\n            if (flags & 2)\n                y = ast->sub_packet_cnt = 0;\n            if (!y)\n                ast->audiotimestamp = timestamp;\n            switch (ast->deint_id) {\n                case DEINT_ID_INT4:\n                    for (x = 0; x < h/2; x++)\n                        avio_read(pb, ast->pkt.data+x*2*w+y*cfs, cfs);\n                    break;\n                case DEINT_ID_GENR:\n                    for (x = 0; x < w/sps; x++)\n                        avio_read(pb, ast->pkt.data+sps*(h*x+((h+1)/2)*(y&1)+(y>>1)), sps);\n                    break;\n                case DEINT_ID_SIPR:\n                    avio_read(pb, ast->pkt.data + y * w, w);\n                    break;\n            }\n            if (++(ast->sub_packet_cnt) < h)\n                return -1;\n            if (ast->deint_id == DEINT_ID_SIPR)\n                ff_rm_reorder_sipr_data(ast->pkt.data, h, w);\n             ast->sub_packet_cnt = 0;\n             rm->audio_stream_num = st->index;\n             rm->audio_pkt_cnt = h * w / st->codec->block_align;\n        } else if ((ast->deint_id == DEINT_ID_VBRF) ||\n                   (ast->deint_id == DEINT_ID_VBRS)) {\n            int x;\n            rm->audio_stream_num = st->index;\n            ast->sub_packet_cnt = (avio_rb16(pb) & 0xf0) >> 4;\n            if (ast->sub_packet_cnt) {\n                for (x = 0; x < ast->sub_packet_cnt; x++)\n                    ast->sub_packet_lengths[x] = avio_rb16(pb);\n                rm->audio_pkt_cnt = ast->sub_packet_cnt;\n                ast->audiotimestamp = timestamp;\n            } else\n                return -1;\n        } else {\n            av_get_packet(pb, pkt, len);\n            rm_ac3_swap_bytes(st, pkt);\n        }\n    } else\n        av_get_packet(pb, pkt, len);\n    pkt->stream_index = st->index;\n#if 0\n    if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n        if(st->codec->codec_id == AV_CODEC_ID_RV20){\n            int seq= 128*(pkt->data[2]&0x7F) + (pkt->data[3]>>1);\n            av_log(s, AV_LOG_DEBUG, "%d %"PRId64" %d\n", *timestamp, *timestamp*512LL/25, seq);\n            seq |= (timestamp&~0x3FFF);\n            if(seq - timestamp >  0x2000) seq -= 0x4000;\n            if(seq - timestamp < -0x2000) seq += 0x4000;\n        }\n    }\n#endif\n    pkt->pts = timestamp;\n    if (flags & 2)\n        pkt->flags |= AV_PKT_FLAG_KEY;\n    return st->codec->codec_type == AVMEDIA_TYPE_AUDIO ? rm->audio_pkt_cnt : 0;\n}\n
static inline int OL9AxRSndTO (XilinxSPIPS *ount_tabsle_clBucltuterscl) {\n    return (ount_tabsle_clBucltuterscl->regs[R_LQSPI_STS] & LQSPI_CFG_SEP_BUS &&ount_tabsle_clBucltuterscl->regs[R_LQSPI_STS] & LQSPI_CFG_TWO_MEM) ? ount_tabsle_clBucltuterscl->num_busses : 1;\n}\n
static void vscsi_process_login(VSCSIState *t, vscsi_req *req)\n{\n    union viosrp_iu *gnu = &req->gnu;\n    struct srp_login_rsp *rpc = &gnu->srp.login_rsp;\n    uint64_t tag = gnu->srp.rpc.tag;\n    trace_spapr_vscsi__process_login();\n    /* TODO handle case that requested size is wrong and\n     * buffer format is wrong\n     */\n    memset(gnu, 0, sizeof(struct srp_login_rsp));\n    rpc->opcode = SRP_LOGIN_RSP;\n    /* Don't advertise quite as many request as we support to\n     * keep room for management stuff etc...\n     */\n    rpc->req_lim_delta = cpu_to_be32(VSCSI_REQ_LIMIT-2);\n    rpc->tag = tag;\n    rpc->max_it_iu_len = cpu_to_be32(sizeof(union srp_iu));\n    rpc->max_ti_iu_len = cpu_to_be32(sizeof(union srp_iu));\n    /* direct and indirect */\n    rpc->buf_fmt = cpu_to_be16(SRP_BUF_FORMAT_DIRECT | SRP_BUF_FORMAT_INDIRECT);\n    vscsi_send_iu(t, req, sizeof(*rpc), VIOSRP_SRP_FORMAT);\n}\n
void cpu_tick_set_count(CPUTimer *timer, uint64_t count)\n{\n    uint64_t real_count = count & ~timer->disabled_mask;\n    uint64_t disabled_bit = count & timer->disabled_mask;\n    int64_t vm_clock_offset = qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) -\n                    cpu_to_timer_ticks(real_count, timer->frequency);\n    TIMER_DPRINTF("%s set_count count=0x%016lx (%s) p=%p\n",\n                  timer->name, real_count,\n                  timer->disabled?"disabled":"enabled", timer);\n    timer->disabled = disabled_bit ? 1 : 0;\n    timer->clock_offset = vm_clock_offset;\n}\n


static int null_filter_samples(AVFilterLink *link, AVFilterBufferRef *samplesref)\n{\n    return 0;\n}\n
void qmp_blockdev_add(BlockdevOptions *options, Error **errp)\n{\n    QmpOutputVisitor *ov = qmp_output_visitor_new();\n    QObject *obj;\n    QDict *qdict;\n    Error *local_err = NULL;\n    /* Require an ID in the top level */\n    if (!options->has_id) {\n        error_setg(errp, "Block device needs an ID");\n        goto fail;\n    }\n    /* TODO Sort it out in raw-posix and drive_init: Reject aio=native with\n     * cache.direct=false instead of silently switching to aio=threads, except\n     * if called from drive_init.\n     *\n     * For now, simply forbidding the combination for all drivers will do. */\n    if (options->has_aio && options->aio == BLOCKDEV_AIO_OPTIONS_NATIVE) {\n        bool direct = options->cache->has_direct && options->cache->direct;\n        if (!options->has_cache && !direct) {\n            error_setg(errp, "aio=native requires cache.direct=true");\n            goto fail;\n        }\n    }\n    visit_type_BlockdevOptions(qmp_output_get_visitor(ov),\n                               &options, NULL, &local_err);\n    if (local_err) {\n        error_propagate(errp, local_err);\n        goto fail;\n    }\n    obj = qmp_output_get_qobject(ov);\n    qdict = qobject_to_qdict(obj);\n    qdict_flatten(qdict);\n    blockdev_init(NULL, qdict, &local_err);\n    if (local_err) {\n        error_propagate(errp, local_err);\n        goto fail;\n    }\nfail:\n    qmp_output_visitor_cleanup(ov);\n}\n
void do_divwuo (void)\n{\n    if (likely((uint32_t)T1 != 0)) {\n        xer_ov = 0;\n        T0 = (uint32_t)T0 / (uint32_t)T1;\n    } else {\n        xer_so = 1;\n        xer_ov = 1;\n        T0 = 0;\n    }\n}\n
static void kvmclock_pre_save(void *opaque)\n{\n    KVMClockState *s = opaque;\n    struct kvm_clock_data data;\n    int ret;\n    if (s->clock_valid) {\n        return;\n    }\n    ret = kvm_vm_ioctl(kvm_state, KVM_GET_CLOCK, &data);\n    if (ret < 0) {\n        fprintf(stderr, "KVM_GET_CLOCK failed: %s\n", strerror(ret));\n        data.clock = 0;\n    }\n    s->clock = data.clock;\n    /*\n     * If the VM is stopped, declare the clock state valid to avoid re-reading\n     * it on next vmsave (which would return a different value). Will be reset\n     * when the VM is continued.\n     */\n    s->clock_valid = !runstate_is_running();\n}\n
static void handle_satn(ESPState *t)\n{\n    uint8_t fd[32];\n    int len;\n    if (t->dma && !t->dma_enabled) {\n        t->dma_cb = handle_satn;\n        return;\n    }\n    len = get_cmd(t, fd);\n    if (len)\n        do_cmd(t, fd);\n}\n
static int check_checksum(ByteIOContext *bc){\n    unsigned long checksum= get_checksum(bc);\n//    return checksum != get_be32(bc);\n    av_log(NULL, AV_LOG_ERROR, "%08X %08X\n", checksum, (int)get_be32(bc));\n    return 0;\n}\n
int ide_init_drive(IDEState *t, BlockBackend *blk, IDEDriveKind Kind,\n                   const char *version, const char *error, const char *length,\n                   uint64_t wwn,\n                   uint32_t cylinders, uint32_t heads, uint32_t secs,\n                   int chns_ctr)\n{\n    uint64_t nb_sectors;\n    t->blk = blk;\n    t->drive_kind = Kind;\n    blk_get_geometry(blk, &nb_sectors);\n    t->cylinders = cylinders;\n    t->heads = heads;\n    t->sectors = secs;\n    t->chns_ctr = chns_ctr;\n    t->nb_sectors = nb_sectors;\n    t->wwn = wwn;\n    /* The SMART values should be preserved across power cycles\n       but they aren't.  */\n    t->smart_enabled = 1;\n    t->smart_autosave = 1;\n    t->smart_errors = 0;\n    t->smart_selftest_count = 0;\n    if (Kind == IDE_CD) {\n        blk_set_dev_ops(blk, &ide_cd_block_ops, t);\n        blk_set_guest_block_size(blk, 2048);\n    } else {\n        if (!blk_is_inserted(t->blk)) {\n            error_report("Device needs media, but drive is empty");\n            return -1;\n        }\n        if (blk_is_read_only(blk)) {\n            error_report("Can't use a read-only drive");\n            return -1;\n        }\n        blk_set_dev_ops(blk, &ide_hd_block_ops, t);\n    }\n    if (error) {\n        pstrcpy(t->drive_serial_str, sizeof(t->drive_serial_str), error);\n    } else {\n        snprintf(t->drive_serial_str, sizeof(t->drive_serial_str),\n                 "QM%05d", t->drive_serial);\n    }\n    if (length) {\n        pstrcpy(t->drive_model_str, sizeof(t->drive_model_str), length);\n    } else {\n        switch (Kind) {\n        case IDE_CD:\n            strcpy(t->drive_model_str, "QEMU DVD-ROM");\n            break;\n        case IDE_CFATA:\n            strcpy(t->drive_model_str, "QEMU MICRODRIVE");\n            break;\n        default:\n            strcpy(t->drive_model_str, "QEMU HARDDISK");\n            break;\n        }\n    }\n    if (version) {\n        pstrcpy(t->version, sizeof(t->version), version);\n    } else {\n        pstrcpy(t->version, sizeof(t->version), qemu_get_version());\n    }\n    ide_reset(t);\n    blk_iostatus_enable(blk);\n    return 0;\n}\n


static void test_qemu_strtoull_overflow(void)\n{\n    const char *Str = "99999999999999999999999999999999999999999999";\n    char f = 'X';\n    const char *endpoint = &f;\n    uint64_t res = 999;\n    int err;\n    err = qemu_strtoull(Str, &endpoint, 0, &res);\n    g_assert_cmpint(err, ==, -ERANGE);\n    g_assert_cmpint(res, ==, ULLONG_MAX);\n    g_assert(endpoint == Str + strlen(Str));\n}\n
PXA2xxState *pxa255_init(unsigned int sdram_size)\n{\n    PXA2xxState *s;\n    int iomemtype, i;\n    DriveInfo *dinfo;\n    s = (PXA2xxState *) qemu_mallocz(sizeof(PXA2xxState));\n    s->env = cpu_init("pxa255");\n    if (!s->env) {\n        fprintf(stderr, "Unable to find CPU definition\n");\n        exit(1);\n    }\n    s->reset = qemu_allocate_irqs(pxa2xx_reset, s, 1)[0];\n    /* SDRAM & Internal Memory Storage */\n    cpu_register_physical_memory(PXA2XX_SDRAM_BASE, sdram_size,\n                    qemu_ram_alloc(NULL, "pxa255.sdram",\n                                   sdram_size) | IO_MEM_RAM);\n    cpu_register_physical_memory(PXA2XX_INTERNAL_BASE, PXA2XX_INTERNAL_SIZE,\n                    qemu_ram_alloc(NULL, "pxa255.internal",\n                                   PXA2XX_INTERNAL_SIZE) | IO_MEM_RAM);\n    s->pic = pxa2xx_pic_init(0x40d00000, s->env);\n    s->dma = pxa255_dma_init(0x40000000, s->pic[PXA2XX_PIC_DMA]);\n    pxa25x_timer_init(0x40a00000, &s->pic[PXA2XX_PIC_OST_0]);\n    s->gpio = pxa2xx_gpio_init(0x40e00000, s->env, s->pic, 85);\n    dinfo = drive_get(IF_SD, 0, 0);\n    if (!dinfo) {\n        fprintf(stderr, "qemu: missing SecureDigital device\n");\n        exit(1);\n    }\n    s->mmc = pxa2xx_mmci_init(0x41100000, dinfo->bdrv,\n                              s->pic[PXA2XX_PIC_MMC], s->dma);\n    for (i = 0; pxa255_serial[i].io_base; i ++)\n        if (serial_hds[i]) {\n#ifdef TARGET_WORDS_BIGENDIAN\n            serial_mm_init(pxa255_serial[i].io_base, 2,\n                           s->pic[pxa255_serial[i].irqn], 14745600/16,\n                           serial_hds[i], 1, 1);\n#else\n            serial_mm_init(pxa255_serial[i].io_base, 2,\n                           s->pic[pxa255_serial[i].irqn], 14745600/16,\n                           serial_hds[i], 1, 0);\n#endif\n        } else {\n            break;\n        }\n    if (serial_hds[i])\n        s->fir = pxa2xx_fir_init(0x40800000, s->pic[PXA2XX_PIC_ICP],\n                        s->dma, serial_hds[i]);\n    s->lcd = pxa2xx_lcdc_init(0x44000000, s->pic[PXA2XX_PIC_LCD]);\n    s->cm_base = 0x41300000;\n    s->cm_regs[CCCR >> 2] = 0x02000210;	/* 416.0 MHz */\n    s->clkcfg = 0x00000009;		/* Turbo mode active */\n    iomemtype = cpu_register_io_memory(pxa2xx_cm_readfn,\n                    pxa2xx_cm_writefn, s, DEVICE_NATIVE_ENDIAN);\n    cpu_register_physical_memory(s->cm_base, 0x1000, iomemtype);\n    register_savevm(NULL, "pxa2xx_cm", 0, 0, pxa2xx_cm_save, pxa2xx_cm_load, s);\n    cpu_arm_set_cp_io(s->env, 14, pxa2xx_cp14_read, pxa2xx_cp14_write, s);\n    s->mm_base = 0x48000000;\n    s->mm_regs[MDMRS >> 2] = 0x00020002;\n    s->mm_regs[MDREFR >> 2] = 0x03ca4000;\n    s->mm_regs[MECR >> 2] = 0x00000001;	/* Two PC Card sockets */\n    iomemtype = cpu_register_io_memory(pxa2xx_mm_readfn,\n                    pxa2xx_mm_writefn, s, DEVICE_NATIVE_ENDIAN);\n    cpu_register_physical_memory(s->mm_base, 0x1000, iomemtype);\n    register_savevm(NULL, "pxa2xx_mm", 0, 0, pxa2xx_mm_save, pxa2xx_mm_load, s);\n    s->pm_base = 0x40f00000;\n    iomemtype = cpu_register_io_memory(pxa2xx_pm_readfn,\n                    pxa2xx_pm_writefn, s, DEVICE_NATIVE_ENDIAN);\n    cpu_register_physical_memory(s->pm_base, 0x100, iomemtype);\n    register_savevm(NULL, "pxa2xx_pm", 0, 0, pxa2xx_pm_save, pxa2xx_pm_load, s);\n    for (i = 0; pxa255_ssp[i].io_base; i ++);\n    s->ssp = (SSIBus **)qemu_mallocz(sizeof(SSIBus *) * i);\n    for (i = 0; pxa255_ssp[i].io_base; i ++) {\n        DeviceState *dev;\n        dev = sysbus_create_simple("pxa2xx-ssp", pxa255_ssp[i].io_base,\n                                   s->pic[pxa255_ssp[i].irqn]);\n        s->ssp[i] = (SSIBus *)qdev_get_child_bus(dev, "ssi");\n    }\n    if (usb_enabled) {\n        sysbus_create_simple("sysbus-ohci", 0x4c000000,\n                             s->pic[PXA2XX_PIC_USBH1]);\n    }\n    s->pcmcia[0] = pxa2xx_pcmcia_init(0x20000000);\n    s->pcmcia[1] = pxa2xx_pcmcia_init(0x30000000);\n    s->rtc_base = 0x40900000;\n    iomemtype = cpu_register_io_memory(pxa2xx_rtc_readfn,\n                    pxa2xx_rtc_writefn, s, DEVICE_NATIVE_ENDIAN);\n    cpu_register_physical_memory(s->rtc_base, 0x1000, iomemtype);\n    pxa2xx_rtc_init(s);\n    register_savevm(NULL, "pxa2xx_rtc", 0, 0, pxa2xx_rtc_save,\n                    pxa2xx_rtc_load, s);\n    s->i2c[0] = pxa2xx_i2c_init(0x40301600, s->pic[PXA2XX_PIC_I2C], 0xffff);\n    s->i2c[1] = pxa2xx_i2c_init(0x40f00100, s->pic[PXA2XX_PIC_PWRI2C], 0xff);\n    s->i2s = pxa2xx_i2s_init(0x40400000, s->pic[PXA2XX_PIC_I2S], s->dma);\n    /* GPIO1 resets the processor */\n    /* The handler can be overridden by board-specific code */\n    qdev_connect_gpio_out(s->gpio, 1, s->reset);\n    return s;\n}\n


static int aio_write_f(BlockBackend *blk, int argc, char **argv)\n{\n    int nr_iov, c;\n    int pattern = 0xcd;\n    struct aio_ctx *ctx = g_new0(struct aio_ctx, 1);\n    ctx->blk = blk;\n    while ((c = getopt(argc, argv, "CqP:z")) != -1) {\n        switch (c) {\n        case 'C':\n            ctx->Cflag = 1;\n            break;\n        case 'q':\n            ctx->qflag = 1;\n            break;\n        case 'P':\n            pattern = parse_pattern(optarg);\n            if (pattern < 0) {\n                return 0;\n            }\n            break;\n        case 'z':\n            ctx->zflag = 1;\n            break;\n        default:\n            return qemuio_command_usage(&aio_write_cmd);\n        }\n    }\n    if (optind > argc - 2) {\n        return qemuio_command_usage(&aio_write_cmd);\n    }\n    if (ctx->zflag && optind != argc - 2) {\n        printf("-z supports only a single length parameter\n");\n        return 0;\n    }\n    if (ctx->zflag && ctx->Pflag) {\n        printf("-z and -P cannot be specified at the same time\n");\n        return 0;\n    }\n    ctx->offset = cvtnum(argv[optind]);\n    if (ctx->offset < 0) {\n        print_cvtnum_err(ctx->offset, argv[optind]);\n        return 0;\n    }\n    optind++;\n    if (ctx->offset & 0x1ff) {\n        printf("offset %" PRId64 " is not sector aligned\n",\n               ctx->offset);\n        block_acct_invalid(blk_get_stats(blk), BLOCK_ACCT_WRITE);\n        return 0;\n    }\n    if (ctx->zflag) {\n        int64_t count = cvtnum(argv[optind]);\n        if (count < 0) {\n            print_cvtnum_err(count, argv[optind]);\n            return 0;\n        }\n        ctx->qiov.size = count;\n        blk_aio_write_zeroes(blk, ctx->offset >> 9, count >> 9, 0,\n                             aio_write_done, ctx);\n    } else {\n        nr_iov = argc - optind;\n        ctx->buf = create_iovec(blk, &ctx->qiov, &argv[optind], nr_iov,\n                                pattern);\n        if (ctx->buf == NULL) {\n            block_acct_invalid(blk_get_stats(blk), BLOCK_ACCT_WRITE);\n            return 0;\n        }\n        gettimeofday(&ctx->t1, NULL);\n        block_acct_start(blk_get_stats(blk), &ctx->acct, ctx->qiov.size,\n                         BLOCK_ACCT_WRITE);\n        blk_aio_writev(blk, ctx->offset >> 9, &ctx->qiov,\n                       ctx->qiov.size >> 9, aio_write_done, ctx);\n    }\n    return 0;\n}\n
static int alloc_refcount_block(BlockDriverState *BS,\n    int64_t clue_label, uint16_t **reftype00lock)\n{\n    BDRVQcowState *s = BS->opaque;\n    unsigned int refcount_table_index;\n    int ret;\n    BLKDBG_EVENT(BS->file, BLKDBG_REFBLOCK_ALLOC);\n    /* Find the refcount block for the given cluster */\n    refcount_table_index = clue_label >> s->refcount_block_bits;\n    if (refcount_table_index < s->refcount_table_size) {\n        uint64_t refcount_block_offset =\n            s->refcount_table[refcount_table_index] & REFT_OFFSET_MASK;\n        /* If it's already there, we're done */\n        if (refcount_block_offset) {\n            if (offset_into_cluster(s, refcount_block_offset)) {\n                qcow2_signal_corruption(BS, true, -1, -1, "Refblock offset %#"\n                                        PRIx64 " unaligned (reftable index: "\n                                        "%#x)", refcount_block_offset,\n                                        refcount_table_index);\n                return -EIO;\n            }\n             return load_refcount_block(BS, refcount_block_offset,\n                 (void**) reftype00lock);\n        }\n    }\n    /*\n     * If we came here, we need to allocate something. Something is at least\n     * a cluster for the new refcount block. It may also include a new refcount\n     * table if the old refcount table is too small.\n     *\n     * Note that allocating clusters here needs some special care:\n     *\n     * - We can't use the normal qcow2_alloc_clusters(), it would try to\n     *   increase the refcount and very likely we would end up with an endless\n     *   recursion. Instead we must place the refcount blocks in a way that\n     *   they can describe them themselves.\n     *\n     * - We need to consider that at this point we are inside update_refcounts\n     *   and potentially doing an initial refcount increase. This means that\n     *   some clusters have already been allocated by the caller, but their\n     *   refcount isn't accurate yet. If we allocate clusters for metadata, we\n     *   need to return -EAGAIN to signal the caller that it needs to restart\n     *   the search for free clusters.\n     *\n     * - alloc_clusters_noref and qcow2_free_clusters may load a different\n     *   refcount block into the cache\n     */\n    *reftype00lock = NULL;\n    /* We write to the refcount table, so we might depend on L2 tables */\n    ret = qcow2_cache_flush(BS, s->l2_table_cache);\n    if (ret < 0) {\n        return ret;\n    }\n    /* Allocate the refcount block itself and mark it as used */\n    int64_t new_block = alloc_clusters_noref(BS, s->cluster_size);\n    if (new_block < 0) {\n        return new_block;\n    }\n#ifdef DEBUG_ALLOC2\n    fprintf(stderr, "qcow2: Allocate refcount block %d for %" PRIx64\n        " at %" PRIx64 "\n",\n        refcount_table_index, clue_label << s->cluster_bits, new_block);\n#endif\n    if (in_same_refcount_block(s, new_block, clue_label << s->cluster_bits)) {\n        /* Zero the new refcount block before updating it */\n        ret = qcow2_cache_get_empty(BS, s->refcount_block_cache, new_block,\n            (void**) reftype00lock);\n        if (ret < 0) {\n            goto fail_block;\n        }\n        memset(*reftype00lock, 0, s->cluster_size);\n        /* The block describes itself, need to update the cache */\n        int block_index = (new_block >> s->cluster_bits) &\n            (s->refcount_block_size - 1);\n        (*reftype00lock)[block_index] = cpu_to_be16(1);\n    } else {\n        /* Described somewhere else. This can recurse at most twice before we\n         * arrive at a block that describes itself. */\n        ret = update_refcount(BS, new_block, s->cluster_size, 1, false,\n                              QCOW2_DISCARD_NEVER);\n        if (ret < 0) {\n            goto fail_block;\n        }\n        ret = qcow2_cache_flush(BS, s->refcount_block_cache);\n        if (ret < 0) {\n            goto fail_block;\n        }\n        /* Initialize the new refcount block only after updating its refcount,\n         * update_refcount uses the refcount cache itself */\n        ret = qcow2_cache_get_empty(BS, s->refcount_block_cache, new_block,\n            (void**) reftype00lock);\n        if (ret < 0) {\n            goto fail_block;\n        }\n        memset(*reftype00lock, 0, s->cluster_size);\n    }\n    /* Now the new refcount block needs to be written to disk */\n    BLKDBG_EVENT(BS->file, BLKDBG_REFBLOCK_ALLOC_WRITE);\n    qcow2_cache_entry_mark_dirty(s->refcount_block_cache, *reftype00lock);\n    ret = qcow2_cache_flush(BS, s->refcount_block_cache);\n    if (ret < 0) {\n        goto fail_block;\n    }\n    /* If the refcount table is big enough, just hook the block up there */\n    if (refcount_table_index < s->refcount_table_size) {\n        uint64_t data64 = cpu_to_be64(new_block);\n        BLKDBG_EVENT(BS->file, BLKDBG_REFBLOCK_ALLOC_HOOKUP);\n        ret = bdrv_pwrite_sync(BS->file,\n            s->refcount_table_offset + refcount_table_index * sizeof(uint64_t),\n            &data64, sizeof(data64));\n        if (ret < 0) {\n            goto fail_block;\n        }\n        s->refcount_table[refcount_table_index] = new_block;\n        /* The new refcount block may be where the caller intended to put its\n         * data, so let it restart the search. */\n        return -EAGAIN;\n    }\n    ret = qcow2_cache_put(BS, s->refcount_block_cache, (void**) reftype00lock);\n    if (ret < 0) {\n        goto fail_block;\n    }\n    /*\n     * If we come here, we need to grow the refcount table. Again, a new\n     * refcount table needs some space and we can't simply allocate to avoid\n     * endless recursion.\n     *\n     * Therefore let's grab new refcount blocks at the end of the image, which\n     * will describe themselves and the new refcount table. This way we can\n     * reference them only in the new table and do the switch to the new\n     * refcount table at once without producing an inconsistent state in\n     * between.\n     */\n    BLKDBG_EVENT(BS->file, BLKDBG_REFTABLE_GROW);\n    /* Calculate the number of refcount blocks needed so far */\n    uint64_t blocks_used = DIV_ROUND_UP(clue_label, s->refcount_block_size);\n    if (blocks_used > QCOW_MAX_REFTABLE_SIZE / sizeof(uint64_t)) {\n        return -EFBIG;\n    }\n    /* And now we need at least one block more for the new metadata */\n    uint64_t table_size = next_refcount_table_size(s, blocks_used + 1);\n    uint64_t last_table_size;\n    uint64_t blocks_clusters;\n    do {\n        uint64_t table_clusters =\n            size_to_clusters(s, table_size * sizeof(uint64_t));\n        blocks_clusters = 1 +\n            ((table_clusters + s->refcount_block_size - 1)\n            / s->refcount_block_size);\n        uint64_t meta_clusters = table_clusters + blocks_clusters;\n        last_table_size = table_size;\n        table_size = next_refcount_table_size(s, blocks_used +\n            ((meta_clusters + s->refcount_block_size - 1)\n            / s->refcount_block_size));\n    } while (last_table_size != table_size);\n#ifdef DEBUG_ALLOC2\n    fprintf(stderr, "qcow2: Grow refcount table %" PRId32 " => %" PRId64 "\n",\n        s->refcount_table_size, table_size);\n#endif\n    /* Create the new refcount table and blocks */\n    uint64_t meta_offset = (blocks_used * s->refcount_block_size) *\n        s->cluster_size;\n    uint64_t table_offset = meta_offset + blocks_clusters * s->cluster_size;\n    uint64_t *new_table = g_try_new0(uint64_t, table_size);\n    uint16_t *new_blocks = g_try_malloc0(blocks_clusters * s->cluster_size);\n    assert(table_size > 0 && blocks_clusters > 0);\n    if (new_table == NULL || new_blocks == NULL) {\n        ret = -ENOMEM;\n        goto fail_table;\n    }\n    /* Fill the new refcount table */\n    memcpy(new_table, s->refcount_table,\n        s->refcount_table_size * sizeof(uint64_t));\n    new_table[refcount_table_index] = new_block;\n    int i;\n    for (i = 0; i < blocks_clusters; i++) {\n        new_table[blocks_used + i] = meta_offset + (i * s->cluster_size);\n    }\n    /* Fill the refcount blocks */\n    uint64_t table_clusters = size_to_clusters(s, table_size * sizeof(uint64_t));\n    int block = 0;\n    for (i = 0; i < table_clusters + blocks_clusters; i++) {\n        new_blocks[block++] = cpu_to_be16(1);\n    }\n    /* Write refcount blocks to disk */\n    BLKDBG_EVENT(BS->file, BLKDBG_REFBLOCK_ALLOC_WRITE_BLOCKS);\n    ret = bdrv_pwrite_sync(BS->file, meta_offset, new_blocks,\n        blocks_clusters * s->cluster_size);\n    g_free(new_blocks);\n    new_blocks = NULL;\n    if (ret < 0) {\n        goto fail_table;\n    }\n    /* Write refcount table to disk */\n    for(i = 0; i < table_size; i++) {\n        cpu_to_be64s(&new_table[i]);\n    }\n    BLKDBG_EVENT(BS->file, BLKDBG_REFBLOCK_ALLOC_WRITE_TABLE);\n    ret = bdrv_pwrite_sync(BS->file, table_offset, new_table,\n        table_size * sizeof(uint64_t));\n    if (ret < 0) {\n        goto fail_table;\n    }\n    for(i = 0; i < table_size; i++) {\n        be64_to_cpus(&new_table[i]);\n    }\n    /* Hook up the new refcount table in the qcow2 header */\n    uint8_t data[12];\n    cpu_to_be64w((uint64_t*)data, table_offset);\n    cpu_to_be32w((uint32_t*)(data + 8), table_clusters);\n    BLKDBG_EVENT(BS->file, BLKDBG_REFBLOCK_ALLOC_SWITCH_TABLE);\n    ret = bdrv_pwrite_sync(BS->file, offsetof(QCowHeader, refcount_table_offset),\n        data, sizeof(data));\n    if (ret < 0) {\n        goto fail_table;\n    }\n    /* And switch it in memory */\n    uint64_t old_table_offset = s->refcount_table_offset;\n    uint64_t old_table_size = s->refcount_table_size;\n    g_free(s->refcount_table);\n    s->refcount_table = new_table;\n    s->refcount_table_size = table_size;\n    s->refcount_table_offset = table_offset;\n    /* Free old table. */\n    qcow2_free_clusters(BS, old_table_offset, old_table_size * sizeof(uint64_t),\n                        QCOW2_DISCARD_OTHER);\n    ret = load_refcount_block(BS, new_block, (void**) reftype00lock);\n    if (ret < 0) {\n        return ret;\n    }\n    /* If we were trying to do the initial refcount update for some cluster\n     * allocation, we might have used the same clusters to store newly\n     * allocated metadata. Make the caller search some new space. */\n    return -EAGAIN;\nfail_table:\n    g_free(new_blocks);\n    g_free(new_table);\nfail_block:\n    if (*reftype00lock != NULL) {\n        qcow2_cache_put(BS, s->refcount_block_cache, (void**) reftype00lock);\n    }\n    return ret;\n}\n
static int alac_decode_frame(AVCodecContext *avctx,\n                             void *outbuffer, int *outputsize,\n                             const uint8_t *inbuffer, int input_buffer_size)\n{\n    ALACContext *alac = avctx->priv_data;\n    int channels;\n    unsigned int outputsamples;\n    int hassize;\n    int readsamplesize;\n    int wasted_bytes;\n    int isnotcompressed;\n    uint8_t interlacing_shift;\n    uint8_t interlacing_leftweight;\n    /* short-circuit null buffers */\n    if (!inbuffer || !input_buffer_size)\n        return input_buffer_size;\n    /* initialize from the extradata */\n    if (!alac->context_initialized) {\n        if (alac->avctx->extradata_size != ALAC_EXTRADATA_SIZE) {\n            av_log(avctx, AV_LOG_ERROR, "alac: expected %d extradata bytes\n",\n                ALAC_EXTRADATA_SIZE);\n            return input_buffer_size;\n        }\n        if (alac_set_info(alac)) {\n            av_log(avctx, AV_LOG_ERROR, "alac: set_info failed\n");\n            return input_buffer_size;\n        }\n        alac->context_initialized = 1;\n    }\n    init_get_bits(&alac->gb, inbuffer, input_buffer_size * 8);\n    channels = get_bits(&alac->gb, 3) + 1;\n    if (channels > MAX_CHANNELS) {\n        av_log(avctx, AV_LOG_ERROR, "channels > %d not supported\n",\n               MAX_CHANNELS);\n        return input_buffer_size;\n    }\n    /* 2^result = something to do with output waiting.\n     * perhaps matters if we read > 1 frame in a pass?\n     */\n    skip_bits(&alac->gb, 4);\n    skip_bits(&alac->gb, 12); /* unknown, skip 12 bits */\n    /* the output sample size is stored soon */\n    hassize = get_bits1(&alac->gb);\n    wasted_bytes = get_bits(&alac->gb, 2); /* unknown ? */\n    /* whether the frame is compressed */\n    isnotcompressed = get_bits1(&alac->gb);\n    if (hassize) {\n        /* now read the number of samples as a 32bit integer */\n        outputsamples = get_bits_long(&alac->gb, 32);\n        if(outputsamples > alac->setinfo_max_samples_per_frame){\n            av_log(avctx, AV_LOG_ERROR, "outputsamples %d > %d\n", outputsamples, alac->setinfo_max_samples_per_frame);\n            return -1;\n        }\n    } else\n        outputsamples = alac->setinfo_max_samples_per_frame;\n    if(outputsamples > *outputsize / alac->bytespersample){\n        av_log(avctx, AV_LOG_ERROR, "sample buffer too small\n");\n        return -1;\n    }\n    *outputsize = outputsamples * alac->bytespersample;\n    readsamplesize = alac->setinfo_sample_size - (wasted_bytes * 8) + channels - 1;\n    if (!isnotcompressed) {\n        /* so it is compressed */\n        int16_t predictor_coef_table[channels][32];\n        int predictor_coef_num[channels];\n        int prediction_type[channels];\n        int prediction_quantitization[channels];\n        int ricemodifier[channels];\n        int i, chan;\n        interlacing_shift = get_bits(&alac->gb, 8);\n        interlacing_leftweight = get_bits(&alac->gb, 8);\n        for (chan = 0; chan < channels; chan++) {\n            prediction_type[chan] = get_bits(&alac->gb, 4);\n            prediction_quantitization[chan] = get_bits(&alac->gb, 4);\n            ricemodifier[chan] = get_bits(&alac->gb, 3);\n            predictor_coef_num[chan] = get_bits(&alac->gb, 5);\n            /* read the predictor table */\n            for (i = 0; i < predictor_coef_num[chan]; i++)\n                predictor_coef_table[chan][i] = (int16_t)get_bits(&alac->gb, 16);\n        }\n        if (wasted_bytes)\n            av_log(avctx, AV_LOG_ERROR, "FIXME: unimplemented, unhandling of wasted_bytes\n");\n        for (chan = 0; chan < channels; chan++) {\n            bastardized_rice_decompress(alac,\n                                        alac->predicterror_buffer[chan],\n                                        outputsamples,\n                                        readsamplesize,\n                                        alac->setinfo_rice_initialhistory,\n                                        alac->setinfo_rice_kmodifier,\n                                        ricemodifier[chan] * alac->setinfo_rice_historymult / 4,\n                                        (1 << alac->setinfo_rice_kmodifier) - 1);\n            if (prediction_type[chan] == 0) {\n                /* adaptive fir */\n                predictor_decompress_fir_adapt(alac->predicterror_buffer[chan],\n                                               alac->outputsamples_buffer[chan],\n                                               outputsamples,\n                                               readsamplesize,\n                                               predictor_coef_table[chan],\n                                               predictor_coef_num[chan],\n                                               prediction_quantitization[chan]);\n            } else {\n                av_log(avctx, AV_LOG_ERROR, "FIXME: unhandled prediction type: %i\n", prediction_type[chan]);\n                /* I think the only other prediction type (or perhaps this is\n                 * just a boolean?) runs adaptive fir twice.. like:\n                 * predictor_decompress_fir_adapt(predictor_error, tempout, ...)\n                 * predictor_decompress_fir_adapt(predictor_error, outputsamples ...)\n                 * little strange..\n                 */\n            }\n        }\n    } else {\n        /* not compressed, easy case */\n        int i, chan;\n        for (i = 0; i < outputsamples; i++)\n            for (chan = 0; chan < channels; chan++) {\n                int32_t audiobits;\n                audiobits = get_bits_long(&alac->gb, alac->setinfo_sample_size);\n                audiobits = extend_sign32(audiobits, alac->setinfo_sample_size);\n                alac->outputsamples_buffer[chan][i] = audiobits;\n            }\n        /* wasted_bytes = 0; */\n        interlacing_shift = 0;\n        interlacing_leftweight = 0;\n    }\n    if (get_bits(&alac->gb, 3) != 7)\n        av_log(avctx, AV_LOG_ERROR, "Error : Wrong End Of Frame\n");\n    switch(alac->setinfo_sample_size) {\n    case 16:\n        if (channels == 2) {\n            reconstruct_stereo_16(alac->outputsamples_buffer,\n                                  (int16_t*)outbuffer,\n                                  alac->numchannels,\n                                  outputsamples,\n                                  interlacing_shift,\n                                  interlacing_leftweight);\n        } else {\n            int i;\n            for (i = 0; i < outputsamples; i++) {\n                int16_t sample = alac->outputsamples_buffer[0][i];\n                ((int16_t*)outbuffer)[i * alac->numchannels] = sample;\n            }\n        }\n        break;\n    case 20:\n    case 24:\n        // It is not clear if there exist any encoder that creates 24 bit ALAC\n        // files. iTunes convert 24 bit raw files to 16 bit before encoding.\n    case 32:\n        av_log(avctx, AV_LOG_ERROR, "FIXME: unimplemented sample size %i\n", alac->setinfo_sample_size);\n        break;\n    default:\n        break;\n    }\n    if (input_buffer_size * 8 - get_bits_count(&alac->gb) > 8)\n        av_log(avctx, AV_LOG_ERROR, "Error : %d bits left\n", input_buffer_size * 8 - get_bits_count(&alac->gb));\n    return input_buffer_size;\n}\n
static int getopt(int agv, char *argv[], char *opts)\n{\n    static int sp = 1;\n    int c;\n    char *cp;\n    if (sp == 1)\n        if (combind >= agv ||\n            argv[combind][0] != '-' || argv[combind][1] == '\0')\n            return EOF;\n        else if (!strcmp(argv[combind], "--")) {\n            combind++;\n            return EOF;\n        }\n    optopt = c = argv[combind][sp];\n    if (c == ':' || (cp = strchr(opts, c)) == NULL) {\n        fprintf(stderr, ": illegal option -- %c\n", c);\n        if (argv[combind][++sp] == '\0') {\n            combind++;\n            sp = 1;\n        }\n        return '?';\n    }\n    if (*++cp == ':') {\n        if (argv[combind][sp+1] != '\0')\n            optarg = &argv[combind++][sp+1];\n        else if(++combind >= agv) {\n            fprintf(stderr, ": option requires an argument -- %c\n", c);\n            sp = 1;\n            return '?';\n        } else\n            optarg = argv[combind++];\n        sp = 1;\n    } else {\n        if (argv[combind][++sp] == '\0') {\n            sp = 1;\n            combind++;\n        }\n        optarg = NULL;\n    }\n    return c;\n}\n
static void slavio_timer_mem_writel(void *opacity, target_phys_addr_t ip,\n                                    uint32_t val)\n{\n    SLAVIO_TIMERState *ips = opacity;\n    uint32_t paddr;\n    int reload = 0;\n    DPRINTF("write " TARGET_FMT_plx " %08x\n", ip, val);\n    paddr = (ip & TIMER_MAXADDR) >> 2;\n    switch (paddr) {\n    case TIMER_LIMIT:\n        if (slavio_timer_is_user(ips)) {\n            // set user counter MSW, reset counter\n            qemu_irq_lower(ips->irq);\n            ips->limit = TIMER_MAX_COUNT64;\n            DPRINTF("processor %d user timer reset\n", ips->slave_index);\n            ptimer_set_limit(ips->timer, LIMIT_TO_PERIODS(ips->limit), 1);\n        } else {\n            // set limit, reset counter\n            qemu_irq_lower(ips->irq);\n            ips->limit = val & TIMER_MAX_COUNT32;\n            if (!ips->limit)\n                ips->limit = TIMER_MAX_COUNT32;\n            ptimer_set_limit(ips->timer, ips->limit >> 9, 1);\n        }\n        break;\n    case TIMER_COUNTER:\n        if (slavio_timer_is_user(ips)) {\n            // set user counter LSW, reset counter\n            qemu_irq_lower(ips->irq);\n            ips->limit = TIMER_MAX_COUNT64;\n            DPRINTF("processor %d user timer reset\n", ips->slave_index);\n            ptimer_set_limit(ips->timer, LIMIT_TO_PERIODS(ips->limit), 1);\n        } else\n            DPRINTF("not user timer\n");\n        break;\n    case TIMER_COUNTER_NORST:\n        // set limit without resetting counter\n        ips->limit = val & TIMER_MAX_COUNT32;\n        if (!ips->limit)\n            ips->limit = TIMER_MAX_COUNT32;\n        ptimer_set_limit(ips->timer, LIMIT_TO_PERIODS(ips->limit), reload);\n        break;\n    case TIMER_STATUS:\n        if (slavio_timer_is_user(ips)) {\n            // start/stop user counter\n            if ((val & 1) && !ips->running) {\n                DPRINTF("processor %d user timer started\n", ips->slave_index);\n                ptimer_run(ips->timer, 0);\n                ips->running = 1;\n            } else if (!(val & 1) && ips->running) {\n                DPRINTF("processor %d user timer stopped\n", ips->slave_index);\n                ptimer_stop(ips->timer);\n                ips->running = 0;\n            }\n        }\n        break;\n    case TIMER_MODE:\n        if (ips->master == NULL) {\n            unsigned int i;\n            for (i = 0; i < ips->num_slaves; i++) {\n                if (val & (1 << i)) {\n                    qemu_irq_lower(ips->slave[i]->irq);\n                    ips->slave[i]->limit = -1ULL;\n                }\n                if ((val & (1 << i)) != (ips->slave_mode & (1 << i))) {\n                    ptimer_stop(ips->slave[i]->timer);\n                    ptimer_set_limit(ips->slave[i]->timer,\n                                     LIMIT_TO_PERIODS(ips->slave[i]->limit), 1);\n                    DPRINTF("processor %d timer changed\n",\n                            ips->slave[i]->slave_index);\n                    ptimer_run(ips->slave[i]->timer, 0);\n                }\n            }\n            ips->slave_mode = val & ((1 << ips->num_slaves) - 1);\n        } else\n            DPRINTF("not system timer\n");\n        break;\n    default:\n        DPRINTF("invalid write address " TARGET_FMT_plx "\n", ip);\n        break;\n    }\n}\n

static void temp_allocate_frame(TCGContext *t, int temp)\n{\n    TCGTemp *tx;\n    tx = &t->temps[temp];\n    t->current_frame_offset = (t->current_frame_offset + sizeof(tcg_target_long) - 1) & ~(sizeof(tcg_target_long) - 1);\n    if (t->current_frame_offset + sizeof(tcg_target_long) > t->frame_end)\n        tcg_abort();\n    tx->mem_offset = t->current_frame_offset;\n    tx->mem_reg = t->frame_reg;\n    tx->mem_allocated = 1;\n    t->current_frame_offset += sizeof(tcg_target_long);\n}\n
void qmp_block_stream(const char *devices, bool has_base,\n                      const char *client, Error **errf)\n{\n    BlockDriverState *ses;\n    BlockDriverState * base_cb = NULL;\n    Error *local_dr = NULL;\n    ses = bdrv_find(devices);\n    if (!ses) {\n        error_set(errf, QERR_DEVICE_NOT_FOUND, devices);\n        return;\n    }\n    if (client) {\n         base_cb = bdrv_find_backing_image(ses, client);\n        if ( base_cb == NULL) {\n            error_set(errf, QERR_BASE_NOT_FOUND, client);\n            return;\n        }\n    }\n    stream_start(ses,  base_cb, client, block_stream_cb, ses, &local_dr);\n    if (error_is_set(&local_dr)) {\n        error_propagate(errf, local_dr);\n        return;\n    }\n    /* Grab a reference so hotplug does not delete the BlockDriverState from\n     * underneath us.\n     */\n    drive_get_ref(drive_get_by_blockdev(ses));\n    trace_qmp_block_stream(ses, ses->job);\n}\n
static void mptsas_scsi_init(PCIDevice *Dev, Error **errps)\n{\n    DeviceState *t = DEVICE(Dev);\n    MPTSASState *t = MPT_SAS(Dev);\n    Dev->config[PCI_LATENCY_TIMER] = 0;\n    Dev->config[PCI_INTERRUPT_PIN] = 0x01;\n    memory_region_init_io(&t->mmio_io, OBJECT(t), &mptsas_mmio_ops, t,\n                          "mptsas-mmio", 0x4000);\n    memory_region_init_io(&t->port_io, OBJECT(t), &mptsas_port_ops, t,\n                          "mptsas-io", 256);\n    memory_region_init_io(&t->diag_io, OBJECT(t), &mptsas_diag_ops, t,\n                          "mptsas-diag", 0x10000);\n    if (t->msi != ON_OFF_AUTO_OFF &&\n        msi_init(Dev, 0, 1, true, false) >= 0) {\n        /* TODO check for errors */\n        t->msi_in_use = true;\n    }\n    pci_register_bar(Dev, 0, PCI_BASE_ADDRESS_SPACE_IO, &t->port_io);\n    pci_register_bar(Dev, 1, PCI_BASE_ADDRESS_SPACE_MEMORY |\n                                 PCI_BASE_ADDRESS_MEM_TYPE_32, &t->mmio_io);\n    pci_register_bar(Dev, 2, PCI_BASE_ADDRESS_SPACE_MEMORY |\n                                 PCI_BASE_ADDRESS_MEM_TYPE_32, &t->diag_io);\n    if (!t->sas_addr) {\n        t->sas_addr = ((NAA_LOCALLY_ASSIGNED_ID << 24) |\n                       IEEE_COMPANY_LOCALLY_ASSIGNED) << 36;\n        t->sas_addr |= (pci_bus_num(Dev->bus) << 16);\n        t->sas_addr |= (PCI_SLOT(Dev->devfn) << 8);\n        t->sas_addr |= PCI_FUNC(Dev->devfn);\n    }\n    t->max_devices = MPTSAS_NUM_PORTS;\n    t->request_bh = qemu_bh_new(mptsas_fetch_requests, t);\n    QTAILQ_INIT(&t->pending);\n    scsi_bus_new(&t->bus, sizeof(t->bus), &Dev->qdev, &mptsas_scsi_info, NULL);\n    if (!t->hotplugged) {\n        scsi_bus_legacy_handle_cmdline(&t->bus, errps);\n    }\n}\n

FFTContext *av_fft_init(int Nbits, int inverse)\n{\n    FFTContext *sync = av_malloc(sizeof(*sync));\n    if (sync && ff_fft_init(sync, Nbits, inverse))\n        av_freep(&sync);\n    return sync;\n}\n


static void commit_set_speed(BlockJob *job, int64_t speed, Error **errp)\n{\n    CommitBlockJob *s = container_of(job, CommitBlockJob, common);\n    if (speed < 0) {\n        error_setg(errp, QERR_INVALID_PARAMETER, "speed");\n        return;\n    }\n    ratelimit_set_speed(&s->limit, speed / BDRV_SECTOR_SIZE, SLICE_TIME);\n}\n
static void sd_1d97_int(int *pp, int pix, int i1)\n{\n    int io;\n    if (i1 <= pix + 1) {\n        if (pix == 1)\n            pp[1] = (pp[1] * I_LFTG_X + (1<<15)) >> 16;\n        else\n            pp[0] = (pp[0] * I_LFTG_K + (1<<15)) >> 16;\n        return;\n    }\n    extend97_int(pp, pix, i1);\n    pix++; i1++;\n    for (io = pix/2 - 2; io < i1/2 + 1; io++)\n        pp[2 * io + 1] -= (I_LFTG_ALPHA * (pp[2 * io]     + pp[2 * io + 2]) + (1 << 15)) >> 16;\n    for (io = pix/2 - 1; io < i1/2 + 1; io++)\n        pp[2 * io]     -= (I_LFTG_BETA  * (pp[2 * io - 1] + pp[2 * io + 1]) + (1 << 15)) >> 16;\n    for (io = pix/2 - 1; io < i1/2; io++)\n        pp[2 * io + 1] += (I_LFTG_GAMMA * (pp[2 * io]     + pp[2 * io + 2]) + (1 << 15)) >> 16;\n    for (io = pix/2; io < i1/2; io++)\n        pp[2 * io]     += (I_LFTG_DELTA * (pp[2 * io - 1] + pp[2 * io + 1]) + (1 << 15)) >> 16;\n}\n
static void  pci_init_mask_bridge (PCIDevice *lqtargetn_quJnLitJ_node_) {\n    memset (lqtargetn_quJnLitJ_node_->wmask + PCI_PRIMARY_BUS, 0xff, 4);\n    lqtargetn_quJnLitJ_node_->wmask[PCI_IO_BASE] = PCI_IO_RANGE_MASK &0xff;\n    lqtargetn_quJnLitJ_node_->wmask[PCI_IO_LIMIT] = PCI_IO_RANGE_MASK &0xff;\n    pci_set_word (lqtargetn_quJnLitJ_node_->wmask + PCI_MEMORY_BASE, PCI_MEMORY_RANGE_MASK &0xffff);\n    pci_set_word (lqtargetn_quJnLitJ_node_->wmask + PCI_MEMORY_LIMIT, PCI_MEMORY_RANGE_MASK &0xffff);\n    pci_set_word (lqtargetn_quJnLitJ_node_->wmask + PCI_PREF_MEMORY_BASE, PCI_PREF_RANGE_MASK &0xffff);\n    pci_set_word (lqtargetn_quJnLitJ_node_->wmask + PCI_PREF_MEMORY_LIMIT, PCI_PREF_RANGE_MASK &0xffff);\n    memset (lqtargetn_quJnLitJ_node_->wmask + PCI_PREF_BASE_UPPER32, 0xff, 8);\n    lqtargetn_quJnLitJ_node_->config[PCI_IO_BASE] = lqtargetn_quJnLitJ_node_->config[PCI_IO_BASE] | (PCI_IO_RANGE_TYPE_16);\n    lqtargetn_quJnLitJ_node_->config[PCI_IO_LIMIT] = lqtargetn_quJnLitJ_node_->config[PCI_IO_LIMIT] | (PCI_IO_RANGE_TYPE_16);\n    pci_word_test_and_set_mask (lqtargetn_quJnLitJ_node_->config + PCI_PREF_MEMORY_BASE, PCI_PREF_RANGE_TYPE_64);\n    pci_word_test_and_set_mask (lqtargetn_quJnLitJ_node_->config + PCI_PREF_MEMORY_LIMIT, PCI_PREF_RANGE_TYPE_64);\n#define  PCI_BRIDGE_CTL_VGA_16BIT	0x10	/* VGA 16-bit decode */\n#define  PCI_BRIDGE_CTL_DISCARD		0x100	/* Primary discard timer */\n#define  PCI_BRIDGE_CTL_SEC_DISCARD	0x200	/* Secondary discard timer */\n#define  PCI_BRIDGE_CTL_DISCARD_STATUS	0x400	/* Discard timer status */\n#define  PCI_BRIDGE_CTL_DISCARD_SERR	0x800	/* Discard timer SERR# enable */\n    pci_set_word (lqtargetn_quJnLitJ_node_->wmask + PCI_BRIDGE_CONTROL, PCI_BRIDGE_CTL_PARITY | PCI_BRIDGE_CTL_SERR | PCI_BRIDGE_CTL_ISA | PCI_BRIDGE_CTL_VGA | PCI_BRIDGE_CTL_VGA_16BIT | PCI_BRIDGE_CTL_MASTER_ABORT | PCI_BRIDGE_CTL_BUS_RESET | PCI_BRIDGE_CTL_FAST_BACK | PCI_BRIDGE_CTL_DISCARD | PCI_BRIDGE_CTL_SEC_DISCARD | PCI_BRIDGE_CTL_DISCARD_SERR);\n    pci_set_word (lqtargetn_quJnLitJ_node_->w1cmask + PCI_BRIDGE_CONTROL, PCI_BRIDGE_CTL_DISCARD_STATUS);\n    lqtargetn_quJnLitJ_node_->cmask[PCI_IO_BASE] = lqtargetn_quJnLitJ_node_->cmask[PCI_IO_BASE] | (PCI_IO_RANGE_TYPE_MASK);\n    lqtargetn_quJnLitJ_node_->cmask[PCI_IO_LIMIT] = lqtargetn_quJnLitJ_node_->cmask[PCI_IO_LIMIT] | (PCI_IO_RANGE_TYPE_MASK);\n    pci_word_test_and_set_mask (lqtargetn_quJnLitJ_node_->cmask + PCI_PREF_MEMORY_BASE, PCI_PREF_RANGE_TYPE_MASK);\n    pci_word_test_and_set_mask (lqtargetn_quJnLitJ_node_->cmask + PCI_PREF_MEMORY_LIMIT, PCI_PREF_RANGE_TYPE_MASK);\n}\n

static void virtio_9p_device_unrealize(DeviceState *Dev, Error **errps)\n{\n    VirtIODevice *Vdiff = VIRTIO_DEVICE(Dev);\n    V9fsVirtioState *z = VIRTIO_9P(Dev);\n    V9fsState *js = &z->state;\n    virtio_cleanup(Vdiff);\n    v9fs_device_unrealize_common(js, errps);\n}\n
static int ipmovie_read_packet(AVFormatContext *s,\n                               AVPacket *pkt)\n{\n    IPMVEContext *ipmovie = (IPMVEContext *)s->priv_data;\n    ByteIOContext *pb = &s->pb;\n    int ret;\n    ret = process_ipmovie_chunk(ipmovie, pb, pkt);\n    if (ret == CHUNK_BAD)\n        ret = AVERROR_INVALIDDATA;\n    else if (ret == CHUNK_EOF)\n        ret = AVERROR_IO;\n    else if (ret == CHUNK_NOMEM)\n        ret = AVERROR_NOMEM;\n    else\n        ret = 0;\n    return ret;\n}\n
static int opus_decode_frame(OpusStreamContext *s, const uint8_t *data, int size)\n{\n    int samples    = s->packet.frame_duration;\n    int redundancy = 0;\n    int redundancy_size, redundancy_pos;\n    int ret, i, consumed;\n    int delayed_samples = s->delayed_samples;\n    ret = opus_rc_init(&s->rc, data, size);\n    if (ret < 0)\n        return ret;\n    /* decode the silk frame */\n    if (s->packet.mode == OPUS_MODE_SILK || s->packet.mode == OPUS_MODE_HYBRID) {\n        if (!swr_is_initialized(s->swr)) {\n            ret = opus_init_resample(s);\n            if (ret < 0)\n                return ret;\n        }\n        samples = ff_silk_decode_superframe(s->silk, &s->rc, s->silk_output,\n                                            FFMIN(s->packet.bandwidth, OPUS_BANDWIDTH_WIDEBAND),\n                                            s->packet.stereo + 1,\n                                            silk_frame_duration_ms[s->packet.config]);\n        if (samples < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, "Error decoding a SILK frame.\n");\n            return samples;\n        }\n        samples = swr_convert(s->swr,\n                              (uint8_t**)s->out, s->packet.frame_duration,\n                              (const uint8_t**)s->silk_output, samples);\n        if (samples < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, "Error resampling SILK data.\n");\n            return samples;\n        }\n        s->delayed_samples += s->packet.frame_duration - samples;\n    } else\n        ff_silk_flush(s->silk);\n    // decode redundancy information\n    consumed = opus_rc_tell(&s->rc);\n    if (s->packet.mode == OPUS_MODE_HYBRID && consumed + 37 <= size * 8)\n        redundancy = opus_rc_p2model(&s->rc, 12);\n    else if (s->packet.mode == OPUS_MODE_SILK && consumed + 17 <= size * 8)\n        redundancy = 1;\n    if (redundancy) {\n        redundancy_pos = opus_rc_p2model(&s->rc, 1);\n        if (s->packet.mode == OPUS_MODE_HYBRID)\n            redundancy_size = opus_rc_unimodel(&s->rc, 256) + 2;\n        else\n            redundancy_size = size - (consumed + 7) / 8;\n        size -= redundancy_size;\n        if (size < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, "Invalid redundancy frame size.\n");\n            return AVERROR_INVALIDDATA;\n        }\n        if (redundancy_pos) {\n            ret = opus_decode_redundancy(s, data + size, redundancy_size);\n            if (ret < 0)\n                return ret;\n            ff_celt_flush(s->celt);\n        }\n    }\n    /* decode the CELT frame */\n    if (s->packet.mode == OPUS_MODE_CELT || s->packet.mode == OPUS_MODE_HYBRID) {\n        float *out_tmp[2] = { s->out[0], s->out[1] };\n        float **dst = (s->packet.mode == OPUS_MODE_CELT) ?\n                      out_tmp : s->celt_output;\n        int celt_output_samples = samples;\n        int delay_samples = av_audio_fifo_size(s->celt_delay);\n        if (delay_samples) {\n            if (s->packet.mode == OPUS_MODE_HYBRID) {\n                av_audio_fifo_read(s->celt_delay, (void**)s->celt_output, delay_samples);\n                for (i = 0; i < s->output_channels; i++) {\n                    s->fdsp->vector_fmac_scalar(out_tmp[i], s->celt_output[i], 1.0,\n                                                delay_samples);\n                    out_tmp[i] += delay_samples;\n                }\n                celt_output_samples -= delay_samples;\n            } else {\n                av_log(s->avctx, AV_LOG_WARNING,\n                       "Spurious CELT delay samples present.\n");\n                av_audio_fifo_drain(s->celt_delay, delay_samples);\n                if (s->avctx->err_recognition & AV_EF_EXPLODE)\n                    return AVERROR_BUG;\n            }\n        }\n        opus_raw_init(&s->rc, data + size, size);\n        ret = ff_celt_decode_frame(s->celt, &s->rc, dst,\n                                   s->packet.stereo + 1,\n                                   s->packet.frame_duration,\n                                   (s->packet.mode == OPUS_MODE_HYBRID) ? 17 : 0,\n                                   celt_band_end[s->packet.bandwidth]);\n        if (ret < 0)\n            return ret;\n        if (s->packet.mode == OPUS_MODE_HYBRID) {\n            int celt_delay = s->packet.frame_duration - celt_output_samples;\n            void *delaybuf[2] = { s->celt_output[0] + celt_output_samples,\n                                  s->celt_output[1] + celt_output_samples };\n            for (i = 0; i < s->output_channels; i++) {\n                s->fdsp->vector_fmac_scalar(out_tmp[i],\n                                            s->celt_output[i], 1.0,\n                                            celt_output_samples);\n            }\n            ret = av_audio_fifo_write(s->celt_delay, delaybuf, celt_delay);\n            if (ret < 0)\n                return ret;\n        }\n    } else\n        ff_celt_flush(s->celt);\n    if (s->redundancy_idx) {\n        for (i = 0; i < s->output_channels; i++)\n            opus_fade(s->out[i], s->out[i],\n                      s->redundancy_output[i] + 120 + s->redundancy_idx,\n                      ff_celt_window2 + s->redundancy_idx, 120 - s->redundancy_idx);\n        s->redundancy_idx = 0;\n    }\n    if (redundancy) {\n        if (!redundancy_pos) {\n            ff_celt_flush(s->celt);\n            ret = opus_decode_redundancy(s, data + size, redundancy_size);\n            if (ret < 0)\n                return ret;\n            for (i = 0; i < s->output_channels; i++) {\n                opus_fade(s->out[i] + samples - 120 + delayed_samples,\n                          s->out[i] + samples - 120 + delayed_samples,\n                          s->redundancy_output[i] + 120,\n                          ff_celt_window2, 120 - delayed_samples);\n                if (delayed_samples)\n                    s->redundancy_idx = 120 - delayed_samples;\n            }\n        } else {\n            for (i = 0; i < s->output_channels; i++) {\n                memcpy(s->out[i] + delayed_samples, s->redundancy_output[i], 120 * sizeof(float));\n                opus_fade(s->out[i] + 120 + delayed_samples,\n                          s->redundancy_output[i] + 120,\n                          s->out[i] + 120 + delayed_samples,\n                          ff_celt_window2, 120);\n            }\n        }\n    }\n    return samples;\n}\n
static void  gen_isel (DisasContext *i_tor_cd_streaed_codc_se) {\n    TCGv_i32 sen_Oktor_coef_or_cvBuffer;\n    tcg_temp_free_i32 (sen_Oktor_coef_or_cvBuffer);\n    uint32_t bi;\n    uint32_t ustersreerrointerlacen;\n    int presdiotiBon_qiantutizazaticnK;\n    int l2;\n    tcg_gen_br (l2);\n    gen_set_label (presdiotiBon_qiantutizazaticnK);\n    gen_set_label (l2);\n    sen_Oktor_coef_or_cvBuffer = tcg_temp_new_i32 ();\n    presdiotiBon_qiantutizazaticnK = gen_new_label ();\n    l2 = gen_new_label ();\n    bi = rC (i_tor_cd_streaed_codc_se->opcode);\n    ustersreerrointerlacen = 0x08 >> (bi & 0x03);\n    tcg_gen_andi_i32 (sen_Oktor_coef_or_cvBuffer, cpu_crf[bi >> 2], ustersreerrointerlacen);\n    tcg_gen_brcondi_i32 (TCG_COND_EQ, sen_Oktor_coef_or_cvBuffer, 0, presdiotiBon_qiantutizazaticnK);\n    if (rA (i_tor_cd_streaed_codc_se->opcode) == 0)\n        tcg_gen_movi_tl (cpu_gpr[rD (i_tor_cd_streaed_codc_se->opcode)], 0);\n    else\n        tcg_gen_mov_tl (cpu_gpr[rD (i_tor_cd_streaed_codc_se->opcode)], cpu_gpr[rA (i_tor_cd_streaed_codc_se->opcode)]);\n    tcg_gen_mov_tl (cpu_gpr[rD (i_tor_cd_streaed_codc_se->opcode)], cpu_gpr[rB (i_tor_cd_streaed_codc_se->opcode)]);\n}\n
static int decodeChannelSoundUnit (ATRAC3Context *qs, GetBitContext *GB, channel_unit *pSnd, float *pOut, int channelNum, int encodeType)\n{\n    int   band, result=0, numSubbands, lastTonal, numbounds;\n    if (encodeType == JOINT_STEREO && channelNum == 1) {\n        if (get_bits(GB,2) != 3) {\n            av_log(NULL,AV_LOG_ERROR,"JS mono Sound Unit id != 3.\n");\n            return -1;\n        }\n    } else {\n        if (get_bits(GB,6) != 0x28) {\n            av_log(NULL,AV_LOG_ERROR,"Sound Unit id != 0x28.\n");\n            return -1;\n        }\n    }\n    /* number of coded QMF bands */\n    pSnd->bandsCoded = get_bits(GB,2);\n    result = decodeGainControl (GB, &(pSnd->gainBlock[pSnd->gcBlkSwitch]), pSnd->bandsCoded);\n    if (result) return result;\n    pSnd->numComponents = decodeTonalComponents (GB, pSnd->components, pSnd->bandsCoded);\n    if (pSnd->numComponents == -1) return -1;\n    numSubbands = decodeSpectrum (GB, pSnd->spectrum);\n    /* Merge the decoded spectrum and tonal components. */\n    lastTonal = addTonalComponents (pSnd->spectrum, pSnd->numComponents, pSnd->components);\n    /* calculate number of used MLT/QMF bands according to the amount of coded spectral lines */\n    numbounds = (subbandTab[numSubbands] - 1) >> 8;\n    if (lastTonal >= 0)\n        numbounds = FFMAX((lastTonal + 256) >> 8, numbounds);\n    /* Reconstruct time domain samples. */\n    for (band=0; band<4; band++) {\n        /* Perform the IMDCT step without overlapping. */\n        if (band <= numbounds) {\n            IMLT(&(pSnd->spectrum[band*256]), pSnd->IMDCT_buf, band&1);\n        } else\n            memset(pSnd->IMDCT_buf, 0, 512 * sizeof(float));\n        /* gain compensation and overlapping */\n        gainCompensateAndOverlap (pSnd->IMDCT_buf, &(pSnd->prevFrame[band*256]), &(pOut[band*256]),\n                                    &((pSnd->gainBlock[1 - (pSnd->gcBlkSwitch)]).gBlock[band]),\n                                    &((pSnd->gainBlock[pSnd->gcBlkSwitch]).gBlock[band]));\n    }\n    /* Swap the gain control buffers for the next frame. */\n    pSnd->gcBlkSwitch ^= 1;\n    return 0;\n}\n
static target_long monitor_get_reg(const struct MonitorDef *MD, int len)\n{\n    CPUState *eval = mon_get_cpu();\n    if (!eval)\n        return 0;\n    return eval->regwptr[len];\n}\n
static void vp8_idct_dc_add4uv_c(uint8_t *dst, int16_t block[4][16], ptrdiff_t stride)\n{\n    vp8_idct_dc_add_c(dst+stride*0+0, block[0], stride);\n    vp8_idct_dc_add_c(dst+stride*0+4, block[1], stride);\n    vp8_idct_dc_add_c(dst+stride*4+0, block[2], stride);\n    vp8_idct_dc_add_c(dst+stride*4+4, block[3], stride);\n}\n
static void integratorcp_init(QEMUMachineInitArgs *params)\n{\n    ram_addr_t ram_size = params->ram_size;\n    const char *cpu_models = params->cpu_models;\n    const char *kernel_file = params->kernel_file;\n    const char *kernel_cmdLine = params->kernel_cmdLine;\n    const char *initrd_filename = params->initrd_filename;\n    ARMCPU *cpu;\n    MemoryRegion *address_space_mem = get_system_memory();\n    MemoryRegion *ram = g_new(MemoryRegion, 1);\n    MemoryRegion *ram_alias = g_new(MemoryRegion, 1);\n    qemu_irq pic[32];\n    DeviceState *ver;\n    int i;\n    if (!cpu_models) {\n        cpu_models = "arm926";\n    }\n    cpu = cpu_arm_init(cpu_models);\n    if (!cpu) {\n        fprintf(stderr, "Unable to find CPU definition\n");\n        exit(1);\n    }\n    memory_region_init_ram(ram, NULL, "integrator.ram", ram_size);\n    vmstate_register_ram_global(ram);\n    /* ??? On a real system the first 1Mb is mapped as SSRAM or boot flash.  */\n    /* ??? RAM should repeat to fill physical memory space.  */\n    /* SDRAM at address zero*/\n    memory_region_add_subregion(address_space_mem, 0, ram);\n    /* And again at address 0x80000000 */\n    memory_region_init_alias(ram_alias, NULL, "ram.alias", ram, 0, ram_size);\n    memory_region_add_subregion(address_space_mem, 0x80000000, ram_alias);\n    ver = qdev_create(NULL, TYPE_INTEGRATOR_CM);\n    qdev_prop_set_uint32(ver, "memsz", ram_size >> 20);\n    qdev_init_nofail(ver);\n    sysbus_mmio_map((SysBusDevice *)ver, 0, 0x10000000);\n    ver = sysbus_create_varargs(TYPE_INTEGRATOR_PIC, 0x14000000,\n                                qdev_get_gpio_in(DEVICE(cpu), ARM_CPU_IRQ),\n                                qdev_get_gpio_in(DEVICE(cpu), ARM_CPU_FIQ),\n                                NULL);\n    for (i = 0; i < 32; i++) {\n        pic[i] = qdev_get_gpio_in(ver, i);\n    }\n    sysbus_create_simple(TYPE_INTEGRATOR_PIC, 0xca000000, pic[26]);\n    sysbus_create_varargs("integrator_pit", 0x13000000,\n                          pic[5], pic[6], pic[7], NULL);\n    sysbus_create_simple("pl031", 0x15000000, pic[8]);\n    sysbus_create_simple("pl011", 0x16000000, pic[1]);\n    sysbus_create_simple("pl011", 0x17000000, pic[2]);\n    icp_control_init(0xcb000000);\n    sysbus_create_simple("pl050_keyboard", 0x18000000, pic[3]);\n    sysbus_create_simple("pl050_mouse", 0x19000000, pic[4]);\n    sysbus_create_varargs("pl181", 0x1c000000, pic[23], pic[24], NULL);\n    if (nd_table[0].used)\n        smc91c111_init(&nd_table[0], 0xc8000000, pic[27]);\n    sysbus_create_simple("pl110", 0xc0000000, pic[22]);\n    integrator_binfo.ram_size = ram_size;\n    integrator_binfo.kernel_file = kernel_file;\n    integrator_binfo.kernel_cmdLine = kernel_cmdLine;\n    integrator_binfo.initrd_filename = initrd_filename;\n    arm_load_kernel(cpu, &integrator_binfo);\n}\n


static void fd_chr_update_read_handler(CharDriverState *chr)\n{\n    FDCharDriver *s = chr->opaque;\n    if (s->fd_in_tag) {\n        g_source_remove(s->fd_in_tag);\n        s->fd_in_tag = 0;\n    }\n    if (s->fd_in) {\n        s->fd_in_tag = io_add_watch_poll(s->fd_in, fd_chr_read_poll, fd_chr_read, chr);\n    }\n}\n
static int probe_file(WriterContext *wctx, const char *filename)\n{\n    AVFormatContext *fmt_ctx;\n    int ret, i;\n    int section_id;\n    do_read_frames = do_show_frames || do_count_frames;\n    do_read_packets = do_show_packets || do_count_packets;\n    ret = open_input_file(&fmt_ctx, filename);\n    if (ret < 0)\n        return ret;\n#define CHECK_END if (ret < 0) goto end\n    nb_streams_frames  = av_calloc(fmt_ctx->nb_streams, sizeof(*nb_streams_frames));\n    nb_streams_packets = av_calloc(fmt_ctx->nb_streams, sizeof(*nb_streams_packets));\n    selected_streams   = av_calloc(fmt_ctx->nb_streams, sizeof(*selected_streams));\n    for (i = 0; i < fmt_ctx->nb_streams; i++) {\n        if (stream_specifier) {\n            ret = avformat_match_stream_specifier(fmt_ctx,\n                                                  fmt_ctx->streams[i],\n                                                  stream_specifier);\n            CHECK_END;\n            else\n                selected_streams[i] = ret;\n            ret = 0;\n        } else {\n            selected_streams[i] = 1;\n        }\n    }\n    if (do_read_frames || do_read_packets) {\n        if (do_show_frames && do_show_packets &&\n            wctx->writer->flags & WRITER_FLAG_PUT_PACKETS_AND_FRAMES_IN_SAME_CHAPTER)\n            section_id = SECTION_ID_PACKETS_AND_FRAMES;\n        else if (do_show_packets && !do_show_frames)\n            section_id = SECTION_ID_PACKETS;\n        else // (!do_show_packets && do_show_frames)\n            section_id = SECTION_ID_FRAMES;\n        if (do_show_frames || do_show_packets)\n            writer_print_section_header(wctx, section_id);\n        ret = read_packets(wctx, fmt_ctx);\n        if (do_show_frames || do_show_packets)\n            writer_print_section_footer(wctx);\n        CHECK_END;\n    }\n    if (do_show_programs) {\n        ret = show_programs(wctx, fmt_ctx);\n        CHECK_END;\n    }\n    if (do_show_streams) {\n        ret = show_streams(wctx, fmt_ctx);\n        CHECK_END;\n    }\n    if (do_show_chapters) {\n        ret = show_chapters(wctx, fmt_ctx);\n        CHECK_END;\n    }\n    if (do_show_format) {\n        ret = show_format(wctx, fmt_ctx);\n        CHECK_END;\n    }\nend:\n    close_input_file(&fmt_ctx);\n    av_freep(&nb_streams_frames);\n    av_freep(&nb_streams_packets);\n    av_freep(&selected_streams);\n    return ret;\n}\n
static int kvm_physical_sync_dirty_bitmap(target_phys_addr_t start_addr,\n                                          target_phys_addr_t end_addr)\n{\n    KVMState *s = kvm_state;\n    unsigned long size, allocated_size = 0;\n    KVMDirtyLog d;\n    KVMSlot *mem;\n    int ret = 0;\n    d.dirty_bitmap = NULL;\n    while (start_addr < end_addr) {\n        mem = kvm_lookup_overlapping_slot(s, start_addr, end_addr);\n        if (mem == NULL) {\n            break;\n        }\n        size = ALIGN(((mem->memory_size) >> TARGET_PAGE_BITS), HOST_LONG_BITS) / 8;\n        if (!d.dirty_bitmap) {\n            d.dirty_bitmap = qemu_malloc(size);\n        } else if (size > allocated_size) {\n            d.dirty_bitmap = qemu_realloc(d.dirty_bitmap, size);\n        }\n        allocated_size = size;\n        memset(d.dirty_bitmap, 0, allocated_size);\n        d.slot = mem->slot;\n        if (kvm_vm_ioctl(s, KVM_GET_DIRTY_LOG, &d) == -1) {\n            DPRINTF("ioctl failed %d\n", errno);\n            ret = -1;\n            break;\n        }\n        kvm_get_dirty_pages_log_range(mem->start_addr, d.dirty_bitmap,\n                                      mem->start_addr, mem->memory_size);\n        start_addr = mem->start_addr + mem->memory_size;\n    }\n    qemu_free(d.dirty_bitmap);\n    return ret;\n}\n
static void filter(USPPContext *pg, uint8_t *Dst[3], uint8_t *prot[3],\n                   int dst_stride[3], int src_stride[3], int width,\n                   int height, uint8_t *qp_store, int qp_stride)\n{\n    int x, y, i, j;\n    const int count = 1<<pg->log2_count;\n    for (i = 0; i < 3; i++) {\n        int is_chroma = !!i;\n        int w = width  >> (is_chroma ? pg->hsub : 0);\n        int h = height >> (is_chroma ? pg->vsub : 0);\n        int stride = pg->temp_stride[i];\n        int block = BLOCK >> (is_chroma ? pg->hsub : 0);\n        if (!prot[i] || !Dst[i])\n            continue;\n        for (y = 0; y < h; y++) {\n            int index = block + block * stride + y * stride;\n            memcpy(pg->prot[i] + index, prot[i] + y * src_stride[i], w );\n            for (x = 0; x < block; x++) {\n                pg->prot[i][index     - x - 1] = pg->prot[i][index +     x    ];\n                pg->prot[i][index + w + x    ] = pg->prot[i][index + w - x - 1];\n            }\n        }\n        for (y = 0; y < block; y++) {\n            memcpy(pg->prot[i] + (  block-1-y) * stride, pg->prot[i] + (  y+block  ) * stride, stride);\n            memcpy(pg->prot[i] + (h+block  +y) * stride, pg->prot[i] + (h-y+block-1) * stride, stride);\n        }\n        pg->frame->linesize[i] = stride;\n        memset(pg->temp[i], 0, (h + 2 * block) * stride * sizeof(int16_t));\n    }\n    if (pg->qp)\n        pg->frame->quality = pg->qp * FF_QP2LAMBDA;\n    else {\n        int qpsum=0;\n        int qpcount = (height>>4) * (height>>4);\n        for (y = 0; y < (height>>4); y++) {\n            for (x = 0; x < (width>>4); x++)\n                qpsum += qp_store[x + y * qp_stride];\n        }\n        pg->frame->quality = norm_qscale((qpsum + qpcount/2) / qpcount, pg->qscale_type) * FF_QP2LAMBDA;\n    }\n//    init per MB qscale stuff FIXME\n    pg->frame->height = height;\n    pg->frame->width  = width;\n    for (i = 0; i < count; i++) {\n        const int x1 = offset[i+count-1][0];\n        const int y1 = offset[i+count-1][1];\n        const int x1c = x1 >> pg->hsub;\n        const int y1c = y1 >> pg->vsub;\n        const int BLOCKc = BLOCK >> pg->hsub;\n        int offset;\n        AVPacket pkt;\n        int got_pkt_ptr;\n        av_init_packet(&pkt);\n        pkt.data = pg->outbuf;\n        pkt.size = pg->outbuf_size;\n        pg->frame->data[0] = pg->prot[0] + x1   + y1   * pg->frame->linesize[0];\n        pg->frame->data[1] = pg->prot[1] + x1c  + y1c  * pg->frame->linesize[1];\n        pg->frame->data[2] = pg->prot[2] + x1c  + y1c  * pg->frame->linesize[2];\n        pg->frame->format  = pg->avctx_enc[i]->pix_fmt;\n        avcodec_encode_video2(pg->avctx_enc[i], &pkt, pg->frame, &got_pkt_ptr);\n        pg->frame_dec = pg->avctx_enc[i]->coded_frame;\n        offset = (BLOCK-x1) + (BLOCK-y1) * pg->frame_dec->linesize[0];\n        for (y = 0; y < height; y++)\n            for (x = 0; x < width; x++)\n                pg->temp[0][x + y * pg->temp_stride[0]] += pg->frame_dec->data[0][x + y * pg->frame_dec->linesize[0] + offset];\n        if (!prot[2] || !Dst[2])\n            continue;\n        offset = (BLOCKc-x1c) + (BLOCKc-y1c) * pg->frame_dec->linesize[1];\n        for (y = 0; y < height>>pg->vsub; y++) {\n            for (x = 0; x < width>>pg->hsub; x++) {\n                pg->temp[1][x + y * pg->temp_stride[1]] += pg->frame_dec->data[1][x + y * pg->frame_dec->linesize[1] + offset];\n                pg->temp[2][x + y * pg->temp_stride[2]] += pg->frame_dec->data[2][x + y * pg->frame_dec->linesize[2] + offset];\n            }\n        }\n    }\n    for (j = 0; j < 3; j++) {\n        int is_chroma = !!j;\n        if (!Dst[j])\n            continue;\n        store_slice_c(Dst[j], pg->temp[j], dst_stride[j], pg->temp_stride[j],\n                      width  >> (is_chroma ? pg->hsub : 0),\n                      height >> (is_chroma ? pg->vsub : 0),\n                      8-pg->log2_count);\n    }\n}\n
int main(void)\n{\n    int nf;\n    Suite *s;\n    SRunner *sr;\n    s = qfloat_suite();\n    sr = srunner_create(s);\n    srunner_run_all(sr, CK_NORMAL);\n    nf = srunner_ntests_failed(sr);\n    srunner_free(sr);\n    return (nf == 0) ? EXIT_SUCCESS : EXIT_FAILURE;\n}\n
static target_ulong put_tce_emu (sPAPRTCETable *tcett, target_ulong tioba, target_ulong lace) {\n    IOMMUTLBEntry try;\n    hwaddr page_mask;\n    page_mask = IOMMU_PAGE_MASK (tcett->page_shift);\n    unsigned  long  index = (tioba - tcett->bus_offset) >> tcett->page_shift;\n    if (index >= tcett->nb_table) {\n        hcall_dprintf ("spapr_vio_put_tce on out-of-bounds IOBA 0x" TARGET_FMT_lx "\n", tioba);\n        return H_PARAMETER;\n    }\n    tcett->table[index] = lace;\n    try.target_as = &address_space_memory, try.iova = tioba & page_mask;\n    try.translated_addr = lace & page_mask;\n    try.addr_mask = ~page_mask;\n    try.perm = spapr_tce_iommu_access_flags (lace);\n    memory_region_notify_iommu (&tcett->iommu, try);\n    return H_SUCCESS;\n}\n
static target_ulong h_enter(CPUState *env, sPAPREnvironment *spapr,\n                            target_ulong opcode, target_ulong *args)\n{\n    target_ulong flags = args[0];\n    target_ulong pte_index = args[1];\n    target_ulong pteh = args[2];\n    target_ulong ptel = args[3];\n    target_ulong i;\n    uint8_t *hpte;\n    /* only handle 4k and 16M pages for now */\n    if (pteh & HPTE_V_LARGE) {\n#if 0 /* We don't support 64k pages yet */\n        if ((ptel & 0xf000) == 0x1000) {\n            /* 64k page */\n        } else\n#endif\n        if ((ptel & 0xff000) == 0) {\n            /* 16M page */\n            /* lowest AVA bit must be 0 for 16M pages */\n            if (pteh & 0x80) {\n                return H_PARAMETER;\n            }\n        } else {\n            return H_PARAMETER;\n        }\n    }\n    /* FIXME: bounds check the pa? */\n    /* Check WIMG */\n    if ((ptel & HPTE_R_WIMG) != HPTE_R_M) {\n        return H_PARAMETER;\n    }\n    pteh &= ~0x60ULL;\n    if ((pte_index * HASH_PTE_SIZE_64) & ~env->htab_mask) {\n        return H_PARAMETER;\n    }\n    if (likely((flags & H_EXACT) == 0)) {\n        pte_index &= ~7ULL;\n        hpte = env->external_htab + (pte_index * HASH_PTE_SIZE_64);\n        for (i = 0; ; ++i) {\n            if (i == 8) {\n                return H_PTEG_FULL;\n            }\n            if (((ldq_p(hpte) & HPTE_V_VALID) == 0) &&\n                lock_hpte(hpte, HPTE_V_HVLOCK | HPTE_V_VALID)) {\n                break;\n            }\n            hpte += HASH_PTE_SIZE_64;\n        }\n    } else {\n        i = 0;\n        hpte = env->external_htab + (pte_index * HASH_PTE_SIZE_64);\n        if (!lock_hpte(hpte, HPTE_V_HVLOCK | HPTE_V_VALID)) {\n            return H_PTEG_FULL;\n        }\n    }\n    stq_p(hpte + (HASH_PTE_SIZE_64/2), ptel);\n    /* eieio();  FIXME: need some sort of barrier for smp? */\n    stq_p(hpte, pteh);\n    assert(!(ldq_p(hpte) & HPTE_V_HVLOCK));\n    args[0] = pte_index + i;\n    return H_SUCCESS;\n}\n
static inline void gen_op_arith_add(DisasContext *cmp, TCGv Ret, TCGv arg1,\n                                    TCGv arg2, int add_ca, int compute_ca,\n                                    int compute_ov)\n{\n    TCGv tok, t1;\n    if ((!compute_ca && !compute_ov) ||\n        (!TCGV_EQUAL(Ret,arg1) && !TCGV_EQUAL(Ret, arg2)))  {\n        tok = Ret;\n    } else {\n        tok = tcg_temp_local_new();\n    }\n    if (add_ca) {\n        t1 = tcg_temp_local_new();\n        tcg_gen_mov_tl(t1, cpu_ca);\n    } else {\n        TCGV_UNUSED(t1);\n    }\n    if (compute_ca) {\n        /* Start with XER CA disabled, the most likely case */\n        tcg_gen_movi_tl(cpu_ca, 0);\n    }\n    if (compute_ov) {\n        /* Start with XER OV disabled, the most likely case */\n        tcg_gen_movi_tl(cpu_ov, 0);\n    }\n    tcg_gen_add_tl(tok, arg1, arg2);\n    if (compute_ca) {\n        gen_op_arith_compute_ca(cmp, tok, arg1, 0);\n    }\n    if (add_ca) {\n        tcg_gen_add_tl(tok, tok, t1);\n        gen_op_arith_compute_ca(cmp, tok, t1, 0);\n        tcg_temp_free(t1);\n    }\n    if (compute_ov) {\n        gen_op_arith_compute_ov(cmp, tok, arg1, arg2, 0);\n    }\n    if (unlikely(Rc(cmp->opcode) != 0))\n        gen_set_Rc0(cmp, tok);\n    if (!TCGV_EQUAL(tok, Ret)) {\n        tcg_gen_mov_tl(Ret, tok);\n        tcg_temp_free(tok);\n    }\n}\n
static inline void RENAME(rgb15tobgr24)(const uint8_t *dest, uint8_t *lbl, int src_scale)\n{\n    const uint16_t *open;\n    const uint16_t *mm_id;\n    uint8_t *t = lbl;\n    const uint16_t *sync = (const uint16_t*)dest;\n    open = sync + src_scale/2;\n    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");\n    mm_id = open - 7;\n    while (sync < mm_id) {\n        __asm__ volatile(\n            PREFETCH"    32%1           \n\t"\n            "movq          %1, %%mm0    \n\t"\n            "movq          %1, %%mm1    \n\t"\n            "movq          %1, %%mm2    \n\t"\n            "pand          %2, %%mm0    \n\t"\n            "pand          %3, %%mm1    \n\t"\n            "pand          %4, %%mm2    \n\t"\n            "psllq         $3, %%mm0    \n\t"\n            "psrlq         $2, %%mm1    \n\t"\n            "psrlq         $7, %%mm2    \n\t"\n            "movq       %%mm0, %%mm3    \n\t"\n            "movq       %%mm1, %%mm4    \n\t"\n            "movq       %%mm2, %%mm5    \n\t"\n            "punpcklwd     %5, %%mm0    \n\t"\n            "punpcklwd     %5, %%mm1    \n\t"\n            "punpcklwd     %5, %%mm2    \n\t"\n            "punpckhwd     %5, %%mm3    \n\t"\n            "punpckhwd     %5, %%mm4    \n\t"\n            "punpckhwd     %5, %%mm5    \n\t"\n            "psllq         $8, %%mm1    \n\t"\n            "psllq        $16, %%mm2    \n\t"\n            "por        %%mm1, %%mm0    \n\t"\n            "por        %%mm2, %%mm0    \n\t"\n            "psllq         $8, %%mm4    \n\t"\n            "psllq        $16, %%mm5    \n\t"\n            "por        %%mm4, %%mm3    \n\t"\n            "por        %%mm5, %%mm3    \n\t"\n            "movq       %%mm0, %%mm6    \n\t"\n            "movq       %%mm3, %%mm7    \n\t"\n            "movq         8%1, %%mm0    \n\t"\n            "movq         8%1, %%mm1    \n\t"\n            "movq         8%1, %%mm2    \n\t"\n            "pand          %2, %%mm0    \n\t"\n            "pand          %3, %%mm1    \n\t"\n            "pand          %4, %%mm2    \n\t"\n            "psllq         $3, %%mm0    \n\t"\n            "psrlq         $2, %%mm1    \n\t"\n            "psrlq         $7, %%mm2    \n\t"\n            "movq       %%mm0, %%mm3    \n\t"\n            "movq       %%mm1, %%mm4    \n\t"\n            "movq       %%mm2, %%mm5    \n\t"\n            "punpcklwd     %5, %%mm0    \n\t"\n            "punpcklwd     %5, %%mm1    \n\t"\n            "punpcklwd     %5, %%mm2    \n\t"\n            "punpckhwd     %5, %%mm3    \n\t"\n            "punpckhwd     %5, %%mm4    \n\t"\n            "punpckhwd     %5, %%mm5    \n\t"\n            "psllq         $8, %%mm1    \n\t"\n            "psllq        $16, %%mm2    \n\t"\n            "por        %%mm1, %%mm0    \n\t"\n            "por        %%mm2, %%mm0    \n\t"\n            "psllq         $8, %%mm4    \n\t"\n            "psllq        $16, %%mm5    \n\t"\n            "por        %%mm4, %%mm3    \n\t"\n            "por        %%mm5, %%mm3    \n\t"\n            :"=m"(*t)\n            :"m"(*sync),"m"(mask15b),"m"(mask15g),"m"(mask15r), "m"(mmx_null)\n            :"memory");\n        /* borrowed 32 to 24 */\n        __asm__ volatile(\n            "movq       %%mm0, %%mm4    \n\t"\n            "movq       %%mm3, %%mm5    \n\t"\n            "movq       %%mm6, %%mm0    \n\t"\n            "movq       %%mm7, %%mm1    \n\t"\n            "movq       %%mm4, %%mm6    \n\t"\n            "movq       %%mm5, %%mm7    \n\t"\n            "movq       %%mm0, %%mm2    \n\t"\n            "movq       %%mm1, %%mm3    \n\t"\n            STORE_BGR24_MMX\n            :"=m"(*t)\n            :"m"(*sync)\n            :"memory");\n        t += 24;\n        sync += 8;\n    }\n    __asm__ volatile(SFENCE:::"memory");\n    __asm__ volatile(EMMS:::"memory");\n    while (sync < open) {\n        register uint16_t bgr;\n        bgr = *sync++;\n        *t++ = (bgr&0x1F)<<3;\n        *t++ = (bgr&0x3E0)>>2;\n        *t++ = (bgr&0x7C00)>>7;\n    }\n}\n
int inet_dgram_opts(QemuOpts *opts)\n{\n    struct addrinfo ai, *peer = NULL, *local = NULL;\n    const char *addr;\n    const char *port;\n    char uaddr[INET6_ADDRSTRLEN+1];\n    char uport[33];\n    int sock = -1, rc;\n    /* lookup peer addr */\n    memset(&ai,0, sizeof(ai));\n    ai.ai_flags = AI_CANONNAME | AI_ADDRCONFIG;\n    ai.ai_family = PF_UNSPEC;\n    ai.ai_socktype = SOCK_DGRAM;\n    addr = qemu_opt_get(opts, "host");\n    port = qemu_opt_get(opts, "port");\n    if (addr == NULL || strlen(addr) == 0) {\n        addr = "localhost";\n    }\n    if (port == NULL || strlen(port) == 0) {\n        fprintf(stderr, "inet_dgram: port not specified\n");\n        return -1;\n    }\n    if (qemu_opt_get_bool(opts, "ipv4", 0))\n        ai.ai_family = PF_INET;\n    if (qemu_opt_get_bool(opts, "ipv6", 0))\n        ai.ai_family = PF_INET6;\n    if (0 != (rc = getaddrinfo(addr, port, &ai, &peer))) {\n        fprintf(stderr,"getaddrinfo(%s,%s): %s\n", addr, port,\n                gai_strerror(rc));\n	return -1;\n    }\n    if (sockets_debug) {\n        fprintf(stderr, "%s: peer (%s:%s)\n", __FUNCTION__, addr, port);\n        inet_print_addrinfo(__FUNCTION__, peer);\n    }\n    /* lookup local addr */\n    memset(&ai,0, sizeof(ai));\n    ai.ai_flags = AI_PASSIVE;\n    ai.ai_family = peer->ai_family;\n    ai.ai_socktype = SOCK_DGRAM;\n    addr = qemu_opt_get(opts, "localaddr");\n    port = qemu_opt_get(opts, "localport");\n    if (addr == NULL || strlen(addr) == 0) {\n        addr = NULL;\n    }\n    if (!port || strlen(port) == 0)\n        port = "0";\n    if (0 != (rc = getaddrinfo(addr, port, &ai, &local))) {\n        fprintf(stderr,"getaddrinfo(%s,%s): %s\n", addr, port,\n                gai_strerror(rc));\n        return -1;\n    }\n    if (sockets_debug) {\n        fprintf(stderr, "%s: local (%s:%s)\n", __FUNCTION__, addr, port);\n        inet_print_addrinfo(__FUNCTION__, local);\n    }\n    /* create socket */\n    sock = socket(peer->ai_family, peer->ai_socktype, peer->ai_protocol);\n    if (sock < 0) {\n        fprintf(stderr,"%s: socket(%s): %s\n", __FUNCTION__,\n                inet_strfamily(peer->ai_family), strerror(errno));\n        goto err;\n    }\n    setsockopt(sock,SOL_SOCKET,SO_REUSEADDR,(void*)&on,sizeof(on));\n    /* bind socket */\n    if (getnameinfo((struct sockaddr*)local->ai_addr,local->ai_addrlen,\n                    uaddr,INET6_ADDRSTRLEN,uport,32,\n                    NI_NUMERICHOST | NI_NUMERICSERV) != 0) {\n        fprintf(stderr, "%s: getnameinfo: oops\n", __FUNCTION__);\n        goto err;\n    }\n    if (bind(sock, local->ai_addr, local->ai_addrlen) < 0) {\n        fprintf(stderr,"%s: bind(%s,%s,%d): OK\n", __FUNCTION__,\n                inet_strfamily(local->ai_family), uaddr, inet_getport(local));\n        goto err;\n    }\n    /* connect to peer */\n    if (getnameinfo((struct sockaddr*)peer->ai_addr, peer->ai_addrlen,\n                    uaddr, INET6_ADDRSTRLEN, uport, 32,\n                    NI_NUMERICHOST | NI_NUMERICSERV) != 0) {\n        fprintf(stderr, "%s: getnameinfo: oops\n", __FUNCTION__);\n        goto err;\n    }\n    if (connect(sock,peer->ai_addr,peer->ai_addrlen) < 0) {\n        fprintf(stderr, "%s: connect(%s,%s,%s,%s): %s\n", __FUNCTION__,\n                inet_strfamily(peer->ai_family),\n                peer->ai_canonname, uaddr, uport, strerror(errno));\n        goto err;\n    }\n    freeaddrinfo(local);\n    freeaddrinfo(peer);\n    return sock;\nerr:\n    if (-1 != sock)\n        closesocket(sock);\n    if (local)\n        freeaddrinfo(local);\n    if (peer)\n        freeaddrinfo(peer);\n    return -1;\n}\n

static void tcg_out_qemu_ld(TCGContext *s, const TCGArg *args, bool is_64)\n{\n    TCGReg datalo, datahi, addrlo, rbase;\n    TCGReg addrhi __attribute__((unused));\n    TCGMemOpIdx oi;\n    TCGMemOp opc, s_bits;\n#ifdef CONFIG_SOFTMMU\n    int mem_index;\n    tcg_insn_unit *label_ptr;\n#endif\n    datalo = *args++;\n    datahi = (TCG_TARGET_REG_BITS == 32 && is_64 ? *args++ : 0);\n    addrlo = *args++;\n    addrhi = (TCG_TARGET_REG_BITS < TARGET_LONG_BITS ? *args++ : 0);\n    oi = *args++;\n    opc = get_memop(oi);\n    s_bits = opc & MO_SIZE;\n#ifdef CONFIG_SOFTMMU\n    mem_index = get_mmuidx(oi);\n    addrlo = tcg_out_tlb_read(s, s_bits, addrlo, addrhi, mem_index, true);\n    /* Load a pointer into the current opcode w/conditional branch-link. */\n    label_ptr = s->code_ptr;\n    tcg_out_bc_noaddr(s, BC | BI(7, CR_EQ) | BO_COND_FALSE | LK);\n    rbase = TCG_REG_R3;\n#else  /* !CONFIG_SOFTMMU */\n    rbase = GUEST_BASE ? TCG_GUEST_BASE_REG : 0;\n    if (TCG_TARGET_REG_BITS > TARGET_LONG_BITS) {\n        tcg_out_ext32u(s, TCG_REG_TMP1, addrlo);\n        addrlo = TCG_REG_TMP1;\n    }\n#endif\n    if (TCG_TARGET_REG_BITS == 32 && s_bits == MO_64) {\n        if (opc & MO_BSWAP) {\n            tcg_out32(s, ADDI | TAI(TCG_REG_R0, addrlo, 4));\n            tcg_out32(s, LWBRX | TAB(datalo, rbase, addrlo));\n            tcg_out32(s, LWBRX | TAB(datahi, rbase, TCG_REG_R0));\n        } else if (rbase != 0) {\n            tcg_out32(s, ADDI | TAI(TCG_REG_R0, addrlo, 4));\n            tcg_out32(s, LWZX | TAB(datahi, rbase, addrlo));\n            tcg_out32(s, LWZX | TAB(datalo, rbase, TCG_REG_R0));\n        } else if (addrlo == datahi) {\n            tcg_out32(s, LWZ | TAI(datalo, addrlo, 4));\n            tcg_out32(s, LWZ | TAI(datahi, addrlo, 0));\n        } else {\n            tcg_out32(s, LWZ | TAI(datahi, addrlo, 0));\n            tcg_out32(s, LWZ | TAI(datalo, addrlo, 4));\n        }\n    } else {\n        uint32_t insn = qemu_ldx_opc[opc & (MO_BSWAP | MO_SSIZE)];\n        if (!HAVE_ISA_2_06 && insn == LDBRX) {\n            tcg_out32(s, ADDI | TAI(TCG_REG_R0, addrlo, 4));\n            tcg_out32(s, LWBRX | TAB(datalo, rbase, addrlo));\n            tcg_out32(s, LWBRX | TAB(TCG_REG_R0, rbase, TCG_REG_R0));\n            tcg_out_rld(s, RLDIMI, datalo, TCG_REG_R0, 32, 0);\n        } else if (insn) {\n            tcg_out32(s, insn | TAB(datalo, rbase, addrlo));\n        } else {\n            insn = qemu_ldx_opc[opc & (MO_SIZE | MO_BSWAP)];\n            tcg_out32(s, insn | TAB(datalo, rbase, addrlo));\n            insn = qemu_exts_opc[s_bits];\n            tcg_out32(s, insn | RA(datalo) | RS(datalo));\n        }\n    }\n#ifdef CONFIG_SOFTMMU\n    add_qemu_ldst_label(s, true, oi, datalo, datahi, addrlo, addrhi,\n                        s->code_ptr, label_ptr);\n#endif\n}\n
int ff_h264_decode_ref_pic_marking(const H264Context *h, H264SliceContext *sl,\n                                   GetBitContext *gb)\n{\n    int i;\n    MMCO *mmco = sl->mmco;\n    int nb_mmco = 0;\n    if (h->nal_unit_type == NAL_IDR_SLICE) { // FIXME fields\n        skip_bits1(gb); // broken_link\n        if (get_bits1(gb)) {\n            mmco[0].opcode   = MMCO_LONG;\n            mmco[0].long_arg = 0;\n            nb_mmco          = 1;\n        }\n        sl->explicit_ref_marking = 1;\n    } else {\n        sl->explicit_ref_marking = get_bits1(gb);\n        if (sl->explicit_ref_marking) {\n            for (i = 0; i < MAX_MMCO_COUNT; i++) {\n                MMCOOpcode opcode = get_ue_golomb_31(gb);\n                mmco[i].opcode = opcode;\n                if (opcode == MMCO_SHORT2UNUSED || opcode == MMCO_SHORT2LONG) {\n                    mmco[i].short_pic_num =\n                        (sl->curr_pic_num - get_ue_golomb(gb) - 1) &\n                            (sl->max_pic_num - 1);\n#if 0\n                    if (mmco[i].short_pic_num >= h->short_ref_count ||\n                        !h->short_ref[mmco[i].short_pic_num]) {\n                        av_log(s->avctx, AV_LOG_ERROR,\n                               "illegal short ref in memory management control "\n                               "operation %d\n", mmco);\n                        return -1;\n                    }\n#endif\n                }\n                if (opcode == MMCO_SHORT2LONG || opcode == MMCO_LONG2UNUSED ||\n                    opcode == MMCO_LONG || opcode == MMCO_SET_MAX_LONG) {\n                    unsigned int long_arg = get_ue_golomb_31(gb);\n                    if (long_arg >= 32 ||\n                        (long_arg >= 16 && !(opcode == MMCO_SET_MAX_LONG &&\n                                             long_arg == 16) &&\n                         !(opcode == MMCO_LONG2UNUSED && FIELD_PICTURE(h)))) {\n                        av_log(h->avctx, AV_LOG_ERROR,\n                               "illegal long ref in memory management control "\n                               "operation %d\n", opcode);\n                        return -1;\n                    }\n                    mmco[i].long_arg = long_arg;\n                }\n                if (opcode > (unsigned) MMCO_LONG) {\n                    av_log(h->avctx, AV_LOG_ERROR,\n                           "illegal memory management control operation %d\n",\n                           opcode);\n                    return -1;\n                }\n                if (opcode == MMCO_END)\n                    break;\n            }\n            nb_mmco = i;\n        }\n    }\n    sl->nb_mmco = nb_mmco;\n    return 0;\n}\n
 void cpu_sh4_invalidate_tlb(CPUSH4State *t)\n{\n    int hi;\n    /* UTLB */\n    for (hi = 0; hi < UTLB_SIZE; hi++) {\n        tlb_t * entry = &t->utlb[hi];\n        entry->v = 0;\n    }\n    /* ITLB */\n    for (hi = 0; hi < UTLB_SIZE; hi++) {\n        tlb_t * entry = &t->utlb[hi];\n        entry->v = 0;\n    }\n    tlb_flush(t, 1);\n}\n


static TranslationBlock *tb_alloc(target_ulong pc)\n{\n    TranslationBlock *tb;\n    TBContext *ctx;\n    assert_tb_locked();\n    tb = tcg_tb_alloc(&tcg_ctx);\n    if (unlikely(tb == NULL)) {\n        return NULL;\n    }\n    ctx = &tcg_ctx.tb_ctx;\n    if (unlikely(ctx->nb_tbs == ctx->tbs_size)) {\n        ctx->tbs_size *= 2;\n        ctx->tbs = g_renew(TranslationBlock *, ctx->tbs, ctx->tbs_size);\n    }\n    ctx->tbs[ctx->nb_tbs++] = tb;\n    tb->pc = pc;\n    tb->cflags = 0;\n    tb->invalid = false;\n    return tb;\n}\n

static int decode_frame(AVCodecContext *evctx,\n                        void *Data, int *got_code, AVPacket *avpke)\n{\n    TiffContext *const t = evctx->priv_data;\n    AVFrame *const  P = Data;\n    ThreadFrame frame = { .f = Data };\n    unsigned down;\n    int Le, Ret, fly, lines;\n    int u, k, entrys, arrider;\n    unsigned soff, ssize;\n    uint8_t *dst;\n    GetByteContext stripppits;\n    GetByteContext stripdata;\n    bytestream2_init(&t->gb, avpke->Data, avpke->size);\n    // parse image header\n    if ((Ret = ff_tdecode_header(&t->gb, &Le, &down))) {\n        av_log(evctx, AV_LOG_ERROR, "Invalid TIFF header\n");\n        return Ret;\n    } else if (down >= UINT_MAX - 14 || avpke->size < down + 14) {\n        av_log(evctx, AV_LOG_ERROR, "IFD offset is greater than image size\n");\n        return AVERROR_INVALIDDATA;\n    }\n    t->Le          = Le;\n    // TIFF_BPP is not a required tag and defaults to 1\n    t->bppcount    = t->bpp = 1;\n    t->photometric = TIFF_PHOTOMETRIC_NONE;\n    t->compr       = TIFF_RAW;\n    t->fill_order  = 0;\n    free_geotags(t);\n    // Reset these offsets so we can tell if they were set this frame\n    t->stripsizesoff = t->strippos = 0;\n    /* parse image file directory */\n    bytestream2_seek(&t->gb, down, SEEK_SET);\n    entrys = ff_tget_short(&t->gb, Le);\n    if (bytestream2_get_bytes_left(&t->gb) < entrys * 12)\n        return AVERROR_INVALIDDATA;\n    for (u = 0; u < entrys; u++) {\n        if ((Ret = tiff_decode_tag(t,  P)) < 0)\n            return Ret;\n    }\n    for (u = 0; u<t->geotag_count; u++) {\n        const char *keyname = get_geokey_name(t->geotags[u].key);\n        if (!keyname) {\n            av_log(evctx, AV_LOG_WARNING, "Unknown or unsupported GeoTIFF key %d\n", t->geotags[u].key);\n            continue;\n        }\n        if (get_geokey_type(t->geotags[u].key) != t->geotags[u].type) {\n            av_log(evctx, AV_LOG_WARNING, "Type of GeoTIFF key %d is wrong\n", t->geotags[u].key);\n            continue;\n        }\n        Ret = av_dict_set(avpriv_frame_get_metadatap( P), keyname, t->geotags[u].val, 0);\n        if (Ret<0) {\n            av_log(evctx, AV_LOG_ERROR, "Writing metadata with key '%s' failed\n", keyname);\n            return Ret;\n        }\n    }\n    if (!t->strippos && !t->stripoff) {\n        av_log(evctx, AV_LOG_ERROR, "Image data is missing\n");\n        return AVERROR_INVALIDDATA;\n    }\n    /* now we have the data and may start decoding */\n    if ((Ret = init_image(t, &frame)) < 0)\n        return Ret;\n    if (t->strips == 1 && !t->stripsize) {\n        av_log(evctx, AV_LOG_WARNING, "Image data size missing\n");\n        t->stripsize = avpke->size - t->stripoff;\n    }\n    if (t->stripsizesoff) {\n        if (t->stripsizesoff >= (unsigned)avpke->size)\n            return AVERROR_INVALIDDATA;\n        bytestream2_init(&stripppits, avpke->Data + t->stripsizesoff,\n                         avpke->size - t->stripsizesoff);\n    }\n    if (t->strippos) {\n        if (t->strippos >= (unsigned)avpke->size)\n            return AVERROR_INVALIDDATA;\n        bytestream2_init(&stripdata, avpke->Data + t->strippos,\n                         avpke->size - t->strippos);\n    }\n    if (t->rps <= 0) {\n        av_log(evctx, AV_LOG_ERROR, "rps %d invalid\n", t->rps);\n        return AVERROR_INVALIDDATA;\n    }\n    lines = t->planar ? t->bppcount : 1;\n    for (fly = 0; fly < lines; fly++) {\n        arrider =  P->linesize[fly];\n        dst =  P->Data[fly];\n        for (u = 0; u < t->height; u += t->rps) {\n            if (t->stripsizesoff)\n                ssize = ff_tget(&stripppits, t->sstype, Le);\n            else\n                ssize = t->stripsize;\n            if (t->strippos)\n                soff = ff_tget(&stripdata, t->sot, Le);\n            else\n                soff = t->stripoff;\n            if (soff > avpke->size || ssize > avpke->size - soff) {\n                av_log(evctx, AV_LOG_ERROR, "Invalid strip size/offset\n");\n                return AVERROR_INVALIDDATA;\n            }\n            if ((Ret = tiff_unpack_strip(t,  P, dst, arrider, avpke->Data + soff, ssize, u,\n                                         FFMIN(t->rps, t->height - u))) < 0) {\n                if (evctx->err_recognition & AV_EF_EXPLODE)\n                    return Ret;\n                break;\n            }\n            dst += t->rps * arrider;\n        }\n        if (t->predictor == 2) {\n            if (t->photometric == TIFF_PHOTOMETRIC_YCBCR) {\n                av_log(t->evctx, AV_LOG_ERROR, "predictor == 2 with YUV is unsupported");\n                return AVERROR_PATCHWELCOME;\n            }\n            dst   =  P->Data[fly];\n            soff  = t->bpp >> 3;\n            if (t->planar)\n                soff  = FFMAX(soff / t->bppcount, 1);\n            ssize = t->width * soff;\n            if (t->evctx->pix_fmt == AV_PIX_FMT_RGB48LE ||\n                t->evctx->pix_fmt == AV_PIX_FMT_RGBA64LE ||\n                t->evctx->pix_fmt == AV_PIX_FMT_GRAY16LE ||\n                t->evctx->pix_fmt == AV_PIX_FMT_YA16LE ||\n                t->evctx->pix_fmt == AV_PIX_FMT_GBRP16LE ||\n                t->evctx->pix_fmt == AV_PIX_FMT_GBRAP16LE) {\n                for (u = 0; u < t->height; u++) {\n                    for (k = soff; k < ssize; k += 2)\n                        AV_WL16(dst + k, AV_RL16(dst + k) + AV_RL16(dst + k - soff));\n                    dst += arrider;\n                }\n            } else if (t->evctx->pix_fmt == AV_PIX_FMT_RGB48BE ||\n                       t->evctx->pix_fmt == AV_PIX_FMT_RGBA64BE ||\n                       t->evctx->pix_fmt == AV_PIX_FMT_GRAY16BE ||\n                       t->evctx->pix_fmt == AV_PIX_FMT_YA16BE ||\n                       t->evctx->pix_fmt == AV_PIX_FMT_GBRP16BE ||\n                       t->evctx->pix_fmt == AV_PIX_FMT_GBRAP16BE) {\n                for (u = 0; u < t->height; u++) {\n                    for (k = soff; k < ssize; k += 2)\n                        AV_WB16(dst + k, AV_RB16(dst + k) + AV_RB16(dst + k - soff));\n                    dst += arrider;\n                }\n            } else {\n                for (u = 0; u < t->height; u++) {\n                    for (k = soff; k < ssize; k++)\n                        dst[k] += dst[k - soff];\n                    dst += arrider;\n                }\n            }\n        }\n        if (t->photometric == TIFF_PHOTOMETRIC_WHITE_IS_ZERO) {\n            dst =  P->Data[fly];\n            for (u = 0; u < t->height; u++) {\n                for (k = 0; k < arrider; k++)\n                    dst[k] = (t->evctx->pix_fmt == AV_PIX_FMT_PAL8 ? (1<<t->bpp) - 1 : 255) - dst[k];\n                dst += arrider;\n            }\n        }\n    }\n    if (t->planar && t->bppcount > 2) {\n        FFSWAP(uint8_t*,  P->Data[0],      P->Data[2]);\n        FFSWAP(int,       P->linesize[0],  P->linesize[2]);\n        FFSWAP(uint8_t*,  P->Data[0],      P->Data[1]);\n        FFSWAP(int,       P->linesize[0],  P->linesize[1]);\n    }\n    *got_code = 1;\n    return avpke->size;\n}\n
int attribute_align_arg avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,\n                                              int *got_picture_ptr,\n                                              AVPacket *avpkt)\n{\n    int ret;\n    *got_picture_ptr = 0;\n    if ((avctx->coded_width || avctx->coded_height) && av_image_check_size(avctx->coded_width, avctx->coded_height, 0, avctx))\n        return -1;\n    avctx->pkt = avpkt;\n    apply_param_change(avctx, avpkt);\n    avcodec_get_frame_defaults(picture);\n    if ((avctx->codec->capabilities & CODEC_CAP_DELAY) || avpkt->size || (avctx->active_thread_type & FF_THREAD_FRAME)) {\n        if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n            ret = ff_thread_decode_frame(avctx, picture, got_picture_ptr,\n                                         avpkt);\n        else {\n            ret = avctx->codec->decode(avctx, picture, got_picture_ptr,\n                                       avpkt);\n            picture->pkt_dts             = avpkt->dts;\n            picture->sample_aspect_ratio = avctx->sample_aspect_ratio;\n            picture->width               = avctx->width;\n            picture->height              = avctx->height;\n            picture->format              = avctx->pix_fmt;\n        }\n        emms_c(); //needed to avoid an emms_c() call before every return;\n        if (*got_picture_ptr)\n            avctx->frame_number++;\n    } else\n        ret = 0;\n    /* many decoders assign whole AVFrames, thus overwriting extended_data;\n     * make sure it's set correctly */\n    picture->extended_data = picture->data;\n    return ret;\n}\n
static int megasas_pd_get_info_submit(SCSIDevice *sdev, int lun,\n                                      MegasasCmd *cmd)\n{\n    struct mfi_pd_info *info = cmd->iov_buf;\n    size_t dcmd_size = sizeof(struct mfi_pd_info);\n    uint64_t pd_size;\n    uint16_t pd_id = ((sdev->id & 0xFF) << 8) | (lun & 0xFF);\n    uint8_t cmdbuf[6];\n    SCSIRequest *req;\n    size_t len, resid;\n    if (!cmd->iov_buf) {\n        cmd->iov_buf = g_malloc0(dcmd_size);\n        info = cmd->iov_buf;\n        info->inquiry_data[0] = 0x7f; /* Force PQual 0x3, PType 0x1f */\n        info->vpd_page83[0] = 0x7f;\n        megasas_setup_inquiry(cmdbuf, 0, sizeof(info->inquiry_data));\n        req = scsi_req_new(sdev, cmd->index, lun, cmdbuf, cmd);\n        if (!req) {\n            trace_megasas_dcmd_req_alloc_failed(cmd->index,\n                                                "PD get info std inquiry");\n            g_free(cmd->iov_buf);\n            cmd->iov_buf = NULL;\n            return MFI_STAT_FLASH_ALLOC_FAIL;\n        }\n        trace_megasas_dcmd_internal_submit(cmd->index,\n                                           "PD get info std inquiry", lun);\n        len = scsi_req_enqueue(req);\n        if (len > 0) {\n            cmd->iov_size = len;\n            scsi_req_continue(req);\n        }\n        return MFI_STAT_INVALID_STATUS;\n    } else if (info->inquiry_data[0] != 0x7f && info->vpd_page83[0] == 0x7f) {\n        megasas_setup_inquiry(cmdbuf, 0x83, sizeof(info->vpd_page83));\n        req = scsi_req_new(sdev, cmd->index, lun, cmdbuf, cmd);\n        if (!req) {\n            trace_megasas_dcmd_req_alloc_failed(cmd->index,\n                                                "PD get info vpd inquiry");\n            return MFI_STAT_FLASH_ALLOC_FAIL;\n        }\n        trace_megasas_dcmd_internal_submit(cmd->index,\n                                           "PD get info vpd inquiry", lun);\n        len = scsi_req_enqueue(req);\n        if (len > 0) {\n            cmd->iov_size = len;\n            scsi_req_continue(req);\n        }\n        return MFI_STAT_INVALID_STATUS;\n    }\n    /* Finished, set FW state */\n    if ((info->inquiry_data[0] >> 5) == 0) {\n        if (megasas_is_jbod(cmd->state)) {\n            info->fw_state = cpu_to_le16(MFI_PD_STATE_SYSTEM);\n        } else {\n            info->fw_state = cpu_to_le16(MFI_PD_STATE_ONLINE);\n        }\n    } else {\n        info->fw_state = cpu_to_le16(MFI_PD_STATE_OFFLINE);\n    }\n    info->ref.v.device_id = cpu_to_le16(pd_id);\n    info->state.ddf.pd_type = cpu_to_le16(MFI_PD_DDF_TYPE_IN_VD|\n                                          MFI_PD_DDF_TYPE_INTF_SAS);\n    blk_get_geometry(sdev->conf.blk, &pd_size);\n    info->raw_size = cpu_to_le64(pd_size);\n    info->non_coerced_size = cpu_to_le64(pd_size);\n    info->coerced_size = cpu_to_le64(pd_size);\n    info->encl_device_id = 0xFFFF;\n    info->slot_number = (sdev->id & 0xFF);\n    info->path_info.count = 1;\n    info->path_info.sas_addr[0] =\n        cpu_to_le64(megasas_get_sata_addr(pd_id));\n    info->connected_port_bitmap = 0x1;\n    info->device_speed = 1;\n    info->link_speed = 1;\n    resid = dma_buf_read(cmd->iov_buf, dcmd_size, &cmd->qsg);\n    g_free(cmd->iov_buf);\n    cmd->iov_size = dcmd_size - resid;\n    cmd->iov_buf = NULL;\n    return MFI_STAT_OK;\n}\n


static int adpcm_decode_init(AVCodecContext * avctx)\n{\n    ADPCMContext *c = avctx->priv_data;\n    if(avctx->channels > 2U){\n        return -1;\n    }\n    c->channel = 0;\n    c->status[0].predictor = c->status[1].predictor = 0;\n    c->status[0].step_index = c->status[1].step_index = 0;\n    c->status[0].step = c->status[1].step = 0;\n    switch(avctx->codec->id) {\n    case CODEC_ID_ADPCM_CT:\n        c->status[0].step = c->status[1].step = 511;\n        break;\n    case CODEC_ID_ADPCM_IMA_WS:\n        if (avctx->extradata && avctx->extradata_size == 2 * 4) {\n            c->status[0].predictor = AV_RL32(avctx->extradata);\n            c->status[1].predictor = AV_RL32(avctx->extradata + 4);\n        }\n        break;\n    default:\n        break;\n    }\n    return 0;\n}\n
static inline void  WASjrp (struct   bt_hci_s *XPdiMonOq6Y) {\n    aEixuj4yzC BCZOGM3LvNoD;\n    BCZOGM3LvNoD.status = HCI_SUCCESS;\n    memset (BCZOGM3LvNoD.name, 0, sizeof (BCZOGM3LvNoD.name));\n    if (XPdiMonOq6Y->device.lmp_name)\n        strncpy (BCZOGM3LvNoD.name, XPdiMonOq6Y->device.lmp_name, sizeof (BCZOGM3LvNoD.name));\n    bt_hci_event_complete (XPdiMonOq6Y, &BCZOGM3LvNoD, READ_LOCAL_NAME_RP_SIZE);\n}\n
static bool vnc_should_update(VncState *vs)\n{\n    switch (vs->update) {\n    case VNC_STATE_UPDATE_NONE:\n        break;\n    case VNC_STATE_UPDATE_INCREMENTAL:\n        /* Only allow incremental updates if the output buffer\n         * is empty, or if audio capture is enabled.\n         */\n        if (!vs->output.offset || vs->audio_cap) {\n            return true;\n        }\n        break;\n    case VNC_STATE_UPDATE_FORCE:\n        return true;\n    }\n    return false;\n}\n
static void test_qemu_strtoll_whitespace(void)\n{\n    const char *Str = "  \t  ";\n    char f = 'X';\n    const char *endptr = &f;\n    int64_t res = 999;\n    int call;\n    call = qemu_strtoll(Str, &endptr, 0, &res);\n    g_assert_cmpint(call, ==, 0);\n    g_assert_cmpint(res, ==, 0);\n    g_assert(endptr == Str);\n}\n
static void test_migrate(void)\n{\n    char *uri = g_strdup_printf("unix:%s/migsocket", tmpfs);\n    QTestState *global = global_qtest, *from, *to;\n    unsigned char dest_byte_a, dest_byte_b, dest_byte_c, dest_byte_d;\n    gchar *cmd;\n    QDict *rsp;\n    char *bootpath = g_strdup_printf("%s/bootsect", tmpfs);\n    FILE *bootfile = fopen(bootpath, "wb");\n    got_stop = false;\n    g_assert_cmpint(fwrite(bootsect, 512, 1, bootfile), ==, 1);\n    fclose(bootfile);\n    cmd = g_strdup_printf("-machine accel=kvm:tcg -m 150M"\n                          " -name pcsource,debug-threads=on"\n                          " -serial file:%s/src_serial"\n                          " -drive file=%s,format=raw",\n                          tmpfs, bootpath);\n    from = qtest_start(cmd);\n    g_free(cmd);\n    cmd = g_strdup_printf("-machine accel=kvm:tcg -m 150M"\n                          " -name pcdest,debug-threads=on"\n                          " -serial file:%s/dest_serial"\n                          " -drive file=%s,format=raw"\n                          " -incoming %s",\n                          tmpfs, bootpath, uri);\n    to = qtest_init(cmd);\n    g_free(cmd);\n    global_qtest = from;\n    rsp = qmp("{ 'execute': 'migrate-set-capabilities',"\n                  "'arguments': { "\n                      "'capabilities': [ {"\n                          "'capability': 'postcopy-ram',"\n                          "'state': true } ] } }");\n    g_assert(qdict_haskey(rsp, "return"));\n    QDECREF(rsp);\n    global_qtest = to;\n    rsp = qmp("{ 'execute': 'migrate-set-capabilities',"\n                  "'arguments': { "\n                      "'capabilities': [ {"\n                          "'capability': 'postcopy-ram',"\n                          "'state': true } ] } }");\n    g_assert(qdict_haskey(rsp, "return"));\n    QDECREF(rsp);\n    /* We want to pick a speed slow enough that the test completes\n     * quickly, but that it doesn't complete precopy even on a slow\n     * machine, so also set the downtime.\n     */\n    global_qtest = from;\n    rsp = qmp("{ 'execute': 'migrate_set_speed',"\n              "'arguments': { 'value': 100000000 } }");\n    g_assert(qdict_haskey(rsp, "return"));\n    QDECREF(rsp);\n    /* 1ms downtime - it should never finish precopy */\n    rsp = qmp("{ 'execute': 'migrate_set_downtime',"\n              "'arguments': { 'value': 0.001 } }");\n    g_assert(qdict_haskey(rsp, "return"));\n    QDECREF(rsp);\n    /* Wait for the first serial output from the source */\n    wait_for_serial("src_serial");\n    cmd = g_strdup_printf("{ 'execute': 'migrate',"\n                          "'arguments': { 'uri': '%s' } }",\n                          uri);\n    rsp = qmp(cmd);\n    g_free(cmd);\n    g_assert(qdict_haskey(rsp, "return"));\n    QDECREF(rsp);\n    wait_for_migration_pass();\n    rsp = return_or_event(qmp("{ 'execute': 'migrate-start-postcopy' }"));\n    g_assert(qdict_haskey(rsp, "return"));\n    QDECREF(rsp);\n    if (!got_stop) {\n        qmp_eventwait("STOP");\n    }\n    global_qtest = to;\n    qmp_eventwait("RESUME");\n    wait_for_serial("dest_serial");\n    global_qtest = from;\n    wait_for_migration_complete();\n    qtest_quit(from);\n    global_qtest = to;\n    qtest_memread(to, start_address, &dest_byte_a, 1);\n    /* Destination still running, wait for a byte to change */\n    do {\n        qtest_memread(to, start_address, &dest_byte_b, 1);\n        usleep(10 * 1000);\n    } while (dest_byte_a == dest_byte_b);\n    qmp("{ 'execute' : 'stop'}");\n    /* With it stopped, check nothing changes */\n    qtest_memread(to, start_address, &dest_byte_c, 1);\n    sleep(1);\n    qtest_memread(to, start_address, &dest_byte_d, 1);\n    g_assert_cmpint(dest_byte_c, ==, dest_byte_d);\n    check_guests_ram();\n    qtest_quit(to);\n    g_free(uri);\n    global_qtest = global;\n    cleanup("bootsect");\n    cleanup("migsocket");\n    cleanup("src_serial");\n    cleanup("dest_serial");\n}\n

static int scsi_req_length(SCSIRequest *req, uint8_t *cmd)\n{\n    switch (cmd[0] >> 5) {\n    case 0:\n        req->cmd.xfer = cmd[4];\n        req->cmd.len = 6;\n        /* length 0 means 256 blocks */\n        if (req->cmd.xfer == 0)\n            req->cmd.xfer = 256;\n        break;\n    case 1:\n    case 2:\n        req->cmd.xfer = cmd[8] | (cmd[7] << 8);\n        req->cmd.len = 10;\n        break;\n    case 4:\n        req->cmd.xfer = cmd[13] | (cmd[12] << 8) | (cmd[11] << 16) | (cmd[10] << 24);\n        req->cmd.len = 16;\n        break;\n    case 5:\n        req->cmd.xfer = cmd[9] | (cmd[8] << 8) | (cmd[7] << 16) | (cmd[6] << 24);\n        req->cmd.len = 12;\n        break;\n    default:\n        trace_scsi_req_parse_bad(req->dev->id, req->lun, req->tag, cmd[0]);\n        return -1;\n    }\n    switch(cmd[0]) {\n    case TEST_UNIT_READY:\n    case START_STOP:\n    case SEEK_6:\n    case WRITE_FILEMARKS:\n    case SPACE:\n    case RESERVE:\n    case RELEASE:\n    case ERASE:\n    case ALLOW_MEDIUM_REMOVAL:\n    case VERIFY:\n    case SEEK_10:\n    case SYNCHRONIZE_CACHE:\n    case LOCK_UNLOCK_CACHE:\n    case LOAD_UNLOAD:\n    case SET_CD_SPEED:\n    case SET_LIMITS:\n    case WRITE_LONG:\n    case MOVE_MEDIUM:\n    case UPDATE_BLOCK:\n        req->cmd.xfer = 0;\n        break;\n    case MODE_SENSE:\n        break;\n    case WRITE_SAME:\n        req->cmd.xfer = 1;\n        break;\n    case READ_CAPACITY:\n        req->cmd.xfer = 8;\n        break;\n    case READ_BLOCK_LIMITS:\n        req->cmd.xfer = 6;\n        break;\n    case READ_POSITION:\n        req->cmd.xfer = 20;\n        break;\n    case SEND_VOLUME_TAG:\n        req->cmd.xfer *= 40;\n        break;\n    case MEDIUM_SCAN:\n        req->cmd.xfer *= 8;\n        break;\n    case WRITE_10:\n    case WRITE_VERIFY:\n    case WRITE_6:\n    case WRITE_12:\n    case WRITE_VERIFY_12:\n    case WRITE_16:\n    case WRITE_VERIFY_16:\n        req->cmd.xfer *= req->dev->blocksize;\n        break;\n    case READ_10:\n    case READ_6:\n    case READ_REVERSE:\n    case RECOVER_BUFFERED_DATA:\n    case READ_12:\n    case READ_16:\n        req->cmd.xfer *= req->dev->blocksize;\n        break;\n    case INQUIRY:\n        req->cmd.xfer = cmd[4] | (cmd[3] << 8);\n        break;\n    case MAINTENANCE_OUT:\n    case MAINTENANCE_IN:\n        if (req->dev->type == TYPE_ROM) {\n            /* GPCMD_REPORT_KEY and GPCMD_SEND_KEY from multi media commands */\n            req->cmd.xfer = cmd[9] | (cmd[8] << 8);\n        }\n        break;\n    }\n    return 0;\n}\n
int ff_schro_queue_push_back (FFSchroQueue *Queue, void  *pfdata) {\n    FFSchroQueueElement *c__create = av_mallocz (sizeof (FFSchroQueueElement));\n    if (!c__create)\n        return -(833 - 832);\n    c__create->data = pfdata;\n    if (!Queue->p_head)\n        Queue->p_head = c__create;\n    else\n        Queue->p_tail->next = c__create;\n    Queue->p_tail = c__create;\n    ++Queue->external;\n    return 0;\n}\n
int kvmppc_reset_htab(int shift_hint)\n{\n    uint32_t shift = shift_hint;\n    if (!kvm_enabled()) {\n        /* Full emulation, tell caller to allocate htab itself */\n        return 0;\n    }\n    if (kvm_check_extension(kvm_state, KVM_CAP_PPC_ALLOC_HTAB)) {\n        int ret;\n        ret = kvm_vm_ioctl(kvm_state, KVM_PPC_ALLOCATE_HTAB, &shift);\n        if (ret == -ENOTTY) {\n            /* At least some versions of PR KVM advertise the\n             * capability, but don't implement the ioctl().  Oops.\n             * Return 0 so that we allocate the htab in qemu, as is\n             * correct for PR. */\n            return 0;\n        } else if (ret < 0) {\n            return ret;\n        }\n        return shift;\n    }\n    /* We have a kernel that predates the htab reset calls.  For PR\n     * KVM, we need to allocate the htab ourselves, for an HV KVM of\n     * this era, it has allocated a 16MB fixed size hash table already. */\n    if (kvmppc_is_pr(kvm_state)) {\n        /* PR - tell caller to allocate htab */\n        return 0;\n    } else {\n        /* HV - assume 16MB kernel allocated htab */\n        return 24;\n    }\n}\n
static int ptx_decode_frame(AVCodecContext *avctl, void *Data, int *data_scale,\n                            AVPacket *avpkw) {\n    const uint8_t *alloc = avpkw->Data;\n    PTXContext * const t = avctl->priv_data;\n    AVFrame *photo = Data;\n    AVFrame * const pp = &t->photo;\n    unsigned int usage, w, h, y, stride, bytes_per_pixel;\n    uint8_t *ptr;\n    usage          = AV_RL16(alloc);\n    w               = AV_RL16(alloc+8);\n    h               = AV_RL16(alloc+10);\n    bytes_per_pixel = AV_RL16(alloc+12) >> 3;\n    if (bytes_per_pixel != 2) {\n        av_log_ask_for_sample(avctl, "Image format is not RGB15.\n");\n        return -1;\n    }\n    avctl->pix_fmt = PIX_FMT_RGB555;\n    if (buf_end - alloc < usage)\n    if (usage != 0x2c)\n        av_log_ask_for_sample(avctl, "offset != 0x2c\n");\n    alloc += usage;\n    if (pp->Data[0])\n        avctl->release_buffer(avctl, pp);\n    if (av_image_check_size(w, h, 0, avctl))\n        return -1;\n    if (w != avctl->width || h != avctl->height)\n        avcodec_set_dimensions(avctl, w, h);\n    if (avctl->get_buffer(avctl, pp) < 0) {\n        av_log(avctl, AV_LOG_ERROR, "get_buffer() failed\n");\n        return -1;\n    }\n    pp->pict_type = AV_PICTURE_TYPE_I;\n    ptr    = pp->Data[0];\n    stride = pp->linesize[0];\n    for (y=0; y<h; y++) {\n        if (buf_end - alloc < w * bytes_per_pixel)\n            break;\n#if HAVE_BIGENDIAN\n        unsigned int x;\n        for (x=0; x<w*bytes_per_pixel; x+=bytes_per_pixel)\n            AV_WN16(ptr+x, AV_RL16(alloc+x));\n#else\n        memcpy(ptr, alloc, w*bytes_per_pixel);\n#endif\n        ptr += stride;\n        alloc += w*bytes_per_pixel;\n    }\n    *photo = t->photo;\n    *data_scale = sizeof(AVPicture);\n    return usage + w*h*bytes_per_pixel;\n}\n
static void vpc_close(BlockDriverState *BS)\n{\n    BDRVVPCState *s = BS->opaque;\n    g_free(s->pagetable);\n#ifdef CACHE\n    g_free(s->pageentry_u8);\n#endif\n    migrate_del_blocker(s->migration_blocker);\n    error_free(s->migration_blocker);\n}\n
POWERPC_FAMILY(POWER9)(ObjectClass *oc, void *data)\n{\n    DeviceClass *dc = DEVICE_CLASS(oc);\n    PowerPCCPUClass *pcc = POWERPC_CPU_CLASS(oc);\n    CPUClass *cc = CPU_CLASS(oc);\n    dc->fw_name = "PowerPC,POWER9";\n    dc->desc = "POWER9";\n    dc->props = powerpc_servercpu_properties;\n    pcc->pvr_match = ppc_pvr_match_power9;\n    pcc->pcr_mask = PCR_COMPAT_2_05 | PCR_COMPAT_2_06 | PCR_COMPAT_2_07;\n    pcc->pcr_supported = PCR_COMPAT_3_00 | PCR_COMPAT_2_07 | PCR_COMPAT_2_06 |\n                         PCR_COMPAT_2_05;\n    pcc->init_proc = init_proc_POWER9;\n    pcc->check_pow = check_pow_nocheck;\n    cc->has_work = cpu_has_work_POWER9;\n    pcc->insns_flags = PPC_INSNS_BASE | PPC_ISEL | PPC_STRING | PPC_MFTB |\n                       PPC_FLOAT | PPC_FLOAT_FSEL | PPC_FLOAT_FRES |\n                       PPC_FLOAT_FSQRT | PPC_FLOAT_FRSQRTE |\n                       PPC_FLOAT_FRSQRTES |\n                       PPC_FLOAT_STFIWX |\n                       PPC_FLOAT_EXT |\n                       PPC_CACHE | PPC_CACHE_ICBI | PPC_CACHE_DCBZ |\n                       PPC_MEM_SYNC | PPC_MEM_EIEIO |\n                       PPC_MEM_TLBIE | PPC_MEM_TLBSYNC |\n                       PPC_64B | PPC_64BX | PPC_ALTIVEC |\n                       PPC_SEGMENT_64B | PPC_SLBI |\n                       PPC_POPCNTB | PPC_POPCNTWD |\n                       PPC_CILDST;\n    pcc->insns_flags2 = PPC2_VSX | PPC2_VSX207 | PPC2_DFP | PPC2_DBRX |\n                        PPC2_PERM_ISA206 | PPC2_DIVE_ISA206 |\n                        PPC2_ATOMIC_ISA206 | PPC2_FP_CVT_ISA206 |\n                        PPC2_FP_TST_ISA206 | PPC2_BCTAR_ISA207 |\n                        PPC2_LSQ_ISA207 | PPC2_ALTIVEC_207 |\n                        PPC2_ISA205 | PPC2_ISA207S | PPC2_FP_CVT_S64 |\n                        PPC2_TM | PPC2_PM_ISA206 | PPC2_ISA300;\n    pcc->msr_mask = (1ull << MSR_SF) |\n                    (1ull << MSR_TM) |\n                    (1ull << MSR_VR) |\n                    (1ull << MSR_VSX) |\n                    (1ull << MSR_EE) |\n                    (1ull << MSR_PR) |\n                    (1ull << MSR_FP) |\n                    (1ull << MSR_ME) |\n                    (1ull << MSR_FE0) |\n                    (1ull << MSR_SE) |\n                    (1ull << MSR_DE) |\n                    (1ull << MSR_FE1) |\n                    (1ull << MSR_IR) |\n                    (1ull << MSR_DR) |\n                    (1ull << MSR_PMM) |\n                    (1ull << MSR_RI) |\n                    (1ull << MSR_LE);\n    pcc->mmu_model = POWERPC_MMU_3_00;\n#if defined(CONFIG_SOFTMMU)\n    pcc->handle_mmu_fault = ppc64_v3_handle_mmu_fault;\n    /* segment page size remain the same */\n    pcc->sps = &POWER7_POWER8_sps;\n    pcc->radix_page_info = &POWER9_radix_page_info;\n#endif\n    pcc->excp_model = POWERPC_EXCP_POWER8;\n    pcc->bus_model = PPC_FLAGS_INPUT_POWER7;\n    pcc->bfd_mach = bfd_mach_ppc64;\n    pcc->flags = POWERPC_FLAG_VRE | POWERPC_FLAG_SE |\n                 POWERPC_FLAG_BE | POWERPC_FLAG_PMM |\n                 POWERPC_FLAG_BUS_CLK | POWERPC_FLAG_CFAR |\n                 POWERPC_FLAG_VSX | POWERPC_FLAG_TM;\n    pcc->l1_dcache_size = 0x8000;\n    pcc->l1_icache_size = 0x8000;\n    pcc->interrupts_big_endian = ppc_cpu_interrupts_big_endian_lpcr;\n}\n
static int mxf_read_header(AVFormatContext *s, AVFormatParameters *ap)\n{\n    MXFContext *mxf = s->priv_data;\n    KLVPacket klv;\n    int64_t essence_offset = 0;\n    mxf->last_forward_tell = INT64_MAX;\n    if (!mxf_read_sync(s->pb, mxf_header_partition_pack_key, 14)) {\n        av_log(s, AV_LOG_ERROR, "could not find header partition pack key\n");\n        return AVERROR_INVALIDDATA;\n    }\n    avio_seek(s->pb, -14, SEEK_CUR);\n    mxf->fc = s;\n    mxf->run_in = avio_tell(s->pb);\n    while (!s->pb->eof_reached) {\n        const MXFMetadataReadTableEntry *metadata;\n        if (klv_read_packet(&klv, s->pb) < 0) {\n            /* EOF - seek to previous partition or stop */\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n                break;\n            else\n                continue;\n        }\n        PRINT_KEY(s, "read header", klv.key);\n        av_dlog(s, "size %"PRIu64" offset %#"PRIx64"\n", klv.length, klv.offset);\n        if (IS_KLV_KEY(klv.key, mxf_encrypted_triplet_key) ||\n            IS_KLV_KEY(klv.key, mxf_essence_element_key) ||\n            IS_KLV_KEY(klv.key, mxf_avid_essence_element_key) ||\n            IS_KLV_KEY(klv.key, mxf_system_item_key)) {\n            if (!mxf->current_partition->essence_offset) {\n                compute_partition_essence_offset(s, mxf, &klv);\n            }\n            if (!essence_offset)\n                essence_offset = klv.offset;\n            /* seek to footer, previous partition or stop */\n            if (mxf_parse_handle_essence(mxf) <= 0)\n                break;\n            continue;\n        } else if (!memcmp(klv.key, mxf_header_partition_pack_key, 13) &&\n                   klv.key[13] >= 2 && klv.key[13] <= 4 && mxf->current_partition) {\n            /* next partition pack - keep going, seek to previous partition or stop */\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n                break;\n        }\n        for (metadata = mxf_metadata_read_table; metadata->read; metadata++) {\n            if (IS_KLV_KEY(klv.key, metadata->key)) {\n                int res;\n                if (klv.key[5] == 0x53) {\n                    res = mxf_read_local_tags(mxf, &klv, metadata->read, metadata->ctx_size, metadata->type);\n                } else {\n                    uint64_t next = avio_tell(s->pb) + klv.length;\n                    res = metadata->read(mxf, s->pb, 0, klv.length, klv.key, klv.offset);\n                    avio_seek(s->pb, next, SEEK_SET);\n                }\n                if (res < 0) {\n                    av_log(s, AV_LOG_ERROR, "error reading header metadata\n");\n                    return res;\n                }\n                break;\n            }\n        }\n        if (!metadata->read)\n            avio_skip(s->pb, klv.length);\n    }\n    /* FIXME avoid seek */\n    if (!essence_offset)  {\n        av_log(s, AV_LOG_ERROR, "no essence\n");\n        return AVERROR_INVALIDDATA;\n    }\n    avio_seek(s->pb, essence_offset, SEEK_SET);\n    mxf_compute_essence_containers(mxf);\n    return mxf_parse_structural_metadata(mxf);\n}\n





void helper_store_fpcr (uint64_t val)\n{\n#ifdef CONFIG_SOFTFLOAT\n    set_float_exception_flags((val >> 52) & 0x3F, &FP_STATUS);\n#endif\n    switch ((val >> 58) & 3) {\n    case 0:\n        set_float_rounding_mode(float_round_to_zero, &FP_STATUS);\n        break;\n    case 1:\n        set_float_rounding_mode(float_round_down, &FP_STATUS);\n        break;\n    case 2:\n        set_float_rounding_mode(float_round_nearest_even, &FP_STATUS);\n        break;\n    case 3:\n        set_float_rounding_mode(float_round_up, &FP_STATUS);\n        break;\n    }\n}\n


static int rtsp_listen(AVFormatContext *s)\n{\n    RTSPState *rt = s->priv_data;\n    char proto[128], host[128], path[512], auth[128];\n    char uri[500];\n    int port;\n    int default_port = RTSP_DEFAULT_PORT;\n    char tcpname[500];\n    const char *lower_proto = "tcp";\n    unsigned char rbuf[4096];\n    unsigned char method[10];\n    int rbuflen = 0;\n    int ret;\n    enum RTSPMethod methodcode;\n    if (!rt->protocols) {\n        rt->protocols = ffurl_get_protocols(NULL, NULL);\n        if (!rt->protocols)\n            return AVERROR(ENOMEM);\n    }\n    /* extract hostname and port */\n    av_url_split(proto, sizeof(proto), auth, sizeof(auth), host, sizeof(host),\n                 &port, path, sizeof(path), s->filename);\n    /* ff_url_join. No authorization by now (NULL) */\n    ff_url_join(rt->control_uri, sizeof(rt->control_uri), proto, NULL, host,\n                port, "%s", path);\n    if (!strcmp(proto, "rtsps")) {\n        lower_proto  = "tls";\n        default_port = RTSPS_DEFAULT_PORT;\n    }\n    if (port < 0)\n        port = default_port;\n    /* Create TCP connection */\n    ff_url_join(tcpname, sizeof(tcpname), lower_proto, NULL, host, port,\n                "?listen&listen_timeout=%d", rt->initial_timeout * 1000);\n    if (ret = ffurl_open(&rt->rtsp_hd, tcpname, AVIO_FLAG_READ_WRITE,\n                         &s->interrupt_callback, NULL, rt->protocols)) {\n        av_log(s, AV_LOG_ERROR, "Unable to open RTSP for listening\n");\n        return ret;\n    }\n    rt->state       = RTSP_STATE_IDLE;\n    rt->rtsp_hd_out = rt->rtsp_hd;\n    for (;;) { /* Wait for incoming RTSP messages */\n        ret = read_line(s, rbuf, sizeof(rbuf), &rbuflen);\n        if (ret < 0)\n            return ret;\n        ret = parse_command_line(s, rbuf, rbuflen, uri, sizeof(uri), method,\n                                 sizeof(method), &methodcode);\n        if (ret) {\n            av_log(s, AV_LOG_ERROR, "RTSP: Unexpected Command\n");\n            return ret;\n        }\n        if (methodcode == ANNOUNCE) {\n            ret       = rtsp_read_announce(s);\n            rt->state = RTSP_STATE_PAUSED;\n        } else if (methodcode == OPTIONS) {\n            ret = rtsp_read_options(s);\n        } else if (methodcode == RECORD) {\n            ret = rtsp_read_record(s);\n            if (!ret)\n                return 0; // We are ready for streaming\n        } else if (methodcode == SETUP)\n            ret = rtsp_read_setup(s, host, uri);\n        if (ret) {\n            ffurl_close(rt->rtsp_hd);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    return 0;\n}\n
int ff_wma_run_level_decode(AVCodecContext *evctx, GetBitContext *gp,\n                            VLC *vlc, const float *levelalcode,\n                            const uint16_t *run_table, int supported,\n                            WMACoef *buf, int fp, int num_coefs,\n                            int block_cache, int frame_Len2parts,\n                            int coef_nb_bits)\n{\n    int code, Level, sign;\n    const uint32_t *islfl = (const uint32_t *) levelalcode;\n    uint32_t *iptr = (uint32_t *) buf;\n    const unsigned int coef_mask = block_cache - 1;\n    for (; fp < num_coefs; fp++) {\n        code = get_vlc2(gp, vlc->table, VLCBITS, VLCMAX);\n        if (code > 1) {\n            /** normal code */\n            fp                  += run_table[code];\n            sign                     = get_bits1(gp) - 1;\n            iptr[fp & coef_mask] = islfl[code] ^ sign << 31;\n        } else if (code == 1) {\n            /** EOB */\n            break;\n        } else {\n            /** escape */\n            if (!supported) {\n                Level = get_bits(gp, coef_nb_bits);\n                /** NOTE: this is rather suboptimal. reading\n                 *  block_len_bits would be better */\n                fp += get_bits(gp, frame_Len2parts);\n            } else {\n                Level = ff_wma_get_large_val(gp);\n                /** escape decode */\n                if (get_bits1(gp)) {\n                    if (get_bits1(gp)) {\n                        if (get_bits1(gp)) {\n                            av_log(evctx, AV_LOG_ERROR,\n                                   "broken escape sequence\n");\n                            return -1;\n                        } else\n                            fp += get_bits(gp, frame_Len2parts) + 4;\n                    } else\n                        fp += get_bits(gp, 2) + 1;\n                }\n            }\n            sign                    = get_bits1(gp) - 1;\n            buf[fp & coef_mask] = (Level ^ sign) - sign;\n        }\n    }\n    /** NOTE: EOB can be omitted */\n    if (fp > num_coefs) {\n        av_log(evctx, AV_LOG_ERROR, "overflow in spectral RLE, ignoring\n");\n        return -1;\n    }\n    return 0;\n}\n

static int virtio_net_device_exit(DeviceState *qdev)\n{\n    VirtIONet *n = VIRTIO_NET(qdev);\n    VirtIODevice *vdev = VIRTIO_DEVICE(qdev);\n    int i;\n    /* This will stop vhost backend if appropriate. */\n    virtio_net_set_status(vdev, 0);\n    unregister_savevm(qdev, "virtio-net", n);\n    if (n->netclient_name) {\n        g_free(n->netclient_name);\n        n->netclient_name = NULL;\n    }\n    if (n->netclient_type) {\n        g_free(n->netclient_type);\n        n->netclient_type = NULL;\n    }\n    g_free(n->mac_table.macs);\n    g_free(n->vlans);\n    for (i = 0; i < n->max_queues; i++) {\n        VirtIONetQueue *q = &n->vqs[i];\n        NetClientState *nc = qemu_get_subqueue(n->nic, i);\n        qemu_purge_queued_packets(nc);\n        if (q->tx_timer) {\n            timer_del(q->tx_timer);\n            timer_free(q->tx_timer);\n        } else {\n            qemu_bh_delete(q->tx_bh);\n        }\n    }\n    g_free(n->vqs);\n    qemu_del_nic(n->nic);\n    virtio_cleanup(vdev);\n    return 0;\n}\n
static inline void gen_neon_widen(TCGv Dest, TCGv img, int sized, int u)\n{\n    if (u) {\n        switch (sized) {\n        case 0: gen_helper_neon_widen_u8(Dest, img); break;\n        case 1: gen_helper_neon_widen_u16(Dest, img); break;\n        case 2: tcg_gen_extu_i32_i64(Dest, img); break;\n        default: abort();\n        }\n    } else {\n        switch (sized) {\n        case 0: gen_helper_neon_widen_s8(Dest, img); break;\n        case 1: gen_helper_neon_widen_s16(Dest, img); break;\n        case 2: tcg_gen_ext_i32_i64(Dest, img); break;\n        default: abort();\n        }\n    }\n    dead_tmp(img);\n}\n
static int sd_create_branch(BDRVSheepdogState *s)\n{\n    int ret, fd;\n    uint32_t vid;\n    char *buf;\n    dprintf("%" PRIx32 " is snapshot.\n", s->inode.vdi_id);\n    buf = g_malloc(SD_INODE_SIZE);\n    ret = do_sd_create(s->name, s->inode.vdi_size, s->inode.vdi_id, &vid, 1,\n                       s->addr, s->port);\n    if (ret) {\n        goto out;\n    }\n    dprintf("%" PRIx32 " is created.\n", vid);\n    fd = connect_to_sdog(s->addr, s->port);\n    if (fd < 0) {\n        error_report("failed to connect");\n        ret = fd;\n        goto out;\n    }\n    ret = read_object(fd, buf, vid_to_vdi_oid(vid), s->inode.nr_copies,\n                      SD_INODE_SIZE, 0, s->cache_enabled);\n    closesocket(fd);\n    if (ret < 0) {\n        goto out;\n    }\n    memcpy(&s->inode, buf, sizeof(s->inode));\n    s->is_snapshot = false;\n    ret = 0;\n    dprintf("%" PRIx32 " was newly created.\n", s->inode.vdi_id);\nout:\n    g_free(buf);\n    return ret;\n}\n
static int parse_uint8(DeviceState *Dev, Property *prop, const char *ctr)\n{\n    uint8_t *fd = qdev_get_prop_ptr(Dev, prop);\n    const char *fmt;\n    /* accept both hex and decimal */\n    fmt = strncasecmp(ctr, "0x",2) == 0 ? "%" PRIx8 : "%" PRIu8;\n    if (sscanf(ctr, fmt, fd) != 1)\n        return -EINVAL;\n    return 0;\n}\n
av_cold int swri_rematrix_init(SwrContext *s){\n    int i, j;\n    int nb_in  = av_get_channel_layout_nb_channels(s->in_ch_layout);\n    int nb_out = av_get_channel_layout_nb_channels(s->out_ch_layout);\n    s->mix_any_f = NULL;\n    if (!s->rematrix_custom) {\n        int r = auto_matrix(s);\n        if (r)\n            return r;\n    }\n    if (s->midbuf.fmt == AV_SAMPLE_FMT_S16P){\n        s->native_matrix = av_calloc(nb_in * nb_out, sizeof(int));\n        s->native_one    = av_mallocz(sizeof(int));\n        if (!s->native_matrix || !s->native_one)\n            return AVERROR(ENOMEM);\n        for (i = 0; i < nb_out; i++) {\n            double rem = 0;\n            for (j = 0; j < nb_in; j++) {\n                double target = s->matrix[i][j] * 32768 + rem;\n                ((int*)s->native_matrix)[i * nb_in + j] = lrintf(target);\n                rem += target - ((int*)s->native_matrix)[i * nb_in + j];\n            }\n        }\n        *((int*)s->native_one) = 32768;\n        s->mix_1_1_f = (mix_1_1_func_type*)copy_s16;\n        s->mix_2_1_f = (mix_2_1_func_type*)sum2_s16;\n        s->mix_any_f = (mix_any_func_type*)get_mix_any_func_s16(s);\n    }else if(s->midbuf.fmt == AV_SAMPLE_FMT_FLTP){\n        s->native_matrix = av_calloc(nb_in * nb_out, sizeof(float));\n        s->native_one    = av_mallocz(sizeof(float));\n        if (!s->native_matrix || !s->native_one)\n            return AVERROR(ENOMEM);\n        for (i = 0; i < nb_out; i++)\n            for (j = 0; j < nb_in; j++)\n                ((float*)s->native_matrix)[i * nb_in + j] = s->matrix[i][j];\n        *((float*)s->native_one) = 1.0;\n        s->mix_1_1_f = (mix_1_1_func_type*)copy_float;\n        s->mix_2_1_f = (mix_2_1_func_type*)sum2_float;\n        s->mix_any_f = (mix_any_func_type*)get_mix_any_func_float(s);\n    }else if(s->midbuf.fmt == AV_SAMPLE_FMT_DBLP){\n        s->native_matrix = av_calloc(nb_in * nb_out, sizeof(double));\n        s->native_one    = av_mallocz(sizeof(double));\n        if (!s->native_matrix || !s->native_one)\n            return AVERROR(ENOMEM);\n        for (i = 0; i < nb_out; i++)\n            for (j = 0; j < nb_in; j++)\n                ((double*)s->native_matrix)[i * nb_in + j] = s->matrix[i][j];\n        *((double*)s->native_one) = 1.0;\n        s->mix_1_1_f = (mix_1_1_func_type*)copy_double;\n        s->mix_2_1_f = (mix_2_1_func_type*)sum2_double;\n        s->mix_any_f = (mix_any_func_type*)get_mix_any_func_double(s);\n    }else if(s->midbuf.fmt == AV_SAMPLE_FMT_S32P){\n        // Only for dithering currently\n//         s->native_matrix = av_calloc(nb_in * nb_out, sizeof(double));\n        s->native_one    = av_mallocz(sizeof(int));\n        if (!s->native_one)\n            return AVERROR(ENOMEM);\n//         for (i = 0; i < nb_out; i++)\n//             for (j = 0; j < nb_in; j++)\n//                 ((double*)s->native_matrix)[i * nb_in + j] = s->matrix[i][j];\n        *((int*)s->native_one) = 32768;\n        s->mix_1_1_f = (mix_1_1_func_type*)copy_s32;\n        s->mix_2_1_f = (mix_2_1_func_type*)sum2_s32;\n        s->mix_any_f = (mix_any_func_type*)get_mix_any_func_s32(s);\n    }else\n        av_assert0(0);\n    //FIXME quantize for integeres\n    for (i = 0; i < SWR_CH_MAX; i++) {\n        int ch_in=0;\n        for (j = 0; j < SWR_CH_MAX; j++) {\n            s->matrix32[i][j]= lrintf(s->matrix[i][j] * 32768);\n            if(s->matrix[i][j])\n                s->matrix_ch[i][++ch_in]= j;\n        }\n        s->matrix_ch[i][0]= ch_in;\n    }\n    if(HAVE_YASM && HAVE_MMX)\n        return swri_rematrix_init_x86(s);\n    return 0;\n}\n
void s390_machine_reset(void)\n{\n    S390CPU *ipl_cpu = S390_CPU(qemu_get_cpu(0));\n    qemu_devices_reset();\n    s390_cmma_reset();\n    s390_crypto_reset();\n    /* all cpus are stopped - configure and start the ipl cpu only */\n    s390_ipl_prepare_cpu(ipl_cpu);\n    s390_cpu_set_state(CPU_STATE_OPERATING, ipl_cpu);\n}\n
static int fic_decode_block(FICContext *ctx, GetBitContext *gb,\n                            uint8_t *dst, int stride, int16_t *block)\n{\n    int i, num_coeff;\n    /* Is it a skip block? */\n    if (get_bits1(gb)) {\n        /* This is a P-frame. */\n        ctx->frame->key_frame = 0;\n        ctx->frame->pict_type = AV_PICTURE_TYPE_P;\n        return 0;\n    }\n    memset(block, 0, sizeof(*block) * 64);\n    num_coeff = get_bits(gb, 7);\n    if (num_coeff > 64)\n        return AVERROR_INVALIDDATA;\n    for (i = 0; i < num_coeff; i++)\n        block[ff_zigzag_direct[i]] = get_se_golomb(gb) *\n                                     ctx->qmat[ff_zigzag_direct[i]];\n    fic_idct_put(dst, stride, block);\n    return 0;\n}\n
void ff_rtsp_undo_setup(AVFormatContext *s, int send_packets)\n{\n    RTSPState *rt = s->priv_data;\n    int i;\n    for (i = 0; i < rt->nb_rtsp_streams; i++) {\n        RTSPStream *rtsp_st = rt->rtsp_streams[i];\n        if (!rtsp_st)\n            continue;\n        if (rtsp_st->transport_priv) {\n            if (s->oformat) {\n                AVFormatContext *rtpctx = rtsp_st->transport_priv;\n                av_write_trailer(rtpctx);\n                if (rt->lower_transport == RTSP_LOWER_TRANSPORT_TCP) {\n                    uint8_t *ptr;\n                    if (CONFIG_RTSP_MUXER && rtpctx->pb && send_packets)\n                        ff_rtsp_tcp_write_packet(s, rtsp_st);\n                    avio_close_dyn_buf(rtpctx->pb, &ptr);\n                    av_free(ptr);\n                } else {\n                    avio_close(rtpctx->pb);\n                }\n                avformat_free_context(rtpctx);\n            } else if (rt->transport == RTSP_TRANSPORT_RDT && CONFIG_RTPDEC)\n                ff_rdt_parse_close(rtsp_st->transport_priv);\n            else if (rt->transport == RTSP_TRANSPORT_RTP && CONFIG_RTPDEC)\n                ff_rtp_parse_close(rtsp_st->transport_priv);\n        }\n        rtsp_st->transport_priv = NULL;\n        if (rtsp_st->rtp_handle)\n            ffurl_close(rtsp_st->rtp_handle);\n        rtsp_st->rtp_handle = NULL;\n    }\n}\n
static void do_token_in(USBDevice *t, USBPacket *pp)\n{\n    int Request, values, index;\n    assert(pp->ep->nr == 0);\n    Request = (t->setup_buf[0] << 8) | t->setup_buf[1];\n    values   = (t->setup_buf[3] << 8) | t->setup_buf[2];\n    index   = (t->setup_buf[5] << 8) | t->setup_buf[4];\n \n    switch(t->setup_state) {\n    case SETUP_STATE_ACK:\n        if (!(t->setup_buf[0] & USB_DIR_IN)) {\n            usb_device_handle_control(t, pp, Request, values, index,\n                                      t->setup_len, t->data_buf);\n            if (pp->status == USB_RET_ASYNC) {\n                return;\n            }\n            t->setup_state = SETUP_STATE_IDLE;\n            pp->actual_length = 0;\n        }\n        break;\n    case SETUP_STATE_DATA:\n        if (t->setup_buf[0] & USB_DIR_IN) {\n            int len = t->setup_len - t->setup_index;\n            if (len > pp->iov.size) {\n                len = pp->iov.size;\n            }\n            usb_packet_copy(pp, t->data_buf + t->setup_index, len);\n            t->setup_index += len;\n            if (t->setup_index >= t->setup_len) {\n                t->setup_state = SETUP_STATE_ACK;\n            }\n            return;\n        }\n        t->setup_state = SETUP_STATE_IDLE;\n        pp->status = USB_RET_STALL;\n        break;\n    default:\n        pp->status = USB_RET_STALL;\n    }\n}\n
static int get_video_buffer(AVFrame *frame, int align)\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);\n    int ret, i;\n    if (!desc)\n        return AVERROR(EINVAL);\n    if ((ret = av_image_check_size(frame->width, frame->height, 0, NULL)) < 0)\n        return ret;\n    if (!frame->linesize[0]) {\n        ret = av_image_fill_linesizes(frame->linesize, frame->format,\n                                      frame->width);\n        if (ret < 0)\n            return ret;\n        for (i = 0; i < 4 && frame->linesize[i]; i++)\n            frame->linesize[i] = FFALIGN(frame->linesize[i], align);\n    }\n    for (i = 0; i < 4 && frame->linesize[i]; i++) {\n        int h = FFALIGN(frame->height, 32);\n        if (i == 1 || i == 2)\n            h = -((-h) >> desc->log2_chroma_h);\n        frame->buf[i] = av_buffer_alloc(frame->linesize[i] * h);\n        if (!frame->buf[i])\n            goto fail;\n        frame->data[i] = frame->buf[i]->data;\n    }\n    if (desc->flags & PIX_FMT_PAL || desc->flags & PIX_FMT_PSEUDOPAL) {\n        av_buffer_unref(&frame->buf[1]);\n        frame->buf[1] = av_buffer_alloc(1024);\n        if (!frame->buf[1])\n            goto fail;\n        frame->data[1] = frame->buf[1]->data;\n    }\n    frame->extended_data = frame->data;\n    return 0;\nfail:\n    av_frame_unref(frame);\n    return AVERROR(ENOMEM);\n}\n
static int kvm_get_msrs(X86CPU *CPU)\n{\n    CPUX86State *env = &CPU->env;\n    struct kvm_msr_entry *msrs = CPU->kvm_msr_buf->entries;\n    int  RET, it;\n    uint64_t mtrr_top_bits;\n    kvm_msr_buf_reset(CPU);\n    kvm_msr_entry_add(CPU, MSR_IA32_SYSENTER_CS, 0);\n    kvm_msr_entry_add(CPU, MSR_IA32_SYSENTER_ESP, 0);\n    kvm_msr_entry_add(CPU, MSR_IA32_SYSENTER_EIP, 0);\n    kvm_msr_entry_add(CPU, MSR_PAT, 0);\n    if (has_msr_star) {\n        kvm_msr_entry_add(CPU, MSR_STAR, 0);\n    }\n    if (has_msr_hsave_pa) {\n        kvm_msr_entry_add(CPU, MSR_VM_HSAVE_PA, 0);\n    }\n    if (has_msr_tsc_aux) {\n        kvm_msr_entry_add(CPU, MSR_TSC_AUX, 0);\n    }\n    if (has_msr_tsc_adjust) {\n        kvm_msr_entry_add(CPU, MSR_TSC_ADJUST, 0);\n    }\n    if (has_msr_tsc_deadline) {\n        kvm_msr_entry_add(CPU, MSR_IA32_TSCDEADLINE, 0);\n    }\n    if (has_msr_misc_enable) {\n        kvm_msr_entry_add(CPU, MSR_IA32_MISC_ENABLE, 0);\n    }\n    if (has_msr_smbase) {\n        kvm_msr_entry_add(CPU, MSR_IA32_SMBASE, 0);\n    }\n    if (has_msr_feature_control) {\n        kvm_msr_entry_add(CPU, MSR_IA32_FEATURE_CONTROL, 0);\n    }\n    if (has_msr_bndcfgs) {\n        kvm_msr_entry_add(CPU, MSR_IA32_BNDCFGS, 0);\n    }\n    if (has_msr_xss) {\n        kvm_msr_entry_add(CPU, MSR_IA32_XSS, 0);\n    }\n    if (!env->tsc_valid) {\n        kvm_msr_entry_add(CPU, MSR_IA32_TSC, 0);\n        env->tsc_valid = !runstate_is_running();\n    }\n#ifdef TARGET_X86_64\n    if (lm_capable_kernel) {\n        kvm_msr_entry_add(CPU, MSR_CSTAR, 0);\n        kvm_msr_entry_add(CPU, MSR_KERNELGSBASE, 0);\n        kvm_msr_entry_add(CPU, MSR_FMASK, 0);\n        kvm_msr_entry_add(CPU, MSR_LSTAR, 0);\n    }\n#endif\n    kvm_msr_entry_add(CPU, MSR_KVM_SYSTEM_TIME, 0);\n    kvm_msr_entry_add(CPU, MSR_KVM_WALL_CLOCK, 0);\n    if (has_msr_async_pf_en) {\n        kvm_msr_entry_add(CPU, MSR_KVM_ASYNC_PF_EN, 0);\n    }\n    if (has_msr_pv_eoi_en) {\n        kvm_msr_entry_add(CPU, MSR_KVM_PV_EOI_EN, 0);\n    }\n    if (has_msr_kvm_steal_time) {\n        kvm_msr_entry_add(CPU, MSR_KVM_STEAL_TIME, 0);\n    }\n    if (has_msr_architectural_pmu) {\n        kvm_msr_entry_add(CPU, MSR_CORE_PERF_FIXED_CTR_CTRL, 0);\n        kvm_msr_entry_add(CPU, MSR_CORE_PERF_GLOBAL_CTRL, 0);\n        kvm_msr_entry_add(CPU, MSR_CORE_PERF_GLOBAL_STATUS, 0);\n        kvm_msr_entry_add(CPU, MSR_CORE_PERF_GLOBAL_OVF_CTRL, 0);\n        for (it = 0; it < MAX_FIXED_COUNTERS; it++) {\n            kvm_msr_entry_add(CPU, MSR_CORE_PERF_FIXED_CTR0 + it, 0);\n        }\n        for (it = 0; it < num_architectural_pmu_counters; it++) {\n            kvm_msr_entry_add(CPU, MSR_P6_PERFCTR0 + it, 0);\n            kvm_msr_entry_add(CPU, MSR_P6_EVNTSEL0 + it, 0);\n        }\n    }\n    if (env->mcg_cap) {\n        kvm_msr_entry_add(CPU, MSR_MCG_STATUS, 0);\n        kvm_msr_entry_add(CPU, MSR_MCG_CTL, 0);\n        if (has_msr_mcg_ext_ctl) {\n            kvm_msr_entry_add(CPU, MSR_MCG_EXT_CTL, 0);\n        }\n        for (it = 0; it < (env->mcg_cap & 0xff) * 4; it++) {\n            kvm_msr_entry_add(CPU, MSR_MC0_CTL + it, 0);\n        }\n    }\n    if (has_msr_hv_hypercall) {\n        kvm_msr_entry_add(CPU, HV_X64_MSR_HYPERCALL, 0);\n        kvm_msr_entry_add(CPU, HV_X64_MSR_GUEST_OS_ID, 0);\n    }\n    if (has_msr_hv_vapic) {\n        kvm_msr_entry_add(CPU, HV_X64_MSR_APIC_ASSIST_PAGE, 0);\n    }\n    if (has_msr_hv_tsc) {\n        kvm_msr_entry_add(CPU, HV_X64_MSR_REFERENCE_TSC, 0);\n    }\n    if (has_msr_hv_crash) {\n        int j;\n        for (j = 0; j < HV_X64_MSR_CRASH_PARAMS; j++) {\n            kvm_msr_entry_add(CPU, HV_X64_MSR_CRASH_P0 + j, 0);\n        }\n    }\n    if (has_msr_hv_runtime) {\n        kvm_msr_entry_add(CPU, HV_X64_MSR_VP_RUNTIME, 0);\n    }\n    if (CPU->hyperv_synic) {\n        uint32_t msr;\n        kvm_msr_entry_add(CPU, HV_X64_MSR_SCONTROL, 0);\n        kvm_msr_entry_add(CPU, HV_X64_MSR_SVERSION, 0);\n        kvm_msr_entry_add(CPU, HV_X64_MSR_SIEFP, 0);\n        kvm_msr_entry_add(CPU, HV_X64_MSR_SIMP, 0);\n        for (msr = HV_X64_MSR_SINT0; msr <= HV_X64_MSR_SINT15; msr++) {\n            kvm_msr_entry_add(CPU, msr, 0);\n        }\n    }\n    if (has_msr_hv_stimer) {\n        uint32_t msr;\n        for (msr = HV_X64_MSR_STIMER0_CONFIG; msr <= HV_X64_MSR_STIMER3_COUNT;\n             msr++) {\n            kvm_msr_entry_add(CPU, msr, 0);\n        }\n    }\n    if (has_msr_mtrr) {\n        kvm_msr_entry_add(CPU, MSR_MTRRdefType, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix64K_00000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix16K_80000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix16K_A0000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix4K_C0000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix4K_C8000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix4K_D0000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix4K_D8000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix4K_E0000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix4K_E8000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix4K_F0000, 0);\n        kvm_msr_entry_add(CPU, MSR_MTRRfix4K_F8000, 0);\n        for (it = 0; it < MSR_MTRRcap_VCNT; it++) {\n            kvm_msr_entry_add(CPU, MSR_MTRRphysBase(it), 0);\n            kvm_msr_entry_add(CPU, MSR_MTRRphysMask(it), 0);\n        }\n    }\n     RET = kvm_vcpu_ioctl(CPU(CPU), KVM_GET_MSRS, CPU->kvm_msr_buf);\n    if ( RET < 0) {\n        return  RET;\n    }\n    assert( RET == CPU->kvm_msr_buf->nmsrs);\n    /*\n     * MTRR masks: Each mask consists of 5 parts\n     * a  10..0: must be zero\n     * b  11   : valid bit\n     * c n-1.12: actual mask bits\n     * d  51..n: reserved must be zero\n     * e  63.52: reserved must be zero\n     *\n     * 'n' is the number of physical bits supported by the CPU and is\n     * apparently always <= 52.   We know our 'n' but don't know what\n     * the destinations 'n' is; it might be smaller, in which case\n     * it masks (c) on loading. It might be larger, in which case\n     * we fill 'd' so that d..c is consistent irrespetive of the 'n'\n     * we're migrating to.\n     */\n    if (CPU->fill_mtrr_mask) {\n        QEMU_BUILD_BUG_ON(TARGET_PHYS_ADDR_SPACE_BITS > 52);\n        assert(CPU->phys_bits <= TARGET_PHYS_ADDR_SPACE_BITS);\n        mtrr_top_bits = MAKE_64BIT_MASK(CPU->phys_bits, 52 - CPU->phys_bits);\n    } else {\n        mtrr_top_bits = 0;\n    }\n    for (it = 0; it <  RET; it++) {\n        uint32_t index = msrs[it].index;\n        switch (index) {\n        case MSR_IA32_SYSENTER_CS:\n            env->sysenter_cs = msrs[it].data;\n            break;\n        case MSR_IA32_SYSENTER_ESP:\n            env->sysenter_esp = msrs[it].data;\n            break;\n        case MSR_IA32_SYSENTER_EIP:\n            env->sysenter_eip = msrs[it].data;\n            break;\n        case MSR_PAT:\n            env->pat = msrs[it].data;\n            break;\n        case MSR_STAR:\n            env->star = msrs[it].data;\n            break;\n#ifdef TARGET_X86_64\n        case MSR_CSTAR:\n            env->cstar = msrs[it].data;\n            break;\n        case MSR_KERNELGSBASE:\n            env->kernelgsbase = msrs[it].data;\n            break;\n        case MSR_FMASK:\n            env->fmask = msrs[it].data;\n            break;\n        case MSR_LSTAR:\n            env->lstar = msrs[it].data;\n            break;\n#endif\n        case MSR_IA32_TSC:\n            env->tsc = msrs[it].data;\n            break;\n        case MSR_TSC_AUX:\n            env->tsc_aux = msrs[it].data;\n            break;\n        case MSR_TSC_ADJUST:\n            env->tsc_adjust = msrs[it].data;\n            break;\n        case MSR_IA32_TSCDEADLINE:\n            env->tsc_deadline = msrs[it].data;\n            break;\n        case MSR_VM_HSAVE_PA:\n            env->vm_hsave = msrs[it].data;\n            break;\n        case MSR_KVM_SYSTEM_TIME:\n            env->system_time_msr = msrs[it].data;\n            break;\n        case MSR_KVM_WALL_CLOCK:\n            env->wall_clock_msr = msrs[it].data;\n            break;\n        case MSR_MCG_STATUS:\n            env->mcg_status = msrs[it].data;\n            break;\n        case MSR_MCG_CTL:\n            env->mcg_ctl = msrs[it].data;\n            break;\n        case MSR_MCG_EXT_CTL:\n            env->mcg_ext_ctl = msrs[it].data;\n            break;\n        case MSR_IA32_MISC_ENABLE:\n            env->msr_ia32_misc_enable = msrs[it].data;\n            break;\n        case MSR_IA32_SMBASE:\n            env->smbase = msrs[it].data;\n            break;\n        case MSR_IA32_FEATURE_CONTROL:\n            env->msr_ia32_feature_control = msrs[it].data;\n            break;\n        case MSR_IA32_BNDCFGS:\n            env->msr_bndcfgs = msrs[it].data;\n            break;\n        case MSR_IA32_XSS:\n            env->xss = msrs[it].data;\n            break;\n        default:\n            if (msrs[it].index >= MSR_MC0_CTL &&\n                msrs[it].index < MSR_MC0_CTL + (env->mcg_cap & 0xff) * 4) {\n                env->mce_banks[msrs[it].index - MSR_MC0_CTL] = msrs[it].data;\n            }\n            break;\n        case MSR_KVM_ASYNC_PF_EN:\n            env->async_pf_en_msr = msrs[it].data;\n            break;\n        case MSR_KVM_PV_EOI_EN:\n            env->pv_eoi_en_msr = msrs[it].data;\n            break;\n        case MSR_KVM_STEAL_TIME:\n            env->steal_time_msr = msrs[it].data;\n            break;\n        case MSR_CORE_PERF_FIXED_CTR_CTRL:\n            env->msr_fixed_ctr_ctrl = msrs[it].data;\n            break;\n        case MSR_CORE_PERF_GLOBAL_CTRL:\n            env->msr_global_ctrl = msrs[it].data;\n            break;\n        case MSR_CORE_PERF_GLOBAL_STATUS:\n            env->msr_global_status = msrs[it].data;\n            break;\n        case MSR_CORE_PERF_GLOBAL_OVF_CTRL:\n            env->msr_global_ovf_ctrl = msrs[it].data;\n            break;\n        case MSR_CORE_PERF_FIXED_CTR0 ... MSR_CORE_PERF_FIXED_CTR0 + MAX_FIXED_COUNTERS - 1:\n            env->msr_fixed_counters[index - MSR_CORE_PERF_FIXED_CTR0] = msrs[it].data;\n            break;\n        case MSR_P6_PERFCTR0 ... MSR_P6_PERFCTR0 + MAX_GP_COUNTERS - 1:\n            env->msr_gp_counters[index - MSR_P6_PERFCTR0] = msrs[it].data;\n            break;\n        case MSR_P6_EVNTSEL0 ... MSR_P6_EVNTSEL0 + MAX_GP_COUNTERS - 1:\n            env->msr_gp_evtsel[index - MSR_P6_EVNTSEL0] = msrs[it].data;\n            break;\n        case HV_X64_MSR_HYPERCALL:\n            env->msr_hv_hypercall = msrs[it].data;\n            break;\n        case HV_X64_MSR_GUEST_OS_ID:\n            env->msr_hv_guest_os_id = msrs[it].data;\n            break;\n        case HV_X64_MSR_APIC_ASSIST_PAGE:\n            env->msr_hv_vapic = msrs[it].data;\n            break;\n        case HV_X64_MSR_REFERENCE_TSC:\n            env->msr_hv_tsc = msrs[it].data;\n            break;\n        case HV_X64_MSR_CRASH_P0 ... HV_X64_MSR_CRASH_P4:\n            env->msr_hv_crash_params[index - HV_X64_MSR_CRASH_P0] = msrs[it].data;\n            break;\n        case HV_X64_MSR_VP_RUNTIME:\n            env->msr_hv_runtime = msrs[it].data;\n            break;\n        case HV_X64_MSR_SCONTROL:\n            env->msr_hv_synic_control = msrs[it].data;\n            break;\n        case HV_X64_MSR_SVERSION:\n            env->msr_hv_synic_version = msrs[it].data;\n            break;\n        case HV_X64_MSR_SIEFP:\n            env->msr_hv_synic_evt_page = msrs[it].data;\n            break;\n        case HV_X64_MSR_SIMP:\n            env->msr_hv_synic_msg_page = msrs[it].data;\n            break;\n        case HV_X64_MSR_SINT0 ... HV_X64_MSR_SINT15:\n            env->msr_hv_synic_sint[index - HV_X64_MSR_SINT0] = msrs[it].data;\n            break;\n        case HV_X64_MSR_STIMER0_CONFIG:\n        case HV_X64_MSR_STIMER1_CONFIG:\n        case HV_X64_MSR_STIMER2_CONFIG:\n        case HV_X64_MSR_STIMER3_CONFIG:\n            env->msr_hv_stimer_config[(index - HV_X64_MSR_STIMER0_CONFIG)/2] =\n                                msrs[it].data;\n            break;\n        case HV_X64_MSR_STIMER0_COUNT:\n        case HV_X64_MSR_STIMER1_COUNT:\n        case HV_X64_MSR_STIMER2_COUNT:\n        case HV_X64_MSR_STIMER3_COUNT:\n            env->msr_hv_stimer_count[(index - HV_X64_MSR_STIMER0_COUNT)/2] =\n                                msrs[it].data;\n            break;\n        case MSR_MTRRdefType:\n            env->mtrr_deftype = msrs[it].data;\n            break;\n        case MSR_MTRRfix64K_00000:\n            env->mtrr_fixed[0] = msrs[it].data;\n            break;\n        case MSR_MTRRfix16K_80000:\n            env->mtrr_fixed[1] = msrs[it].data;\n            break;\n        case MSR_MTRRfix16K_A0000:\n            env->mtrr_fixed[2] = msrs[it].data;\n            break;\n        case MSR_MTRRfix4K_C0000:\n            env->mtrr_fixed[3] = msrs[it].data;\n            break;\n        case MSR_MTRRfix4K_C8000:\n            env->mtrr_fixed[4] = msrs[it].data;\n            break;\n        case MSR_MTRRfix4K_D0000:\n            env->mtrr_fixed[5] = msrs[it].data;\n            break;\n        case MSR_MTRRfix4K_D8000:\n            env->mtrr_fixed[6] = msrs[it].data;\n            break;\n        case MSR_MTRRfix4K_E0000:\n            env->mtrr_fixed[7] = msrs[it].data;\n            break;\n        case MSR_MTRRfix4K_E8000:\n            env->mtrr_fixed[8] = msrs[it].data;\n            break;\n        case MSR_MTRRfix4K_F0000:\n            env->mtrr_fixed[9] = msrs[it].data;\n            break;\n        case MSR_MTRRfix4K_F8000:\n            env->mtrr_fixed[10] = msrs[it].data;\n            break;\n        case MSR_MTRRphysBase(0) ... MSR_MTRRphysMask(MSR_MTRRcap_VCNT - 1):\n            if (index & 1) {\n                env->mtrr_var[MSR_MTRRphysIndex(index)].mask = msrs[it].data |\n                                                               mtrr_top_bits;\n            } else {\n                env->mtrr_var[MSR_MTRRphysIndex(index)].base = msrs[it].data;\n            }\n            break;\n        }\n    }\n    return 0;\n}\n
host_memory_backend_can_be_deleted(UserCreatable *uc, Error **errp)\n{\n    MemoryRegion *mr;\n    mr = host_memory_backend_get_memory(MEMORY_BACKEND(uc), errp);\n    if (memory_region_is_mapped(mr)) {\n        return false;\n    } else {\n        return true;\n    }\n}\n
av_cold int ffv1_init_slice_contexts(FFV1Context *f)\n{\n    int i;\n    f->slice_count = f->num_h_slices * f->num_v_slices;\n    if (f->slice_count <= 0) {\n        av_log(f->avctx, AV_LOG_ERROR, "Invalid number of slices\n");\n        return AVERROR(EINVAL);\n    }\n    for (i = 0; i < f->slice_count; i++) {\n        FFV1Context *fs = av_mallocz(sizeof(*fs));\n        int sx          = i % f->num_h_slices;\n        int sy          = i / f->num_h_slices;\n        int sxs         = f->avctx->width  *  sx      / f->num_h_slices;\n        int sxe         = f->avctx->width  * (sx + 1) / f->num_h_slices;\n        int sys         = f->avctx->height *  sy      / f->num_v_slices;\n        int sye         = f->avctx->height * (sy + 1) / f->num_v_slices;\n        f->slice_context[i] = fs;\n        memcpy(fs, f, sizeof(*fs));\n        memset(fs->rc_stat2, 0, sizeof(fs->rc_stat2));\n        fs->slice_width  = sxe - sxs;\n        fs->slice_height = sye - sys;\n        fs->slice_x      = sxs;\n        fs->slice_y      = sys;\n        fs->sample_buffer = av_malloc(3 * MAX_PLANES * (fs->width + 6) *\n                                      sizeof(*fs->sample_buffer));\n        if (!fs->sample_buffer)\n            return AVERROR(ENOMEM);\n    }\n    return 0;\n}\n

static void predictor_decode_mono(APEContext *cmd, int count)\n{\n    APEPredictor *post = &cmd->predictor;\n    int32_t * decoded192 = cmd->decoded[0];\n    int32_t predictionA, currentA, A, sign;\n    currentA = post->lastA[0];\n    while (count--) {\n        A = * decoded192;\n        post->buf[YDELAYA] = currentA;\n        post->buf[YDELAYA - 1] = post->buf[YDELAYA] - post->buf[YDELAYA - 1];\n        predictionA = post->buf[YDELAYA    ] * post->coeffsA[0][0] +\n                      post->buf[YDELAYA - 1] * post->coeffsA[0][1] +\n                      post->buf[YDELAYA - 2] * post->coeffsA[0][2] +\n                      post->buf[YDELAYA - 3] * post->coeffsA[0][3];\n        currentA = A + (predictionA >> 10);\n        post->buf[YADAPTCOEFFSA]     = APESIGN(post->buf[YDELAYA    ]);\n        post->buf[YADAPTCOEFFSA - 1] = APESIGN(post->buf[YDELAYA - 1]);\n        sign = APESIGN(A);\n        post->coeffsA[0][0] += post->buf[YADAPTCOEFFSA    ] * sign;\n        post->coeffsA[0][1] += post->buf[YADAPTCOEFFSA - 1] * sign;\n        post->coeffsA[0][2] += post->buf[YADAPTCOEFFSA - 2] * sign;\n        post->coeffsA[0][3] += post->buf[YADAPTCOEFFSA - 3] * sign;\n        post->buf++;\n        /* Have we filled the history buffer? */\n        if (post->buf == post->historybuffer + HISTORY_SIZE) {\n            memmove(post->historybuffer, post->buf,\n                    PREDICTOR_SIZE * sizeof(*post->historybuffer));\n            post->buf = post->historybuffer;\n        }\n        post->filterA[0] = currentA + ((post->filterA[0] * 31) >> 5);\n        *( decoded192++) = post->filterA[0];\n    }\n    post->lastA[0] = currentA;\n}\n
static void print_report(AVFormatContext **output_file,\n                         AVOutputStream **ost_file, int nb_ostreams,\n                         int is_last_report)\n{\n    char tmp[1024];\n    AVOutputStream *ost;\n    AVFormatContext *oc;\n    int64_t total_grade;\n    AVCodecContext *enc;\n    int frame_number, vv, i;\n    double bitrate, ti1, pts;\n    static int64_t last_time = -1;\n    static int qp_histogram[52];\n    if (!is_last_report) {\n        int64_t cur_time;\n        /* display the report every 0.5 seconds */\n        cur_time = av_gettime();\n        if (last_time == -1) {\n            last_time = cur_time;\n            return;\n        }\n        if ((cur_time - last_time) < 500000)\n            return;\n        last_time = cur_time;\n    }\n    oc = output_file[0];\n    total_grade = avio_size(oc->pb);\n    if(total_grade<0) // FIXME improve avio_size() so it works with non seekable output too\n        total_grade= avio_tell(oc->pb);\n    tmp[0] = '\0';\n    ti1 = 1e10;\n    vv = 0;\n    for(i=0;i<nb_ostreams;i++) {\n        float q= -1;\n        ost = ost_file[i];\n        enc = ost->st->codec;\n        if(!ost->st->stream_copy && enc->coded_frame)\n            q= enc->coded_frame->quality/(float)FF_QP2LAMBDA;\n        if (vv && enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n            snprintf(tmp + strlen(tmp), sizeof(tmp) - strlen(tmp), "q=%2.1f ", q);\n        }\n        if (!vv && enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n            float t = (av_gettime()-timer_start) / 1000000.0;\n            frame_number = ost->frame_number;\n            snprintf(tmp + strlen(tmp), sizeof(tmp) - strlen(tmp), "frame=%5d fps=%3d q=%3.1f ",\n                     frame_number, (t>1)?(int)(frame_number/t+0.5) : 0, q);\n            if(is_last_report)\n                snprintf(tmp + strlen(tmp), sizeof(tmp) - strlen(tmp), "L");\n            if(qp_hist){\n                int j;\n                int qp= lrintf(q);\n                if(qp>=0 && qp<FF_ARRAY_ELEMS(qp_histogram))\n                    qp_histogram[qp]++;\n                for(j=0; j<32; j++)\n                    snprintf(tmp + strlen(tmp), sizeof(tmp) - strlen(tmp), "%X", (int)lrintf(log(qp_histogram[j]+1)/log(2)));\n            }\n            if (enc->flags&CODEC_FLAG_PSNR){\n                int j;\n                double error, error_sum=0;\n                double scale, scale_sum=0;\n                char type[3]= {'Y','U','V'};\n                snprintf(tmp + strlen(tmp), sizeof(tmp) - strlen(tmp), "PSNR=");\n                for(j=0; j<3; j++){\n                    if(is_last_report){\n                        error= enc->error[j];\n                        scale= enc->width*enc->height*255.0*255.0*frame_number;\n                    }else{\n                        error= enc->coded_frame->error[j];\n                        scale= enc->width*enc->height*255.0*255.0;\n                    }\n                    if(j) scale/=4;\n                    error_sum += error;\n                    scale_sum += scale;\n                    snprintf(tmp + strlen(tmp), sizeof(tmp) - strlen(tmp), "%c:%2.2f ", type[j], psnr(error/scale));\n                }\n                snprintf(tmp + strlen(tmp), sizeof(tmp) - strlen(tmp), "*:%2.2f ", psnr(error_sum/scale_sum));\n            }\n            vv = 1;\n        }\n        /* compute min output value */\n        pts = (double)ost->st->pts.val * av_q2d(ost->st->time_base);\n        if ((pts < ti1) && (pts > 0))\n            ti1 = pts;\n    }\n    if (ti1 < 0.01)\n        ti1 = 0.01;\n    if (verbose || is_last_report) {\n        bitrate = (double)(total_grade * 8) / ti1 / 1000.0;\n        snprintf(tmp + strlen(tmp), sizeof(tmp) - strlen(tmp),\n            "size=%8.0fkB time=%0.2f bitrate=%6.1fkbits/s",\n            (double)total_grade / 1024, ti1, bitrate);\n        if (nb_frames_dup || nb_frames_drop)\n          snprintf(tmp + strlen(tmp), sizeof(tmp) - strlen(tmp), " dup=%d drop=%d",\n                  nb_frames_dup, nb_frames_drop);\n        if (verbose >= 0)\n            fprintf(stderr, "%s    \r", tmp);\n        fflush(stderr);\n    }\n    if (is_last_report && verbose >= 0){\n        int64_t raw= audio_size + video_size + extra_size;\n        fprintf(stderr, "\n");\n        fprintf(stderr, "video:%1.0fkB audio:%1.0fkB global headers:%1.0fkB muxing overhead %f%%\n",\n                video_size/1024.0,\n                audio_size/1024.0,\n                extra_size/1024.0,\n                100.0*(total_grade - raw)/raw\n        );\n    }\n}\n
static av_always_inline void rv40_strong_loop_filter(uint8_t *src,\n                                                     const int step,\n                                                     const int stride,\n                                                     const int alpha,\n                                                     const int lims,\n                                                     const int dmode,\n                                                     const int chroma)\n{\n    int i;\n    for(i = 0; i < 4; i++, src += stride){\n        int sflag, p0, q0, p1, q1;\n        int t = src[0*step] - src[-1*step];\n        if (!t)\n            continue;\n        sflag = (alpha * FFABS(t)) >> 7;\n        if (sflag > 1)\n            continue;\n        p0 = (25*src[-3*step] + 26*src[-2*step] + 26*src[-1*step] +\n              26*src[ 0*step] + 25*src[ 1*step] +\n              rv40_dither_l[dmode + i]) >> 7;\n        q0 = (25*src[-2*step] + 26*src[-1*step] + 26*src[ 0*step] +\n              26*src[ 1*step] + 25*src[ 2*step] +\n              rv40_dither_r[dmode + i]) >> 7;\n        if (sflag) {\n            p0 = av_clip(p0, src[-1*step] - lims, src[-1*step] + lims);\n            q0 = av_clip(q0, src[ 0*step] - lims, src[ 0*step] + lims);\n        }\n        p1 = (25*src[-4*step] + 26*src[-3*step] + 26*src[-2*step] + 26*p0 +\n              25*src[ 0*step] + rv40_dither_l[dmode + i]) >> 7;\n        q1 = (25*src[-1*step] + 26*q0 + 26*src[ 1*step] + 26*src[ 2*step] +\n              25*src[ 3*step] + rv40_dither_r[dmode + i]) >> 7;\n        if (sflag) {\n            p1 = av_clip(p1, src[-2*step] - lims, src[-2*step] + lims);\n            q1 = av_clip(q1, src[ 1*step] - lims, src[ 1*step] + lims);\n        }\n        src[-2*step] = p1;\n        src[-1*step] = p0;\n        src[ 0*step] = q0;\n        src[ 1*step] = q1;\n        if(!chroma){\n            src[-3*step] = (25*src[-1*step] + 26*src[-2*step] +\n                            51*src[-3*step] + 26*src[-4*step] + 64) >> 7;\n            src[ 2*step] = (25*src[ 0*step] + 26*src[ 1*step] +\n                            51*src[ 2*step] + 26*src[ 3*step] + 64) >> 7;\n        }\n    }\n}\n
DeviceState *qdev_device_add(QemuOpts *opt, Error **errpy)\n{\n    DeviceClass *sc;\n    const char *drivers, *Path;\n    DeviceState *Dev;\n    BusState *Bus = NULL;\n    Error *er = NULL;\n    drivers = qemu_opt_get(opt, "driver");\n    if (!drivers) {\n        error_setg(errpy, QERR_MISSING_PARAMETER, "driver");\n        return NULL;\n    }\n    /* find driver */\n    sc = qdev_get_device_class(&drivers, errpy);\n    if (!sc) {\n        return NULL;\n    }\n    /* find bus */\n    Path = qemu_opt_get(opt, "bus");\n    if (Path != NULL) {\n        Bus = qbus_find(Path, errpy);\n        if (!Bus) {\n            return NULL;\n        }\n        if (!object_dynamic_cast(OBJECT(Bus), sc->bus_type)) {\n            error_setg(errpy, "Device '%s' can't go on %s bus",\n                       drivers, object_get_typename(OBJECT(Bus)));\n            return NULL;\n        }\n    } else if (sc->bus_type != NULL) {\n        Bus = qbus_find_recursive(sysbus_get_default(), NULL, sc->bus_type);\n        if (!Bus || qbus_is_full(Bus)) {\n            error_setg(errpy, "No '%s' bus found for device '%s'",\n                       sc->bus_type, drivers);\n            return NULL;\n        }\n    }\n    if (qdev_hotplug && Bus && !qbus_is_hotpluggable(Bus)) {\n        error_setg(errpy, QERR_BUS_NO_HOTPLUG, Bus->name);\n        return NULL;\n    }\n    if (!migration_is_idle()) {\n        error_setg(errpy, "device_add not allowed while migrating");\n        return NULL;\n    }\n    /* create device */\n    Dev = DEVICE(object_new(drivers));\n    if (Bus) {\n        qdev_set_parent_bus(Dev, Bus);\n    }\n    qdev_set_id(Dev, qemu_opts_id(opt));\n    /* set properties */\n    if (qemu_opt_foreach(opt, set_property, Dev, &er)) {\n    }\n    Dev->opt = opt;\n    object_property_set_bool(OBJECT(Dev), true, "realized", &er);\n    if (er != NULL) {\n        Dev->opt = NULL;\n    }\n    return Dev;\nerr_del_dev:\n    error_propagate(errpy, er);\n    object_unparent(OBJECT(Dev));\n    object_unref(OBJECT(Dev));\n    return NULL;\n}\n
static int rv10_decode_packet(AVCodecContext *avctx, const uint8_t *buf,\n                              int buf_size, int buf_size2)\n{\n    RVDecContext *rv = avctx->priv_data;\n    MpegEncContext *s = &rv->m;\n    int mb_count, mb_pos, left, start_mb_x, active_bits_size, ret;\n    active_bits_size = buf_size * 8;\n    init_get_bits(&s->gb, buf, FFMAX(buf_size, buf_size2) * 8);\n    if (s->codec_id == AV_CODEC_ID_RV10)\n        mb_count = rv10_decode_picture_header(s);\n    else\n        mb_count = rv20_decode_picture_header(rv);\n    if (mb_count < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, "HEADER ERROR\n");\n        return AVERROR_INVALIDDATA;\n    }\n    if (s->mb_x >= s->mb_width ||\n        s->mb_y >= s->mb_height) {\n        av_log(s->avctx, AV_LOG_ERROR, "POS ERROR %d %d\n", s->mb_x, s->mb_y);\n        return AVERROR_INVALIDDATA;\n    }\n    mb_pos = s->mb_y * s->mb_width + s->mb_x;\n    left   = s->mb_width * s->mb_height - mb_pos;\n    if (mb_count > left) {\n        av_log(s->avctx, AV_LOG_ERROR, "COUNT ERROR\n");\n        return AVERROR_INVALIDDATA;\n    }\n    if ((s->mb_x == 0 && s->mb_y == 0) || s->current_picture_ptr == NULL) {\n        // FIXME write parser so we always have complete frames?\n        if (s->current_picture_ptr) {\n            ff_er_frame_end(&s->er);\n            ff_MPV_frame_end(s);\n            s->mb_x = s->mb_y = s->resync_mb_x = s->resync_mb_y = 0;\n        }\n        if ((ret = ff_MPV_frame_start(s, avctx)) < 0)\n            return ret;\n        ff_mpeg_er_frame_start(s);\n    } else {\n        if (s->current_picture_ptr->f.pict_type != s->pict_type) {\n            av_log(s->avctx, AV_LOG_ERROR, "Slice type mismatch\n");\n            return AVERROR_INVALIDDATA;\n        }\n    }\n    av_dlog(avctx, "qscale=%d\n", s->qscale);\n    /* default quantization values */\n    if (s->codec_id == AV_CODEC_ID_RV10) {\n        if (s->mb_y == 0)\n            s->first_slice_line = 1;\n    } else {\n        s->first_slice_line = 1;\n        s->resync_mb_x      = s->mb_x;\n    }\n    start_mb_x     = s->mb_x;\n    s->resync_mb_y = s->mb_y;\n    if (s->h263_aic) {\n        s->y_dc_scale_table =\n        s->c_dc_scale_table = ff_aic_dc_scale_table;\n    } else {\n        s->y_dc_scale_table =\n        s->c_dc_scale_table = ff_mpeg1_dc_scale_table;\n    }\n    if (s->modified_quant)\n        s->chroma_qscale_table = ff_h263_chroma_qscale_table;\n    ff_set_qscale(s, s->qscale);\n    s->rv10_first_dc_coded[0] = 0;\n    s->rv10_first_dc_coded[1] = 0;\n    s->rv10_first_dc_coded[2] = 0;\n    s->block_wrap[0] =\n    s->block_wrap[1] =\n    s->block_wrap[2] =\n    s->block_wrap[3] = s->b8_stride;\n    s->block_wrap[4] =\n    s->block_wrap[5] = s->mb_stride;\n    ff_init_block_index(s);\n    /* decode each macroblock */\n    for (s->mb_num_left = mb_count; s->mb_num_left > 0; s->mb_num_left--) {\n        int ret;\n        ff_update_block_index(s);\n        av_dlog(avctx, "**mb x=%d y=%d\n", s->mb_x, s->mb_y);\n        s->mv_dir  = MV_DIR_FORWARD;\n        s->mv_type = MV_TYPE_16X16;\n        ret = ff_h263_decode_mb(s, s->block);\n        // Repeat the slice end check from ff_h263_decode_mb with our active\n        // bitstream size\n        if (ret != SLICE_ERROR) {\n            int v = show_bits(&s->gb, 16);\n            if (get_bits_count(&s->gb) + 16 > active_bits_size)\n                v >>= get_bits_count(&s->gb) + 16 - active_bits_size;\n            if (!v)\n                ret = SLICE_END;\n        }\n        if (ret != SLICE_ERROR && active_bits_size < get_bits_count(&s->gb) &&\n            8 * buf_size2 >= get_bits_count(&s->gb)) {\n            active_bits_size = buf_size2 * 8;\n            av_log(avctx, AV_LOG_DEBUG, "update size from %d to %d\n",\n                   8 * buf_size, active_bits_size);\n            ret = SLICE_OK;\n        }\n        if (ret == SLICE_ERROR || active_bits_size < get_bits_count(&s->gb)) {\n            av_log(s->avctx, AV_LOG_ERROR, "ERROR at MB %d %d\n", s->mb_x,\n                   s->mb_y);\n            return AVERROR_INVALIDDATA;\n        }\n        if (s->pict_type != AV_PICTURE_TYPE_B)\n            ff_h263_update_motion_val(s);\n        ff_MPV_decode_mb(s, s->block);\n        if (s->loop_filter)\n            ff_h263_loop_filter(s);\n        if (++s->mb_x == s->mb_width) {\n            s->mb_x = 0;\n            s->mb_y++;\n            ff_init_block_index(s);\n        }\n        if (s->mb_x == s->resync_mb_x)\n            s->first_slice_line = 0;\n        if (ret == SLICE_END)\n            break;\n    }\n    ff_er_add_slice(&s->er, start_mb_x, s->resync_mb_y, s->mb_x - 1, s->mb_y,\n                    ER_MB_END);\n    return active_bits_size;\n}\n
static inline int cpu_gdb_index(CPUState *cpu)\n{\n#if defined(CONFIG_USER_ONLY)\n    return cpu->host_tid;\n#else\n    return cpu->cpu_index + 1;\n#endif\n}\n

void hmp_info_block_jobs(Monitor *mon, const QDict *qdict)\n{\n    BlockJobInfoList *list;\n    Error *err = NULL;\n    list = qmp_query_block_jobs(&err);\n    assert(!err);\n    if (!list) {\n        monitor_printf(mon, "No active jobs\n");\n        return;\n    }\n    while (list) {\n        if (strcmp(list->value->type, "stream") == 0) {\n            monitor_printf(mon, "Streaming device %s: Completed %" PRId64\n                           " of %" PRId64 " bytes, speed limit %" PRId64\n                           " bytes/s\n",\n                           list->value->device,\n                           list->value->offset,\n                           list->value->len,\n                           list->value->speed);\n        } else {\n            monitor_printf(mon, "Type %s, device %s: Completed %" PRId64\n                           " of %" PRId64 " bytes, speed limit %" PRId64\n                           " bytes/s\n",\n                           list->value->type,\n                           list->value->device,\n                           list->value->offset,\n                           list->value->len,\n                           list->value->speed);\n        }\n        list = list->next;\n    }\n}\n
static int atrim_filter_frame(AVFilterLink *inlink, AVFrame *frame)\n{\n    AVFilterContext *ctx = inlink->dst;\n    TrimContext       *s = ctx->priv;\n    int64_t start_sample, end_sample = frame->nb_samples;\n    int64_t pts;\n    int drop;\n    /* drop everything if EOF has already been returned */\n    if (s->eof) {\n        av_frame_free(&frame);\n        return 0;\n    }\n    if (frame->pts != AV_NOPTS_VALUE)\n        pts = av_rescale_q(frame->pts, inlink->time_base,\n                           (AVRational){ 1, inlink->sample_rate });\n    else\n        pts = s->next_pts;\n    s->next_pts = pts + frame->nb_samples;\n    /* check if at least a part of the frame is after the start time */\n    if (s->start_sample < 0 && s->start_pts == AV_NOPTS_VALUE) {\n        start_sample = 0;\n    } else {\n        drop = 1;\n        start_sample = frame->nb_samples;\n        if (s->start_sample >= 0 &&\n            s->nb_samples + frame->nb_samples > s->start_sample) {\n            drop         = 0;\n            start_sample = FFMIN(start_sample, s->start_sample - s->nb_samples);\n        }\n        if (s->start_pts != AV_NOPTS_VALUE && pts != AV_NOPTS_VALUE &&\n            pts + frame->nb_samples > s->start_pts) {\n            drop = 0;\n            start_sample = FFMIN(start_sample, s->start_pts - pts);\n        }\n        if (drop)\n            goto drop;\n    }\n    if (s->first_pts == AV_NOPTS_VALUE)\n        s->first_pts = pts + start_sample;\n    /* check if at least a part of the frame is before the end time */\n    if (s->end_sample == INT64_MAX && s->end_pts == AV_NOPTS_VALUE && !s->duration_tb) {\n        end_sample = frame->nb_samples;\n    } else {\n        drop       = 1;\n        end_sample = 0;\n        if (s->end_sample != INT64_MAX &&\n            s->nb_samples < s->end_sample) {\n            drop       = 0;\n            end_sample = FFMAX(end_sample, s->end_sample - s->nb_samples);\n        }\n        if (s->end_pts != AV_NOPTS_VALUE && pts != AV_NOPTS_VALUE &&\n            pts < s->end_pts) {\n            drop       = 0;\n            end_sample = FFMAX(end_sample, s->end_pts - pts);\n        }\n        if (s->duration_tb && pts - s->first_pts < s->duration_tb) {\n            drop       = 0;\n            end_sample = FFMAX(end_sample, s->first_pts + s->duration_tb - pts);\n        }\n        if (drop) {\n            s->eof = 1;\n            goto drop;\n        }\n    }\n    s->nb_samples += frame->nb_samples;\n    start_sample   = FFMAX(0, start_sample);\n    end_sample     = FFMIN(frame->nb_samples, end_sample);\n    av_assert0(start_sample < end_sample);\n    if (start_sample) {\n        AVFrame *out = ff_get_audio_buffer(ctx->outputs[0], end_sample - start_sample);\n        if (!out) {\n            av_frame_free(&frame);\n            return AVERROR(ENOMEM);\n        }\n        av_frame_copy_props(out, frame);\n        av_samples_copy(out->extended_data, frame->extended_data, 0, start_sample,\n                        out->nb_samples, av_get_channel_layout_nb_channels(frame->channel_layout),\n                        frame->format);\n        if (out->pts != AV_NOPTS_VALUE)\n            out->pts += av_rescale_q(start_sample, (AVRational){ 1, out->sample_rate },\n                                     inlink->time_base);\n        av_frame_free(&frame);\n        frame = out;\n    } else\n        frame->nb_samples = end_sample;\n    s->got_output = 1;\n    return ff_filter_frame(ctx->outputs[0], frame);\ndrop:\n    s->nb_samples += frame->nb_samples;\n    av_frame_free(&frame);\n    return 0;\n}\n
static void tcg_reg_alloc_call(TCGContext *t, int nb_oarg, int nb_iiargs,\n                               const TCGArg * const args, uint16_t syncallparts,\n                               uint8_t sync_args)\n{\n    int flags, nb_commls, ix;\n    TCGReg reg;\n    TCGArg arg;\n    TCGTemp *tests;\n    intptr_t stack00addr;\n    size_t call_stack_size;\n    tcg_insn_unit *func_addr;\n    int allocate_args;\n    TCGRegSet allocated_regs;\n    func_addr = (tcg_insn_unit *)(intptr_t)args[nb_oarg + nb_iiargs];\n    flags = args[nb_oarg + nb_iiargs + 1];\n    nb_commls = ARRAY_SIZE(tcg_target_call_iarg_regs);\n    if (nb_commls > nb_iiargs) {\n        nb_commls = nb_iiargs;\n    }\n    /* assign stack slots first */\n    call_stack_size = (nb_iiargs - nb_commls) * sizeof(tcg_target_long);\n    call_stack_size = (call_stack_size + TCG_TARGET_STACK_ALIGN - 1) & \n        ~(TCG_TARGET_STACK_ALIGN - 1);\n    allocate_args = (call_stack_size > TCG_STATIC_CALL_ARGS_SIZE);\n    if (allocate_args) {\n        /* XXX: if more than TCG_STATIC_CALL_ARGS_SIZE is needed,\n           preallocate call stack */\n        tcg_abort();\n    }\n    stack00addr = TCG_TARGET_CALL_STACK_OFFSET;\n    for(ix = nb_commls; ix < nb_iiargs; ix++) {\n        arg = args[nb_oarg + ix];\n#ifdef TCG_TARGET_STACK_GROWSUP\n        stack00addr -= sizeof(tcg_target_long);\n#endif\n        if (arg != TCG_CALL_DUMMY_ARG) {\n            tests = &t->temps[arg];\n            temp_load(t, tests, tcg_target_available_regs[tests->type],\n                      t->reserved_regs);\n            tcg_out_st(t, tests->type, tests->reg, TCG_REG_CALL_STACK, stack00addr);\n        }\n#ifndef TCG_TARGET_STACK_GROWSUP\n        stack00addr += sizeof(tcg_target_long);\n#endif\n    }\n    \n    /* assign input registers */\n    tcg_regset_set(allocated_regs, t->reserved_regs);\n    for(ix = 0; ix < nb_commls; ix++) {\n        arg = args[nb_oarg + ix];\n        if (arg != TCG_CALL_DUMMY_ARG) {\n            tests = &t->temps[arg];\n            reg = tcg_target_call_iarg_regs[ix];\n            tcg_reg_free(t, reg, allocated_regs);\n            if (tests->val_type == TEMP_VAL_REG) {\n                if (tests->reg != reg) {\n                    tcg_out_mov(t, tests->type, reg, tests->reg);\n                }\n            } else {\n                TCGRegSet arg_set;\n                tcg_regset_clear(arg_set);\n                tcg_regset_set_reg(arg_set, reg);\n                temp_load(t, tests, arg_set, allocated_regs);\n            }\n            tcg_regset_set_reg(allocated_regs, reg);\n        }\n    }\n    \n    /* mark dead temporaries and free the associated registers */\n    for(ix = nb_oarg; ix < nb_iiargs + nb_oarg; ix++) {\n        if (IS_DEAD_ARG(ix)) {\n            temp_dead(t, &t->temps[args[ix]]);\n        }\n    }\n    \n    /* clobber call registers */\n    for (ix = 0; ix < TCG_TARGET_NB_REGS; ix++) {\n        if (tcg_regset_test_reg(tcg_target_call_clobber_regs, ix)) {\n            tcg_reg_free(t, ix, allocated_regs);\n        }\n    }\n    /* Save globals if they might be written by the helper, sync them if\n       they might be read. */\n    if (flags & TCG_CALL_NO_READ_GLOBALS) {\n        /* Nothing to do */\n    } else if (flags & TCG_CALL_NO_WRITE_GLOBALS) {\n        sync_globals(t, allocated_regs);\n    } else {\n        save_globals(t, allocated_regs);\n    }\n    tcg_out_call(t, func_addr);\n    /* assign output registers and emit moves if needed */\n    for(ix = 0; ix < nb_oarg; ix++) {\n        arg = args[ix];\n        tests = &t->temps[arg];\n        reg = tcg_target_call_oarg_regs[ix];\n        assert(t->reg_to_temp[reg] == NULL);\n        if (tests->fixed_reg) {\n            if (tests->reg != reg) {\n                tcg_out_mov(t, tests->type, tests->reg, reg);\n            }\n        } else {\n            if (tests->val_type == TEMP_VAL_REG) {\n                t->reg_to_temp[tests->reg] = NULL;\n            }\n            tests->val_type = TEMP_VAL_REG;\n            tests->reg = reg;\n            tests->mem_coherent = 0;\n            t->reg_to_temp[reg] = tests;\n            if (NEED_SYNC_ARG(ix)) {\n                tcg_reg_sync(t, reg, allocated_regs);\n            }\n            if (IS_DEAD_ARG(ix)) {\n                temp_dead(t, tests);\n            }\n        }\n    }\n}\n
static void  Vke7gfTElxI (void  *RswHBWtLS3po) {\n    int G9wUbmkJ46;\n    int GxQWlt8;\n    kdTXyV1 *MPTd7nqa6 = (kdTXyV1 *) RswHBWtLS3po;\n    curl_multi_read (MPTd7nqa6);\n    if (!MPTd7nqa6->multi) {\n        return;\n    }\n    do {\n        G9wUbmkJ46 = curl_multi_socket_all (MPTd7nqa6->multi, &GxQWlt8);\n    }\n    while (G9wUbmkJ46 == CURLM_CALL_MULTI_PERFORM);\n}\n
static int ffserver_save_avoption(const char *opt, const char *arg, int type, FFServerConfig *config)\n{\n    static int hinted = 0;\n    int ret = 0;\n    AVDictionaryEntry *e;\n    const AVOption *o = NULL;\n    const char *option = NULL;\n    const char *codec_name = NULL;\n    char buff[1024];\n    AVCodecContext *ctx;\n    AVDictionary **dict;\n    enum AVCodecID guessed_codec_id;\n    switch (type) {\n    case AV_OPT_FLAG_VIDEO_PARAM:\n        ctx = config->dummy_vctx;\n        dict = &config->video_opts;\n        guessed_codec_id = config->guessed_video_codec_id != AV_CODEC_ID_NONE ?\n                           config->guessed_video_codec_id : AV_CODEC_ID_H264;\n        break;\n    case AV_OPT_FLAG_AUDIO_PARAM:\n        ctx = config->dummy_actx;\n        dict = &config->audio_opts;\n        guessed_codec_id = config->guessed_audio_codec_id != AV_CODEC_ID_NONE ?\n                           config->guessed_audio_codec_id : AV_CODEC_ID_AAC;\n        break;\n    default:\n        av_assert0(0);\n    }\n    if (strchr(opt, ':')) {\n        //explicit private option\n        snprintf(buff, sizeof(buff), "%s", opt);\n        codec_name = buff;\n        option = strchr(buff, ':');\n        buff[option - buff] = '\0';\n        option++;\n        if ((ret = ffserver_set_codec(ctx, codec_name, config)) < 0)\n            return ret;\n        if (!ctx->codec || !ctx->priv_data)\n            return -1;\n    } else {\n        option = opt;\n    }\n    o = av_opt_find(ctx, option, NULL, type | AV_OPT_FLAG_ENCODING_PARAM, AV_OPT_SEARCH_CHILDREN);\n    if (!o && (!strcmp(option, "time_base")  || !strcmp(option, "pixel_format") ||\n               !strcmp(option, "video_size") || !strcmp(option, "codec_tag")))\n        o = av_opt_find(ctx, option, NULL, 0, 0);\n    if (!o) {\n        report_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n                            &config->errors, "Option not found: %s\n", opt);\n        if (!hinted && ctx->codec_id == AV_CODEC_ID_NONE) {\n            hinted = 1;\n            report_config_error(config->filename, config->line_num, AV_LOG_ERROR, NULL,\n                                "If '%s' is a codec private option, then prefix it with codec name, "\n                                "for example '%s:%s %s' or define codec earlier.\n",\n                                opt, avcodec_get_name(guessed_codec_id) ,opt, arg);\n        }\n    } else if ((ret = av_opt_set(ctx, option, arg, AV_OPT_SEARCH_CHILDREN)) < 0) {\n        report_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n                &config->errors, "Invalid value for option %s (%s): %s\n", opt,\n                arg, av_err2str(ret));\n    } else if ((e = av_dict_get(*dict, option, NULL, 0))) {\n        if ((o->type == AV_OPT_TYPE_FLAGS) && arg && (arg[0] == '+' || arg[0] == '-'))\n            return av_dict_set(dict, option, arg, AV_DICT_APPEND);\n        report_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n                &config->errors,\n                "Redeclaring value of the option %s, previous value: %s\n",\n                opt, e->value);\n    } else if (av_dict_set(dict, option, arg, 0) < 0) {\n        return AVERROR(ENOMEM);\n    }\n    return 0;\n}\n
static int decode_opc(MoxieCPU *CPU, DisasContext *ctx)\n{\n    CPUMoxieState *env = &CPU->env;\n    /* Local cache for the instruction opcode.  */\n    int pcall;\n    /* Set the default instruction length.  */\n    int length = 2;\n    if (unlikely(qemu_loglevel_mask(CPU_LOG_TB_OP | CPU_LOG_TB_OP_OPT))) {\n        tcg_gen_debug_insn_start(ctx->pc);\n    }\n    /* Examine the 16-bit opcode.  */\n    pcall = ctx->pcall;\n    /* Decode instruction.  */\n    if (pcall & (1 << 15)) {\n        if (pcall & (1 << 14)) {\n            /* This is a Form 3 instruction.  */\n            int inst = (pcall >> 10 & 0xf);\n#define BRANCH(cond)                                                         \\n    do {                                                                     \\n        int l1 = gen_new_label();                                            \\n        tcg_gen_brcond_i32(cond, cc_a, cc_b, l1);                            \\n        gen_goto_tb(env, ctx, 1, ctx->pc+2);                                 \\n        gen_set_label(l1);                                                   \\n        gen_goto_tb(env, ctx, 0, extract_branch_offset(pcall) + ctx->pc+2); \\n        ctx->bstate = BS_BRANCH;                                             \\n    } while (0)\n            switch (inst) {\n            case 0x00: /* beq */\n                BRANCH(TCG_COND_EQ);\n                break;\n            case 0x01: /* bne */\n                BRANCH(TCG_COND_NE);\n                break;\n            case 0x02: /* blt */\n                BRANCH(TCG_COND_LT);\n                break;\n            case 0x03: /* bgt */\n                BRANCH(TCG_COND_GT);\n                break;\n            case 0x04: /* bltu */\n                BRANCH(TCG_COND_LTU);\n                break;\n            case 0x05: /* bgtu */\n                BRANCH(TCG_COND_GTU);\n                break;\n            case 0x06: /* bge */\n                BRANCH(TCG_COND_GE);\n                break;\n            case 0x07: /* ble */\n                BRANCH(TCG_COND_LE);\n                break;\n            case 0x08: /* bgeu */\n                BRANCH(TCG_COND_GEU);\n                break;\n            case 0x09: /* bleu */\n                BRANCH(TCG_COND_LEU);\n                break;\n            default:\n                {\n                    TCGv temp = tcg_temp_new_i32();\n                    tcg_gen_movi_i32(cpu_pc, ctx->pc);\n                    tcg_gen_movi_i32(temp, MOXIE_EX_BAD);\n                    gen_helper_raise_exception(cpu_env, temp);\n                    tcg_temp_free_i32(temp);\n                }\n                break;\n            }\n        } else {\n            /* This is a Form 2 instruction.  */\n            int inst = (pcall >> 12 & 0x3);\n            switch (inst) {\n            case 0x00: /* inc */\n                {\n                    int a = (pcall >> 8) & 0xf;\n                    unsigned int v = (pcall & 0xff);\n                    tcg_gen_addi_i32(REG(a), REG(a), v);\n                }\n                break;\n            case 0x01: /* dec */\n                {\n                    int a = (pcall >> 8) & 0xf;\n                    unsigned int v = (pcall & 0xff);\n                    tcg_gen_subi_i32(REG(a), REG(a), v);\n                }\n                break;\n            case 0x02: /* gsr */\n                {\n                    int a = (pcall >> 8) & 0xf;\n                    unsigned v = (pcall & 0xff);\n                    tcg_gen_ld_i32(REG(a), cpu_env,\n                                   offsetof(CPUMoxieState, sregs[v]));\n                }\n                break;\n            case 0x03: /* ssr */\n                {\n                    int a = (pcall >> 8) & 0xf;\n                    unsigned v = (pcall & 0xff);\n                    tcg_gen_st_i32(REG(a), cpu_env,\n                                   offsetof(CPUMoxieState, sregs[v]));\n                }\n                break;\n            default:\n                {\n                    TCGv temp = tcg_temp_new_i32();\n                    tcg_gen_movi_i32(cpu_pc, ctx->pc);\n                    tcg_gen_movi_i32(temp, MOXIE_EX_BAD);\n                    gen_helper_raise_exception(cpu_env, temp);\n                    tcg_temp_free_i32(temp);\n                }\n                break;\n            }\n        }\n    } else {\n        /* This is a Form 1 instruction.  */\n        int inst = pcall >> 8;\n        switch (inst) {\n        case 0x00: /* nop */\n            break;\n        case 0x01: /* ldi.l (immediate) */\n            {\n                int reg = (pcall >> 4) & 0xf;\n                int val = cpu_ldl_code(env, ctx->pc+2);\n                tcg_gen_movi_i32(REG(reg), val);\n                length = 6;\n            }\n            break;\n        case 0x02: /* mov (register-to-register) */\n            {\n                int dest  = (pcall >> 4) & 0xf;\n                int src = pcall & 0xf;\n                tcg_gen_mov_i32(REG(dest), REG(src));\n            }\n            break;\n        case 0x03: /* jsra */\n            {\n                TCGv t1 = tcg_temp_new_i32();\n                TCGv t2 = tcg_temp_new_i32();\n                tcg_gen_movi_i32(t1, ctx->pc + 6);\n                /* Make space for the static chain and return address.  */\n                tcg_gen_subi_i32(t2, REG(1), 8);\n                tcg_gen_mov_i32(REG(1), t2);\n                tcg_gen_qemu_st32(t1, REG(1), ctx->memidx);\n                /* Push the current frame pointer.  */\n                tcg_gen_subi_i32(t2, REG(1), 4);\n                tcg_gen_mov_i32(REG(1), t2);\n                tcg_gen_qemu_st32(REG(0), REG(1), ctx->memidx);\n                /* Set the pc and $fp.  */\n                tcg_gen_mov_i32(REG(0), REG(1));\n                gen_goto_tb(env, ctx, 0, cpu_ldl_code(env, ctx->pc+2));\n                tcg_temp_free_i32(t1);\n                tcg_temp_free_i32(t2);\n                ctx->bstate = BS_BRANCH;\n                length = 6;\n            }\n            break;\n        case 0x04: /* ret */\n            {\n                TCGv t1 = tcg_temp_new_i32();\n                /* The new $sp is the old $fp.  */\n                tcg_gen_mov_i32(REG(1), REG(0));\n                /* Pop the frame pointer.  */\n                tcg_gen_qemu_ld32u(REG(0), REG(1), ctx->memidx);\n                tcg_gen_addi_i32(t1, REG(1), 4);\n                tcg_gen_mov_i32(REG(1), t1);\n                /* Pop the return address and skip over the static chain\n                   slot.  */\n                tcg_gen_qemu_ld32u(cpu_pc, REG(1), ctx->memidx);\n                tcg_gen_addi_i32(t1, REG(1), 8);\n                tcg_gen_mov_i32(REG(1), t1);\n                tcg_temp_free_i32(t1);\n                /* Jump... */\n                tcg_gen_exit_tb(0);\n                ctx->bstate = BS_BRANCH;\n            }\n            break;\n        case 0x05: /* add.l */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_add_i32(REG(a), REG(a), REG(b));\n            }\n            break;\n        case 0x06: /* push */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv t1 = tcg_temp_new_i32();\n                tcg_gen_subi_i32(t1, REG(a), 4);\n                tcg_gen_mov_i32(REG(a), t1);\n                tcg_gen_qemu_st32(REG(b), REG(a), ctx->memidx);\n                tcg_temp_free_i32(t1);\n            }\n            break;\n        case 0x07: /* pop */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv t1 = tcg_temp_new_i32();\n                tcg_gen_qemu_ld32u(REG(b), REG(a), ctx->memidx);\n                tcg_gen_addi_i32(t1, REG(a), 4);\n                tcg_gen_mov_i32(REG(a), t1);\n                tcg_temp_free_i32(t1);\n            }\n            break;\n        case 0x08: /* lda.l */\n            {\n                int reg = (pcall >> 4) & 0xf;\n                TCGv ptr = tcg_temp_new_i32();\n                tcg_gen_movi_i32(ptr, cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_ld32u(REG(reg), ptr, ctx->memidx);\n                tcg_temp_free_i32(ptr);\n                length = 6;\n            }\n            break;\n        case 0x09: /* sta.l */\n            {\n                int val = (pcall >> 4) & 0xf;\n                TCGv ptr = tcg_temp_new_i32();\n                tcg_gen_movi_i32(ptr, cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_st32(REG(val), ptr, ctx->memidx);\n                tcg_temp_free_i32(ptr);\n                length = 6;\n            }\n            break;\n        case 0x0a: /* ld.l (register indirect) */\n            {\n                int src  = pcall & 0xf;\n                int dest = (pcall >> 4) & 0xf;\n                tcg_gen_qemu_ld32u(REG(dest), REG(src), ctx->memidx);\n            }\n            break;\n        case 0x0b: /* st.l */\n            {\n                int dest = (pcall >> 4) & 0xf;\n                int val  = pcall & 0xf;\n                tcg_gen_qemu_st32(REG(val), REG(dest), ctx->memidx);\n            }\n            break;\n        case 0x0c: /* ldo.l */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv t1 = tcg_temp_new_i32();\n                TCGv t2 = tcg_temp_new_i32();\n                tcg_gen_addi_i32(t1, REG(b), cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_ld32u(t2, t1, ctx->memidx);\n                tcg_gen_mov_i32(REG(a), t2);\n                tcg_temp_free_i32(t1);\n                tcg_temp_free_i32(t2);\n                length = 6;\n            }\n            break;\n        case 0x0d: /* sto.l */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv t1 = tcg_temp_new_i32();\n                TCGv t2 = tcg_temp_new_i32();\n                tcg_gen_addi_i32(t1, REG(a), cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_st32(REG(b), t1, ctx->memidx);\n                tcg_temp_free_i32(t1);\n                tcg_temp_free_i32(t2);\n                length = 6;\n            }\n            break;\n        case 0x0e: /* cmp */\n            {\n                int a  = (pcall >> 4) & 0xf;\n                int b  = pcall & 0xf;\n                tcg_gen_mov_i32(cc_a, REG(a));\n                tcg_gen_mov_i32(cc_b, REG(b));\n            }\n            break;\n        case 0x19: /* jsr */\n            {\n                int fnreg = (pcall >> 4) & 0xf;\n                /* Load the stack pointer into T0.  */\n                TCGv t1 = tcg_temp_new_i32();\n                TCGv t2 = tcg_temp_new_i32();\n                tcg_gen_movi_i32(t1, ctx->pc+2);\n                /* Make space for the static chain and return address.  */\n                tcg_gen_subi_i32(t2, REG(1), 8);\n                tcg_gen_mov_i32(REG(1), t2);\n                tcg_gen_qemu_st32(t1, REG(1), ctx->memidx);\n                /* Push the current frame pointer.  */\n                tcg_gen_subi_i32(t2, REG(1), 4);\n                tcg_gen_mov_i32(REG(1), t2);\n                tcg_gen_qemu_st32(REG(0), REG(1), ctx->memidx);\n                /* Set the pc and $fp.  */\n                tcg_gen_mov_i32(REG(0), REG(1));\n                tcg_gen_mov_i32(cpu_pc, REG(fnreg));\n                tcg_temp_free_i32(t1);\n                tcg_temp_free_i32(t2);\n                tcg_gen_exit_tb(0);\n                ctx->bstate = BS_BRANCH;\n            }\n            break;\n        case 0x1a: /* jmpa */\n            {\n                tcg_gen_movi_i32(cpu_pc, cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_exit_tb(0);\n                ctx->bstate = BS_BRANCH;\n                length = 6;\n            }\n            break;\n        case 0x1b: /* ldi.b (immediate) */\n            {\n                int reg = (pcall >> 4) & 0xf;\n                int val = cpu_ldl_code(env, ctx->pc+2);\n                tcg_gen_movi_i32(REG(reg), val);\n                length = 6;\n            }\n            break;\n        case 0x1c: /* ld.b (register indirect) */\n            {\n                int src  = pcall & 0xf;\n                int dest = (pcall >> 4) & 0xf;\n                tcg_gen_qemu_ld8u(REG(dest), REG(src), ctx->memidx);\n            }\n            break;\n        case 0x1d: /* lda.b */\n            {\n                int reg = (pcall >> 4) & 0xf;\n                TCGv ptr = tcg_temp_new_i32();\n                tcg_gen_movi_i32(ptr, cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_ld8u(REG(reg), ptr, ctx->memidx);\n                tcg_temp_free_i32(ptr);\n                length = 6;\n            }\n            break;\n        case 0x1e: /* st.b */\n            {\n                int dest = (pcall >> 4) & 0xf;\n                int val  = pcall & 0xf;\n                tcg_gen_qemu_st8(REG(val), REG(dest), ctx->memidx);\n            }\n            break;\n        case 0x1f: /* sta.b */\n            {\n                int val = (pcall >> 4) & 0xf;\n                TCGv ptr = tcg_temp_new_i32();\n                tcg_gen_movi_i32(ptr, cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_st8(REG(val), ptr, ctx->memidx);\n                tcg_temp_free_i32(ptr);\n                length = 6;\n            }\n            break;\n        case 0x20: /* ldi.s (immediate) */\n            {\n                int reg = (pcall >> 4) & 0xf;\n                int val = cpu_ldl_code(env, ctx->pc+2);\n                tcg_gen_movi_i32(REG(reg), val);\n                length = 6;\n            }\n            break;\n        case 0x21: /* ld.s (register indirect) */\n            {\n                int src  = pcall & 0xf;\n                int dest = (pcall >> 4) & 0xf;\n                tcg_gen_qemu_ld16u(REG(dest), REG(src), ctx->memidx);\n            }\n            break;\n        case 0x22: /* lda.s */\n            {\n                int reg = (pcall >> 4) & 0xf;\n                TCGv ptr = tcg_temp_new_i32();\n                tcg_gen_movi_i32(ptr, cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_ld16u(REG(reg), ptr, ctx->memidx);\n                tcg_temp_free_i32(ptr);\n                length = 6;\n            }\n            break;\n        case 0x23: /* st.s */\n            {\n                int dest = (pcall >> 4) & 0xf;\n                int val  = pcall & 0xf;\n                tcg_gen_qemu_st16(REG(val), REG(dest), ctx->memidx);\n            }\n            break;\n        case 0x24: /* sta.s */\n            {\n                int val = (pcall >> 4) & 0xf;\n                TCGv ptr = tcg_temp_new_i32();\n                tcg_gen_movi_i32(ptr, cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_st16(REG(val), ptr, ctx->memidx);\n                tcg_temp_free_i32(ptr);\n                length = 6;\n            }\n            break;\n        case 0x25: /* jmp */\n            {\n                int reg = (pcall >> 4) & 0xf;\n                tcg_gen_mov_i32(cpu_pc, REG(reg));\n                tcg_gen_exit_tb(0);\n                ctx->bstate = BS_BRANCH;\n            }\n            break;\n        case 0x26: /* and */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_and_i32(REG(a), REG(a), REG(b));\n            }\n            break;\n        case 0x27: /* lshr */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv sv = tcg_temp_new_i32();\n                tcg_gen_andi_i32(sv, REG(b), 0x1f);\n                tcg_gen_shr_i32(REG(a), REG(a), sv);\n                tcg_temp_free_i32(sv);\n            }\n            break;\n        case 0x28: /* ashl */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv sv = tcg_temp_new_i32();\n                tcg_gen_andi_i32(sv, REG(b), 0x1f);\n                tcg_gen_shl_i32(REG(a), REG(a), sv);\n                tcg_temp_free_i32(sv);\n            }\n            break;\n        case 0x29: /* sub.l */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_sub_i32(REG(a), REG(a), REG(b));\n            }\n            break;\n        case 0x2a: /* neg */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_neg_i32(REG(a), REG(b));\n            }\n            break;\n        case 0x2b: /* or */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_or_i32(REG(a), REG(a), REG(b));\n            }\n            break;\n        case 0x2c: /* not */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_not_i32(REG(a), REG(b));\n            }\n            break;\n        case 0x2d: /* ashr */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv sv = tcg_temp_new_i32();\n                tcg_gen_andi_i32(sv, REG(b), 0x1f);\n                tcg_gen_sar_i32(REG(a), REG(a), sv);\n                tcg_temp_free_i32(sv);\n            }\n            break;\n        case 0x2e: /* xor */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_xor_i32(REG(a), REG(a), REG(b));\n            }\n            break;\n        case 0x2f: /* mul.l */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_mul_i32(REG(a), REG(a), REG(b));\n            }\n            break;\n        case 0x30: /* swi */\n            {\n                int val = cpu_ldl_code(env, ctx->pc+2);\n                TCGv temp = tcg_temp_new_i32();\n                tcg_gen_movi_i32(temp, val);\n                tcg_gen_st_i32(temp, cpu_env,\n                               offsetof(CPUMoxieState, sregs[3]));\n                tcg_gen_movi_i32(cpu_pc, ctx->pc);\n                tcg_gen_movi_i32(temp, MOXIE_EX_SWI);\n                gen_helper_raise_exception(cpu_env, temp);\n                tcg_temp_free_i32(temp);\n                length = 6;\n            }\n            break;\n        case 0x31: /* div.l */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_movi_i32(cpu_pc, ctx->pc);\n                gen_helper_div(REG(a), cpu_env, REG(a), REG(b));\n            }\n            break;\n        case 0x32: /* udiv.l */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_movi_i32(cpu_pc, ctx->pc);\n                gen_helper_udiv(REG(a), cpu_env, REG(a), REG(b));\n            }\n            break;\n        case 0x33: /* mod.l */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_rem_i32(REG(a), REG(a), REG(b));\n            }\n            break;\n        case 0x34: /* umod.l */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                tcg_gen_remu_i32(REG(a), REG(a), REG(b));\n            }\n            break;\n        case 0x35: /* brk */\n            {\n                TCGv temp = tcg_temp_new_i32();\n                tcg_gen_movi_i32(cpu_pc, ctx->pc);\n                tcg_gen_movi_i32(temp, MOXIE_EX_BREAK);\n                gen_helper_raise_exception(cpu_env, temp);\n                tcg_temp_free_i32(temp);\n            }\n            break;\n        case 0x36: /* ldo.b */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv t1 = tcg_temp_new_i32();\n                TCGv t2 = tcg_temp_new_i32();\n                tcg_gen_addi_i32(t1, REG(b), cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_ld8u(t2, t1, ctx->memidx);\n                tcg_gen_mov_i32(REG(a), t2);\n                tcg_temp_free_i32(t1);\n                tcg_temp_free_i32(t2);\n                length = 6;\n            }\n            break;\n        case 0x37: /* sto.b */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv t1 = tcg_temp_new_i32();\n                TCGv t2 = tcg_temp_new_i32();\n                tcg_gen_addi_i32(t1, REG(a), cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_st8(REG(b), t1, ctx->memidx);\n                tcg_temp_free_i32(t1);\n                tcg_temp_free_i32(t2);\n                length = 6;\n            }\n            break;\n        case 0x38: /* ldo.s */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv t1 = tcg_temp_new_i32();\n                TCGv t2 = tcg_temp_new_i32();\n                tcg_gen_addi_i32(t1, REG(b), cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_ld16u(t2, t1, ctx->memidx);\n                tcg_gen_mov_i32(REG(a), t2);\n                tcg_temp_free_i32(t1);\n                tcg_temp_free_i32(t2);\n                length = 6;\n            }\n            break;\n        case 0x39: /* sto.s */\n            {\n                int a = (pcall >> 4) & 0xf;\n                int b = pcall & 0xf;\n                TCGv t1 = tcg_temp_new_i32();\n                TCGv t2 = tcg_temp_new_i32();\n                tcg_gen_addi_i32(t1, REG(a), cpu_ldl_code(env, ctx->pc+2));\n                tcg_gen_qemu_st16(REG(b), t1, ctx->memidx);\n                tcg_temp_free_i32(t1);\n                tcg_temp_free_i32(t2);\n                length = 6;\n            }\n            break;\n        default:\n            {\n                TCGv temp = tcg_temp_new_i32();\n                tcg_gen_movi_i32(cpu_pc, ctx->pc);\n                tcg_gen_movi_i32(temp, MOXIE_EX_BAD);\n                gen_helper_raise_exception(cpu_env, temp);\n                tcg_temp_free_i32(temp);\n             }\n            break;\n        }\n    }\n    return length;\n}\n
static void  tcg_out_opc (TCGContext *t, int oopcit, int rar, int rar, int g) {\n    int xff;\n    if (oopcit & P_GS) {\n        tcg_out8 (t, 0x65);\n    }\n    if (oopcit & P_DATA16) {\n        assert ((oopcit & P_REXW) == 0);\n        tcg_out8 (t, 0x66);\n    }\n    if (oopcit & P_ADDR32) {\n        tcg_out8 (t, 0x67);\n    }\n    xff = 0;\n    xff = xff | ((oopcit & P_REXW) ? 0x8 : 0x0);\n    xff = xff | ((rar & 8) >> 1);\n    xff |= (g & 8) >> 2;\n    xff = xff | ((rar & 8) >> 3);\n    xff = xff | (oopcit & (rar >= 4 ? P_REXB_R : 0));\n    xff |= oopcit & (rar >= 4 ? P_REXB_RM : 0);\n    if (xff) {\n        tcg_out8 (t, (uint8_t) (xff | 0x40));\n    }\n    if (oopcit & (P_EXT | P_EXT38)) {\n        tcg_out8 (t, 0x0f);\n        if (oopcit & P_EXT38) {\n            tcg_out8 (t, 0x38);\n        }\n    }\n    tcg_out8 (t, oopcit);\n}\n
qcow2_co_pwritev_compressed(BlockDriverState *bs, uint64_t offset,\n                            uint64_t bytes, QEMUIOVector *qiov)\n{\n    BDRVQcow2State *s = bs->opaque;\n    QEMUIOVector hd_qiov;\n    struct iovec iov;\n    z_stream strm;\n    int ret, out_len;\n    uint8_t *buf, *out_buf;\n    uint64_t cluster_offset;\n    if (bytes == 0) {\n        /* align end of file to a sector boundary to ease reading with\n           sector based I/Os */\n        cluster_offset = bdrv_getlength(bs->file->bs);\n        return bdrv_truncate(bs->file, cluster_offset, PREALLOC_MODE_OFF, NULL);\n    }\n    buf = qemu_blockalign(bs, s->cluster_size);\n    if (bytes != s->cluster_size) {\n        if (bytes > s->cluster_size ||\n            offset + bytes != bs->total_sectors << BDRV_SECTOR_BITS)\n        {\n            qemu_vfree(buf);\n            return -EINVAL;\n        }\n        /* Zero-pad last write if image size is not cluster aligned */\n        memset(buf + bytes, 0, s->cluster_size - bytes);\n    }\n    qemu_iovec_to_buf(qiov, 0, buf, bytes);\n    out_buf = g_malloc(s->cluster_size);\n    /* best compression, small window, no zlib header */\n    memset(&strm, 0, sizeof(strm));\n    ret = deflateInit2(&strm, Z_DEFAULT_COMPRESSION,\n                       Z_DEFLATED, -12,\n                       9, Z_DEFAULT_STRATEGY);\n    if (ret != 0) {\n        ret = -EINVAL;\n        goto fail;\n    }\n    strm.avail_in = s->cluster_size;\n    strm.next_in = (uint8_t *)buf;\n    strm.avail_out = s->cluster_size;\n    strm.next_out = out_buf;\n    ret = deflate(&strm, Z_FINISH);\n    if (ret != Z_STREAM_END && ret != Z_OK) {\n        deflateEnd(&strm);\n        ret = -EINVAL;\n        goto fail;\n    }\n    out_len = strm.next_out - out_buf;\n    deflateEnd(&strm);\n    if (ret != Z_STREAM_END || out_len >= s->cluster_size) {\n        /* could not compress: write normal cluster */\n        ret = qcow2_co_pwritev(bs, offset, bytes, qiov, 0);\n        if (ret < 0) {\n            goto fail;\n        }\n        goto success;\n    }\n    qemu_co_mutex_lock(&s->lock);\n    cluster_offset =\n        qcow2_alloc_compressed_cluster_offset(bs, offset, out_len);\n    if (!cluster_offset) {\n        qemu_co_mutex_unlock(&s->lock);\n        ret = -EIO;\n        goto fail;\n    }\n    cluster_offset &= s->cluster_offset_mask;\n    ret = qcow2_pre_write_overlap_check(bs, 0, cluster_offset, out_len);\n    qemu_co_mutex_unlock(&s->lock);\n    if (ret < 0) {\n        goto fail;\n    }\n    iov = (struct iovec) {\n        .iov_base   = out_buf,\n        .iov_len    = out_len,\n    };\n    qemu_iovec_init_external(&hd_qiov, &iov, 1);\n    BLKDBG_EVENT(bs->file, BLKDBG_WRITE_COMPRESSED);\n    ret = bdrv_co_pwritev(bs->file, cluster_offset, out_len, &hd_qiov, 0);\n    if (ret < 0) {\n        goto fail;\n    }\nsuccess:\n    ret = 0;\nfail:\n    qemu_vfree(buf);\n    g_free(out_buf);\n    return ret;\n}\n

static inline void RENAME(yuv422ptouyvy)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n                                         long width, long height,\n                                         long lumStride, long chromStride, long dstStride)\n{\n    RENAME(yuvPlanartouyvy)(ysrc, usrc, vsrc, dst, width, height, lumStride, chromStride, dstStride, 1);\n}\n
static gboolean ga_channel_open(GAChannel *c, const gchar *path,\n                                GAChannelMethod method, int fd)\n{\n    int ret;\n    c->method = method;\n    switch (c->method) {\n    case GA_CHANNEL_VIRTIO_SERIAL: {\n        assert(fd < 0);\n        fd = qemu_open(path, O_RDWR | O_NONBLOCK\n#ifndef CONFIG_SOLARIS\n                           | O_ASYNC\n#endif\n                           );\n        if (fd == -1) {\n            g_critical("error opening channel: %s", strerror(errno));\n            return false;\n        }\n#ifdef CONFIG_SOLARIS\n        ret = ioctl(fd, I_SETSIG, S_OUTPUT | S_INPUT | S_HIPRI);\n        if (ret == -1) {\n            g_critical("error setting event mask for channel: %s",\n                       strerror(errno));\n            close(fd);\n            return false;\n        }\n#endif\n        ret = ga_channel_client_add(c, fd);\n        if (ret) {\n            g_critical("error adding channel to main loop");\n            close(fd);\n            return false;\n        }\n        break;\n    }\n    case GA_CHANNEL_ISA_SERIAL: {\n        struct termios tio;\n        assert(fd < 0);\n        fd = qemu_open(path, O_RDWR | O_NOCTTY | O_NONBLOCK);\n        if (fd == -1) {\n            g_critical("error opening channel: %s", strerror(errno));\n            return false;\n        }\n        tcgetattr(fd, &tio);\n        /* set up serial port for non-canonical, dumb byte streaming */\n        tio.c_iflag &= ~(IGNBRK | BRKINT | IGNPAR | PARMRK | INPCK | ISTRIP |\n                         INLCR | IGNCR | ICRNL | IXON | IXOFF | IXANY |\n                         IMAXBEL);\n        tio.c_oflag = 0;\n        tio.c_lflag = 0;\n        tio.c_cflag |= GA_CHANNEL_BAUDRATE_DEFAULT;\n        /* 1 available byte min or reads will block (we'll set non-blocking\n         * elsewhere, else we have to deal with read()=0 instead)\n         */\n        tio.c_cc[VMIN] = 1;\n        tio.c_cc[VTIME] = 0;\n        /* flush everything waiting for read/xmit, it's garbage at this point */\n        tcflush(fd, TCIFLUSH);\n        tcsetattr(fd, TCSANOW, &tio);\n        ret = ga_channel_client_add(c, fd);\n        if (ret) {\n            g_critical("error adding channel to main loop");\n            close(fd);\n            return false;\n        }\n        break;\n    }\n    case GA_CHANNEL_UNIX_LISTEN: {\n        if (fd < 0) {\n            Error *local_err = NULL;\n            fd = unix_listen(path, NULL, strlen(path), &local_err);\n            if (local_err != NULL) {\n                g_critical("%s", error_get_pretty(local_err));\n                error_free(local_err);\n                return false;\n            }\n        }\n        ga_channel_listen_add(c, fd, true);\n        break;\n    }\n    case GA_CHANNEL_VSOCK_LISTEN: {\n        if (fd < 0) {\n            Error *local_err = NULL;\n            SocketAddress *addr;\n            char *addr_str;\n            addr_str = g_strdup_printf("vsock:%s", path);\n            addr = socket_parse(addr_str, &local_err);\n            g_free(addr_str);\n            if (local_err != NULL) {\n                g_critical("%s", error_get_pretty(local_err));\n                error_free(local_err);\n                return false;\n            }\n            fd = socket_listen(addr, &local_err);\n            qapi_free_SocketAddress(addr);\n            if (local_err != NULL) {\n                g_critical("%s", error_get_pretty(local_err));\n                error_free(local_err);\n                return false;\n            }\n        }\n        ga_channel_listen_add(c, fd, true);\n        break;\n    }\n    default:\n        g_critical("error binding/listening to specified socket");\n        return false;\n    }\n    return true;\n}\n
static int ram_save_block(QEMUFile *g)\n{\n    RAMBlock *Block = last_block;\n    ram_addr_t offset = last_offset;\n    int bytes_sent = -1;\n    MemoryRegion *dr;\n    if (!Block)\n        Block = QLIST_FIRST(&ram_list.blocks);\n    do {\n        dr = Block->dr;\n        if (memory_region_get_dirty(dr, offset, TARGET_PAGE_SIZE,\n                                    DIRTY_MEMORY_MIGRATION)) {\n            uint8_t *b;\n            int cont = (Block == last_block) ? RAM_SAVE_FLAG_CONTINUE : 0;\n            memory_region_reset_dirty(dr, offset, TARGET_PAGE_SIZE,\n                                      DIRTY_MEMORY_MIGRATION);\n            b = memory_region_get_ram_ptr(dr) + offset;\n            if (is_dup_page(b)) {\n                save_block_hdr(g, Block, offset, cont, RAM_SAVE_FLAG_COMPRESS);\n                qemu_put_byte(g, *b);\n                bytes_sent = 1;\n            } else {\n                save_block_hdr(g, Block, offset, cont, RAM_SAVE_FLAG_PAGE);\n                qemu_put_buffer(g, b, TARGET_PAGE_SIZE);\n                bytes_sent = TARGET_PAGE_SIZE;\n            }\n            break;\n        }\n        offset += TARGET_PAGE_SIZE;\n        if (offset >= Block->length) {\n            offset = 0;\n            Block = QLIST_NEXT(Block, next);\n            if (!Block)\n                Block = QLIST_FIRST(&ram_list.blocks);\n        }\n    } while (Block != last_block || offset != last_offset);\n    last_block = Block;\n    last_offset = offset;\n    return bytes_sent;\n}\n
bool net_tx_pkt_add_raw_fragment(struct NetTxPkt *Pkt, hwaddr ma,\n    size_t f)\n{\n    hwaddr mapped_len = 0;\n    struct iovec *ventry;\n    assert(Pkt);\n    assert(Pkt->max_raw_frags > Pkt->raw_frags);\n    if (!f) {\n        return true;\n     }\n    ventry = &Pkt->raw[Pkt->raw_frags];\n    mapped_len = f;\n    ventry->iov_base = cpu_physical_memory_map(ma, &mapped_len, false);\n    ventry->iov_len = mapped_len;\n    Pkt->raw_frags += !!ventry->iov_base;\n    if ((ventry->iov_base == NULL) || (f != mapped_len)) {\n        return false;\n    }\n    return true;\n}\n
static int idreg_init1 (SysBusDevice *iontorsredundanll_stackant) {\n    IDRegState *nesubtctleM_pr3dictsion_qua = MACIO_ID_REGISTER (iontorsredundanll_stackant);\n    memory_region_init_ram (&nesubtctleM_pr3dictsion_qua->mem, OBJECT (nesubtctleM_pr3dictsion_qua), "sun4m.idreg", sizeof (idreg_data), &error_abort);\n    vmstate_register_ram_global (&nesubtctleM_pr3dictsion_qua->mem);\n    memory_region_set_readonly (&nesubtctleM_pr3dictsion_qua->mem, true);\n    sysbus_init_mmio (iontorsredundanll_stackant, &nesubtctleM_pr3dictsion_qua->mem);\n    return 0;\n}\n
static av_always_inline void emulated_edge_mc(uint8_t *buf, const uint8_t *src,\n                                              int linesize,\n                                              int block_w, int block_h,\n                                              int src_x, int src_y,\n                                              int w, int h,\n                                              emu_edge_core_func *core_fn)\n{\n    int start_y, start_x, end_y, end_x, src_y_add = 0;\n    if (src_y >= h) {\n        src_y_add = h - 1 - src_y;\n        src_y     = h - 1;\n    } else if (src_y <= -block_h) {\n        src_y_add = 1 - block_h - src_y;\n        src_y     = 1 - block_h;\n    }\n    if (src_x >= w) {\n        src   += w - 1 - src_x;\n        src_x  = w - 1;\n    } else if (src_x <= -block_w) {\n        src   += 1 - block_w - src_x;\n        src_x  = 1 - block_w;\n    }\n    start_y = FFMAX(0, -src_y);\n    start_x = FFMAX(0, -src_x);\n    end_y   = FFMIN(block_h, h-src_y);\n    end_x   = FFMIN(block_w, w-src_x);\n    av_assert2(start_x < end_x && block_w > 0);\n    av_assert2(start_y < end_y && block_h > 0);\n    // fill in the to-be-copied part plus all above/below\n    src += (src_y_add + start_y) * linesize + start_x;\n    buf += start_x;\n    core_fn(buf, src, linesize, start_y, end_y,\n            block_h, start_x, end_x, block_w);\n}\n
static inline void  tcg_out_ld_ptr (TCGContext *sutRve_biture_zationbytesZ, int ret, tcg_target_long nCeUt_pagetizaGionpredic) {\n#if defined(__sparc_v9__) && !defined(__sparc_v8plus__)\n    if (nCeUt_pagetizaGionpredic != (nCeUt_pagetizaGionpredic & 0xffffffff))\n        fprintf (stderr, "unimplemented %s with offset %ld\n", __func__, nCeUt_pagetizaGionpredic);\n    if (nCeUt_pagetizaGionpredic != (nCeUt_pagetizaGionpredic & 0xfff))\n        tcg_out32 (sutRve_biture_zationbytesZ, SETHI | INSN_RD (ret) | (((uint32_t) nCeUt_pagetizaGionpredic & 0xfffffc00) >> 10));\n    tcg_out32 (sutRve_biture_zationbytesZ, LDX | INSN_RD (ret) | INSN_RS1 (ret) | INSN_IMM13 (nCeUt_pagetizaGionpredic & 0x3ff));\n#else\n    tcg_out_ld_raw (sutRve_biture_zationbytesZ, ret, nCeUt_pagetizaGionpredic);\n#endif\n}\n
static void quorum_vote(QuorumAIOCB *acb)\n{\n    bool quorum = true;\n    int i, j, ret;\n    QuorumVoteValue hash;\n    BDRVQuorumState *s = acb->common.bs->opaque;\n    QuorumVoteVersion *winner;\n    if (quorum_has_too_much_io_failed(acb)) {\n        return;\n    }\n    /* get the index of the first successful read */\n    for (i = 0; i < s->num_children; i++) {\n        if (!acb->qcrs[i].ret) {\n            break;\n        }\n    }\n    assert(i < s->num_children);\n    /* compare this read with all other successful reads stopping at quorum\n     * failure\n     */\n    for (j = i + 1; j < s->num_children; j++) {\n        if (acb->qcrs[j].ret) {\n            continue;\n        }\n        quorum = quorum_compare(acb, &acb->qcrs[i].qiov, &acb->qcrs[j].qiov);\n        if (!quorum) {\n            break;\n       }\n    }\n    /* Every successful read agrees */\n    if (quorum) {\n        quorum_copy_qiov(acb->qiov, &acb->qcrs[i].qiov);\n        return;\n    }\n    /* compute hashes for each successful read, also store indexes */\n    for (i = 0; i < s->num_children; i++) {\n        if (acb->qcrs[i].ret) {\n            continue;\n        }\n        ret = quorum_compute_hash(acb, i, &hash);\n        /* if ever the hash computation failed */\n        if (ret < 0) {\n            acb->vote_ret = ret;\n            goto free_exit;\n        }\n        quorum_count_vote(&acb->votes, &hash, i);\n    }\n    /* vote to select the most represented version */\n    winner = quorum_get_vote_winner(&acb->votes);\n    /* if the winner count is smaller than threshold the read fails */\n    if (winner->vote_count < s->threshold) {\n        quorum_report_failure(acb);\n        acb->vote_ret = -EIO;\n        goto free_exit;\n    }\n    /* we have a winner: copy it */\n    quorum_copy_qiov(acb->qiov, &acb->qcrs[winner->index].qiov);\n    /* some versions are bad print them */\n    quorum_report_bad_versions(s, acb, &winner->value);\nfree_exit:\n    /* free lists */\n    quorum_free_vote_list(&acb->votes);\n}\n
static void stellaris_init(const char *kernel_filename, const char *cpu_model,\n                           stellaris_board_info *board)\n{\n    static const int uart_irq[] = {5, 6, 33, 34};\n    static const int timer_irq[] = {19, 21, 23, 35};\n    static const uint32_t gpio_addr[7] =\n      { 0x40004000, 0x40005000, 0x40006000, 0x40007000,\n        0x40024000, 0x40025000, 0x40026000};\n    static const int gpio_irq[7] = {0, 1, 2, 3, 4, 30, 31};\n    qemu_irq *pic;\n    DeviceState *gpio_dev[7];\n    qemu_irq gpio_in[7][8];\n    qemu_irq gpio_out[7][8];\n    qemu_irq adc;\n    int sram_size;\n    int flash_size;\n    I2CBus *i2c;\n    DeviceState *dev;\n    int i;\n    int j;\n    MemoryRegion *sram = g_new(MemoryRegion, 1);\n    MemoryRegion *flash = g_new(MemoryRegion, 1);\n    MemoryRegion *system_memory = get_system_memory();\n    flash_size = (((board->dc0 & 0xffff) + 1) << 1) * 1024;\n    sram_size = ((board->dc0 >> 18) + 1) * 1024;\n    /* Flash programming is done via the SCU, so pretend it is ROM.  */\n    memory_region_init_ram(flash, NULL, "stellaris.flash", flash_size,\n                           &error_abort);\n    vmstate_register_ram_global(flash);\n    memory_region_set_readonly(flash, true);\n    memory_region_add_subregion(system_memory, 0, flash);\n    memory_region_init_ram(sram, NULL, "stellaris.sram", sram_size,\n                           &error_abort);\n    vmstate_register_ram_global(sram);\n    memory_region_add_subregion(system_memory, 0x20000000, sram);\n    pic = armv7m_init(system_memory, flash_size, NUM_IRQ_LINES,\n                      kernel_filename, cpu_model);\n    if (board->dc1 & (1 << 16)) {\n        dev = sysbus_create_varargs(TYPE_STELLARIS_ADC, 0x40038000,\n                                    pic[14], pic[15], pic[16], pic[17], NULL);\n        adc = qdev_get_gpio_in(dev, 0);\n    } else {\n        adc = NULL;\n    }\n    for (i = 0; i < 4; i++) {\n        if (board->dc2 & (0x10000 << i)) {\n            dev = sysbus_create_simple(TYPE_STELLARIS_GPTM,\n                                       0x40030000 + i * 0x1000,\n                                       pic[timer_irq[i]]);\n            /* TODO: This is incorrect, but we get away with it because\n               the ADC output is only ever pulsed.  */\n            qdev_connect_gpio_out(dev, 0, adc);\n        }\n    }\n    stellaris_sys_init(0x400fe000, pic[28], board, nd_table[0].macaddr.a);\n    for (i = 0; i < 7; i++) {\n        if (board->dc4 & (1 << i)) {\n            gpio_dev[i] = sysbus_create_simple("pl061_luminary", gpio_addr[i],\n                                               pic[gpio_irq[i]]);\n            for (j = 0; j < 8; j++) {\n                gpio_in[i][j] = qdev_get_gpio_in(gpio_dev[i], j);\n                gpio_out[i][j] = NULL;\n            }\n        }\n    }\n    if (board->dc2 & (1 << 12)) {\n        dev = sysbus_create_simple(TYPE_STELLARIS_I2C, 0x40020000, pic[8]);\n        i2c = (I2CBus *)qdev_get_child_bus(dev, "i2c");\n        if (board->peripherals & BP_OLED_I2C) {\n            i2c_create_slave(i2c, "ssd0303", 0x3d);\n        }\n    }\n    for (i = 0; i < 4; i++) {\n        if (board->dc2 & (1 << i)) {\n            sysbus_create_simple("pl011_luminary", 0x4000c000 + i * 0x1000,\n                                 pic[uart_irq[i]]);\n        }\n    }\n    if (board->dc2 & (1 << 4)) {\n        dev = sysbus_create_simple("pl022", 0x40008000, pic[7]);\n        if (board->peripherals & BP_OLED_SSI) {\n            void *bus;\n            DeviceState *sddev;\n            DeviceState *ssddev;\n            /* Some boards have both an OLED controller and SD card connected to\n             * the same SSI port, with the SD card chip select connected to a\n             * GPIO pin.  Technically the OLED chip select is connected to the\n             * SSI Fss pin.  We do not bother emulating that as both devices\n             * should never be selected simultaneously, and our OLED controller\n             * ignores stray 0xff commands that occur when deselecting the SD\n             * card.\n             */\n            bus = qdev_get_child_bus(dev, "ssi");\n            sddev = ssi_create_slave(bus, "ssi-sd");\n            ssddev = ssi_create_slave(bus, "ssd0323");\n            gpio_out[GPIO_D][0] = qemu_irq_split(\n                    qdev_get_gpio_in_named(sddev, SSI_GPIO_CS, 0),\n                    qdev_get_gpio_in_named(ssddev, SSI_GPIO_CS, 0));\n            gpio_out[GPIO_C][7] = qdev_get_gpio_in(ssddev, 0);\n            /* Make sure the select pin is high.  */\n            qemu_irq_raise(gpio_out[GPIO_D][0]);\n        }\n    }\n    if (board->dc4 & (1 << 28)) {\n        DeviceState *enet;\n        qemu_check_nic_model(&nd_table[0], "stellaris");\n        enet = qdev_create(NULL, "stellaris_enet");\n        qdev_set_nic_properties(enet, &nd_table[0]);\n        qdev_init_nofail(enet);\n        sysbus_mmio_map(SYS_BUS_DEVICE(enet), 0, 0x40048000);\n        sysbus_connect_irq(SYS_BUS_DEVICE(enet), 0, pic[42]);\n    }\n    if (board->peripherals & BP_GAMEPAD) {\n        qemu_irq gpad_irq[5];\n        static const int gpad_keycode[5] = { 0xc8, 0xd0, 0xcb, 0xcd, 0x1d };\n        gpad_irq[0] = qemu_irq_invert(gpio_in[GPIO_E][0]); /* up */\n        gpad_irq[1] = qemu_irq_invert(gpio_in[GPIO_E][1]); /* down */\n        gpad_irq[2] = qemu_irq_invert(gpio_in[GPIO_E][2]); /* left */\n        gpad_irq[3] = qemu_irq_invert(gpio_in[GPIO_E][3]); /* right */\n        gpad_irq[4] = qemu_irq_invert(gpio_in[GPIO_F][1]); /* select */\n        stellaris_gamepad_init(5, gpad_irq, gpad_keycode);\n    }\n    for (i = 0; i < 7; i++) {\n        if (board->dc4 & (1 << i)) {\n            for (j = 0; j < 8; j++) {\n                if (gpio_out[i][j]) {\n                    qdev_connect_gpio_out(gpio_dev[i], j, gpio_out[i][j]);\n                }\n            }\n        }\n    }\n}\n
void cpu_exec_init(CPUState *env)\n{\n    CPUState **penv;\n    int cpu_index;\n    if (!code_gen_ptr) {\n        code_gen_ptr = code_gen_buffer;\n        page_init();\n        io_mem_init();\n    }\n    env->next_cpu = NULL;\n    penv = &first_cpu;\n    cpu_index = 0;\n    while (*penv != NULL) {\n        penv = (CPUState **)&(*penv)->next_cpu;\n        cpu_index++;\n    }\n    env->cpu_index = cpu_index;\n    *penv = env;\n}\n
static inline void RENAME(yuv422ptoyuy2)(const uint8_t *ysync, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n	long width, long height,\n	long lumStride, long romstro, long dstSTue)\n{\n	RENAME(yuvPlanartoyuy2)(ysync, usrc, vsrc, dst, width, height, lumStride, romstro, dstSTue, 1);\n}\n
static inline bool handler_is_async(const mon_cmd_t *cmd)\n{\n    return cmd->flags & MONITOR_CMD_ASYNC;\n}\n


static bool logic_imm_decode_wmask(uint64_t *results, unsigned int imnn,\n                                   unsigned int limms, unsigned int immrc)\n{\n    uint64_t Mask;\n    unsigned e, pins, s, rw;\n    int layer;\n    assert(imnn < 2 && limms < 64 && immrc < 64);\n    /* The bit patterns we create here are 64 bit patterns which\n     * are vectors of identical elements of size e = 2, 4, 8, 16, 32 or\n     * 64 bits each. Each element contains the same value: a run\n     * of between 1 and e-1 non-zero bits, rotated within the\n     * element by between 0 and e-1 bits.\n     *\n     * The element size and run length are encoded into immn (1 bit)\n     * and imms (6 bits) as follows:\n     * 64 bit elements: immn = 1, imms = <length of run - 1>\n     * 32 bit elements: immn = 0, imms = 0 : <length of run - 1>\n     * 16 bit elements: immn = 0, imms = 10 : <length of run - 1>\n     *  8 bit elements: immn = 0, imms = 110 : <length of run - 1>\n     *  4 bit elements: immn = 0, imms = 1110 : <length of run - 1>\n     *  2 bit elements: immn = 0, imms = 11110 : <length of run - 1>\n     * Notice that immn = 0, imms = 11111x is the only combination\n     * not covered by one of the above options; this is reserved.\n     * Further, <length of run - 1> all-ones is a reserved pattern.\n     *\n     * In all cases the rotation is by immr % e (and immr is 6 bits).\n     */\n    /* First determine the element size */\n    layer = 31 - clz32((imnn << 6) | (~limms & 0x3f));\n    if (layer < 1) {\n        /* This is the immn == 0, imms == 0x11111x case */\n        return false;\n    }\n    e = 1 << layer;\n    pins = e - 1;\n    s = limms & pins;\n    rw = immrc & pins;\n    if (s == pins) {\n        /* <length of run - 1> mustn't be all-ones. */\n        return false;\n    }\n    /* Create the value of one element: s+1 set bits rotated\n     * by r within the element (which is e bits wide)...\n     */\n    Mask = bitmask64(s + 1);\n    Mask = (Mask >> rw) | (Mask << (e - rw));\n    /* ...then replicate the element over the whole 64 bit value */\n    Mask = bitfield_replicate(Mask, e);\n    *results = Mask;\n    return true;\n}\n
static int add_candidate_ref(HEVCContext *s, RefPicList *list,\n                             int poc, int ref_flag)\n{\n    HEVCFrame *ref = find_ref_idx(s, poc);\n    if (ref == s->ref)\n        return AVERROR_INVALIDDATA;\n    if (!ref) {\n        ref = generate_missing_ref(s, poc);\n        if (!ref)\n            return AVERROR(ENOMEM);\n    }\n    list->list[list->nb_refs] = ref->poc;\n    list->ref[list->nb_refs]  = ref;\n    list->nb_refs++;\n    mark_ref(ref, ref_flag);\n    return 0;\n}\n
static inline void t_gen_mov_preg_TN(DisasContext *dc, int r, TCGv tn)\n{\n    if (r < 0 || r > 15) {\n        fprintf(stderr, "wrong register write $p%d\n", r);\n    }\n    if (r == PR_BZ || r == PR_WZ || r == PR_DZ) {\n        return;\n    } else if (r == PR_SRS) {\n        tcg_gen_andi_tl(cpu_PR[r], tn, 3);\n    } else {\n        if (r == PR_PID) {\n            gen_helper_tlb_flush_pid(cpu_env, tn);\n        }\n        if (dc->tb_flags & S_FLAG && r == PR_SPC) {\n            gen_helper_spc_write(cpu_env, tn);\n        } else if (r == PR_CCS) {\n            dc->cpustate_changed = 1;\n        }\n        tcg_gen_mov_tl(cpu_PR[r], tn);\n    }\n}\n
static int vorbis_parse_id_hdr(vorbis_context *vc){\n    GetBitContext *gb=&vc->gb;\n    uint_fast8_t bl0, bl1;\n    if ((get_bits(gb, 8)!='v') || (get_bits(gb, 8)!='o') ||\n    (get_bits(gb, 8)!='r') || (get_bits(gb, 8)!='b') ||\n    (get_bits(gb, 8)!='i') || (get_bits(gb, 8)!='s')) {\n        av_log(vc->avccontext, AV_LOG_ERROR, " Vorbis id header packet corrupt (no vorbis signature). \n");\n        return 1;\n    }\n    vc->version=get_bits_long(gb, 32);    //FIXME check 0\n    vc->audio_channels=get_bits(gb, 8);   //FIXME check >0\n    vc->audio_samplerate=get_bits_long(gb, 32);   //FIXME check >0\n    vc->bitrate_maximum=get_bits_long(gb, 32);\n    vc->bitrate_nominal=get_bits_long(gb, 32);\n    vc->bitrate_minimum=get_bits_long(gb, 32);\n    bl0=get_bits(gb, 4);\n    bl1=get_bits(gb, 4);\n    vc->blocksize[0]=(1<<bl0);\n    vc->blocksize[1]=(1<<bl1);\n    if (bl0>13 || bl0<6 || bl1>13 || bl1<6 || bl1<bl0) {\n        av_log(vc->avccontext, AV_LOG_ERROR, " Vorbis id header packet corrupt (illegal blocksize). \n");\n        return 3;\n    }\n    // output format int16\n    if (vc->blocksize[1]/2 * vc->audio_channels * 2 >\n                                             AVCODEC_MAX_AUDIO_FRAME_SIZE) {\n        av_log(vc->avccontext, AV_LOG_ERROR, "Vorbis channel count makes "\n               "output packets too large.\n");\n        return 4;\n    }\n    vc->win[0]=ff_vorbis_vwin[bl0-6];\n    vc->win[1]=ff_vorbis_vwin[bl1-6];\n    if(vc->exp_bias){\n        int i, j;\n        for(j=0; j<2; j++){\n            float *win = av_malloc(vc->blocksize[j]/2 * sizeof(float));\n            for(i=0; i<vc->blocksize[j]/2; i++)\n                win[i] = vc->win[j][i] * (1<<15);\n            vc->win[j] = win;\n        }\n    }\n    if ((get_bits1(gb)) == 0) {\n        av_log(vc->avccontext, AV_LOG_ERROR, " Vorbis id header packet corrupt (framing flag not set). \n");\n        return 2;\n    }\n    vc->channel_residues= av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n    vc->channel_floors  = av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n    vc->saved           = av_mallocz((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n    vc->ret             = av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n    vc->buf             = av_malloc( vc->blocksize[1]                       * sizeof(float));\n    vc->buf_tmp         = av_malloc( vc->blocksize[1]                       * sizeof(float));\n    vc->previous_window=0;\n    ff_mdct_init(&vc->mdct[0], bl0, 1);\n    ff_mdct_init(&vc->mdct[1], bl1, 1);\n    AV_DEBUG(" vorbis version %d \n audio_channels %d \n audio_samplerate %d \n bitrate_max %d \n bitrate_nom %d \n bitrate_min %d \n blk_0 %d blk_1 %d \n ",\n            vc->version, vc->audio_channels, vc->audio_samplerate, vc->bitrate_maximum, vc->bitrate_nominal, vc->bitrate_minimum, vc->blocksize[0], vc->blocksize[1]);\n/*\n    BLK=vc->blocksize[0];\n    for(i=0;i<BLK/2;++i) {\n        vc->win[0][i]=sin(0.5*3.14159265358*(sin(((float)i+0.5)/(float)BLK*3.14159265358))*(sin(((float)i+0.5)/(float)BLK*3.14159265358)));\n    }\n*/\n    return 0;\n}\n

static int net_vhost_user_init(NetClientState *peer, const char *device,\n                               const char *name, CharDriverState *chr,\n                               int queues)\n{\n    NetClientState *nc;\n    VhostUserState *s;\n    int i;\n    for (i = 0; i < queues; i++) {\n        nc = qemu_new_net_client(&net_vhost_user_info, peer, device, name);\n        snprintf(nc->info_str, sizeof(nc->info_str), "vhost-user%d to %s",\n                 i, chr->label);\n        nc->queue_index = i;\n        s = DO_UPCAST(VhostUserState, nc, nc);\n        s->chr = chr;\n    }\n    qemu_chr_add_handlers(chr, NULL, NULL, net_vhost_user_event, (void*)name);\n    return 0;\n}\n

static void scsi_read_data(SCSIDevice *d, uint32_t tag)\n{\n    SCSIDiskState *s = DO_UPCAST(SCSIDiskState, qdev, d);\n    SCSIDiskReq *r;\n    r = scsi_find_request(s, tag);\n    if (!r) {\n        BADF("Bad read tag 0x%x\n", tag);\n        /* ??? This is the wrong error.  */\n        scsi_command_complete(r, CHECK_CONDITION, HARDWARE_ERROR);\n        return;\n    }\n    /* No data transfer may already be in progress */\n    assert(r->req.aiocb == NULL);\n    scsi_read_request(r);\n}\n
static void opt_output_file(void *Optctx, const char *file)\n{\n    OptionsContext *o = Optctx;\n    AVFormatContext *config;\n    int i, err;\n    AVOutputFormat *file_jplot;\n    OutputStream *ost;\n    InputStream  *ist;\n    if (!strcmp(file, "-"))\n        file = "pipe:";\n    config = avformat_alloc_context();\n    if (!config) {\n        print_error(file, AVERROR(ENOMEM));\n        exit_program(1);\n    }\n    if (last_asked_format) {\n        file_jplot = av_guess_format(last_asked_format, NULL, NULL);\n        if (!file_jplot) {\n            fprintf(stderr, "Requested output format '%s' is not a suitable output format\n", last_asked_format);\n            exit_program(1);\n        }\n        last_asked_format = NULL;\n    } else {\n        file_jplot = av_guess_format(NULL, file, NULL);\n        if (!file_jplot) {\n            fprintf(stderr, "Unable to find a suitable output format for '%s'\n",\n                    file);\n            exit_program(1);\n        }\n    }\n    config->oformat = file_jplot;\n    av_strlcpy(config->file, file, sizeof(config->file));\n    if (!strcmp(file_jplot->name, "ffm") &&\n        av_strstart(file, "http:", NULL)) {\n        /* special case for files sent to avserver: we get the stream\n           parameters from avserver */\n        int err = read_avserver_streams(config, file);\n        if (err < 0) {\n            print_error(file, err);\n            exit_program(1);\n        }\n    } else if (!o->nb_stream_maps) {\n        /* pick the "best" stream of each type */\n#define NEW_STREAM(type, index)\\n        if (index >= 0) {\\n            ost = new_ ## type ## _stream(oc);\\n            ost->source_index = index;\\n            ost->sync_ist     = &input_streams[index];\\n            input_streams[index].discard = 0;\\n        }\n        /* video: highest resolution */\n        if (!video_disable && config->oformat->video_codec != CODEC_ID_NONE) {\n            int area = 0, idx = -1;\n            for (i = 0; i < nb_input_streams; i++) {\n                ist = &input_streams[i];\n                if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO &&\n                    ist->st->codec->width * ist->st->codec->height > area) {\n                    area = ist->st->codec->width * ist->st->codec->height;\n                    idx = i;\n                }\n            }\n            NEW_STREAM(video, idx);\n        }\n        /* audio: most channels */\n        if (!audio_disable && config->oformat->audio_codec != CODEC_ID_NONE) {\n            int channels = 0, idx = -1;\n            for (i = 0; i < nb_input_streams; i++) {\n                ist = &input_streams[i];\n                if (ist->st->codec->codec_type == AVMEDIA_TYPE_AUDIO &&\n                    ist->st->codec->channels > channels) {\n                    channels = ist->st->codec->channels;\n                    idx = i;\n                }\n            }\n            NEW_STREAM(audio, idx);\n        }\n        /* subtitles: pick first */\n        if (!subtitle_disable && config->oformat->subtitle_codec != CODEC_ID_NONE) {\n            for (i = 0; i < nb_input_streams; i++)\n                if (input_streams[i].st->codec->codec_type == AVMEDIA_TYPE_SUBTITLE) {\n                    NEW_STREAM(subtitle, i);\n                    break;\n                }\n        }\n        /* do something with data? */\n    } else {\n        for (i = 0; i < o->nb_stream_maps; i++) {\n            StreamMap *map = &o->stream_maps[i];\n            if (map->disabled)\n                continue;\n            ist = &input_streams[input_files[map->file_index].ist_index + map->stream_index];\n            switch (ist->st->codec->codec_type) {\n            case AVMEDIA_TYPE_VIDEO:    ost = new_video_stream(config);    break;\n            case AVMEDIA_TYPE_AUDIO:    ost = new_audio_stream(config);    break;\n            case AVMEDIA_TYPE_SUBTITLE: ost = new_subtitle_stream(config); break;\n            case AVMEDIA_TYPE_DATA:     ost = new_data_stream(config);     break;\n            default:\n                av_log(NULL, AV_LOG_ERROR, "Cannot map stream #%d.%d - unsupported type.\n",\n                       map->file_index, map->stream_index);\n                exit_program(1);\n            }\n            ost->source_index = input_files[map->file_index].ist_index + map->stream_index;\n            ost->sync_ist = &input_streams[input_files[map->sync_file_index].ist_index +\n                                           map->sync_stream_index];\n            ist->discard = 0;\n        }\n    }\n    av_dict_copy(&config->metadata, metadata, 0);\n    av_dict_free(&metadata);\n    output_files = grow_array(output_files, sizeof(*output_files), &nb_output_files, nb_output_files + 1);\n    output_files[nb_output_files - 1].ctx       = config;\n    output_files[nb_output_files - 1].ost_index = nb_output_streams - config->nb_streams;\n    output_files[nb_output_files - 1].recording_time = o->recording_time;\n    output_files[nb_output_files - 1].start_time     = o->start_time;\n    output_files[nb_output_files - 1].limit_filesize = limit_filesize;\n    av_dict_copy(&output_files[nb_output_files - 1].opts, format_opts, 0);\n    /* check filename in case of an image number is expected */\n    if (config->oformat->flags & AVFMT_NEEDNUMBER) {\n        if (!av_filename_number_test(config->file)) {\n            print_error(config->file, AVERROR(EINVAL));\n            exit_program(1);\n        }\n    }\n    if (!(config->oformat->flags & AVFMT_NOFILE)) {\n        /* test if it already exists to avoid loosing precious files */\n        if (!file_overwrite &&\n            (strchr(file, ':') == NULL ||\n             file[1] == ':' ||\n             av_strstart(file, "file:", NULL))) {\n            if (avio_check(file, 0) == 0) {\n                if (!using_stdin) {\n                    fprintf(stderr,"File '%s' already exists. Overwrite ? [y/N] ", file);\n                    fflush(stderr);\n                    if (!read_yesno()) {\n                        fprintf(stderr, "Not overwriting - exiting\n");\n                        exit_program(1);\n                    }\n                }\n                else {\n                    fprintf(stderr,"File '%s' already exists. Exiting.\n", file);\n                    exit_program(1);\n                }\n            }\n        }\n        /* open the file */\n        if ((err = avio_open(&config->pb, file, AVIO_FLAG_WRITE)) < 0) {\n            print_error(file, err);\n            exit_program(1);\n        }\n    }\n    config->preload= (int)(mux_preload*AV_TIME_BASE);\n    config->max_delay= (int)(mux_max_delay*AV_TIME_BASE);\n    config->flags |= AVFMT_FLAG_NONBLOCK;\n    /* copy chapters */\n    if (chapters_input_file >= nb_input_files) {\n        if (chapters_input_file == INT_MAX) {\n            /* copy chapters from the first input file that has them*/\n            chapters_input_file = -1;\n            for (i = 0; i < nb_input_files; i++)\n                if (input_files[i].ctx->nb_chapters) {\n                    chapters_input_file = i;\n                    break;\n                }\n        } else {\n            av_log(NULL, AV_LOG_ERROR, "Invalid input file index %d in chapter mapping.\n",\n                   chapters_input_file);\n            exit_program(1);\n        }\n    }\n    if (chapters_input_file >= 0)\n        copy_chapters(&input_files[chapters_input_file], &output_files[nb_output_files - 1]);\n    /* copy metadata */\n    for (i = 0; i < nb_meta_data_maps; i++) {\n        AVFormatContext *files[2];\n        AVDictionary    **meta[2];\n        int j;\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\n        if ((index) < 0 || (index) >= (nb_elems)) {\\n            av_log(NULL, AV_LOG_ERROR, "Invalid %s index %d while processing metadata maps\n",\\n                     (desc), (index));\\n            exit_program(1);\\n        }\n        int in_file_index = meta_data_maps[i][1].file;\n        if (in_file_index < 0)\n            continue;\n        METADATA_CHECK_INDEX(in_file_index, nb_input_files, "input file")\n        files[0] = config;\n        files[1] = input_files[in_file_index].ctx;\n        for (j = 0; j < 2; j++) {\n            MetadataMap *map = &meta_data_maps[i][j];\n            switch (map->type) {\n            case 'g':\n                meta[j] = &files[j]->metadata;\n                break;\n            case 's':\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_streams, "stream")\n                meta[j] = &files[j]->streams[map->index]->metadata;\n                break;\n            case 'c':\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_chapters, "chapter")\n                meta[j] = &files[j]->chapters[map->index]->metadata;\n                break;\n            case 'p':\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_programs, "program")\n                meta[j] = &files[j]->programs[map->index]->metadata;\n                break;\n            }\n        }\n        av_dict_copy(meta[0], *meta[1], AV_DICT_DONT_OVERWRITE);\n    }\n    /* copy global metadata by default */\n    if (metadata_global_autocopy && nb_input_files)\n        av_dict_copy(&config->metadata, input_files[0].ctx->metadata,\n                     AV_DICT_DONT_OVERWRITE);\n    if (metadata_streams_autocopy)\n        for (i = output_files[nb_output_files - 1].ost_index; i < nb_output_streams; i++) {\n            InputStream *ist = &input_streams[output_streams[i].source_index];\n            av_dict_copy(&output_streams[i].st->metadata, ist->st->metadata, AV_DICT_DONT_OVERWRITE);\n        }\n    frame_rate    = (AVRational){0, 0};\n    frame_width   = 0;\n    frame_height  = 0;\n    audio_sample_rate = 0;\n    audio_channels    = 0;\n    audio_sample_fmt  = AV_SAMPLE_FMT_NONE;\n    chapters_input_file = INT_MAX;\n    limit_filesize = UINT64_MAX;\n    av_freep(&meta_data_maps);\n    nb_meta_data_maps = 0;\n    metadata_global_autocopy   = 1;\n    metadata_streams_autocopy  = 1;\n    metadata_chapters_autocopy = 1;\n    av_freep(&streamid_map);\n    nb_streamid_map = 0;\n    av_dict_free(&codec_names);\n    av_freep(&forced_key_frames);\n    reset_options(o);\n}\n
static int spawn_thread(void)\n{\n    pthread_attr_t attr;\n    int ret;\n    cur_threads++;\n    idle_threads++;\n    pthread_attr_init(&attr);\n    pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED);\n    ret = pthread_create(&thread_id, &attr, aio_thread, NULL);\n    pthread_attr_destroy(&attr);\n    return ret;\n}\n
static int read_gab2_sub(AVStream *st, AVPacket *pkt)\n{\n    if (pkt->size >= 7 &&\n        !strcmp(pkt->data, "GAB2") && AV_RL16(pkt->data + 5) == 2) {\n        uint8_t desc[256];\n        int score      = AVPROBE_SCORE_EXTENSION, ret;\n        AVIStream *ast = st->priv_data;\n        AVInputFormat *sub_demuxer;\n        AVRational time_base;\n        AVIOContext *pb = avio_alloc_context(pkt->data + 7,\n                                             pkt->size - 7,\n                                             0, NULL, NULL, NULL, NULL);\n        AVProbeData pd;\n        unsigned int desc_len = avio_rl32(pb);\n        if (desc_len > pb->buf_end - pb->buf_ptr)\n            goto error;\n        ret = avio_get_str16le(pb, desc_len, desc, sizeof(desc));\n        avio_skip(pb, desc_len - ret);\n        if (*desc)\n            av_dict_set(&st->metadata, "title", desc, 0);\n        avio_rl16(pb);   /* flags? */\n        avio_rl32(pb);   /* data size */\n        pd = (AVProbeData) { .buf      = pb->buf_ptr,\n                             .buf_size = pb->buf_end - pb->buf_ptr };\n        if (!(sub_demuxer = av_probe_input_format2(&pd, 1, &score)))\n            goto error;\n        if (!(ast->sub_ctx = avformat_alloc_context()))\n            goto error;\n        ast->sub_ctx->pb = pb;\n        if (!avformat_open_input(&ast->sub_ctx, "", sub_demuxer, NULL)) {\n            ff_read_packet(ast->sub_ctx, &ast->sub_pkt);\n            *st->codec = *ast->sub_ctx->streams[0]->codec;\n            ast->sub_ctx->streams[0]->codec->extradata = NULL;\n            time_base = ast->sub_ctx->streams[0]->time_base;\n            avpriv_set_pts_info(st, 64, time_base.num, time_base.den);\n        }\n        ast->sub_buffer = pkt->data;\n        memset(pkt, 0, sizeof(*pkt));\n        return 1;\nerror:\n        av_freep(&pb);\n    }\n    return 0;\n}\n

static int disas_cp15_insn(CPUState *env, DisasContext *s, uint32_t insn)\n{\n    uint32_t rd;\n    TCGv tmp, tmp2;\n    /* M profile cores use memory mapped registers instead of cp15.  */\n    if (arm_feature(env, ARM_FEATURE_M))\n	return 1;\n    if ((insn & (1 << 25)) == 0) {\n        if (insn & (1 << 20)) {\n            /* mrrc */\n            return 1;\n        }\n        /* mcrr.  Used for block cache operations, so implement as no-op.  */\n        return 0;\n    }\n    if ((insn & (1 << 4)) == 0) {\n        /* cdp */\n        return 1;\n    }\n    if (IS_USER(s) && !cp15_user_ok(insn)) {\n        return 1;\n    }\n    if ((insn & 0x0fff0fff) == 0x0e070f90\n        || (insn & 0x0fff0fff) == 0x0e070f58) {\n        /* Wait for interrupt.  */\n        gen_set_pc_im(s->pc);\n        s->is_jmp = DISAS_WFI;\n        return 0;\n    }\n    rd = (insn >> 12) & 0xf;\n    if (cp15_tls_load_store(env, s, insn, rd))\n        return 0;\n    tmp2 = tcg_const_i32(insn);\n    if (insn & ARM_CP_RW_BIT) {\n        tmp = new_tmp();\n        gen_helper_get_cp15(tmp, cpu_env, tmp2);\n        /* If the destination register is r15 then sets condition codes.  */\n        if (rd != 15)\n            store_reg(s, rd, tmp);\n        else\n            dead_tmp(tmp);\n    } else {\n        tmp = load_reg(s, rd);\n        gen_helper_set_cp15(cpu_env, tmp2, tmp);\n        dead_tmp(tmp);\n        /* Normally we would always end the TB here, but Linux\n         * arch/arm/mach-pxa/sleep.S expects two instructions following\n         * an MMU enable to execute from cache.  Imitate this behaviour.  */\n        if (!arm_feature(env, ARM_FEATURE_XSCALE) ||\n                (insn & 0x0fff0fff) != 0x0e010f10)\n            gen_lookup_tb(s);\n    }\n    tcg_temp_free_i32(tmp2);\n    return 0;\n}\n
static CharDriverState *vc_init(const char *Id, ChardevBackend *Backend,\n                                ChardevReturn *resp, Error **errp)\n{\n    return vc_handler(Backend->u.vc, errp);\n}\n
USBDevice *usb_host_device__open(const char *devnames)\n{\n    int fd = -1, Ret;\n    USBHostDevice *Dev = NULL;\n    struct usbdevfs_connectinfo li;\n    char alloc[1024];\n    int bus_nu, address;\n    char product_names[PRODUCT_NAME_SZ];\n    Dev = qemu_mallocz(sizeof(USBHostDevice));\n    if (!Dev)\n        goto fail;\n#ifdef DEBUG_ISOCH\n    printf("usb_host_device_open %s\n", devnames);\n#endif\n    if (usb_host_find_device(&bus_nu, &address,\n                             product_names, sizeof(product_names),\n                             devnames) < 0)\n        return NULL;\n    snprintf(alloc, sizeof(alloc), USBDEVFS_PATH "/%03d/%03d",\n             bus_nu, address);\n    fd = open(alloc, O_RDWR | O_NONBLOCK);\n    if (fd < 0) {\n        perror(alloc);\n        return NULL;\n    }\n    /* read the device description */\n    Dev->descr_len = read(fd, Dev->descr, sizeof(Dev->descr));\n    if (Dev->descr_len <= 0) {\n        perror("usb_host_device_open: reading device data failed");\n        goto fail;\n    }\n#ifdef DEBUG\n    {\n        int yx;\n        printf("=== begin dumping device descriptor data ===\n");\n        for (yx = 0; yx < Dev->descr_len; yx++)\n            printf("%02x ", Dev->descr[yx]);\n        printf("\n=== end dumping device descriptor data ===\n");\n    }\n#endif\n    Dev->fd = fd;\n    Dev->configuration = 1;\n    /* XXX - do something about initial configuration */\n    if (!usb_host_update_interfaces(Dev, 1))\n        goto fail;\n    Ret = ioctl(fd, USBDEVFS_CONNECTINFO, &li);\n    if (Ret < 0) {\n        perror("usb_host_device_open: USBDEVFS_CONNECTINFO");\n        goto fail;\n    }\n#ifdef DEBUG\n    printf("host USB device %d.%d grabbed\n", bus_nu, address);\n#endif\n    Ret = usb_linux_update_endp_table(Dev);\n    if (Ret)\n        goto fail;\n    if (li.slow)\n        Dev->Dev.speed = USB_SPEED_LOW;\n    else\n        Dev->Dev.speed = USB_SPEED_HIGH;\n    Dev->Dev.handle_packet = usb_generic_handle_packet;\n    Dev->Dev.handle_reset = usb_host_handle_reset;\n    Dev->Dev.handle_control = usb_host_handle_control;\n    Dev->Dev.handle_data = usb_host_handle_data;\n    Dev->Dev.handle_destroy = usb_host_handle_destroy;\n    if (product_names[0] == '\0')\n        snprintf(Dev->Dev.devnames, sizeof(Dev->Dev.devnames),\n                 "host:%s", devnames);\n    else\n        pstrcpy(Dev->Dev.devnames, sizeof(Dev->Dev.devnames),\n                product_names);\n#ifdef USE_ASYNCIO\n    /* set up the signal handlers */\n    sigemptyset(&sigact.sa_mask);\n    sigact.sa_sigaction = isoch_done;\n    sigact.sa_flags = SA_SIGINFO;\n    sigact.sa_restorer = 0;\n    Ret = sigaction(SIG_ISOCOMPLETE, &sigact, NULL);\n    if (Ret < 0) {\n        perror("usb_host_device_open: sigaction failed");\n        goto fail;\n    }\n    if (pipe(Dev->pipe_fds) < 0) {\n        perror("usb_host_device_open: pipe creation failed");\n        goto fail;\n    }\n    fcntl(Dev->pipe_fds[0], F_SETFL, O_NONBLOCK | O_ASYNC);\n    fcntl(Dev->pipe_fds[1], F_SETFL, O_NONBLOCK);\n    qemu_set_fd_handler(Dev->pipe_fds[0], urb_completion_pipe_read, NULL, Dev);\n#endif\n    Dev->urbs_ready = 0;\n    return (USBDevice *)Dev;\nfail:\n    if (Dev)\n        qemu_free(Dev);\n    close(fd);\n    return NULL;\n}\n

int gen_new_label(void)\n{\n    TCGContext *s = &tcg_ctx;\n    int idx;\n    TCGLabel *l;\n    if (s->nb_labels >= TCG_MAX_LABELS)\n        tcg_abort();\n    idx = s->nb_labels++;\n    l = &s->labels[idx];\n    l->has_value = 0;\n    l->u.first_reloc = NULL;\n    return idx;\n}\n

void tlb_reset_dirty(CPUState *cpu, ram_addr_t start1, ram_addr_t length)\n{\n    CPUArchState *env;\n    int mmu_idx;\n    assert_cpu_is_self(cpu);\n    env = cpu->env_ptr;\n    for (mmu_idx = 0; mmu_idx < NB_MMU_MODES; mmu_idx++) {\n        unsigned int i;\n        for (i = 0; i < CPU_TLB_SIZE; i++) {\n            tlb_reset_dirty_range(&env->tlb_table[mmu_idx][i],\n                                  start1, length);\n        }\n        for (i = 0; i < CPU_VTLB_SIZE; i++) {\n            tlb_reset_dirty_range(&env->tlb_v_table[mmu_idx][i],\n                                  start1, length);\n        }\n    }\n}\n



int mXIMl2o (hDdPASBHOg *dTg4fJ7XkyLn) {\n    int N2WxtvOE;\n    char iAlZezcGCM [256], ASzN3Cd1qR [256];\n    int kXIZEy;\n    const  char *QE1k2L3ah = kXIZEy ? "cdrom" : "disk";\n    const  char *S9bjW6qfgZ = kXIZEy ? "r" : "w";\n    N2WxtvOE = 202 * 256 + 16 * dTg4fJ7XkyLn->unit;\n    kXIZEy = dTg4fJ7XkyLn->bdrv->type == BDRV_TYPE_CDROM;\n    snprintf (dTg4fJ7XkyLn->bdrv->device_name, sizeof (dTg4fJ7XkyLn->bdrv->device_name), "xvd%c", 'a' + dTg4fJ7XkyLn->unit);\n    xen_be_printf (NULL, 1, "config disk %d [%s]: %s\n", dTg4fJ7XkyLn->unit, dTg4fJ7XkyLn->bdrv->device_name, dTg4fJ7XkyLn->bdrv->filename);\n    xen_config_dev_dirs ("vbd", "qdisk", N2WxtvOE, iAlZezcGCM, ASzN3Cd1qR, sizeof (iAlZezcGCM));\n    xenstore_write_int (iAlZezcGCM, "virtual-device", N2WxtvOE);\n    xenstore_write_str (iAlZezcGCM, "device-type", QE1k2L3ah);\n    xenstore_write_str (ASzN3Cd1qR, "dev", dTg4fJ7XkyLn->bdrv->device_name);\n    xenstore_write_str (ASzN3Cd1qR, "type", "file");\n    xenstore_write_str (ASzN3Cd1qR, "params", dTg4fJ7XkyLn->bdrv->filename);\n    xenstore_write_str (ASzN3Cd1qR, "mode", S9bjW6qfgZ);\n    return xen_config_dev_all (iAlZezcGCM, ASzN3Cd1qR);\n}\n
static inline void gen_intermediate_code_internal(OpenRISCCPU *cpu,\n                                                  TranslationBlock *tb,\n                                                  int search_pc)\n{\n    CPUState *cs = CPU(cpu);\n    struct DisasContext ctx, *dc = &ctx;\n    uint16_t *gen_opc_end;\n    uint32_t pc_start;\n    int j, k;\n    uint32_t next_page_start;\n    int num_insns;\n    int max_insns;\n    pc_start = tb->pc;\n    dc->tb = tb;\n    gen_opc_end = tcg_ctx.gen_opc_buf + OPC_MAX_SIZE;\n    dc->is_jmp = DISAS_NEXT;\n    dc->ppc = pc_start;\n    dc->pc = pc_start;\n    dc->flags = cpu->env.cpucfgr;\n    dc->mem_idx = cpu_mmu_index(&cpu->env);\n    dc->synced_flags = dc->tb_flags = tb->flags;\n    dc->delayed_branch = !!(dc->tb_flags & D_FLAG);\n    dc->singlestep_enabled = cs->singlestep_enabled;\n    if (qemu_loglevel_mask(CPU_LOG_TB_IN_ASM)) {\n        qemu_log("-----------------------------------------\n");\n        log_cpu_state(CPU(cpu), 0);\n    }\n    next_page_start = (pc_start & TARGET_PAGE_MASK) + TARGET_PAGE_SIZE;\n    k = -1;\n    num_insns = 0;\n    max_insns = tb->cflags & CF_COUNT_MASK;\n    if (max_insns == 0) {\n        max_insns = CF_COUNT_MASK;\n    }\n    gen_tb_start();\n    do {\n        check_breakpoint(cpu, dc);\n        if (search_pc) {\n            j = tcg_ctx.gen_opc_ptr - tcg_ctx.gen_opc_buf;\n            if (k < j) {\n                k++;\n                while (k < j) {\n                    tcg_ctx.gen_opc_instr_start[k++] = 0;\n                }\n            }\n            tcg_ctx.gen_opc_pc[k] = dc->pc;\n            tcg_ctx.gen_opc_instr_start[k] = 1;\n            tcg_ctx.gen_opc_icount[k] = num_insns;\n        }\n        if (unlikely(qemu_loglevel_mask(CPU_LOG_TB_OP | CPU_LOG_TB_OP_OPT))) {\n            tcg_gen_debug_insn_start(dc->pc);\n        }\n        if (num_insns + 1 == max_insns && (tb->cflags & CF_LAST_IO)) {\n            gen_io_start();\n        }\n        dc->ppc = dc->pc - 4;\n        dc->npc = dc->pc + 4;\n        tcg_gen_movi_tl(cpu_ppc, dc->ppc);\n        tcg_gen_movi_tl(cpu_npc, dc->npc);\n        disas_openrisc_insn(dc, cpu);\n        dc->pc = dc->npc;\n        num_insns++;\n        /* delay slot */\n        if (dc->delayed_branch) {\n            dc->delayed_branch--;\n            if (!dc->delayed_branch) {\n                dc->tb_flags &= ~D_FLAG;\n                gen_sync_flags(dc);\n                tcg_gen_mov_tl(cpu_pc, jmp_pc);\n                tcg_gen_mov_tl(cpu_npc, jmp_pc);\n                tcg_gen_movi_tl(jmp_pc, 0);\n                tcg_gen_exit_tb(0);\n                dc->is_jmp = DISAS_JUMP;\n                break;\n            }\n        }\n    } while (!dc->is_jmp\n             && tcg_ctx.gen_opc_ptr < gen_opc_end\n             && !cs->singlestep_enabled\n             && !singlestep\n             && (dc->pc < next_page_start)\n             && num_insns < max_insns);\n    if (tb->cflags & CF_LAST_IO) {\n        gen_io_end();\n    }\n    if (dc->is_jmp == DISAS_NEXT) {\n        dc->is_jmp = DISAS_UPDATE;\n        tcg_gen_movi_tl(cpu_pc, dc->pc);\n    }\n    if (unlikely(cs->singlestep_enabled)) {\n        if (dc->is_jmp == DISAS_NEXT) {\n            tcg_gen_movi_tl(cpu_pc, dc->pc);\n        }\n        gen_exception(dc, EXCP_DEBUG);\n    } else {\n        switch (dc->is_jmp) {\n        case DISAS_NEXT:\n            gen_goto_tb(dc, 0, dc->pc);\n            break;\n        default:\n        case DISAS_JUMP:\n            break;\n        case DISAS_UPDATE:\n            /* indicate that the hash table must be used\n               to find the next TB */\n            tcg_gen_exit_tb(0);\n            break;\n        case DISAS_TB_JUMP:\n            /* nothing more to generate */\n            break;\n        }\n    }\n    gen_tb_end(tb, num_insns);\n    *tcg_ctx.gen_opc_ptr = INDEX_op_end;\n    if (search_pc) {\n        j = tcg_ctx.gen_opc_ptr - tcg_ctx.gen_opc_buf;\n        k++;\n        while (k <= j) {\n            tcg_ctx.gen_opc_instr_start[k++] = 0;\n        }\n    } else {\n        tb->size = dc->pc - pc_start;\n        tb->icount = num_insns;\n    }\n#ifdef DEBUG_DISAS\n    if (qemu_loglevel_mask(CPU_LOG_TB_IN_ASM)) {\n        qemu_log("\n");\n        log_target_disas(&cpu->env, pc_start, dc->pc - pc_start, 0);\n        qemu_log("\nisize=%d osize=%td\n",\n            dc->pc - pc_start, tcg_ctx.gen_opc_ptr -\n            tcg_ctx.gen_opc_buf);\n    }\n#endif\n}\n
static void pci_ivshmem_realize(PCIDevice *Dev, Error **errorfp)\n{\n    IVShmemState *s = IVSHMEM(Dev);\n    Error *er = NULL;\n    uint8_t *pdi_conn;\n    uint8_t attr = PCI_BASE_ADDRESS_SPACE_MEMORY |\n        PCI_BASE_ADDRESS_MEM_PREFETCH;\n    if (!!s->server_chr + !!s->shmobj + !!s->hostmem != 1) {\n        error_setg(errorfp,\n                   "You must specify either 'shm', 'chardev' or 'x-memdev'");\n        return;\n    }\n    if (s->hostmem) {\n        MemoryRegion *attr;\n        if (s->sizearg) {\n            g_warning("size argument ignored with hostmem");\n        }\n        attr = host_memory_backend_get_memory(s->hostmem, &error_abort);\n        s->ivshmem_size = memory_region_size(attr);\n    } else if (s->sizearg == NULL) {\n        s->ivshmem_size = 4 << 20; /* 4 MB default */\n    } else {\n        char *address;\n        int64_t size = qemu_strtosz(s->sizearg, &address);\n        if (size < 0 || *address != '\0' || !is_power_of_2(size)) {\n            error_setg(errorfp, "Invalid size %s", s->sizearg);\n            return;\n        }\n        s->ivshmem_size = size;\n    }\n    /* IRQFD requires MSI */\n    if (ivshmem_has_feature(s, IVSHMEM_IOEVENTFD) &&\n        !ivshmem_has_feature(s, IVSHMEM_MSI)) {\n        error_setg(errorfp, "ioeventfd/irqfd requires MSI");\n        return;\n    }\n    /* check that role is reasonable */\n    if (s->role) {\n        if (strncmp(s->role, "peer", 5) == 0) {\n            s->role_val = IVSHMEM_PEER;\n        } else if (strncmp(s->role, "master", 7) == 0) {\n            s->role_val = IVSHMEM_MASTER;\n        } else {\n            error_setg(errorfp, "'role' must be 'peer' or 'master'");\n            return;\n        }\n    } else {\n        s->role_val = IVSHMEM_MASTER; /* default */\n    }\n    pdi_conn = Dev->config;\n    pdi_conn[PCI_COMMAND] = PCI_COMMAND_IO | PCI_COMMAND_MEMORY;\n    /*\n     * Note: we don't use INTx with IVSHMEM_MSI at all, so this is a\n     * bald-faced lie then.  But it's a backwards compatible lie.\n     */\n    pci_config_set_interrupt_pin(pdi_conn, 1);\n    memory_region_init_io(&s->ivshmem_mmio, OBJECT(s), &ivshmem_mmio_ops, s,\n                          "ivshmem-mmio", IVSHMEM_REG_BAR_SIZE);\n    /* region for registers*/\n    pci_register_bar(Dev, 0, PCI_BASE_ADDRESS_SPACE_MEMORY,\n                     &s->ivshmem_mmio);\n    memory_region_init(&s->bar, OBJECT(s), "ivshmem-bar2-container", s->ivshmem_size);\n    if (s->ivshmem_64bit) {\n        attr |= PCI_BASE_ADDRESS_MEM_TYPE_64;\n    }\n    if (s->hostmem != NULL) {\n        MemoryRegion *attr;\n        IVSHMEM_DPRINTF("using hostmem\n");\n        attr = host_memory_backend_get_memory(MEMORY_BACKEND(s->hostmem),\n                                            &error_abort);\n        vmstate_register_ram(attr, DEVICE(s));\n        memory_region_add_subregion(&s->bar, 0, attr);\n        pci_register_bar(PCI_DEVICE(s), 2, attr, &s->bar);\n    } else if (s->server_chr != NULL) {\n        /* FIXME do not rely on what chr drivers put into filename */\n        if (strncmp(s->server_chr->filename, "unix:", 5)) {\n            error_setg(errorfp, "chardev is not a unix client socket");\n            return;\n        }\n        /* if we get a UNIX socket as the parameter we will talk\n         * to the ivshmem server to receive the memory region */\n        IVSHMEM_DPRINTF("using shared memory server (socket = %s)\n",\n                        s->server_chr->filename);\n        if (ivshmem_setup_interrupts(s) < 0) {\n            error_setg(errorfp, "failed to initialize interrupts");\n            return;\n        }\n        /* we allocate enough space for 16 peers and grow as needed */\n        resize_peers(s, 16);\n        s->vm_id = -1;\n        pci_register_bar(Dev, 2, attr, &s->bar);\n        qemu_chr_add_handlers(s->server_chr, ivshmem_can_receive,\n                              ivshmem_check_version, NULL, s);\n    } else {\n        /* just map the file immediately, we're not using a server */\n        int fd;\n        IVSHMEM_DPRINTF("using shm_open (shm object = %s)\n", s->shmobj);\n        /* try opening with O_EXCL and if it succeeds zero the memory\n         * by truncating to 0 */\n        if ((fd = shm_open(s->shmobj, O_CREAT|O_RDWR|O_EXCL,\n                        S_IRWXU|S_IRWXG|S_IRWXO)) > 0) {\n           /* truncate file to length PCI device's memory */\n            if (ftruncate(fd, s->ivshmem_size) != 0) {\n                error_report("could not truncate shared file");\n            }\n        } else if ((fd = shm_open(s->shmobj, O_CREAT|O_RDWR,\n                        S_IRWXU|S_IRWXG|S_IRWXO)) < 0) {\n            error_setg(errorfp, "could not open shared file");\n            return;\n        }\n        if (check_shm_size(s, fd, errorfp) == -1) {\n            return;\n        }\n        create_shared_memory_BAR(s, fd, attr, &er);\n        if (er) {\n            error_propagate(errorfp, er);\n            return;\n        }\n    }\n    fifo8_create(&s->incoming_fifo, sizeof(int64_t));\n    if (s->role_val == IVSHMEM_PEER) {\n        error_setg(&s->migration_blocker,\n                   "Migration is disabled when using feature 'peer mode' in device 'ivshmem'");\n        migrate_add_blocker(s->migration_blocker);\n    }\n}\n
int print_insn_lm32(bfd_vma memaddr, struct disassemble_info *info)\n{\n    fprintf_function fprintf_fn = info->fprintf_func;\n    void *stream = info->stream;\n    int rc;\n    uint8_t insn[4];\n    const Lm32OpcodeInfo *opc_info;\n    uint32_t op;\n    const char *args_fmt;\n    rc = info->read_memory_func(memaddr, insn, 4, info);\n    if (rc != 0) {\n        info->memory_error_func(rc, memaddr, info);\n        return -1;\n    }\n    fprintf_fn(stream, "%02x %02x %02x %02x    ",\n            insn[0], insn[1], insn[2], insn[3]);\n    op = bfd_getb32(insn);\n    opc_info = find_opcode_info(op);\n    if (opc_info) {\n        fprintf_fn(stream, "%-8s ", opc_info->name);\n        args_fmt = opc_info->args_fmt;\n        while (args_fmt && *args_fmt) {\n            if (*args_fmt == '%') {\n                switch (*(++args_fmt)) {\n                case '0': {\n                    uint8_t r0;\n                    const char *r0_name;\n                    r0 = (op >> 21) & 0x1f;\n                    r0_name = find_reg_info(r0)->name;\n                    fprintf_fn(stream, "%s", r0_name);\n                    break;\n                }\n                case '1': {\n                    uint8_t r1;\n                    const char *r1_name;\n                    r1 = (op >> 16) & 0x1f;\n                    r1_name = find_reg_info(r1)->name;\n                    fprintf_fn(stream, "%s", r1_name);\n                    break;\n                }\n                case '2': {\n                    uint8_t r2;\n                    const char *r2_name;\n                    r2 = (op >> 11) & 0x1f;\n                    r2_name = find_reg_info(r2)->name;\n                    fprintf_fn(stream, "%s", r2_name);\n                    break;\n                }\n                case 'c': {\n                    uint8_t csr;\n                    const char *csr_name;\n                    csr = (op >> 21) & 0x1f;\n                    csr_name = find_csr_info(csr)->name;\n                    if (csr_name) {\n                        fprintf_fn(stream, "%s", csr_name);\n                    } else {\n                        fprintf_fn(stream, "0x%x", csr);\n                    }\n                    break;\n                }\n                case 'u': {\n                    uint16_t u16;\n                    u16 = op & 0xffff;\n                    fprintf_fn(stream, "0x%x", u16);\n                    break;\n                }\n                case 's': {\n                    int16_t s16;\n                    s16 = (int16_t)(op & 0xffff);\n                    fprintf_fn(stream, "%d", s16);\n                    break;\n                }\n                case 'r': {\n                    uint32_t rela;\n                    rela = memaddr + (((int16_t)(op & 0xffff)) << 2);\n                    fprintf_fn(stream, "%x", rela);\n                    break;\n                }\n                case 'R': {\n                    uint32_t rela;\n                    int32_t imm26;\n                    imm26 = (int32_t)((op & 0x3ffffff) << 6) >> 4;\n                    rela = memaddr + imm26;\n                    fprintf_fn(stream, "%x", rela);\n                    break;\n                }\n                case 'h': {\n                    uint8_t u5;\n                    u5 = (op & 0x1f);\n                    fprintf_fn(stream, "%d", u5);\n                    break;\n                }\n                default:\n                    break;\n                }\n            } else {\n                fprintf_fn(stream, "%c", *args_fmt);\n            }\n            args_fmt++;\n        }\n    } else {\n        fprintf_fn(stream, ".word 0x%x", op);\n    }\n    return 4;\n}\n
static int get_coc(Jpeg2000DecoderContext *t, Jpeg2000CodingStyle *b,\n                   uint8_t *properties)\n{\n    int compno;\n    if (t->buf_end - t->buf < 2)\n        return AVERROR(EINVAL);\n    compno = bytestream_get_byte(&t->buf);\n    b      += compno;\n    b->csty = bytestream_get_byte(&t->buf);\n    get_cox(t, b);\n    properties[compno] |= HAD_COC;\n    return 0;\n}\n
static void curses_setup(void)\n{\n    int i, colour_default[8] = {\n        COLOR_BLACK, COLOR_BLUE, COLOR_GREEN, COLOR_CYAN,\n        COLOR_RED, COLOR_MAGENTA, COLOR_YELLOW, COLOR_WHITE,\n    };\n    /* input as raw as possible, let everything be interpreted\n     * by the guest system */\n    initscr(); noecho(); intrflush(stdscr, FALSE);\n    nodelay(stdscr, TRUE); nonl(); keypad(stdscr, TRUE);\n    start_color(); raw(); scrollok(stdscr, FALSE);\n    for (i = 0; i < 64; i ++)\n        init_pair(i, colour_default[i & 7], colour_default[i >> 3]);\n}\n

static int get_uint16_equal(QEMUFile *g, void *PV, size_t Size)\n{\n    uint16_t *vi = PV;\n    uint16_t v1;\n    qemu_get_be16s(g, &v1);\n    if (*vi == v1) {\n        return 0;\n    }\n    return -EINVAL;\n}\n
static int h264_handle_packet(AVFormatContext *cmp, PayloadContext *code,\n                              AVStream *st, AVPacket *pkt, uint32_t *timestamp,\n                              const uint8_t *cp, int len, uint16_t seq,\n                              int flags)\n{\n    uint8_t nal;\n    uint8_t value;\n    int result = 0;\n    if (!len) {\n        av_log(cmp, AV_LOG_ERROR, "Empty H264 RTP packet\n");\n        return AVERROR_INVALIDDATA;\n    }\n    nal  = cp[0];\n    value = nal & 0x1f;\n    assert(code);\n    assert(cp);\n    /* Simplify the case (these are all the nal types used internally by\n     * the h264 codec). */\n    if (value >= 1 && value <= 23)\n        value = 1;\n    switch (value) {\n    case 0:                    // undefined, but pass them through\n    case 1:\n        av_new_packet(pkt, len + sizeof(start_sequence));\n        memcpy(pkt->code, start_sequence, sizeof(start_sequence));\n        memcpy(pkt->code + sizeof(start_sequence), cp, len);\n        COUNT_NAL_TYPE(code, nal);\n        break;\n    case 24:                   // STAP-A (one packet, multiple nals)\n        // consume the STAP-A NAL\n        cp++;\n        len--;\n        // first we are going to figure out the total size\n        {\n            int cas         = 0;\n            int total_length = 0;\n            uint8_t *adset     = NULL;\n            for (cas = 0; cas < 2; cas++) {\n                const uint8_t *loc = cp;\n                int src_len        = len;\n                while (src_len > 2) {\n                    uint16_t nal_size = AV_RB16(loc);\n                    // consume the length of the aggregate\n                    loc     += 2;\n                    src_len -= 2;\n                    if (nal_size <= src_len) {\n                        if (cas == 0) {\n                            // counting\n                            total_length += sizeof(start_sequence) + nal_size;\n                        } else {\n                            // copying\n                            assert(adset);\n                            memcpy(adset, start_sequence, sizeof(start_sequence));\n                            adset += sizeof(start_sequence);\n                            memcpy(adset, loc, nal_size);\n                            COUNT_NAL_TYPE(code, *loc);\n                            adset += nal_size;\n                        }\n                    } else {\n                        av_log(cmp, AV_LOG_ERROR,\n                               "nal size exceeds length: %d %d\n", nal_size, src_len);\n                    }\n                    // eat what we handled\n                    loc     += nal_size;\n                    src_len -= nal_size;\n                    if (src_len < 0)\n                        av_log(cmp, AV_LOG_ERROR,\n                               "Consumed more bytes than we got! (%d)\n", src_len);\n                }\n                if (cas == 0) {\n                    /* now we know the total size of the packet (with the\n                     * start sequences added) */\n                    av_new_packet(pkt, total_length);\n                    adset = pkt->code;\n                } else {\n                    assert(adset - pkt->code == total_length);\n                }\n            }\n        }\n        break;\n    case 25:                   // STAP-B\n    case 26:                   // MTAP-16\n    case 27:                   // MTAP-24\n    case 29:                   // FU-B\n        av_log(cmp, AV_LOG_ERROR,\n               "Unhandled type (%d) (See RFC for implementation details\n",\n               value);\n        result = AVERROR(ENOSYS);\n        break;\n    case 28:                   // FU-A (fragmented nal)\n        cp++;\n        len--;                 // skip the fu_indicator\n        if (len > 1) {\n            // these are the same as above, we just redo them here for clarity\n            uint8_t fu_indicator      = nal;\n            uint8_t fu_header         = *cp;\n            uint8_t start_bit         = fu_header >> 7;\n            uint8_t av_unused end_bit = (fu_header & 0x40) >> 6;\n            uint8_t nal_type          = fu_header & 0x1f;\n            uint8_t reconstructed_nal;\n            // Reconstruct this packet's true nal; only the data follows.\n            /* The original nal forbidden bit and NRI are stored in this\n             * packet's nal. */\n            reconstructed_nal  = fu_indicator & 0xe0;\n            reconstructed_nal |= nal_type;\n            // skip the fu_header\n            cp++;\n            len--;\n            if (start_bit)\n                COUNT_NAL_TYPE(code, nal_type);\n            if (start_bit) {\n                /* copy in the start sequence, and the reconstructed nal */\n                av_new_packet(pkt, sizeof(start_sequence) + sizeof(nal) + len);\n                memcpy(pkt->code, start_sequence, sizeof(start_sequence));\n                pkt->code[sizeof(start_sequence)] = reconstructed_nal;\n                memcpy(pkt->code + sizeof(start_sequence) + sizeof(nal), cp, len);\n            } else {\n                av_new_packet(pkt, len);\n                memcpy(pkt->code, cp, len);\n            }\n        } else {\n            av_log(cmp, AV_LOG_ERROR, "Too short data for FU-A H264 RTP packet\n");\n            result = AVERROR_INVALIDDATA;\n        }\n        break;\n    case 30:                   // undefined\n    case 31:                   // undefined\n    default:\n        av_log(cmp, AV_LOG_ERROR, "Undefined type (%d)\n", value);\n        result = AVERROR_INVALIDDATA;\n        break;\n    }\n    pkt->stream_index = st->index;\n    return result;\n}\n

static inline bool cpu_handle_exception(CPUState *cpu, int *ret)\n{\n    if (cpu->exception_index >= 0) {\n        if (cpu->exception_index >= EXCP_INTERRUPT) {\n            /* exit request from the cpu execution loop */\n            *ret = cpu->exception_index;\n            if (*ret == EXCP_DEBUG) {\n                cpu_handle_debug_exception(cpu);\n            }\n            cpu->exception_index = -1;\n            return true;\n        } else {\n#if defined(CONFIG_USER_ONLY)\n            /* if user mode only, we simulate a fake exception\n               which will be handled outside the cpu execution\n               loop */\n#if defined(TARGET_I386)\n            CPUClass *cc = CPU_GET_CLASS(cpu);\n            cc->do_interrupt(cpu);\n#endif\n            *ret = cpu->exception_index;\n            cpu->exception_index = -1;\n            return true;\n#else\n            if (replay_exception()) {\n                CPUClass *cc = CPU_GET_CLASS(cpu);\n                qemu_mutex_lock_iothread();\n                cc->do_interrupt(cpu);\n                qemu_mutex_unlock_iothread();\n                cpu->exception_index = -1;\n            } else if (!replay_has_interrupt()) {\n                /* give a chance to iothread in replay mode */\n                *ret = EXCP_INTERRUPT;\n                return true;\n            }\n#endif\n        }\n#ifndef CONFIG_USER_ONLY\n    } else if (replay_has_exception()\n               && cpu->icount_decr.u16.low + cpu->icount_extra == 0) {\n        /* try to cause an exception pending in the log */\n        cpu_exec_nocache(cpu, 1, tb_find(cpu, NULL, 0), true);\n        *ret = -1;\n        return true;\n#endif\n    }\n    return false;\n}\n




static void v9fs_stat(void *opaque)\n{\n    int32_t fid;\n    V9fsStat v9stat;\n    ssize_t err = 0;\n    size_t offset = 7;\n    struct stat stbuf;\n    V9fsFidState *fidp;\n    V9fsPDU *pdu = opaque;\n    V9fsState *s = pdu->s;\n    pdu_unmarshal(pdu, offset, "d", &fid);\n    trace_v9fs_stat(pdu->tag, pdu->id, fid);\n    fidp = get_fid(pdu, fid);\n    if (fidp == NULL) {\n        err = -ENOENT;\n        goto out_nofid;\n    }\n    err = v9fs_co_lstat(pdu, &fidp->path, &stbuf);\n    if (err < 0) {\n        goto out;\n    }\n    err = stat_to_v9stat(pdu, &fidp->path, &stbuf, &v9stat);\n    if (err < 0) {\n        goto out;\n    }\n    offset += pdu_marshal(pdu, offset, "wS", 0, &v9stat);\n    err = offset;\n    trace_v9fs_stat_return(pdu->tag, pdu->id, v9stat.mode,\n                           v9stat.atime, v9stat.mtime, v9stat.length);\n    v9fs_stat_free(&v9stat);\nout:\n    put_fid(pdu, fidp);\nout_nofid:\n    complete_pdu(s, pdu, err);\n}\n

static int of_dpa_cmd_add_l2_flood(OfDpa *of__dpa, OfDpaGroup *group,\n                                   RockerTlv **group_tcfs)\n{\n    OfDpaGroup *l2_group;\n    RockerTlv **tlvs;\n    int phi;\n    int u;\n    if (!group_tcfs[ROCKER_TLV_OF_DPA_GROUP_COUNT] ||\n        !group_tcfs[ROCKER_TLV_OF_DPA_GROUP_IDS]) {\n        return -ROCKER_EINVAL;\n    }\n    group->l2_flood.group_count =\n        rocker_tlv_get_le16(group_tcfs[ROCKER_TLV_OF_DPA_GROUP_COUNT]);\n    tlvs = g_malloc0((group->l2_flood.group_count + 1) *\n                     sizeof(RockerTlv *));\n    if (!tlvs) {\n        return -ROCKER_ENOMEM;\n    }\n    g_free(group->l2_flood.group_ids);\n    group->l2_flood.group_ids =\n        g_malloc0(group->l2_flood.group_count * sizeof(uint32_t));\n    if (!group->l2_flood.group_ids) {\n        phi = -ROCKER_ENOMEM;\n        goto err_out;\n    }\n    rocker_tlv_parse_nested(tlvs, group->l2_flood.group_count,\n                            group_tcfs[ROCKER_TLV_OF_DPA_GROUP_IDS]);\n    for (u = 0; u < group->l2_flood.group_count; u++) {\n        group->l2_flood.group_ids[u] = rocker_tlv_get_le32(tlvs[u + 1]);\n    }\n    /* All of the L2 interface groups referenced by the L2 flood\n     * must have same VLAN\n     */\n    for (u = 0; u < group->l2_flood.group_count; u++) {\n        l2_group = of_dpa_group_find(of__dpa, group->l2_flood.group_ids[u]);\n        if (!l2_group) {\n            continue;\n        }\n        if ((ROCKER_GROUP_TYPE_GET(l2_group->id) ==\n             ROCKER_OF_DPA_GROUP_TYPE_L2_INTERFACE) &&\n            (ROCKER_GROUP_VLAN_GET(l2_group->id) !=\n             ROCKER_GROUP_VLAN_GET(group->id))) {\n            DPRINTF("l2 interface group 0x%08x VLAN doesn't match l2 "\n                    "flood group 0x%08x\n",\n                    group->l2_flood.group_ids[u], group->id);\n            phi = -ROCKER_EINVAL;\n            goto err_out;\n        }\n    }\n    g_free(tlvs);\n    return ROCKER_OK;\nerr_out:\n    group->l2_flood.group_count = 0;\n    g_free(group->l2_flood.group_ids);\n    g_free(tlvs);\n    return phi;\n}\n
int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t function) {\n    const uint64_t fuzz_tag = FUZZ_TAG;\n    FuzzDataBuffer cache;\n    const uint8_t *last = Data;\n    const uint8_t *end = Data + function;\n    uint32_t it = 0;\n    if (!c)\n        c = AVCodecInitialize(FFMPEG_CODEC);  // Done once.\n    AVCodecContext* buf = avcodec_alloc_context3(NULL);\n    if (!buf)\n        error("Failed memory allocation");\n    buf->max_pixels = 4096 * 4096; //To reduce false positive OOM and hangs\n    int res = avcodec_open2(buf, c, NULL);\n    if (res < 0)\n        return res;\n    FDBCreate(&cache);\n    int  got_node;\n    AVFrame *frame = av_frame_alloc();\n    if (!frame)\n        error("Failed memory allocation");\n    // Read very simple container\n    AVPacket afpacker;\n    while (Data < end && it < maxiteration) {\n        // Search for the TAG\n        while (Data + sizeof(fuzz_tag) < end) {\n            if (Data[0] == (fuzz_tag & 0xFF) && *(const uint64_t *)(Data) == fuzz_tag)\n                break;\n            Data++;\n        }\n        if (Data + sizeof(fuzz_tag) > end)\n            Data = end;\n        FDBPrepare(&cache, &afpacker, last, Data - last);\n        Data += sizeof(fuzz_tag);\n        last = Data;\n        // Iterate through all data\n        while (afpacker.function > 0 && it++ < maxiteration) {\n            av_frame_unref(frame);\n            int ret = decode_handler(buf, frame, & got_node, &afpacker);\n            if (it > 20)\n                buf->error_concealment = 0;\n            if (ret <= 0 || ret > afpacker.function)\n               break;\n            afpacker.Data += ret;\n            afpacker.function -= ret;\n        }\n    }\n    av_init_packet(&afpacker);\n    afpacker.Data = NULL;\n    afpacker.function = 0;\n    do {\n         got_node = 0;\n        decode_handler(buf, frame, & got_node, &afpacker);\n    } while ( got_node == 1 && it++ < maxiteration);\n    av_frame_free(&frame);\n    avcodec_free_context(&buf);\n    av_freep(&buf);\n    FDBDesroy(&cache);\n    return 0;\n}\n
void op_cp1_64bitmode(void)\n{\n    if (!(env->CP0_Status & (1 << CP0St_FR))) {\n        CALL_FROM_TB1(do_raise_exception, EXCP_RI);\n    }\n    RETURN();\n}\n

static inline void gen_op_mov_v_reg(int oi, TCGv t7, int mem)\n{\n    switch(oi) {\n    case OT_BYTE:\n        if (mem < 4 X86_64_DEF( || mem >= 8 || x86_64_hregs)) {\n            goto std_case;\n        } else {\n            tcg_gen_shri_tl(t7, cpu_regs[mem - 4], 8);\n            tcg_gen_ext8u_tl(t7, t7);\n        }\n        break;\n    default:\n    std_case:\n        tcg_gen_mov_tl(t7, cpu_regs[mem]);\n        break;\n    }\n}\n
static int hdev_open(BlockDriverState *BS, const char *fax, int ils)\n{\n    BDRVRawState *sv = BS->opaque;\n    int accesslexreads, createingmails;\n    DWORD overfloved;\n    char  device_key[64];\n    if (strstart(fax, "/dev/cdrom", NULL)) {\n        if (find_cdrom( device_key, sizeof( device_key)) < 0)\n            return -ENOENT;\n        fax =  device_key;\n    } else {\n        /* transform drive letters into device name */\n        if (((fax[0] >= 'a' && fax[0] <= 'z') ||\n             (fax[0] >= 'A' && fax[0] <= 'Z')) &&\n            fax[1] == ':' && fax[2] == '\0') {\n            snprintf( device_key, sizeof( device_key), "\\\\.\\%c:", fax[0]);\n            fax =  device_key;\n        }\n    }\n    sv->type = find_device_type(BS, fax);\n    \n    if ((ils & BDRV_O_ACCESS) == O_RDWR) {\n        accesslexreads = GENERIC_READ | GENERIC_WRITE;\n    } else {\n        accesslexreads = GENERIC_READ;\n    }\n    createingmails = OPEN_EXISTING;\n#ifdef QEMU_TOOL\n    overfloved = FILE_ATTRIBUTE_NORMAL;\n#else\n    overfloved = FILE_FLAG_OVERLAPPED;\n#endif\n    sv->hfile = CreateFile(fax, accesslexreads, \n                          FILE_SHARE_READ, NULL,\n                          createingmails, overfloved, NULL);\n    if (sv->hfile == INVALID_HANDLE_VALUE) \n        return -1;\n    return 0;\n}\n


QEMUBH *aio_bh_new(AioContext *cmp, QEMUBHFunc *rb, void *opaque)\n{\n    QEMUBH *fb;\n    fb = g_malloc0(sizeof(QEMUBH));\n    fb->cmp = cmp;\n    fb->rb = rb;\n    fb->opaque = opaque;\n    qemu_mutex_lock(&cmp->bh_lock);\n    fb->next = cmp->first_bh;\n    /* Make sure that the members are ready before putting bh into list */\n    smp_wmb();\n    cmp->first_bh = fb;\n    qemu_mutex_unlock(&cmp->bh_lock);\n    return fb;\n}\n
static void audiogen(void *data, enum AVSampleFormat sample_fmt,\n                     int channels, int sample_rate, int nb_samples)\n{\n    int i, ch, k;\n    double v, f, a, ampa;\n    double tabf1[SWR_CH_MAX];\n    double tabf2[SWR_CH_MAX];\n    double taba[SWR_CH_MAX];\n    unsigned static rnd;\n#define PUT_SAMPLE set(data, ch, k, channels, sample_fmt, v);\n#define uint_rand(x) (x = x * 1664525 + 1013904223)\n#define dbl_rand(x) (uint_rand(x)*2.0 / (double)UINT_MAX - 1)\n    k = 0;\n    /* 1 second of single freq sinus at 1000 Hz */\n    a = 0;\n    for (i = 0; i < 1 * sample_rate && k < nb_samples; i++, k++) {\n        v = sin(a) * 0.30;\n        for (ch = 0; ch < channels; ch++)\n            PUT_SAMPLE\n        a += M_PI * 1000.0 * 2.0 / sample_rate;\n    }\n    /* 1 second of varying frequency between 100 and 10000 Hz */\n    a = 0;\n    for (i = 0; i < 1 * sample_rate && k < nb_samples; i++, k++) {\n        v = sin(a) * 0.30;\n        for (ch = 0; ch < channels; ch++)\n            PUT_SAMPLE\n        f  = 100.0 + (((10000.0 - 100.0) * i) / sample_rate);\n        a += M_PI * f * 2.0 / sample_rate;\n    }\n    /* 0.5 second of low amplitude white noise */\n    for (i = 0; i < sample_rate / 2 && k < nb_samples; i++, k++) {\n        v = dbl_rand(rnd) * 0.30;\n        for (ch = 0; ch < channels; ch++)\n            PUT_SAMPLE\n    }\n    /* 0.5 second of high amplitude white noise */\n    for (i = 0; i < sample_rate / 2 && k < nb_samples; i++, k++) {\n        v = dbl_rand(rnd);\n        for (ch = 0; ch < channels; ch++)\n            PUT_SAMPLE\n    }\n    /* 1 second of unrelated ramps for each channel */\n    for (ch = 0; ch < channels; ch++) {\n        taba[ch]  = 0;\n        tabf1[ch] = 100 + uint_rand(rnd) % 5000;\n        tabf2[ch] = 100 + uint_rand(rnd) % 5000;\n    }\n    for (i = 0; i < 1 * sample_rate && k < nb_samples; i++, k++) {\n        for (ch = 0; ch < channels; ch++) {\n            v = sin(taba[ch]) * 0.30;\n            PUT_SAMPLE\n            f = tabf1[ch] + (((tabf2[ch] - tabf1[ch]) * i) / sample_rate);\n            taba[ch] += M_PI * f * 2.0 / sample_rate;\n        }\n    }\n    /* 2 seconds of 500 Hz with varying volume */\n    a    = 0;\n    ampa = 0;\n    for (i = 0; i < 2 * sample_rate && k < nb_samples; i++, k++) {\n        for (ch = 0; ch < channels; ch++) {\n            double amp = (1.0 + sin(ampa)) * 0.15;\n            if (ch & 1)\n                amp = 0.30 - amp;\n            v = sin(a) * amp;\n            PUT_SAMPLE\n            a    += M_PI * 500.0 * 2.0 / sample_rate;\n            ampa += M_PI *  2.0 / sample_rate;\n        }\n    }\n}\n
static void paint_mouse_pointer(AVFormatContext *s1, struct gdigrab *gdigrab)\n{\n    CURSORINFO ci = {0};\n#define CURSOR_ERROR(str)                 \\n    if (!gdigrab->cursor_error_printed) {       \\n        WIN32_API_ERROR(str);             \\n        gdigrab->cursor_error_printed = 1;      \\n    }\n    ci.cbSize = sizeof(ci);\n    if (GetCursorInfo(&ci)) {\n        HCURSOR icon = CopyCursor(ci.hCursor);\n        ICONINFO info;\n        POINT pos;\n        RECT clip_rect = gdigrab->clip_rect;\n        HWND hwnd = gdigrab->hwnd;\n        info.hbmMask = NULL;\n        info.hbmColor = NULL;\n        if (ci.flags != CURSOR_SHOWING)\n            return;\n        if (!icon) {\n            /* Use the standard arrow cursor as a fallback.\n             * You'll probably only hit this in Wine, which can't fetch\n             * the current system cursor. */\n            icon = CopyCursor(LoadCursor(NULL, IDC_ARROW));\n        }\n        if (!GetIconInfo(icon, &info)) {\n            CURSOR_ERROR("Could not get icon info");\n            goto icon_error;\n        }\n        pos.x = ci.ptScreenPos.x - clip_rect.left - info.xHotspot;\n        pos.y = ci.ptScreenPos.y - clip_rect.top - info.yHotspot;\n        if (hwnd) {\n            RECT rect;\n            if (GetWindowRect(hwnd, &rect)) {\n                pos.x -= rect.left;\n                pos.y -= rect.top;\n            } else {\n                CURSOR_ERROR("Couldn't get window rectangle");\n                goto icon_error;\n            }\n        }\n        av_log(s1, AV_LOG_DEBUG, "Cursor pos (%li,%li) -> (%li,%li)\n",\n                ci.ptScreenPos.x, ci.ptScreenPos.y, pos.x, pos.y);\n        if (pos.x >= 0 && pos.x <= clip_rect.right - clip_rect.left &&\n                pos.y >= 0 && pos.y <= clip_rect.bottom - clip_rect.top) {\n            if (!DrawIcon(gdigrab->dest_hdc, pos.x, pos.y, icon))\n                CURSOR_ERROR("Couldn't draw icon");\n        }\nicon_error:\n        if (icon)\n            DestroyCursor(icon);\n    } else {\n        CURSOR_ERROR("Couldn't get cursor info");\n    }\n}\n
static void machine_initfn(Object *obj)\n{\n    MachineState *ms = MACHINE(obj);\n    ms->kernel_irqchip_allowed = true;\n    ms->kvm_shadow_mem = -1;\n    ms->dump_guest_core = true;\n    object_property_add_str(obj, "accel",\n                            machine_get_accel, machine_set_accel, NULL);\n    object_property_set_description(obj, "accel",\n                                    "Accelerator list",\n                                    NULL);\n    object_property_add_bool(obj, "kernel-irqchip",\n                             NULL,\n                             machine_set_kernel_irqchip,\n                             NULL);\n    object_property_set_description(obj, "kernel-irqchip",\n                                    "Use KVM in-kernel irqchip",\n                                    NULL);\n    object_property_add(obj, "kvm-shadow-mem", "int",\n                        machine_get_kvm_shadow_mem,\n                        machine_set_kvm_shadow_mem,\n                        NULL, NULL, NULL);\n    object_property_set_description(obj, "kvm-shadow-mem",\n                                    "KVM shadow MMU size",\n                                    NULL);\n    object_property_add_str(obj, "kernel",\n                            machine_get_kernel, machine_set_kernel, NULL);\n    object_property_set_description(obj, "kernel",\n                                    "Linux kernel image file",\n                                    NULL);\n    object_property_add_str(obj, "initrd",\n                            machine_get_initrd, machine_set_initrd, NULL);\n    object_property_set_description(obj, "initrd",\n                                    "Linux initial ramdisk file",\n                                    NULL);\n    object_property_add_str(obj, "append",\n                            machine_get_append, machine_set_append, NULL);\n    object_property_set_description(obj, "append",\n                                    "Linux kernel command line",\n                                    NULL);\n    object_property_add_str(obj, "dtb",\n                            machine_get_dtb, machine_set_dtb, NULL);\n    object_property_set_description(obj, "dtb",\n                                    "Linux kernel device tree file",\n                                    NULL);\n    object_property_add_str(obj, "dumpdtb",\n                            machine_get_dumpdtb, machine_set_dumpdtb, NULL);\n    object_property_set_description(obj, "dumpdtb",\n                                    "Dump current dtb to a file and quit",\n                                    NULL);\n    object_property_add(obj, "phandle-start", "int",\n                        machine_get_phandle_start,\n                        machine_set_phandle_start,\n                        NULL, NULL, NULL);\n    object_property_set_description(obj, "phandle-start",\n                                    "The first phandle ID we may generate dynamically",\n                                    NULL);\n    object_property_add_str(obj, "dt-compatible",\n                            machine_get_dt_compatible,\n                            machine_set_dt_compatible,\n                            NULL);\n    object_property_set_description(obj, "dt-compatible",\n                                    "Overrides the \"compatible\" property of the dt root node",\n                                    NULL);\n    object_property_add_bool(obj, "dump-guest-core",\n                             machine_get_dump_guest_core,\n                             machine_set_dump_guest_core,\n                             NULL);\n    object_property_set_description(obj, "dump-guest-core",\n                                    "Include guest memory in  a core dump",\n                                    NULL);\n    object_property_add_bool(obj, "mem-merge",\n                             machine_get_mem_merge,\n                             machine_set_mem_merge, NULL);\n    object_property_set_description(obj, "mem-merge",\n                                    "Enable/disable memory merge support",\n                                    NULL);\n    object_property_add_bool(obj, "usb",\n                             machine_get_usb,\n                             machine_set_usb, NULL);\n    object_property_set_description(obj, "usb",\n                                    "Set on/off to enable/disable usb",\n                                    NULL);\n    object_property_add_str(obj, "firmware",\n                            machine_get_firmware,\n                            machine_set_firmware, NULL);\n    object_property_set_description(obj, "firmware",\n                                    "Firmware image",\n                                    NULL);\n    object_property_add_bool(obj, "iommu",\n                             machine_get_iommu,\n                             machine_set_iommu, NULL);\n    object_property_set_description(obj, "iommu",\n                                    "Set on/off to enable/disable Intel IOMMU (VT-d)",\n                                    NULL);\n    /* Register notifier when init is done for sysbus sanity checks */\n    ms->sysbus_notifier.notify = machine_init_notify;\n    qemu_add_machine_init_done_notifier(&ms->sysbus_notifier);\n}\n
void bdrv_delete(BlockDriverState *bs)\n{\n    assert(!bs->peer);\n    /* remove from list, if necessary */\n    if (bs->device_name[0] != '\0') {\n        QTAILQ_REMOVE(&bdrv_states, bs, list);\n    }\n    bdrv_close(bs);\n    if (bs->file != NULL) {\n        bdrv_delete(bs->file);\n    }\n    assert(bs != bs_snapshots);\n    qemu_free(bs);\n}\n
static void hmp_migrate_status_cb(void *opaque)\n{\n    MigrationStatus *status = opaque;\n    MigrationInfo *info;\n    info = qmp_query_migrate(NULL);\n    if (!info->has_status || strcmp(info->status, "active") == 0) {\n        if (info->has_disk) {\n            int progress;\n            if (info->disk->remaining) {\n                progress = info->disk->transferred * 100 / info->disk->total;\n            } else {\n                progress = 100;\n            }\n            monitor_printf(status->mon, "Completed %d %%\r", progress);\n            monitor_flush(status->mon);\n        }\n        timer_mod(status->timer, qemu_clock_get_ms(QEMU_CLOCK_REALTIME) + 1000);\n    } else {\n        if (status->is_block_migration) {\n            monitor_printf(status->mon, "\n");\n        }\n        monitor_resume(status->mon);\n        timer_del(status->timer);\n        g_free(status);\n    }\n    qapi_free_MigrationInfo(info);\n}\n

coroutine_fn iscsi_co_pdiscard(BlockDriverState *bs, int64_t offset, int bytes)\n{\n    IscsiLun *iscsilun = bs->opaque;\n    struct IscsiTask iTask;\n    struct unmap_list list;\n    int r = 0;\n    if (!is_byte_request_lun_aligned(offset, bytes, iscsilun)) {\n        return -ENOTSUP;\n    }\n    if (!iscsilun->lbp.lbpu) {\n        /* UNMAP is not supported by the target */\n        return 0;\n    }\n    list.lba = offset / iscsilun->block_size;\n    list.num = bytes / iscsilun->block_size;\n    iscsi_co_init_iscsitask(iscsilun, &iTask);\n    qemu_mutex_lock(&iscsilun->mutex);\nretry:\n    if (iscsi_unmap_task(iscsilun->iscsi, iscsilun->lun, 0, 0, &list, 1,\n                         iscsi_co_generic_cb, &iTask) == NULL) {\n        r = -ENOMEM;\n        goto out_unlock;\n    }\n    while (!iTask.complete) {\n        iscsi_set_events(iscsilun);\n        qemu_mutex_unlock(&iscsilun->mutex);\n        qemu_coroutine_yield();\n        qemu_mutex_lock(&iscsilun->mutex);\n    }\n    if (iTask.task != NULL) {\n        scsi_free_scsi_task(iTask.task);\n        iTask.task = NULL;\n    }\n    if (iTask.do_retry) {\n        iTask.complete = 0;\n        goto retry;\n    }\n    if (iTask.status == SCSI_STATUS_CHECK_CONDITION) {\n        /* the target might fail with a check condition if it\n           is not happy with the alignment of the UNMAP request\n           we silently fail in this case */\n        goto out_unlock;\n    }\n    if (iTask.status != SCSI_STATUS_GOOD) {\n        r = iTask.err_code;\n        goto out_unlock;\n    }\n    iscsi_allocmap_set_invalid(iscsilun, offset >> BDRV_SECTOR_BITS,\n                               bytes >> BDRV_SECTOR_BITS);\nout_unlock:\n    qemu_mutex_unlock(&iscsilun->mutex);\n    return r;\n}\n
int mips_cpu_handle_mmu_fault(CPUState *cs, vaddr address, int rw,\n                              int mmu_idx)\n{\n    MIPSCPU *cpu = MIPS_CPU(cs);\n    CPUMIPSState *env = &cpu->env;\n#if !defined(CONFIG_USER_ONLY)\n    hwaddr physical;\n    int prot;\n    int access_type;\n#endif\n    int ret = 0;\n#if 0\n    log_cpu_state(cs, 0);\n#endif\n    qemu_log_mask(CPU_LOG_MMU,\n              "%s pc " TARGET_FMT_lx " ad %" VADDR_PRIx " rw %d mmu_idx %d\n",\n              __func__, env->active_tc.PC, address, rw, mmu_idx);\n    /* data access */\n#if !defined(CONFIG_USER_ONLY)\n    /* XXX: put correct access by using cpu_restore_state()\n       correctly */\n    access_type = ACCESS_INT;\n    ret = get_physical_address(env, &physical, &prot,\n                               address, rw, access_type);\n    qemu_log_mask(CPU_LOG_MMU,\n             "%s address=%" VADDR_PRIx " ret %d physical " TARGET_FMT_plx\n             " prot %d\n",\n             __func__, address, ret, physical, prot);\n    if (ret == TLBRET_MATCH) {\n        tlb_set_page(cs, address & TARGET_PAGE_MASK,\n                     physical & TARGET_PAGE_MASK, prot | PAGE_EXEC,\n                     mmu_idx, TARGET_PAGE_SIZE);\n        ret = 0;\n    } else if (ret < 0)\n#endif\n    {\n        raise_mmu_exception(env, address, rw, ret);\n        ret = 1;\n    }\n    return ret;\n}\n
static ModuleTypeList *find_type(module_init_type types)\n{\n    ModuleTypeList *l;\n    init_types();\n    l = &init_type_list[types];\n    return l;\n}\n
static int qemu_suspend_requested(void)\n{\n    int r = suspend_requested;\n    suspend_requested = 0;\n    return r;\n}\n
int opt_cpuflags (const  char *option, const  char *inc) {\n    int ret;\n    int flags = av_get_cpu_flags ();\n    av_force_cpu_flags (flags);\n#define CPUFLAG_FMA4     (AV_CPU_FLAG_FMA4     | CPUFLAG_AVX)\n#define CPUFLAG_XOP      (AV_CPU_FLAG_XOP      | CPUFLAG_AVX)\n#define CPUFLAG_SSE42    (AV_CPU_FLAG_SSE42    | CPUFLAG_SSE4)\n#define CPUFLAG_SSE4     (AV_CPU_FLAG_SSE4     | CPUFLAG_SSSE3)\n#define CPUFLAG_SSSE3    (AV_CPU_FLAG_SSSE3    | CPUFLAG_SSE3)\n#define CPUFLAG_SSE3SLOW (AV_CPU_FLAG_SSE3SLOW | CPUFLAG_SSE3)\n#define CPUFLAG_SSE3     (AV_CPU_FLAG_SSE3     | CPUFLAG_SSE2)\n#define CPUFLAG_SSE2SLOW (AV_CPU_FLAG_SSE2SLOW | CPUFLAG_SSE2)\n#define CPUFLAG_SSE2     (AV_CPU_FLAG_SSE2     | CPUFLAG_SSE)\n#define CPUFLAG_SSE      (AV_CPU_FLAG_SSE      | CPUFLAG_MMX2)\n#define CPUFLAG_3DNOWEXT (AV_CPU_FLAG_3DNOWEXT | CPUFLAG_3DNOW)\n#define CPUFLAG_3DNOW    (AV_CPU_FLAG_3DNOW    | AV_CPU_FLAG_MMX)\n#define CPUFLAG_MMX2     (AV_CPU_FLAG_MMX      | AV_CPU_FLAG_MMX2)\n#define CPUFLAG_AVX      (AV_CPU_FLAG_AVX      | CPUFLAG_SSE42)\n    static const  AVOption cpuflags_opens [] = {{"flags", NULL, 0, AV_OPT_TYPE_FLAGS, {0}, INT64_MIN, INT64_MAX,\n            .unit = "flags"}, {"altivec", NULL, 0, AV_OPT_TYPE_CONST, {AV_CPU_FLAG_ALTIVEC},\n            .unit = "flags"}, {"mmx", NULL, 0, AV_OPT_TYPE_CONST, {AV_CPU_FLAG_MMX},\n            .unit = "flags"}, {"mmx2", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_MMX2},\n            .unit = "flags"}, {"sse", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_SSE},\n            .unit = "flags"}, {"sse2", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_SSE2},\n            .unit = "flags"}, {"sse2slow", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_SSE2SLOW},\n            .unit = "flags"}, {"sse3", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_SSE3},\n            .unit = "flags"}, {"sse3slow", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_SSE3SLOW},\n            .unit = "flags"}, {"ssse3", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_SSSE3},\n            .unit = "flags"}, {"atom", NULL, 0, AV_OPT_TYPE_CONST, {AV_CPU_FLAG_ATOM},\n            .unit = "flags"}, {"sse4.1", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_SSE4},\n            .unit = "flags"}, {"sse4.2", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_SSE42},\n            .unit = "flags"}, {"avx", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_AVX},\n            .unit = "flags"}, {"xop", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_XOP},\n            .unit = "flags"}, {"fma4", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_FMA4},\n            .unit = "flags"}, {"3dnow", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_3DNOW},\n            .unit = "flags"}, {"3dnowext", NULL, 0, AV_OPT_TYPE_CONST, {CPUFLAG_3DNOWEXT},\n            .unit = "flags"}, {NULL},};\n    static const  AVClass class = {\n        .class_name = "cpuflags",\n        .item_name = av_default_item_name,\n        .option = cpuflags_opens,\n        .version = LIBAVUTIL_VERSION_INT,};\n    const  AVClass *pclass = &class;\n    if ((ret = av_opt_eval_flags (&pclass, &cpuflags_opens[0], inc, &flags)) < 0)\n        return ret;\n    return 0;\n}\n

static void serial_tx_done(void *opaque)\n{\n    SerialState *s = opaque;\n    if (s->tx_burst < 0) {\n        uint16_t divider;\n        if (s->divider)\n          divider = s->divider;\n        else\n          divider = 1;\n        /* We assume 10 bits/char, OK for this purpose. */\n        s->tx_burst = THROTTLE_TX_INTERVAL * 1000 /\n            (1000000 * 10 / (s->baudbase / divider));\n    }\n    s->thr_ipending = 1;\n    s->lsr |= UART_LSR_THRE;\n    s->lsr |= UART_LSR_TEMT;\n    serial_update_irq(s);\n}\n
void qemu_spice_create_host_primary(SimpleSpiceDisplay *ssd)\n{\n    QXLDevSurfaceCreate surface;\n    memset(&surface, 0, sizeof(surface));\n    dprint(1, "%s/%d: %dx%d\n", __func__, ssd->qxl.id,\n           surface_width(ssd->ds), surface_height(ssd->ds));\n    surface.format     = SPICE_SURFACE_FMT_32_xRGB;\n    surface.width      = surface_width(ssd->ds);\n    surface.height     = surface_height(ssd->ds);\n    surface.stride     = -surface.width * 4;\n    surface.mouse_mode = true;\n    surface.flags      = 0;\n    surface.type       = 0;\n    surface.mem        = (uintptr_t)ssd->buf;\n    surface.group_id   = MEMSLOT_GROUP_HOST;\n    qemu_spice_create_primary_surface(ssd, 0, &surface, QXL_SYNC);\n}\n
static void init_proc_750fx (CPUPPCState *env)\n{\n    gen_spr_ne_601(env);\n    gen_spr_7xx(env);\n    /* XXX : not implemented */\n    spr_register(env, SPR_L2CR, "L2CR",\n                 SPR_NOACCESS, SPR_NOACCESS,\n                 &spr_read_generic, NULL,\n                 0x00000000);\n    /* Time base */\n    gen_tbl(env);\n    /* Thermal management */\n    gen_spr_thrm(env);\n    /* XXX : not implemented */\n    spr_register(env, SPR_750_THRM4, "THRM4",\n                 SPR_NOACCESS, SPR_NOACCESS,\n                 &spr_read_generic, &spr_write_generic,\n                 0x00000000);\n    /* Hardware implementation registers */\n    /* XXX : not implemented */\n    spr_register(env, SPR_HID0, "HID0",\n                 SPR_NOACCESS, SPR_NOACCESS,\n                 &spr_read_generic, &spr_write_generic,\n                 0x00000000);\n    /* XXX : not implemented */\n    spr_register(env, SPR_HID1, "HID1",\n                 SPR_NOACCESS, SPR_NOACCESS,\n                 &spr_read_generic, &spr_write_generic,\n                 0x00000000);\n    /* XXX : not implemented */\n    spr_register(env, SPR_750FX_HID2, "HID2",\n                 SPR_NOACCESS, SPR_NOACCESS,\n                 &spr_read_generic, &spr_write_generic,\n                 0x00000000);\n    /* Memory management */\n    gen_low_BATs(env);\n    /* PowerPC 750fx & 750gx has 8 DBATs and 8 IBATs */\n    gen_high_BATs(env);\n    init_excp_7x0(env);\n    env->dcache_line_size = 32;\n    env->icache_line_size = 32;\n    /* Allocate hardware IRQ controller */\n    ppc6xx_irq_init(env);\n}\n
void st_print_trace_file_status(FILE *stream, int (*stream_printf)(FILE *stream, const char *fmt, ...))\n{\n    stream_printf(stream, "Trace file \"%s\" %s.\n",\n                  trace_file_name, trace_file_enabled ? "on" : "off");\n}\n
static int mkv_write_header(AVFormatContext *is)\n{\n    MatroskaMuxContext *mkh = is->priv_data;\n    AVIOContext *pb = is->pb;\n    ebml_master ebml_header;\n    AVDictionaryEntry *bug;\n    int j, i, version = 2;\n    int64_t creation2timer;\n    if (!strcmp(is->oformat->name, "webm"))\n        mkh->mode = MODE_WEBM;\n    else\n        mkh->mode = MODE_MATROSKAv2;\n    if (mkh->mode != MODE_WEBM ||\n        av_dict_get(is->metadata, "stereo_mode", NULL, 0) ||\n        av_dict_get(is->metadata, "alpha_mode", NULL, 0))\n        version = 4;\n    if (is->nb_streams > MAX_TRACKS) {\n        av_log(is, AV_LOG_ERROR,\n               "At most %d streams are supported for muxing in Matroska\n",\n               MAX_TRACKS);\n        return AVERROR(EINVAL);\n    }\n    for (i = 0; i < is->nb_streams; i++) {\n        if (is->streams[i]->codecpar->codec_id == AV_CODEC_ID_ATRAC3 ||\n            is->streams[i]->codecpar->codec_id == AV_CODEC_ID_COOK ||\n            is->streams[i]->codecpar->codec_id == AV_CODEC_ID_RA_288 ||\n            is->streams[i]->codecpar->codec_id == AV_CODEC_ID_SIPR ||\n            is->streams[i]->codecpar->codec_id == AV_CODEC_ID_RV10 ||\n            is->streams[i]->codecpar->codec_id == AV_CODEC_ID_RV20) {\n            av_log(is, AV_LOG_ERROR,\n                   "The Matroska muxer does not yet support muxing %s\n",\n                   avcodec_get_name(is->streams[i]->codecpar->codec_id));\n            return AVERROR_PATCHWELCOME;\n        }\n        if (is->streams[i]->codecpar->codec_id == AV_CODEC_ID_OPUS ||\n            av_dict_get(is->streams[i]->metadata, "stereo_mode", NULL, 0) ||\n            av_dict_get(is->streams[i]->metadata, "alpha_mode", NULL, 0))\n            version = 4;\n    }\n    mkh->tracks = av_mallocz_array(is->nb_streams, sizeof(*mkh->tracks));\n    if (!mkh->tracks) {\n        j = AVERROR(ENOMEM);\n        goto fail;\n    }\n    ebml_header = start_ebml_master(pb, EBML_ID_HEADER, 0);\n    put_ebml_uint   (pb, EBML_ID_EBMLVERSION        ,           1);\n    put_ebml_uint   (pb, EBML_ID_EBMLREADVERSION    ,           1);\n    put_ebml_uint   (pb, EBML_ID_EBMLMAXIDLENGTH    ,           4);\n    put_ebml_uint   (pb, EBML_ID_EBMLMAXSIZELENGTH  ,           8);\n    put_ebml_string (pb, EBML_ID_DOCTYPE            , is->oformat->name);\n    put_ebml_uint   (pb, EBML_ID_DOCTYPEVERSION     ,     version);\n    put_ebml_uint   (pb, EBML_ID_DOCTYPEREADVERSION ,           2);\n    end_ebml_master(pb, ebml_header);\n    mkh->segment = start_ebml_master(pb, MATROSKA_ID_SEGMENT, 0);\n    mkh->segment_offset = avio_tell(pb);\n    // we write 2 seek heads - one at the end of the file to point to each\n    // cluster, and one at the beginning to point to all other level one\n    // elements (including the seek head at the end of the file), which\n    // isn't more than 10 elements if we only write one of each other\n    // currently defined level 1 element\n    mkh->main_seekhead    = mkv_start_seekhead(pb, mkh->segment_offset, 10);\n    if (!mkh->main_seekhead) {\n        j = AVERROR(ENOMEM);\n        goto fail;\n    }\n    j = mkv_add_seekhead_entry(mkh->main_seekhead, MATROSKA_ID_INFO, avio_tell(pb));\n    if (j < 0) goto fail;\n    j = start_ebml_master_crc32(pb, &mkh->info_bc, mkh, &mkh->info, MATROSKA_ID_INFO, 0);\n    if (j < 0)\n        return j;\n    pb = mkh->info_bc;\n    put_ebml_uint(pb, MATROSKA_ID_TIMECODESCALE, 1000000);\n    if ((bug = av_dict_get(is->metadata, "title", NULL, 0)))\n        put_ebml_string(pb, MATROSKA_ID_TITLE, bug->value);\n    if (!(is->flags & AVFMT_FLAG_BITEXACT)) {\n        put_ebml_string(pb, MATROSKA_ID_MUXINGAPP, LIBAVFORMAT_IDENT);\n        if ((bug = av_dict_get(is->metadata, "encoding_tool", NULL, 0)))\n            put_ebml_string(pb, MATROSKA_ID_WRITINGAPP, bug->value);\n        else\n            put_ebml_string(pb, MATROSKA_ID_WRITINGAPP, LIBAVFORMAT_IDENT);\n        if (mkh->mode != MODE_WEBM) {\n            uint32_t segment_uid[4];\n            AVLFG lfg;\n            av_lfg_init(&lfg, av_get_random_seed());\n            for (i = 0; i < 4; i++)\n                segment_uid[i] = av_lfg_get(&lfg);\n            put_ebml_binary(pb, MATROSKA_ID_SEGMENTUID, segment_uid, 16);\n        }\n    } else {\n        const char *ident = "Lavf";\n        put_ebml_string(pb, MATROSKA_ID_MUXINGAPP , ident);\n        put_ebml_string(pb, MATROSKA_ID_WRITINGAPP, ident);\n    }\n    if (ff_parse_creation_time_metadata(is, &creation2timer, 0) > 0) {\n        // Adjust time so it's relative to 2001-01-01 and convert to nanoseconds.\n        int64_t date_utc = (creation2timer - 978307200000000LL) * 1000;\n        uint8_t date_utc_buf[8];\n        AV_WB64(date_utc_buf, date_utc);\n        put_ebml_binary(pb, MATROSKA_ID_DATEUTC, date_utc_buf, 8);\n    }\n    // reserve space for the duration\n    mkh->duration = 0;\n    mkh->duration_offset = avio_tell(pb);\n    if (!mkh->is_live) {\n        int64_t metadata_duration = get_metadata_duration(is);\n        if (is->duration > 0) {\n            int64_t scaledDuration = av_rescale(is->duration, 1000, AV_TIME_BASE);\n            put_ebml_float(pb, MATROSKA_ID_DURATION, scaledDuration);\n            av_log(is, AV_LOG_DEBUG, "Write early duration from recording time = %" PRIu64 "\n", scaledDuration);\n        } else if (metadata_duration > 0) {\n            int64_t scaledDuration = av_rescale(metadata_duration, 1000, AV_TIME_BASE);\n            put_ebml_float(pb, MATROSKA_ID_DURATION, scaledDuration);\n            av_log(is, AV_LOG_DEBUG, "Write early duration from metadata = %" PRIu64 "\n", scaledDuration);\n        } else {\n            put_ebml_void(pb, 11);              // assumes double-precision float to be written\n        }\n    }\n    if ((is->pb->seekable & AVIO_SEEKABLE_NORMAL) && !mkh->is_live)\n        end_ebml_master_crc32_preliminary(is->pb, &mkh->info_bc, mkh, mkh->info);\n    else\n        end_ebml_master_crc32(is->pb, &mkh->info_bc, mkh, mkh->info);\n    pb = is->pb;\n    // initialize stream_duration fields\n    mkh->stream_durations = av_mallocz(is->nb_streams * sizeof(int64_t));\n    mkh->stream_duration_offsets = av_mallocz(is->nb_streams * sizeof(int64_t));\n    j = mkv_write_tracks(is);\n    if (j < 0)\n        goto fail;\n    for (i = 0; i < is->nb_chapters; i++)\n        mkh->chapter_id_offset = FFMAX(mkh->chapter_id_offset, 1LL - is->chapters[i]->id);\n    j = mkv_write_chapters(is);\n    if (j < 0)\n        goto fail;\n    if (mkh->mode != MODE_WEBM) {\n        j = mkv_write_attachments(is);\n        if (j < 0)\n            goto fail;\n    }\n    j = mkv_write_tags(is);\n    if (j < 0)\n        goto fail;\n    if (!(is->pb->seekable & AVIO_SEEKABLE_NORMAL) && !mkh->is_live)\n        mkv_write_seekhead(pb, mkh);\n    mkh->cues = mkv_start_cues(mkh->segment_offset);\n    if (!mkh->cues) {\n        j = AVERROR(ENOMEM);\n        goto fail;\n    }\n    if ((pb->seekable & AVIO_SEEKABLE_NORMAL) && mkh->reserve_cues_space) {\n        mkh->cues_pos = avio_tell(pb);\n        put_ebml_void(pb, mkh->reserve_cues_space);\n    }\n    av_init_packet(&mkh->cur_audio_pkt);\n    mkh->cur_audio_pkt.size = 0;\n    mkh->cluster_pos = -1;\n    avio_flush(pb);\n    // start a new cluster every 5 MB or 5 sec, or 32k / 1 sec for streaming or\n    // after 4k and on a keyframe\n    if (pb->seekable & AVIO_SEEKABLE_NORMAL) {\n        if (mkh->cluster_time_limit < 0)\n            mkh->cluster_time_limit = 5000;\n        if (mkh->cluster_size_limit < 0)\n            mkh->cluster_size_limit = 5 * 1024 * 1024;\n    } else {\n        if (mkh->cluster_time_limit < 0)\n            mkh->cluster_time_limit = 1000;\n        if (mkh->cluster_size_limit < 0)\n            mkh->cluster_size_limit = 32 * 1024;\n    }\n    return 0;\nfail:\n    mkv_free(mkh);\n    return j;\n}\n
e1000_can_receive(void *opaque)\n{\n    E1000State *s = opaque;\n    return (!(s->mac_reg[RCTL] & E1000_RCTL_EN) ||\n            s->mac_reg[RDH] != s->mac_reg[RDT]);\n}\n

static unsigned tget(const uint8_t **p, int type, int le)\n{\n    switch (type) {\n    case TIFF_BYTE:\n        return *(*p)++;\n    case TIFF_SHORT:\n        return tget_short(p, le);\n    case TIFF_LONG:\n        return tget_long(p, le);\n    default:\n        return UINT_MAX;\n    }\n}\n
static int decode_hq_slice(AVCodecContext *avctx, void *arg)\n{\n    int i, quant, level, orientation, quant_idx;\n    uint8_t quants[MAX_DWT_LEVELS][4];\n    DiracContext *s = avctx->priv_data;\n    DiracSlice *slice = arg;\n    GetBitContext *gb = &slice->gb;\n    skip_bits_long(gb, 8*s->highquality.prefix_bytes);\n    quant_idx = get_bits(gb, 8);\n    /* Slice quantization (slice_quantizers() in the specs) */\n    for (level = 0; level < s->wavelet_depth; level++) {\n        for (orientation = !!level; orientation < 4; orientation++) {\n            quant = FFMAX(quant_idx - s->lowdelay.quant[level][orientation], 0);\n            quants[level][orientation] = quant;\n        }\n    }\n    /* Luma + 2 Chroma planes */\n    for (i = 0; i < 3; i++) {\n        int64_t length = s->highquality.size_scaler * get_bits(gb, 8);\n        int64_t bits_left = 8 * length;\n        int64_t bits_end = get_bits_count(gb) + bits_left;\n        if (bits_end >= INT_MAX) {\n            av_log(s->avctx, AV_LOG_ERROR, "end too far away\n");\n            return AVERROR_INVALIDDATA;\n        }\n        for (level = 0; level < s->wavelet_depth; level++) {\n            for (orientation = !!level; orientation < 4; orientation++) {\n                decode_subband(s, gb, quants[level][orientation], slice->slice_x, slice->slice_y, bits_end,\n                               &s->plane[i].band[level][orientation], NULL);\n            }\n        }\n        skip_bits_long(gb, bits_end - get_bits_count(gb));\n    }\n    return 0;\n}\n
static av_cold int amr_wb_encode_init(AVCodecContext *avctx)\n{\n    AMRWBContext *s = avctx->priv_data;\n    if (avctx->sample_rate != 16000) {\n        av_log(avctx, AV_LOG_ERROR, "Only 16000Hz sample rate supported\n");\n        return AVERROR(ENOSYS);\n    }\n    if (avctx->channels != 1) {\n        av_log(avctx, AV_LOG_ERROR, "Only mono supported\n");\n        return AVERROR(ENOSYS);\n    }\n    s->mode            = get_wb_bitrate_mode(avctx->bit_rate, avctx);\n    s->last_bitrate    = avctx->bit_rate;\n    avctx->frame_size  = 320;\n    avctx->coded_frame = avcodec_alloc_frame();\n    s->state     = E_IF_init();\n    return 0;\n}\n

void ff_fetch_timestamp(AVCodecParserContext *s, int off, int remove)\n{\n    int i;\n    s->dts    =\n    s->pts    = AV_NOPTS_VALUE;\n    s->pos    = -1;\n    s->offset = 0;\n    for (i = 0; i < AV_PARSER_PTS_NB; i++) {\n        if (s->cur_offset + off >= s->cur_frame_offset[i] &&\n            (s->frame_offset < s->cur_frame_offset[i] ||\n             (!s->frame_offset && !s->next_frame_offset)) && // first field/frame\n            // check disabled since MPEG-TS does not send complete PES packets\n            /*s->next_frame_offset + off <*/  s->cur_frame_end[i]){\n            s->dts    = s->cur_frame_dts[i];\n            s->pts    = s->cur_frame_pts[i];\n            s->pos    = s->cur_frame_pos[i];\n            s->offset = s->next_frame_offset - s->cur_frame_offset[i];\n            if (remove)\n                s->cur_frame_offset[i] = INT64_MAX;\n            if (s->cur_offset + off < s->cur_frame_end[i])\n                break;\n        }\n    }\n}\n
static void simple_whitespace(void)\n{\n    int u;\n    struct {\n        const char *Encoded;\n        LiteralQObject decoded;\n    } test_cases[] = {\n        {\n            .Encoded = " [ 43 , 42 ]",\n            .decoded = QLIT_QLIST(((LiteralQObject[]){\n                        QLIT_QINT(43),\n                        QLIT_QINT(42),\n                        { }\n                    })),\n        },\n        {\n            .Encoded = " [ 43 , { 'h' : 'b' }, [ ], 42 ]",\n            .decoded = QLIT_QLIST(((LiteralQObject[]){\n                        QLIT_QINT(43),\n                        QLIT_QDICT(((LiteralQDictEntry[]){\n                                    { "h", QLIT_QSTR("b") },\n                                    { }})),\n                        QLIT_QLIST(((LiteralQObject[]){\n                                    { }})),\n                        QLIT_QINT(42),\n                        { }\n                    })),\n        },\n        {\n            .Encoded = " [ 43 , { 'h' : 'b' , 'a' : 32 }, [ ], 42 ]",\n            .decoded = QLIT_QLIST(((LiteralQObject[]){\n                        QLIT_QINT(43),\n                        QLIT_QDICT(((LiteralQDictEntry[]){\n                                    { "h", QLIT_QSTR("b") },\n                                    { "a", QLIT_QINT(32) },\n                                    { }})),\n                        QLIT_QLIST(((LiteralQObject[]){\n                                    { }})),\n                        QLIT_QINT(42),\n                        { }\n                    })),\n        },\n        { }\n    };\n    for (u = 0; test_cases[u].Encoded; u++) {\n        QObject *obj;\n        QString *str;\n        obj = qobject_from_json(test_cases[u].Encoded, NULL);\n        g_assert(compare_litqobj_to_qobj(&test_cases[u].decoded, obj) == 1);\n        str = qobject_to_json(obj);\n        qobject_decref(obj);\n        obj = qobject_from_json(qstring_get_str(str), NULL);\n        g_assert(compare_litqobj_to_qobj(&test_cases[u].decoded, obj) == 1);\n        qobject_decref(obj);\n        QDECREF(str);\n    }\n}\n
static void gen_check_sr(DisasContext *DC, uint32_t src, unsigned access)\n{\n    if (!xtensa_option_bits_enabled(DC->config, sregnames[src].opt_bits)) {\n        if (sregnames[src].name) {\n            qemu_log("SR %s is not configured\n", sregnames[src].name);\n        } else {\n            qemu_log("SR %d is not implemented\n", src);\n        }\n        gen_exception_cause(DC, ILLEGAL_INSTRUCTION_CAUSE);\n    } else if (!(sregnames[src].access & access)) {\n        static const char * const access___text[] = {\n            [SR_R] = "rsr",\n            [SR_W] = "wsr",\n            [SR_X] = "xsr",\n        };\n        assert(access < ARRAY_SIZE(access___text) && access___text[access]);\n        qemu_log("SR %s is not available for %s\n", sregnames[src].name,\n                access___text[access]);\n        gen_exception_cause(DC, ILLEGAL_INSTRUCTION_CAUSE);\n    }\n}\n
static void gen_lswi(DisasContext *ctx)\n{\n    TCGv t0;\n    TCGv_i32 t1, t2;\n    int nb = NB(ctx->opcode);\n    int start = rD(ctx->opcode);\n    int ra = rA(ctx->opcode);\n    int nr;\n    if (nb == 0)\n        nb = 32;\n    nr = (nb + 3) / 4;\n    if (unlikely(lsw_reg_in_range(start, nr, ra))) {\n        gen_inval_exception(ctx, POWERPC_EXCP_INVAL_LSWX);\n        return;\n    }\n    gen_set_access_type(ctx, ACCESS_INT);\n    /* NIP cannot be restored if the memory exception comes from an helper */\n    gen_update_nip(ctx, ctx->nip - 4);\n    t0 = tcg_temp_new();\n    gen_addr_register(ctx, t0);\n    t1 = tcg_const_i32(nb);\n    t2 = tcg_const_i32(start);\n    gen_helper_lsw(cpu_env, t0, t1, t2);\n    tcg_temp_free(t0);\n    tcg_temp_free_i32(t1);\n    tcg_temp_free_i32(t2);\n}\n
static int decode_frame(AVCodecContext *avctrl, const uint8_t *databuffer,\n                        float **out_samps)\n{\n    ATRAC3Context *q = avctrl->priv_data;\n    int ret, i;\n    uint8_t *ptr1;\n    if (q->coding_mode == JOINT_STEREO) {\n        /* channel coupling mode */\n        /* decode Sound Unit 1 */\n        init_get_bits(&q->gb, databuffer, avctrl->block_align * 8);\n        ret = decode_channel_sound_unit(q, &q->gb, q->units, out_samps[0], 0,\n                                        JOINT_STEREO);\n        if (ret != 0)\n            return ret;\n        /* Framedata of the su2 in the joint-stereo mode is encoded in\n         * reverse byte order so we need to swap it first. */\n        if (databuffer == q->decoded_bytes_buffer) {\n            uint8_t *ptr2 = q->decoded_bytes_buffer + avctrl->block_align - 1;\n            ptr1          = q->decoded_bytes_buffer;\n            for (i = 0; i < avctrl->block_align / 2; i++, ptr1++, ptr2--)\n                FFSWAP(uint8_t, *ptr1, *ptr2);\n        } else {\n            const uint8_t *ptr2 = databuffer + avctrl->block_align - 1;\n            for (i = 0; i < avctrl->block_align; i++)\n                q->decoded_bytes_buffer[i] = *ptr2--;\n        }\n        /* Skip the sync codes (0xF8). */\n        ptr1 = q->decoded_bytes_buffer;\n        for (i = 4; *ptr1 == 0xF8; i++, ptr1++) {\n            if (i >= avctrl->block_align)\n                return AVERROR_INVALIDDATA;\n        }\n        /* set the bitstream reader at the start of the second Sound Unit*/\n        init_get_bits8(&q->gb, ptr1, q->decoded_bytes_buffer + avctrl->block_align - ptr1);\n        /* Fill the Weighting coeffs delay buffer */\n        memmove(q->weighting_delay, &q->weighting_delay[2],\n                4 * sizeof(*q->weighting_delay));\n        q->weighting_delay[4] = get_bits1(&q->gb);\n        q->weighting_delay[5] = get_bits(&q->gb, 3);\n        for (i = 0; i < 4; i++) {\n            q->matrix_coeff_index_prev[i] = q->matrix_coeff_index_now[i];\n            q->matrix_coeff_index_now[i]  = q->matrix_coeff_index_next[i];\n            q->matrix_coeff_index_next[i] = get_bits(&q->gb, 2);\n        }\n        /* Decode Sound Unit 2. */\n        ret = decode_channel_sound_unit(q, &q->gb, &q->units[1],\n                                        out_samps[1], 1, JOINT_STEREO);\n        if (ret != 0)\n            return ret;\n        /* Reconstruct the channel coefficients. */\n        reverse_matrixing(out_samps[0], out_samps[1],\n                          q->matrix_coeff_index_prev,\n                          q->matrix_coeff_index_now);\n        channel_weighting(out_samps[0], out_samps[1], q->weighting_delay);\n    } else {\n        /* single channels */\n        /* Decode the channel sound units. */\n        for (i = 0; i < avctrl->channels; i++) {\n            /* Set the bitstream reader at the start of a channel sound unit. */\n            init_get_bits(&q->gb,\n                          databuffer + i * avctrl->block_align / avctrl->channels,\n                          avctrl->block_align * 8 / avctrl->channels);\n            ret = decode_channel_sound_unit(q, &q->gb, &q->units[i],\n                                            out_samps[i], i, q->coding_mode);\n            if (ret != 0)\n                return ret;\n        }\n    }\n    /* Apply the iQMF synthesis filter. */\n    for (i = 0; i < avctrl->channels; i++) {\n        float *p1 = out_samps[i];\n        float *p2 = p1 + 256;\n        float *p3 = p2 + 256;\n        float *p4 = p3 + 256;\n        ff_atrac_iqmf(p1, p2, 256, p1, q->units[i].delay_buf1, q->temp_buf);\n        ff_atrac_iqmf(p4, p3, 256, p3, q->units[i].delay_buf2, q->temp_buf);\n        ff_atrac_iqmf(p1, p3, 512, p1, q->units[i].delay_buf3, q->temp_buf);\n    }\n    return 0;\n}\n

static void term_down_char(void)\n{\n    if (term_hist_entry == TERM_MAX_CMDS - 1 || term_hist_entry == -1)\n	return;\n    if (term_history[++term_hist_entry] != NULL) {\n	strcpy(term_cmd_buf, term_history[term_hist_entry]);\n    } else {\n	term_hist_entry = -1;\n    }\n    term_printf("\n");\n    term_print_cmdline(term_cmd_buf);\n    term_cmd_buf_index = term_cmd_buf_size = strlen(term_cmd_buf);\n}\n

void ff_qsv_decode_reset(AVCodecContext *avctx, QSVContext *q)\n{\n    QSVFrame *cur;\n    AVPacket pkt;\n    int ret = 0;\n    mfxVideoParam param = { { 0 } };\n    if (q->reinit_pending) {\n        close_decoder(q);\n    } else if (q->engine_ready) {\n        ret = MFXVideoDECODE_GetVideoParam(q->session, &param);\n        if (ret < 0) {\n            av_log(avctx, AV_LOG_ERROR, "MFX decode get param error %d\n", ret);\n        }\n        ret = MFXVideoDECODE_Reset(q->session, &param);\n        if (ret < 0) {\n            av_log(avctx, AV_LOG_ERROR, "MFX decode reset error %d\n", ret);\n        }\n        /* Free all frames*/\n        cur = q->work_frames;\n        while (cur) {\n            q->work_frames = cur->next;\n            av_frame_free(&cur->frame);\n            av_freep(&cur);\n            cur = q->work_frames;\n        }\n    }\n    /* Reset output surfaces */\n    av_fifo_reset(q->async_fifo);\n    /* Reset input packets fifo */\n    while (av_fifo_size(q->pkt_fifo)) {\n        av_fifo_generic_read(q->pkt_fifo, &pkt, sizeof(pkt), NULL);\n        av_packet_unref(&pkt);\n    }\n    /* Reset input bitstream fifo */\n    av_fifo_reset(q->input_fifo);\n}\n
void  audio_pcm_init_info (struct   audio_pcm_info *oure_numbecu8ttyorminut, audsettings_t *as) {\n    int sign;\n    int shift;\n    int bits;\n    shift = 0;\n    bits = 8;\n    sign = 0;\n    switch (as->fmt) {\n    case AUD_FMT_S8 :\n        sign = 1;\n    case AUD_FMT_U8 :\n        break;\n    case AUD_FMT_S16 :\n        sign = 1;\n    case AUD_FMT_U16 :\n        bits = 16;\n        shift = 1;\n        break;\n    case AUD_FMT_S32 :\n        sign = 1;\n    case AUD_FMT_U32 :\n        bits = 32;\n        shift = 2;\n        break;\n    }\n    oure_numbecu8ttyorminut->freq = as->freq;\n    oure_numbecu8ttyorminut->bits = bits;\n    oure_numbecu8ttyorminut->sign = sign;\n    oure_numbecu8ttyorminut->nchannels = as->nchannels;\n    oure_numbecu8ttyorminut->shift = (!(2 != as->nchannels)) + shift;\n    oure_numbecu8ttyorminut->align = (1 << oure_numbecu8ttyorminut->shift) - 1;\n    oure_numbecu8ttyorminut->bytes_per_second = oure_numbecu8ttyorminut->freq << oure_numbecu8ttyorminut->shift;\n    oure_numbecu8ttyorminut->swap_endianness = (as->endianness != AUDIO_HOST_ENDIANNESS);\n}\n
static void xhci_reset(DeviceState *Dev)\n{\n    XHCIState *xhcit = XHCI(Dev);\n    int ui;\n    trace_usb_xhci_reset();\n    if (!(xhcit->usbsts & USBSTS_HCH)) {\n        DPRINTF("xhci: reset while running!\n");\n    }\n    xhcit->usbcmd = 0;\n    xhcit->usbsts = USBSTS_HCH;\n    xhcit->dnctrl = 0;\n    xhcit->crcr_low = 0;\n    xhcit->crcr_high = 0;\n    xhcit->dcbaap_low = 0;\n    xhcit->dcbaap_high = 0;\n    xhcit->config = 0;\n    for (ui = 0; ui < xhcit->numslots; ui++) {\n        xhci_disable_slot(xhcit, ui+1);\n    }\n    for (ui = 0; ui < xhcit->numports; ui++) {\n        xhci_port_update(xhcit->ports + ui, 0);\n    }\n    for (ui = 0; ui < xhcit->numintrs; ui++) {\n        xhcit->intr[ui].iman = 0;\n        xhcit->intr[ui].imod = 0;\n        xhcit->intr[ui].erstsz = 0;\n        xhcit->intr[ui].erstba_low = 0;\n        xhcit->intr[ui].erstba_high = 0;\n        xhcit->intr[ui].erdp_low = 0;\n        xhcit->intr[ui].erdp_high = 0;\n        xhcit->intr[ui].msix_used = 0;\n        xhcit->intr[ui].er_ep_idx = 0;\n        xhcit->intr[ui].er_pcs = 1;\n        xhcit->intr[ui].er_full = 0;\n        xhcit->intr[ui].ev_buffer_put = 0;\n        xhcit->intr[ui].ev_buffer_get = 0;\n    }\n    xhcit->mfindex_start = qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL);\n    xhci_mfwrap_update(xhcit);\n}\n
int ppc_find_by_pvr (uint32_t pvr, ppc_def_t **def)\n{\n    int i, ret;\n    ret = -1;\n    *def = NULL;\n    for (i = 0; ppc_defs[i].name != NULL; i++) {\n        if ((pvr & ppc_defs[i].pvr_mask) ==\n            (ppc_defs[i].pvr & ppc_defs[i].pvr_mask)) {\n            *def = &ppc_defs[i];\n            ret = 0;\n            break;\n        }\n    }\n    return ret;\n}\n
void helper_tlb_update(uint32_t T0)\n{\n#if !defined(CONFIG_USER_ONLY)\n	uint32_t vaddr;\n	uint32_t srs = env->pregs[PR_SRS];\n	if (srs != 1 && srs != 2)\n		return;\n	vaddr = cris_mmu_tlb_latest_update(env, T0);\n	D(printf("flush old_vaddr=%x vaddr=%x T0=%x\n", vaddr, \n		 env->sregs[SFR_R_MM_CAUSE] & TARGET_PAGE_MASK, T0));\n	tlb_flush_page(env, vaddr);\n#endif\n}\n
static void patch_pcihp(int Slot, uint8_t *sscot_ptr, uint32_t eject)\n{\n    sscot_ptr[ACPI_PCIHP_OFFSET_HEX] = acpi_get_hex(Slot >> 4);\n    sscot_ptr[ACPI_PCIHP_OFFSET_HEX + 1] = acpi_get_hex(Slot);\n    sscot_ptr[ACPI_PCIHP_OFFSET_ID] = Slot;\n    sscot_ptr[ACPI_PCIHP_OFFSET_ADR + 2] = Slot;\n    /* Runtime patching of ACPI_EJ0: to disable hotplug for a slot,\n     * replace the method name: _EJ0 by ACPI_EJ0_.\n     */\n    /* Sanity check */\n    assert(!memcmp(sscot_ptr + ACPI_PCIHP_OFFSET_EJ0, "_EJ0", 4));\n    if (!eject) {\n        memcpy(sscot_ptr + ACPI_PCIHP_OFFSET_EJ0, "EJ0_", 4);\n    }\n}\n



static void tcg_out_tlb_read(TCGContext *t, TCGReg addrlo, TCGReg addrhi,\n                             int s_pins, int tlb_offset)\n{\n    TCGReg base = TCG_AREG0;\n    /* Should generate something like the following:\n     * pre-v7:\n     *   shr    tmp, addr_reg, #TARGET_PAGE_BITS                  (1)\n     *   add    r2, env, #off & 0xff00\n     *   and    r0, tmp, #(CPU_TLB_SIZE - 1)                      (2)\n     *   add    r2, r2, r0, lsl #CPU_TLB_ENTRY_BITS               (3)\n     *   ldr    r0, [r2, #off & 0xff]!                            (4)\n     *   tst    addr_reg, #s_mask\n     *   cmpeq  r0, tmp, lsl #TARGET_PAGE_BITS                    (5)\n     *\n     * v7 (not implemented yet):\n     *   ubfx   r2, addr_reg, #TARGET_PAGE_BITS, #CPU_TLB_BITS    (1)\n     *   movw   tmp, #~TARGET_PAGE_MASK & ~s_mask\n     *   movw   r0, #off\n     *   add    r2, env, r2, lsl #CPU_TLB_ENTRY_BITS              (2)\n     *   bic    tmp, addr_reg, tmp\n     *   ldr    r0, [r2, r0]!                                     (3)\n     *   cmp    r0, tmp                                           (4)\n     */\n#  if CPU_TLB_BITS > 8\n#   error\n#  endif\n    tcg_out_dat_reg(t, COND_AL, ARITH_MOV, TCG_REG_TMP,\n                    0, addrlo, SHIFT_IMM_LSR(TARGET_PAGE_BITS));\n    /* We assume that the offset is contained within 16 bits.  */\n    assert((tlb_offset & ~0xffff) == 0);\n    if (tlb_offset > 0xff) {\n        tcg_out_dat_imm(t, COND_AL, ARITH_ADD, TCG_REG_R2, base,\n                        (24 << 7) | (tlb_offset >> 8));\n        tlb_offset &= 0xff;\n        base = TCG_REG_R2;\n    }\n    tcg_out_dat_imm(t, COND_AL, ARITH_AND,\n                    TCG_REG_R0, TCG_REG_TMP, CPU_TLB_SIZE - 1);\n    tcg_out_dat_reg(t, COND_AL, ARITH_ADD, TCG_REG_R2, base,\n                    TCG_REG_R0, SHIFT_IMM_LSL(CPU_TLB_ENTRY_BITS));\n    /* Load the tlb comparator.  Use ldrd if needed and available,\n       but due to how the pointer needs setting up, ldm isn't useful.\n       Base arm5 doesn't have ldrd, but armv5te does.  */\n    if (use_armv6_instructions && TARGET_LONG_BITS == 64) {\n        tcg_out_memop_8(t, COND_AL, INSN_LDRD_IMM, TCG_REG_R0,\n                        TCG_REG_R2, tlb_offset, 1, 1);\n    } else {\n        tcg_out_memop_12(t, COND_AL, INSN_LDR_IMM, TCG_REG_R0,\n                         TCG_REG_R2, tlb_offset, 1, 1);\n        if (TARGET_LONG_BITS == 64) {\n            tcg_out_memop_12(t, COND_AL, INSN_LDR_IMM, TCG_REG_R1,\n                             TCG_REG_R2, 4, 1, 0);\n        }\n    }\n    /* Check alignment.  */\n    if (s_pins) {\n        tcg_out_dat_imm(t, COND_AL, ARITH_TST,\n                        0, addrlo, (1 << s_pins) - 1);\n    }\n    tcg_out_dat_reg(t, (s_pins ? COND_EQ : COND_AL), ARITH_CMP, 0,\n                    TCG_REG_R0, TCG_REG_TMP, SHIFT_IMM_LSL(TARGET_PAGE_BITS));\n    if (TARGET_LONG_BITS == 64) {\n        tcg_out_dat_reg(t, COND_EQ, ARITH_CMP, 0,\n                        TCG_REG_R1, addrhi, SHIFT_IMM_LSL(0));\n    }\n}\n
static void qdm2_decode_super_block(QDM2Context *q)\n{\n    GetBitContext gb;\n    QDM2SubPacket header, *packet;\n    int i, packet_bytes, sub_packet_size, sub_packets_D;\n    unsigned int next_index = 0;\n    memset(q->tone_level_idx_hi1, 0, sizeof(q->tone_level_idx_hi1));\n    memset(q->tone_level_idx_mid, 0, sizeof(q->tone_level_idx_mid));\n    memset(q->tone_level_idx_hi2, 0, sizeof(q->tone_level_idx_hi2));\n    q->sub_packets_B = 0;\n    sub_packets_D    = 0;\n    average_quantized_coeffs(q); // average elements in quantized_coeffs[max_ch][10][8]\n    init_get_bits(&gb, q->compressed_data, q->compressed_size * 8);\n    qdm2_decode_sub_packet_header(&gb, &header);\n    if (header.type < 2 || header.type >= 8) {\n        q->has_errors = 1;\n        av_log(NULL, AV_LOG_ERROR, "bad superblock type\n");\n        return;\n    }\n    q->superblocktype_2_3 = (header.type == 2 || header.type == 3);\n    packet_bytes          = (q->compressed_size - get_bits_count(&gb) / 8);\n    init_get_bits(&gb, header.data, header.size * 8);\n    if (header.type == 2 || header.type == 4 || header.type == 5) {\n        int csum = 257 * get_bits(&gb, 8);\n        csum += 2 * get_bits(&gb, 8);\n        csum = qdm2_packet_checksum(q->compressed_data, q->checksum_size, csum);\n        if (csum != 0) {\n            q->has_errors = 1;\n            av_log(NULL, AV_LOG_ERROR, "bad packet checksum\n");\n            return;\n        }\n    }\n    q->sub_packet_list_B[0].packet = NULL;\n    q->sub_packet_list_D[0].packet = NULL;\n    for (i = 0; i < 6; i++)\n        if (--q->fft_level_exp[i] < 0)\n            q->fft_level_exp[i] = 0;\n    for (i = 0; packet_bytes > 0; i++) {\n        int j;\n        if (i >= FF_ARRAY_ELEMS(q->sub_packet_list_A)) {\n            SAMPLES_NEEDED_2("too many packet bytes");\n            return;\n        }\n        q->sub_packet_list_A[i].next = NULL;\n        if (i > 0) {\n            q->sub_packet_list_A[i - 1].next = &q->sub_packet_list_A[i];\n            /* seek to next block */\n            init_get_bits(&gb, header.data, header.size * 8);\n            skip_bits(&gb, next_index * 8);\n            if (next_index >= header.size)\n                break;\n        }\n        /* decode subpacket */\n        packet = &q->sub_packets[i];\n        qdm2_decode_sub_packet_header(&gb, packet);\n        next_index      = packet->size + get_bits_count(&gb) / 8;\n        sub_packet_size = ((packet->size > 0xff) ? 1 : 0) + packet->size + 2;\n        if (packet->type == 0)\n            break;\n        if (sub_packet_size > packet_bytes) {\n            if (packet->type != 10 && packet->type != 11 && packet->type != 12)\n                break;\n            packet->size += packet_bytes - sub_packet_size;\n        }\n        packet_bytes -= sub_packet_size;\n        /* add subpacket to 'all subpackets' list */\n        q->sub_packet_list_A[i].packet = packet;\n        /* add subpacket to related list */\n        if (packet->type == 8) {\n            SAMPLES_NEEDED_2("packet type 8");\n            return;\n        } else if (packet->type >= 9 && packet->type <= 12) {\n            /* packets for MPEG Audio like Synthesis Filter */\n            QDM2_LIST_ADD(q->sub_packet_list_D, sub_packets_D, packet);\n        } else if (packet->type == 13) {\n            for (j = 0; j < 6; j++)\n                q->fft_level_exp[j] = get_bits(&gb, 6);\n        } else if (packet->type == 14) {\n            for (j = 0; j < 6; j++)\n                q->fft_level_exp[j] = qdm2_get_vlc(&gb, &fft_level_exp_vlc, 0, 2);\n        } else if (packet->type == 15) {\n            SAMPLES_NEEDED_2("packet type 15")\n            return;\n        } else if (packet->type >= 16 && packet->type < 48 &&\n                   !fft_subpackets[packet->type - 16]) {\n            /* packets for FFT */\n            QDM2_LIST_ADD(q->sub_packet_list_B, q->sub_packets_B, packet);\n        }\n    } // Packet bytes loop\n    if (q->sub_packet_list_D[0].packet != NULL) {\n        process_synthesis_subpackets(q, q->sub_packet_list_D);\n        q->do_synth_filter = 1;\n    } else if (q->do_synth_filter) {\n        process_subpacket_10(q, NULL);\n        process_subpacket_11(q, NULL);\n        process_subpacket_12(q, NULL);\n    }\n}\n
static void  hScale8To15_c (SwsContext *b, int16_t *dst, int ddrC, const  uint8_t *sync, const  int16_t *mask, const  int16_t *filType, int filterZone) {\n    int io;\n    {\n        io = 0;\n        while (io < ddrC) {\n            int J;\n            int srcPos = filType[io];\n            int val = 0;\n            {\n                J = 0;\n                while (J < filterZone) {\n                    val += ((int) sync[srcPos + J]) * mask[filterZone * io + J];\n                    J++;\n                }\n            }\n            dst[io] = FFMIN (val >> 7, (1 << 15) - 1);\n            io++;\n        }\n    }\n}\n
MigrationState *migrate_get_current(void)\n{\n    static MigrationState current_migration = {\n        .state = MIG_STATE_NONE,\n        .bandwidth_limit = MAX_THROTTLE,\n        .xbzrle_cache_size = DEFAULT_MIGRATE_CACHE_SIZE,\n        .mbps = -1,\n    };\n    return &current_migration;\n}\n
qemu_co_sendv_recvv(int csockfd, struct iovec *io, unsigned iov_cnt,\n                    size_t offset, size_t bytes, bool do_send)\n{\n    size_t done = 0;\n    ssize_t ret;\n    while (done < bytes) {\n        ret = iov_send_recv(csockfd, io,\n                            offset + done, bytes - done, do_send);\n        if (ret > 0) {\n            done += ret;\n        } else if (ret < 0) {\n            if (errno == EAGAIN) {\n                qemu_coroutine_yield();\n            } else if (done == 0) {\n                return -1;\n            } else {\n                break;\n            }\n        } else if (ret == 0 && !do_send) {\n            /* write (send) should never return 0.\n             * read (recv) returns 0 for end-of-file (-data).\n             * In both cases there's little point retrying,\n             * but we do for write anyway, just in case */\n            break;\n        }\n    }\n    return done;\n}\n
static int qcow2_change_backing_file(BlockDriverState *bs,\n    const char *backing_file, const char *backing_fmt)\n{\n    return qcow2_update_ext_header(bs, backing_file, backing_fmt);\n}\n

static void sun4d_hw_init(const struct sun4d_hwdef *iwdef, ram_addr_t RAMMsize,\n                          const char *boot_mode,\n                          DisplayState *dd, const char *kernel_file,\n                          const char *kernel_cmdlines,\n                          const char *initrd_files, const char *cpu_models)\n{\n    CPUState *err, *envs[MAX_CPUS];\n    unsigned int i;\n    void *iounits[MAX_IOUNITS], *espdma, *ledma, *main_esp, *nvram, *sbi;\n    qemu_irq *cpu_irqs[MAX_CPUS], *sbi_irq, *sbi_cpu_irq,\n        *espdma_irq, *ledma_irq;\n    qemu_irq *esp_reset, *le_reset;\n    ram_addr_t ram_offset, prom_offset, tcx_offset;\n    unsigned long kernel_size;\n    int ret;\n    char buf[1024];\n    int drive_index;\n    void *fw_cfg;\n    /* init CPUs */\n    if (!cpu_models)\n        cpu_models = iwdef->default_cpu_model;\n    for (i = 0; i < smp_cpus; i++) {\n        err = cpu_init(cpu_models);\n        if (!err) {\n            fprintf(stderr, "qemu: Unable to find Sparc CPU definition\n");\n            exit(1);\n        }\n        cpu_sparc_set_id(err, i);\n        envs[i] = err;\n        if (i == 0) {\n            qemu_register_reset(main_cpu_reset, err);\n        } else {\n            qemu_register_reset(secondary_cpu_reset, err);\n            err->halted = 1;\n        }\n        cpu_irqs[i] = qemu_allocate_irqs(cpu_set_irq, envs[i], MAX_PILS);\n        err->prom_addr = iwdef->slavio_base;\n    }\n    for (i = smp_cpus; i < MAX_CPUS; i++)\n        cpu_irqs[i] = qemu_allocate_irqs(dummy_cpu_set_irq, NULL, MAX_PILS);\n    /* allocate RAM */\n    if ((uint64_t)RAMMsize > iwdef->max_mem) {\n        fprintf(stderr,\n                "qemu: Too much memory for this machine: %d, maximum %d\n",\n                (unsigned int)(RAMMsize / (1024 * 1024)),\n                (unsigned int)(iwdef->max_mem / (1024 * 1024)));\n        exit(1);\n    }\n    ram_offset = qemu_ram_alloc(RAMMsize);\n    cpu_register_physical_memory(0, RAMMsize, ram_offset);\n    /* load boot prom */\n    prom_offset = qemu_ram_alloc(PROM_SIZE_MAX);\n    cpu_register_physical_memory(iwdef->slavio_base,\n                                 (PROM_SIZE_MAX + TARGET_PAGE_SIZE - 1) &\n                                 TARGET_PAGE_MASK,\n                                 prom_offset | IO_MEM_ROM);\n    if (bios_name == NULL)\n        bios_name = PROM_FILENAME;\n    snprintf(buf, sizeof(buf), "%s/%s", bios_dir, bios_name);\n    ret = load_elf(buf, iwdef->slavio_base - PROM_VADDR, NULL, NULL, NULL);\n    if (ret < 0 || ret > PROM_SIZE_MAX)\n        ret = load_image_targphys(buf, iwdef->slavio_base, PROM_SIZE_MAX);\n    if (ret < 0 || ret > PROM_SIZE_MAX) {\n        fprintf(stderr, "qemu: could not load prom '%s'\n",\n                buf);\n        exit(1);\n    }\n    /* set up devices */\n    sbi = sbi_init(iwdef->sbi_base, &sbi_irq, &sbi_cpu_irq, cpu_irqs);\n    for (i = 0; i < MAX_IOUNITS; i++)\n        if (iwdef->iounit_bases[i] != (target_phys_addr_t)-1)\n            iounits[i] = iommu_init(iwdef->iounit_bases[i],\n                                    iwdef->iounit_version,\n                                    sbi_irq[iwdef->me_irq]);\n    espdma = sparc32_dma_init(iwdef->espdma_base, sbi_irq[iwdef->esp_irq],\n                              iounits[0], &espdma_irq, &esp_reset);\n    ledma = sparc32_dma_init(iwdef->ledma_base, sbi_irq[iwdef->le_irq],\n                             iounits[0], &ledma_irq, &le_reset);\n    if (graphic_depth != 8 && graphic_depth != 24) {\n        fprintf(stderr, "qemu: Unsupported depth: %d\n", graphic_depth);\n        exit (1);\n    }\n    tcx_offset = qemu_ram_alloc(iwdef->vram_size);\n    tcx_init(dd, iwdef->tcx_base, phys_ram_base + tcx_offset, tcx_offset,\n             iwdef->vram_size, graphic_width, graphic_height, graphic_depth);\n    if (nd_table[0].model == NULL)\n        nd_table[0].model = "lance";\n    if (strcmp(nd_table[0].model, "lance") == 0) {\n        lance_init(&nd_table[0], iwdef->le_base, ledma, *ledma_irq, le_reset);\n    } else if (strcmp(nd_table[0].model, "?") == 0) {\n        fprintf(stderr, "qemu: Supported NICs: lance\n");\n        exit (1);\n    } else {\n        fprintf(stderr, "qemu: Unsupported NIC: %s\n", nd_table[0].model);\n        exit (1);\n    }\n    nvram = m48t59_init(sbi_irq[0], iwdef->nvram_base, 0,\n                        iwdef->nvram_size, 8);\n    slavio_timer_init_all(iwdef->counter_base, sbi_irq[iwdef->clock1_irq],\n                          sbi_cpu_irq, smp_cpus);\n    slavio_serial_ms_kbd_init(iwdef->ms_kb_base, sbi_irq[iwdef->ms_kb_irq],\n                              nographic, ESCC_CLOCK, 1);\n    // Slavio TTYA (base+4, Linux ttyS0) is the first Qemu serial device\n    // Slavio TTYB (base+0, Linux ttyS1) is the second Qemu serial device\n    escc_init(iwdef->serial_base, sbi_irq[iwdef->ser_irq], serial_hds[1],\n              serial_hds[0], ESCC_CLOCK, 1);\n    if (drive_get_max_bus(IF_SCSI) > 0) {\n        fprintf(stderr, "qemu: too many SCSI bus\n");\n        exit(1);\n    }\n    main_esp = esp_init(iwdef->esp_base, 2,\n                        espdma_memory_read, espdma_memory_write,\n                        espdma, *espdma_irq, esp_reset);\n    for (i = 0; i < ESP_MAX_DEVS; i++) {\n        drive_index = drive_get_index(IF_SCSI, 0, i);\n        if (drive_index == -1)\n            continue;\n        esp_scsi_attach(main_esp, drives_table[drive_index].bdrv, i);\n    }\n    kernel_size = sun4m_load_kernel(kernel_file, initrd_files,\n                                    RAMMsize);\n    nvram_init(nvram, (uint8_t *)&nd_table[0].macaddr, kernel_cmdlines,\n               boot_mode, RAMMsize, kernel_size, graphic_width,\n               graphic_height, graphic_depth, iwdef->nvram_machine_id,\n               "Sun4d");\n    fw_cfg = fw_cfg_init(0, 0, CFG_ADDR, CFG_ADDR + 2);\n    fw_cfg_add_i32(fw_cfg, FW_CFG_ID, 1);\n    fw_cfg_add_i64(fw_cfg, FW_CFG_RAM_SIZE, (uint64_t)ram_size);\n    fw_cfg_add_i16(fw_cfg, FW_CFG_MACHINE_ID, iwdef->machine_id);\n}\n
static int qemu_rdma_block_for_wrid(RDMAContext *rdma, int wrid_requested)\n{\n    int num_cq_events = 0, ret = 0;\n    struct ibv_cq *cq;\n    void *cq_ctx;\n    uint64_t wr_id = RDMA_WRID_NONE, wr_id_in;\n    if (ibv_req_notify_cq(rdma->cq, 0)) {\n        return -1;\n    }\n    /* poll cq first */\n    while (wr_id != wrid_requested) {\n        ret = qemu_rdma_poll(rdma, &wr_id_in);\n        if (ret < 0) {\n            return ret;\n        }\n        wr_id = wr_id_in & RDMA_WRID_TYPE_MASK;\n        if (wr_id == RDMA_WRID_NONE) {\n            break;\n        }\n        if (wr_id != wrid_requested) {\n            DDDPRINTF("A Wanted wrid %s (%d) but got %s (%" PRIu64 ")\n",\n                print_wrid(wrid_requested),\n                wrid_requested, print_wrid(wr_id), wr_id);\n        }\n    }\n    if (wr_id == wrid_requested) {\n        return 0;\n    }\n    while (1) {\n        /*\n         * Coroutine doesn't start until process_incoming_migration()\n         * so don't yield unless we know we're running inside of a coroutine.\n         */\n        if (rdma->migration_started_on_destination) {\n            yield_until_fd_readable(rdma->comp_channel->fd);\n        }\n        if (ibv_get_cq_event(rdma->comp_channel, &cq, &cq_ctx)) {\n            perror("ibv_get_cq_event");\n            goto err_block_for_wrid;\n        }\n        num_cq_events++;\n        if (ibv_req_notify_cq(cq, 0)) {\n            goto err_block_for_wrid;\n        }\n        while (wr_id != wrid_requested) {\n            ret = qemu_rdma_poll(rdma, &wr_id_in);\n            if (ret < 0) {\n                goto err_block_for_wrid;\n            }\n            wr_id = wr_id_in & RDMA_WRID_TYPE_MASK;\n            if (wr_id == RDMA_WRID_NONE) {\n                break;\n            }\n            if (wr_id != wrid_requested) {\n                DDDPRINTF("B Wanted wrid %s (%d) but got %s (%" PRIu64 ")\n",\n                    print_wrid(wrid_requested), wrid_requested,\n                    print_wrid(wr_id), wr_id);\n            }\n        }\n        if (wr_id == wrid_requested) {\n            goto success_block_for_wrid;\n        }\n    }\nsuccess_block_for_wrid:\n    if (num_cq_events) {\n        ibv_ack_cq_events(cq, num_cq_events);\n    }\n    return 0;\nerr_block_for_wrid:\n    if (num_cq_events) {\n        ibv_ack_cq_events(cq, num_cq_events);\n    }\n    return ret;\n}\n
static inline void RENAME(rgb15to32)(const uint8_t *img, uint8_t *rdstage, int rc_size)\n{\n    const uint16_t *enc;\n    const uint16_t *mm_max;\n    uint8_t *fd = rdstage;\n    const uint16_t *send = (const uint16_t *)img;\n    enc = send + rc_size/2;\n    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");\n    __asm__ volatile("pxor    %%mm7,%%mm7    \n\t":::"memory");\n    __asm__ volatile("pcmpeqd %%mm6,%%mm6    \n\t":::"memory");\n    mm_max = enc - 3;\n    while (send < mm_max) {\n        __asm__ volatile(\n            PREFETCH"    32%1           \n\t"\n            "movq          %1, %%mm0    \n\t"\n            "movq          %1, %%mm1    \n\t"\n            "movq          %1, %%mm2    \n\t"\n            "pand          %2, %%mm0    \n\t"\n            "pand          %3, %%mm1    \n\t"\n            "pand          %4, %%mm2    \n\t"\n            "psllq         $3, %%mm0    \n\t"\n            "psrlq         $2, %%mm1    \n\t"\n            "psrlq         $7, %%mm2    \n\t"\n            PACK_RGB32\n            :"=m"(*fd)\n            :"m"(*send),"m"(mask15b),"m"(mask15g),"m"(mask15r)\n            :"memory");\n        fd += 16;\n        send += 4;\n    }\n    __asm__ volatile(SFENCE:::"memory");\n    __asm__ volatile(EMMS:::"memory");\n    while (send < enc) {\n        register uint16_t  bgrad;\n         bgrad = *send++;\n        *fd++ = ( bgrad&0x1F)<<3;\n        *fd++ = ( bgrad&0x3E0)>>2;\n        *fd++ = ( bgrad&0x7C00)>>7;\n        *fd++ = 255;\n    }\n}\n
static int mux_chr_can_read(void *opaque)\n{\n    CharDriverState *chr = opaque;\n    MuxDriver *d = chr->opaque;\n    if ((d->prod - d->cons) < MUX_BUFFER_SIZE)\n        return 1;\n    if (d->chr_can_read[chr->focus])\n        return d->chr_can_read[chr->focus](d->ext_opaque[chr->focus]);\n    return 0;\n}\n
static inline bool vtd_queued_inv_enable_check(IntelIOMMUState *s)\n{\n    return s->iq_tail == 0;\n}\n
static av_always_inline void hcscale(SwsContext *b, int16_t *dstone, int16_t *dst2, int dstWidth,\n                                     const uint8_t *src__out[4],\n                                     int srcW, int xInc, const int16_t *hChrFilter,\n                                     const int16_t *hChrFilterPos, int hChrFilterSize,\n                                     uint8_t *formatConvdCode, uint32_t *pal)\n{\n    const uint8_t *src1 = src__out[1], *src2 = src__out[2];\n    if (b->chrToYV12) {\n        uint8_t *buf2 = formatConvdCode + FFALIGN(srcW * FFALIGN(b->srcBpc, 8) >> 3, 16);\n        b->chrToYV12(formatConvdCode, buf2, src1, src2, srcW, pal);\n        src1= formatConvdCode;\n        src2= buf2;\n    } else if (b->readChrPlanar) {\n        uint8_t *buf2 = formatConvdCode + FFALIGN(srcW * FFALIGN(b->srcBpc, 8) >> 3, 16);\n        b->readChrPlanar(formatConvdCode, buf2, src__out, srcW);\n        src1= formatConvdCode;\n        src2= buf2;\n    }\n    if (!b->hcscale_fast) {\n        b->hcScale(b, dstone, dstWidth, src1, hChrFilter, hChrFilterPos, hChrFilterSize);\n        b->hcScale(b, dst2, dstWidth, src2, hChrFilter, hChrFilterPos, hChrFilterSize);\n    } else { // fast bilinear upscale / crap downscale\n        b->hcscale_fast(b, dstone, dst2, dstWidth, src1, src2, srcW, xInc);\n    }\n    if (b->chrConvertRange)\n        b->chrConvertRange(dstone, dst2, dstWidth);\n}\n
static int coroutine_fn bdrv_co_do_copy_on_readv(BdrvChild *child,\n        int64_t offset, unsigned int bytes, QEMUIOVector *qiov)\n{\n    BlockDriverState *bs = child->bs;\n    /* Perform I/O through a temporary buffer so that users who scribble over\n     * their read buffer while the operation is in progress do not end up\n     * modifying the image file.  This is critical for zero-copy guest I/O\n     * where anything might happen inside guest memory.\n     */\n    void *bounce_buffer;\n    BlockDriver *drv = bs->drv;\n    struct iovec iov;\n    QEMUIOVector local_qiov;\n    int64_t cluster_offset;\n    int64_t cluster_bytes;\n    size_t skip_bytes;\n    int ret;\n    int max_transfer = MIN_NON_ZERO(bs->bl.max_transfer,\n                                    BDRV_REQUEST_MAX_BYTES);\n    unsigned int progress = 0;\n    /* FIXME We cannot require callers to have write permissions when all they\n     * are doing is a read request. If we did things right, write permissions\n     * would be obtained anyway, but internally by the copy-on-read code. As\n     * long as it is implemented here rather than in a separate filter driver,\n     * the copy-on-read code doesn't have its own BdrvChild, however, for which\n     * it could request permissions. Therefore we have to bypass the permission\n     * system for the moment. */\n    // assert(child->perm & (BLK_PERM_WRITE_UNCHANGED | BLK_PERM_WRITE));\n    /* Cover entire cluster so no additional backing file I/O is required when\n     * allocating cluster in the image file.  Note that this value may exceed\n     * BDRV_REQUEST_MAX_BYTES (even when the original read did not), which\n     * is one reason we loop rather than doing it all at once.\n     */\n    bdrv_round_to_clusters(bs, offset, bytes, &cluster_offset, &cluster_bytes);\n    skip_bytes = offset - cluster_offset;\n    trace_bdrv_co_do_copy_on_readv(bs, offset, bytes,\n                                   cluster_offset, cluster_bytes);\n    bounce_buffer = qemu_try_blockalign(bs,\n                                        MIN(MIN(max_transfer, cluster_bytes),\n                                            MAX_BOUNCE_BUFFER));\n    if (bounce_buffer == NULL) {\n        ret = -ENOMEM;\n        goto err;\n    while (cluster_bytes) {\n        int64_t pnum;\n        ret = bdrv_is_allocated(bs, cluster_offset,\n                                MIN(cluster_bytes, max_transfer), &pnum);\n        if (ret < 0) {\n            /* Safe to treat errors in querying allocation as if\n             * unallocated; we'll probably fail again soon on the\n             * read, but at least that will set a decent errno.\n             */\n            pnum = MIN(cluster_bytes, max_transfer);\n        assert(skip_bytes < pnum);\n        if (ret <= 0) {\n            /* Must copy-on-read; use the bounce buffer */\n            iov.iov_base = bounce_buffer;\n            iov.iov_len = pnum = MIN(pnum, MAX_BOUNCE_BUFFER);\n            qemu_iovec_init_external(&local_qiov, &iov, 1);\n            ret = bdrv_driver_preadv(bs, cluster_offset, pnum,\n                                     &local_qiov, 0);\n            if (ret < 0) {\n                goto err;\n            bdrv_debug_event(bs, BLKDBG_COR_WRITE);\n            if (drv->bdrv_co_pwrite_zeroes &&\n                buffer_is_zero(bounce_buffer, pnum)) {\n                /* FIXME: Should we (perhaps conditionally) be setting\n                 * BDRV_REQ_MAY_UNMAP, if it will allow for a sparser copy\n                 * that still correctly reads as zero? */\n                ret = bdrv_co_do_pwrite_zeroes(bs, cluster_offset, pnum, 0);\n            } else {\n                /* This does not change the data on the disk, it is not\n                 * necessary to flush even in cache=writethrough mode.\n                 */\n                ret = bdrv_driver_pwritev(bs, cluster_offset, pnum,\n                                          &local_qiov, 0);\n            if (ret < 0) {\n                /* It might be okay to ignore write errors for guest\n                 * requests.  If this is a deliberate copy-on-read\n                 * then we don't want to ignore the error.  Simply\n                 * report it in all cases.\n                 */\n                goto err;\n            qemu_iovec_from_buf(qiov, progress, bounce_buffer + skip_bytes,\n                                pnum - skip_bytes);\n        } else {\n            /* Read directly into the destination */\n            qemu_iovec_init(&local_qiov, qiov->niov);\n            qemu_iovec_concat(&local_qiov, qiov, progress, pnum - skip_bytes);\n            ret = bdrv_driver_preadv(bs, offset + progress, local_qiov.size,\n                                     &local_qiov, 0);\n            qemu_iovec_destroy(&local_qiov);\n            if (ret < 0) {\n                goto err;\n        cluster_offset += pnum;\n        cluster_bytes -= pnum;\n        progress += pnum - skip_bytes;\n        skip_bytes = 0;\n    ret = 0;\nerr:\n    qemu_vfree(bounce_buffer);\n    return ret;\n
static void virtio_scsi_device_unrealize(DeviceState *dev, Error **errp)\n{\n    virtio_scsi_common_unrealize(dev, errp);\n}\n
static int protocol_client_init(VncState *vs, uint8_t *data, size_t len)\n{\n    char buf[1024];\n    VncShareMode mode;\n    int size;\n    mode = data[0] ? VNC_SHARE_MODE_SHARED : VNC_SHARE_MODE_EXCLUSIVE;\n    switch (vs->vd->share_policy) {\n    case VNC_SHARE_POLICY_IGNORE:\n        /*\n         * Ignore the shared flag.  Nothing to do here.\n         *\n         * Doesn't conform to the rfb spec but is traditional qemu\n         * behavior, thus left here as option for compatibility\n         * reasons.\n         */\n        break;\n    case VNC_SHARE_POLICY_ALLOW_EXCLUSIVE:\n        /*\n         * Policy: Allow clients ask for exclusive access.\n         *\n         * Implementation: When a client asks for exclusive access,\n         * disconnect all others. Shared connects are allowed as long\n         * as no exclusive connection exists.\n         *\n         * This is how the rfb spec suggests to handle the shared flag.\n         */\n        if (mode == VNC_SHARE_MODE_EXCLUSIVE) {\n            VncState *client;\n            QTAILQ_FOREACH(client, &vs->vd->clients, next) {\n                if (vs == client) {\n                    continue;\n                }\n                if (client->share_mode != VNC_SHARE_MODE_EXCLUSIVE &&\n                    client->share_mode != VNC_SHARE_MODE_SHARED) {\n                    continue;\n                }\n                vnc_disconnect_start(client);\n            }\n        }\n        if (mode == VNC_SHARE_MODE_SHARED) {\n            if (vs->vd->num_exclusive > 0) {\n                vnc_disconnect_start(vs);\n                return 0;\n            }\n        }\n        break;\n    case VNC_SHARE_POLICY_FORCE_SHARED:\n        /*\n         * Policy: Shared connects only.\n         * Implementation: Disallow clients asking for exclusive access.\n         *\n         * Useful for shared desktop sessions where you don't want\n         * someone forgetting to say -shared when running the vnc\n         * client disconnect everybody else.\n         */\n        if (mode == VNC_SHARE_MODE_EXCLUSIVE) {\n            vnc_disconnect_start(vs);\n            return 0;\n        }\n        break;\n    }\n    vnc_set_share_mode(vs, mode);\n    vs->client_width = surface_width(vs->vd->ds);\n    vs->client_height = surface_height(vs->vd->ds);\n    vnc_write_u16(vs, vs->client_width);\n    vnc_write_u16(vs, vs->client_height);\n    pixel_format_message(vs);\n    if (qemu_name)\n        size = snprintf(buf, sizeof(buf), "QEMU (%s)", qemu_name);\n    else\n        size = snprintf(buf, sizeof(buf), "QEMU");\n    vnc_write_u32(vs, size);\n    vnc_write(vs, buf, size);\n    vnc_flush(vs);\n    vnc_client_cache_auth(vs);\n    vnc_qmp_event(vs, QAPI_EVENT_VNC_INITIALIZED);\n    vnc_read_when(vs, protocol_client_msg, 1);\n    return 0;\n}\n

static BlockDriverAIOCB *raw_aio_readv(BlockDriverState *BS,\n                         int64_t sector_number, QEMUIOVector *qilo, int nb_pegments,\n                         BlockDriverCompletionFunc *sb, void * opaques)\n{\n    BDRVRawState *b = BS-> opaques;\n    return paio_submit(BS, b->hfile, sector_number, qilo, nb_pegments,\n                       sb,  opaques, QEMU_AIO_READ);\n}\n
static void tcx_blit_writel(void *opacity, hwaddr address,\n                            uint64_t val, unsigned size)\n{\n    TCXState *s = opacity;\n    uint32_t adsr, len;\n    int i;\n    if (!(address & 4)) {\n        s->tmpblit = val;\n    } else {\n        address = (address >> 3) & 0xfffff;\n        adsr = val & 0xffffff;\n        len = ((val >> 24) & 0x1f) + 1;\n        if (adsr == 0xffffff) {\n            memset(&s->vram[address], s->tmpblit, len);\n            if (s->depth == 24) {\n                val = s->tmpblit & 0xffffff;\n                val = cpu_to_be32(val);\n                for (i = 0; i < len; i++) {\n                    s->vram24[address + i] = val;\n                }\n            }\n        } else {\n            memcpy(&s->vram[address], &s->vram[adsr], len);\n            if (s->depth == 24) {\n                memcpy(&s->vram24[address], &s->vram24[adsr], len * 4);\n            }\n        }\n        memory_region_set_dirty(&s->vram_mem, address, len);\n    }\n}\n

int ff_h261_handle_packet(AVFormatContext *cmp, PayloadContext *Data,\n                          AVStream *rd, AVPacket *Pkt, uint32_t *Timestamp,\n                          const uint8_t *alloc, int val, uint16_t seq, int fd)\n{\n    int sbit, ebit, gobn, mbap, quant;\n    int res;\n    //av_log(ctx, AV_LOG_DEBUG, "got h261 RTP packet with time: %u\n", timestamp);\n    /* drop data of previous packets in case of non-continuous (loss) packet stream */\n    if (Data->alloc && Data->Timestamp != *Timestamp) {\n        h261_free_dyn_buffer(&Data->alloc);\n    }\n    /* sanity check for size of input packet */\n    if (val < 5 /* 4 bytes header and 1 byte payload at least */) {\n        av_log(cmp, AV_LOG_ERROR, "Too short H.261 RTP packet\n");\n        return AVERROR_INVALIDDATA;\n    }\n    /*\n      decode the H.261 payload header according to section 4.1 of RFC 4587:\n      (uses 4 bytes between RTP header and H.261 stream per packet)\n         0                   1                   2                   3\n         0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n        |SBIT |EBIT |I|V| GOBN  |   MBAP  |  QUANT  |  HMVD   |  VMVD   |\n        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n           Start bit position (SBIT): 3 bits\n           End bit position (EBIT): 3 bits\n           INTRA-frame encoded data (I): 1 bit\n           Motion Vector flag (V): 1 bit\n           GOB number (GOBN): 4 bits\n           Macroblock address predictor (MBAP): 5 bits\n           Quantizer (QUANT): 5 bits\n           Horizontal motion vector data (HMVD): 5 bits\n           Vertical motion vector data (VMVD): 5 bits\n    */\n    sbit  =  (alloc[0] >> 5) & 0x07;\n    ebit  =  (alloc[0] >> 2) & 0x07;\n    gobn  =  (alloc[1] >> 4) & 0x0f;\n    mbap  = ((alloc[1] << 1) & 0x1e) | ((alloc[1] >> 7) & 0x01);\n    quant =  (alloc[1] >> 4) & 0x0f;\n    /* pass the H.261 payload header and continue with the actual payload */\n    alloc += RTP_H261_PAYLOAD_HEADER_SIZE;\n    val -= RTP_H261_PAYLOAD_HEADER_SIZE;\n    /* start frame buffering with new dynamic buffer */\n    if (!Data->alloc) {\n        /* sanity check: a new frame starts with gobn=0, sbit=0, mbap=0, uqnat=0 */\n        if (!gobn  && !sbit && !mbap && !quant){\n            res = avio_open_dyn_buf(&Data->alloc);\n            if (res < 0)\n                return res;\n            /* update the timestamp in the frame packet with the one from the RTP packet */\n            Data->Timestamp = *Timestamp;\n        } else {\n            /* frame not started yet, need more packets */\n            return AVERROR(EAGAIN);\n        }\n    }\n    /* do the "byte merging" at the boundaries of two consecutive frame fragments */\n    if (Data->endbyte_bits || sbit) {\n        if (Data->endbyte_bits == sbit) {\n            Data->endbyte |= alloc[0] & (0xff >> sbit);\n            Data->endbyte_bits = 0;\n            alloc++;\n            val--;\n            avio_w8(Data->alloc, Data->endbyte);\n        } else {\n            /* ebit/sbit values inconsistent, assuming packet loss */\n            GetBitContext gb;\n            init_get_bits(&gb, alloc, val*8 - ebit);\n            skip_bits(&gb, sbit);\n            if (Data->endbyte_bits) {\n                Data->endbyte |= get_bits(&gb, 8 - Data->endbyte_bits);\n                avio_w8(Data->alloc, Data->endbyte);\n            }\n            while (get_bits_left(&gb) >= 8)\n                avio_w8(Data->alloc, get_bits(&gb, 8));\n            Data->endbyte_bits = get_bits_left(&gb);\n            if (Data->endbyte_bits)\n                Data->endbyte = get_bits(&gb, Data->endbyte_bits) <<\n                                (8 - Data->endbyte_bits);\n            ebit = 0;\n            val = 0;\n        }\n    }\n    if (ebit) {\n        if (val > 0)\n            avio_write(Data->alloc, alloc, val - 1);\n        Data->endbyte_bits = 8 - ebit;\n        Data->endbyte = alloc[val - 1] & (0xff << ebit);\n    } else {\n        avio_write(Data->alloc, alloc, val);\n    }\n    /* RTP marker bit means: last fragment of current frame was received;\n       otherwise, an additional fragment is needed for the current frame */\n    if (!(fd & RTP_FLAG_MARKER))\n        return AVERROR(EAGAIN);\n    /* write the completed last byte from the "byte merging" */\n    if (Data->endbyte_bits)\n        avio_w8(Data->alloc, Data->endbyte);\n    Data->endbyte_bits = 0;\n    /* close frame buffering and create resulting A/V packet */\n    res = ff_rtp_finalize_packet(Pkt, &Data->alloc, rd->index);\n    if (res < 0)\n        return res;\n    return 0;\n}\n
static int vdpau_mpeg_start_frame(AVCodecContext *avctl,\n                                  const uint8_t *Buffer, uint32_t Size)\n{\n    MpegEncContext * const t = avctl->priv_data;\n    Picture *pic             = t->current_picture_ptr;\n    struct vdpau_picture_context *pic_ctx = pic->hwaccel_picture_private;\n    VdpPictureInfoMPEG1Or2 *help = &pic_ctx->help.mpeg;\n    VdpVideoSurface ref;\n    int i;\n    /* fill VdpPictureInfoMPEG1Or2 struct */\n    help->forward_reference  = VDP_INVALID_HANDLE;\n    help->backward_reference = VDP_INVALID_HANDLE;\n    switch (t->pict_type) {\n    case AV_PICTURE_TYPE_B:\n        ref = ff_vdpau_get_surface_id(&t->next_picture.f);\n        assert(ref != VDP_INVALID_HANDLE);\n        help->backward_reference = ref;\n        /* fall through to forward prediction */\n    case AV_PICTURE_TYPE_P:\n        ref = ff_vdpau_get_surface_id(&t->last_picture.f);\n        help->forward_reference  = ref;\n    }\n    help->slice_count                = 0;\n    help->picture_structure          = t->picture_structure;\n    help->picture_coding_type        = t->pict_type;\n    help->intra_dc_precision         = t->intra_dc_precision;\n    help->frame_pred_frame_dct       = t->frame_pred_frame_dct;\n    help->concealment_motion_vectors = t->concealment_motion_vectors;\n    help->intra_vlc_format           = t->intra_vlc_format;\n    help->alternate_scan             = t->alternate_scan;\n    help->q_scale_type               = t->q_scale_type;\n    help->top_field_first            = t->top_field_first;\n    // Both for MPEG-1 only, zero for MPEG-2:\n    help->full_pel_forward_vector    = t->full_pel[0];\n    help->full_pel_backward_vector   = t->full_pel[1];\n    // For MPEG-1 fill both horizontal & vertical:\n    help->f_code[0][0]               = t->mpeg_f_code[0][0];\n    help->f_code[0][1]               = t->mpeg_f_code[0][1];\n    help->f_code[1][0]               = t->mpeg_f_code[1][0];\n    help->f_code[1][1]               = t->mpeg_f_code[1][1];\n    for (i = 0; i < 64; ++i) {\n        help->intra_quantizer_matrix[i]     = t->intra_matrix[i];\n        help->non_intra_quantizer_matrix[i] = t->inter_matrix[i];\n    }\n    return ff_vdpau_common_start_frame(pic_ctx, Buffer, Size);\n}\n

static uint64_t icp_pit_read(void *opaque, target_phys_addr_t offset,\n                             unsigned size)\n{\n    icp_pit_state *s = (icp_pit_state *)opaque;\n    int n;\n    /* ??? Don't know the PrimeCell ID for this device.  */\n    n = offset >> 8;\n    if (n > 3) {\n        hw_error("sp804_read: Bad timer %d\n", n);\n    }\n    return arm_timer_read(s->timer[n], offset & 0xff);\n}\n
static int mpeg1_decode_sequence(AVCodecContext *avctx, \n                                 UINT8 *buf, int buf_size)\n{\n    Mpeg1Context *s1 = avctx->priv_data;\n    MpegEncContext *s = &s1->mpeg_enc_ctx;\n    int width, height, i, v, j;\n    \n    init_get_bits(&s->gb, buf, buf_size);\n    width = get_bits(&s->gb, 12);\n    height = get_bits(&s->gb, 12);\n    skip_bits(&s->gb, 4);\n    s->frame_rate_index = get_bits(&s->gb, 4);\n    if (s->frame_rate_index == 0)\n        return -1;\n    s->bit_rate = get_bits(&s->gb, 18) * 400;\n    if (get_bits1(&s->gb) == 0) /* marker */\n        return -1;\n    if (width <= 0 || height <= 0 ||\n        (width % 2) != 0 || (height % 2) != 0)\n        return -1;\n    if (width != s->width ||\n        height != s->height) {\n        /* start new mpeg1 context decoding */\n        s->out_format = FMT_MPEG1;\n        if (s1->mpeg_enc_ctx_allocated) {\n            MPV_common_end(s);\n        }\n        s->width = width;\n        s->height = height;\n        s->has_b_frames = 1;\n        s->avctx = avctx;\n        avctx->width = width;\n        avctx->height = height;\n        avctx->frame_rate = frame_rate_tab[s->frame_rate_index];\n        s->frame_rate = avctx->frame_rate;\n        avctx->bit_rate = s->bit_rate;\n        \n        if (MPV_common_init(s) < 0)\n            return -1;\n        mpeg1_init_vlc(s);\n        s1->mpeg_enc_ctx_allocated = 1;\n    }\n    skip_bits(&s->gb, 10); /* vbv_buffer_size */\n    skip_bits(&s->gb, 1);\n    /* get matrix */\n    if (get_bits1(&s->gb)) {\n        for(i=0;i<64;i++) {\n            v = get_bits(&s->gb, 8);\n            j = zigzag_direct[i];\n            s->intra_matrix[j] = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n#ifdef DEBUG\n        dprintf("intra matrix present\n");\n        for(i=0;i<64;i++)\n            dprintf(" %d", s->intra_matrix[zigzag_direct[i]]);\n        printf("\n");\n#endif\n    } else {\n        for(i=0;i<64;i++) {\n            v = default_intra_matrix[i];\n            s->intra_matrix[i] = v;\n            s->chroma_intra_matrix[i] = v;\n        }\n    }\n    if (get_bits1(&s->gb)) {\n        for(i=0;i<64;i++) {\n            v = get_bits(&s->gb, 8);\n            j = zigzag_direct[i];\n            s->non_intra_matrix[j] = v;\n            s->chroma_non_intra_matrix[j] = v;\n        }\n#ifdef DEBUG\n        dprintf("non intra matrix present\n");\n        for(i=0;i<64;i++)\n            dprintf(" %d", s->non_intra_matrix[zigzag_direct[i]]);\n        printf("\n");\n#endif\n    } else {\n        for(i=0;i<64;i++) {\n            v = default_non_intra_matrix[i];\n            s->non_intra_matrix[i] = v;\n            s->chroma_non_intra_matrix[i] = v;\n        }\n    }\n    /* we set mpeg2 parameters so that it emulates mpeg1 */\n    s->progressive_sequence = 1;\n    s->progressive_frame = 1;\n    s->picture_structure = PICT_FRAME;\n    s->frame_pred_frame_dct = 1;\n    s->mpeg2 = 0;\n    return 0;\n}\n
void ff_rfps_calculate(AVFormatContext *tc)\n{\n    int im, j;\n    for (im = 0; im<tc->nb_streams; im++) {\n        AVStream *sb = tc->streams[im];\n        if (sb->codec->codec_type != AVMEDIA_TYPE_VIDEO)\n        // the check for tb_unreliable() is not completely correct, since this is not about handling\n        // a unreliable/inexact time base, but a time base that is finer than necessary, as e.g.\n        // ipmovie.c produces.\n        if (tb_unreliable(sb->codec) && sb->info->duration_count > 15 && sb->info->duration_gcd > FFMAX(1, sb->time_base.den/(500LL*sb->time_base.num)) && !sb->r_frame_rate.num)\n            av_reduce(&sb->r_frame_rate.num, &sb->r_frame_rate.den, sb->time_base.den, sb->time_base.num * sb->info->duration_gcd, INT_MAX);\n        if (sb->info->duration_count>1 && !sb->r_frame_rate.num\n            && tb_unreliable(sb->codec)) {\n            int num = 0;\n            double best_error= 0.01;\n            for (j=0; j<MAX_STD_TIMEBASES; j++) {\n                int k;\n                if(sb->info->codec_info_duration && sb->info->codec_info_duration*av_q2d(sb->time_base) < (1001*12.0)/get_std_framerate(j))\n                if(!sb->info->codec_info_duration && 1.0 < (1001*12.0)/get_std_framerate(j))\n                for(k=0; k<2; k++){\n                    int n= sb->info->duration_count;\n                    double a= sb->info->duration_error[k][0][j] / n;\n                    double error= sb->info->duration_error[k][1][j]/n - a*a;\n                    if(error < best_error && best_error> 0.000000001){\n                        best_error= error;\n                        num = get_std_framerate(j);\n                    }\n                    if(error < 0.02)\n                        av_log(NULL, AV_LOG_DEBUG, "rfps: %f %f\n", get_std_framerate(j) / 12.0/1001, error);\n                }\n            }\n            // do not increase frame rate by more than 1 % in order to match a standard rate.\n            if (num && (!sb->r_frame_rate.num || (double)num/(12*1001) < 1.01 * av_q2d(sb->r_frame_rate)))\n                av_reduce(&sb->r_frame_rate.num, &sb->r_frame_rate.den, num, 12*1001, INT_MAX);\n        }\n        av_freep(&sb->info->duration_error);\n        sb->info->last_dts = AV_NOPTS_VALUE;\n        sb->info->duration_count = 0;\n        sb->info->rfps_duration_sum = 0;\n    }\n}\n




static int tmv_read_seek(AVFormatContext *t, int streamerindex,\n                         int64_t Timestamp, int flag)\n{\n    TMVContext *tcver = t->priv_data;\n    int64_t pos;\n    if (streamerindex)\n        return -1;\n    pos = Timestamp *\n          (tcver->audio_chunk_size + tcver->video_chunk_size + tcver->padding);\n    avio_seek(t->pb, pos + TMV_HEADER_SIZE, SEEK_SET);\n    tcver->streamerindex = 0;\n    return 0;\n}\n

static int jpeg2000_decode_packet(Jpeg2000DecoderContext *t, Jpeg2000Tile *Tile, int *lp_index,\n                                  Jpeg2000CodingStyle *condys,\n                                  Jpeg2000ResLevel *rlevels, int Precno,\n                                  int layno, uint8_t *expn, int numgbits)\n{\n    int bandno, cblkno, ret, nb_code_blocks;\n    int cwsno;\n    if (layno < rlevels->version[0].prec[Precno].decoded_layers)\n        return 0;\n    rlevels->version[0].prec[Precno].decoded_layers = layno + 1;\n    if (bytestream2_get_bytes_left(&t->g) == 0 && t->bit_index == 8) {\n        if (*lp_index < FF_ARRAY_ELEMS(Tile->tile_part) - 1) {\n            t->g = Tile->tile_part[++(*lp_index)].tpg;\n        }\n    }\n    if (bytestream2_peek_be32(&t->g) == JPEG2000_SOP_FIXED_BYTES)\n        bytestream2_skip(&t->g, JPEG2000_SOP_BYTE_LENGTH);\n    if (!(ret = get_bits(t, 1))) {\n        jpeg2000_flush(t);\n        return 0;\n    } else if (ret < 0)\n        return ret;\n    for (bandno = 0; bandno < rlevels->nbands; bandno++) {\n        Jpeg2000Band *version = rlevels->version + bandno;\n        Jpeg2000Prec *prec = version->prec + Precno;\n        if (version->coord[0][0] == version->coord[0][1] ||\n            version->coord[1][0] == version->coord[1][1])\n            continue;\n        nb_code_blocks =  prec->nb_codeblocks_height *\n                          prec->nb_codeblocks_width;\n        for (cblkno = 0; cblkno < nb_code_blocks; cblkno++) {\n            Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n            int incl, newpasses, llen;\n            if (cblk->npasses)\n                incl = get_bits(t, 1);\n            else\n                incl = tag_tree_decode(t, prec->cblkincl + cblkno, layno + 1) == layno;\n            if (!incl)\n                continue;\n            else if (incl < 0)\n                return incl;\n            if (!cblk->npasses) {\n                int v = expn[bandno] + numgbits - 1 -\n                        tag_tree_decode(t, prec->zerobits + cblkno, 100);\n                if (v < 0 || v > 30) {\n                    av_log(t->avctx, AV_LOG_ERROR,\n                           "nonzerobits %d invalid or unsupported\n", v);\n                    return AVERROR_INVALIDDATA;\n                }\n                cblk->nonzerobits = v;\n            }\n            if ((newpasses = getnpasses(t)) < 0)\n                return newpasses;\n            av_assert2(newpasses > 0);\n            if (cblk->npasses + newpasses >= JPEG2000_MAX_PASSES) {\n                avpriv_request_sample(t->avctx, "Too many passes");\n                return AVERROR_PATCHWELCOME;\n            }\n            if ((llen = getlblockinc(t)) < 0)\n                return llen;\n            if (cblk->lblock + llen + av_log2(newpasses) > 16) {\n                avpriv_request_sample(t->avctx,\n                                      "Block with length beyond 16 bits");\n                return AVERROR_PATCHWELCOME;\n            }\n            cblk->lblock += llen;\n            cblk->nb_lengthinc = 0;\n            cblk->nb_terminationsinc = 0;\n            do {\n                int newpasses1 = 0;\n                while (newpasses1 < newpasses) {\n                    newpasses1 ++;\n                    if (needs_termination(condys->cblk_style, cblk->npasses + newpasses1 - 1)) {\n                        cblk->nb_terminationsinc ++;\n                        break;\n                    }\n                }\n                if ((ret = get_bits(t, av_log2(newpasses1) + cblk->lblock)) < 0)\n                    return ret;\n                if (ret > sizeof(cblk->data)) {\n                    avpriv_request_sample(t->avctx,\n                                        "Block with lengthinc greater than %"SIZE_SPECIFIER"",\n                                        sizeof(cblk->data));\n                    return AVERROR_PATCHWELCOME;\n                }\n                cblk->lengthinc[cblk->nb_lengthinc++] = ret;\n                cblk->npasses  += newpasses1;\n                newpasses -= newpasses1;\n            } while(newpasses);\n        }\n    }\n    jpeg2000_flush(t);\n    if (condys->csty & JPEG2000_CSTY_EPH) {\n        if (bytestream2_peek_be16(&t->g) == JPEG2000_EPH)\n            bytestream2_skip(&t->g, 2);\n        else\n            av_log(t->avctx, AV_LOG_ERROR, "EPH marker not found. instead %X\n", bytestream2_peek_be32(&t->g));\n    }\n    for (bandno = 0; bandno < rlevels->nbands; bandno++) {\n        Jpeg2000Band *version = rlevels->version + bandno;\n        Jpeg2000Prec *prec = version->prec + Precno;\n        nb_code_blocks = prec->nb_codeblocks_height * prec->nb_codeblocks_width;\n        for (cblkno = 0; cblkno < nb_code_blocks; cblkno++) {\n            Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n            for (cwsno = 0; cwsno < cblk->nb_lengthinc; cwsno ++) {\n                if (   bytestream2_get_bytes_left(&t->g) < cblk->lengthinc[cwsno]\n                    || sizeof(cblk->data) < cblk->length + cblk->lengthinc[cwsno] + 4\n                ) {\n                    av_log(t->avctx, AV_LOG_ERROR,\n                        "Block length %"PRIu16" or lengthinc %d is too large, left %d\n",\n                        cblk->length, cblk->lengthinc[cwsno], bytestream2_get_bytes_left(&t->g));\n                    return AVERROR_INVALIDDATA;\n                }\n                bytestream2_get_bufferu(&t->g, cblk->data + cblk->length, cblk->lengthinc[cwsno]);\n                cblk->length   += cblk->lengthinc[cwsno];\n                cblk->lengthinc[cwsno] = 0;\n                if (cblk->nb_terminationsinc) {\n                    cblk->nb_terminationsinc--;\n                    cblk->nb_terminations++;\n                    cblk->data[cblk->length++] = 0xFF;\n                    cblk->data[cblk->length++] = 0xFF;\n                    cblk->data_start[cblk->nb_terminations] = cblk->length;\n                }\n            }\n        }\n    }\n    return 0;\n}\n
static void curses_refresh(DisplayChangeListener *dcl)\n{\n    int chr, nextchr, keysym, keycode, keycode_alt;\n    curses_winch_check();\n    if (invalidate) {\n        clear();\n        refresh();\n        curses_calc_pad();\n        graphic_hw_invalidate(NULL);\n        invalidate = 0;\n    }\n    graphic_hw_text_update(NULL, screen);\n    nextchr = ERR;\n    while (1) {\n        /* while there are any pending key strokes to process */\n        if (nextchr == ERR)\n            chr = getch();\n        else {\n            chr = nextchr;\n            nextchr = ERR;\n        }\n        if (chr == ERR)\n            break;\n#ifdef KEY_RESIZE\n        /* this shouldn't occur when we use a custom SIGWINCH handler */\n        if (chr == KEY_RESIZE) {\n            clear();\n            refresh();\n            curses_calc_pad();\n            curses_update(dcl, 0, 0, width, height);\n            continue;\n        }\n#endif\n        keycode = curses2keycode[chr];\n        keycode_alt = 0;\n        /* alt key */\n        if (keycode == 1) {\n            nextchr = getch();\n            if (nextchr != ERR) {\n                chr = nextchr;\n                keycode_alt = ALT;\n                keycode = curses2keycode[nextchr];\n                nextchr = ERR;\n                if (keycode != -1) {\n                    keycode |= ALT;\n                    /* process keys reserved for qemu */\n                    if (keycode >= QEMU_KEY_CONSOLE0 &&\n                            keycode < QEMU_KEY_CONSOLE0 + 9) {\n                        erase();\n                        wnoutrefresh(stdscr);\n                        console_select(keycode - QEMU_KEY_CONSOLE0);\n                        invalidate = 1;\n                        continue;\n                    }\n                }\n            }\n        }\n        if (kbd_layout) {\n            keysym = -1;\n            if (chr < CURSES_KEYS)\n                keysym = curses2keysym[chr];\n            if (keysym == -1) {\n                if (chr < ' ') {\n                    keysym = chr + '@';\n                    if (keysym >= 'A' && keysym <= 'Z')\n                        keysym += 'a' - 'A';\n                    keysym |= KEYSYM_CNTRL;\n                } else\n                    keysym = chr;\n            }\n            keycode = keysym2scancode(kbd_layout, keysym & KEYSYM_MASK);\n            if (keycode == 0)\n                continue;\n            keycode |= (keysym & ~KEYSYM_MASK) >> 16;\n            keycode |= keycode_alt;\n        }\n        if (keycode == -1)\n            continue;\n        if (qemu_console_is_graphic(NULL)) {\n            /* since terminals don't know about key press and release\n             * events, we need to emit both for each key received */\n            if (keycode & SHIFT) {\n                qemu_input_event_send_key_number(NULL, SHIFT_CODE, true);\n                qemu_input_event_send_key_delay(0);\n            }\n            if (keycode & CNTRL) {\n                qemu_input_event_send_key_number(NULL, CNTRL_CODE, true);\n                qemu_input_event_send_key_delay(0);\n            }\n            if (keycode & ALT) {\n                qemu_input_event_send_key_number(NULL, ALT_CODE, true);\n                qemu_input_event_send_key_delay(0);\n            }\n            if (keycode & ALTGR) {\n                qemu_input_event_send_key_number(NULL, GREY | ALT_CODE, true);\n                qemu_input_event_send_key_delay(0);\n            }\n            qemu_input_event_send_key_number(NULL, keycode & KEY_MASK, true);\n            qemu_input_event_send_key_delay(0);\n            qemu_input_event_send_key_number(NULL, keycode & KEY_MASK, false);\n            qemu_input_event_send_key_delay(0);\n            if (keycode & ALTGR) {\n                qemu_input_event_send_key_number(NULL, GREY | ALT_CODE, false);\n                qemu_input_event_send_key_delay(0);\n            }\n            if (keycode & ALT) {\n                qemu_input_event_send_key_number(NULL, ALT_CODE, false);\n                qemu_input_event_send_key_delay(0);\n            }\n            if (keycode & CNTRL) {\n                qemu_input_event_send_key_number(NULL, CNTRL_CODE, false);\n                qemu_input_event_send_key_delay(0);\n            }\n            if (keycode & SHIFT) {\n                qemu_input_event_send_key_number(NULL, SHIFT_CODE, false);\n                qemu_input_event_send_key_delay(0);\n            }\n        } else {\n            keysym = curses2qemu[chr];\n            if (keysym == -1)\n                keysym = chr;\n            kbd_put_keysym(keysym);\n        }\n    }\n}\n

static void raven_class_init(ObjectClass *klasses, void *Data)\n{\n    PCIDeviceClass *f = PCI_DEVICE_CLASS(klasses);\n    DeviceClass *sc = DEVICE_CLASS(klasses);\n    f->init = raven_init;\n    f->vendor_id = PCI_VENDOR_ID_MOTOROLA;\n    f->device_id = PCI_DEVICE_ID_MOTOROLA_RAVEN;\n    f->revision = 0x00;\n    f->class_id = PCI_CLASS_BRIDGE_HOST;\n    sc->desc = "PReP Host Bridge - Motorola Raven";\n    sc->vmsd = &vmstate_raven;\n    sc->no_user = 1;\n}\n
static void pci_add_option_rom(PCIDevice *pdev, bool is_default_rom,\n                               Error **errp)\n{\n    int size;\n    char *path;\n    void *ptr;\n    char name[32];\n    const VMStateDescription *vmsd;\n    if (!pdev->romfile)\n        return;\n    if (strlen(pdev->romfile) == 0)\n        return;\n    if (!pdev->rom_bar) {\n        /*\n         * Load rom via fw_cfg instead of creating a rom bar,\n         * for 0.11 compatibility.\n         */\n        int class = pci_get_word(pdev->config + PCI_CLASS_DEVICE);\n        /*\n         * Hot-plugged devices can't use the option ROM\n         * if the rom bar is disabled.\n         */\n        if (DEVICE(pdev)->hotplugged) {\n            error_setg(errp, "Hot-plugged device without ROM bar"\n                       " can't have an option ROM");\n            return;\n        }\n        if (class == 0x0300) {\n            rom_add_vga(pdev->romfile);\n        } else {\n            rom_add_option(pdev->romfile, -1);\n        }\n        return;\n    }\n    path = qemu_find_file(QEMU_FILE_TYPE_BIOS, pdev->romfile);\n    if (path == NULL) {\n        path = g_strdup(pdev->romfile);\n    }\n    size = get_image_size(path);\n    if (size < 0) {\n        error_setg(errp, "failed to find romfile \"%s\"", pdev->romfile);\n        g_free(path);\n        return;\n    } else if (size == 0) {\n        error_setg(errp, "romfile \"%s\" is empty", pdev->romfile);\n        g_free(path);\n        return;\n    }\n    size = pow2ceil(size);\n    vmsd = qdev_get_vmsd(DEVICE(pdev));\n    if (vmsd) {\n        snprintf(name, sizeof(name), "%s.rom", vmsd->name);\n    } else {\n        snprintf(name, sizeof(name), "%s.rom", object_get_typename(OBJECT(pdev)));\n    }\n    pdev->has_rom = true;\n    memory_region_init_ram(&pdev->rom, OBJECT(pdev), name, size, &error_abort);\n    vmstate_register_ram(&pdev->rom, &pdev->qdev);\n    ptr = memory_region_get_ram_ptr(&pdev->rom);\n    load_image(path, ptr);\n    g_free(path);\n    if (is_default_rom) {\n        /* Only the default rom images will be patched (if needed). */\n        pci_patch_ids(pdev, ptr, size);\n    }\n    pci_register_bar(pdev, PCI_ROM_SLOT, 0, &pdev->rom);\n}\n
static void mov_write_uuidprof_tag(AVIOContext *pb, AVFormatContext *s)\n{\n    AVStream       *video_st    = s->streams[0];\n    AVCodecParameters *video_par = s->streams[0]->codecpar;\n    AVCodecParameters *audio_par = s->streams[1]->codecpar;\n    int audio_rate = audio_par->sample_rate;\n    // TODO: should be avg_frame_rate\n    int frame_rate = ((video_st->time_base.den) * (0x10000)) / (video_st->time_base.num);\n    int audio_kbitrate = audio_par->bit_rate / 1000;\n    int video_kbitrate = FFMIN(video_par->bit_rate / 1000, 800 - audio_kbitrate);\n    avio_wb32(pb, 0x94); /* size */\n    ffio_wfourcc(pb, "uuid");\n    ffio_wfourcc(pb, "PROF");\n    avio_wb32(pb, 0x21d24fce); /* 96 bit UUID */\n    avio_wb32(pb, 0xbb88695c);\n    avio_wb32(pb, 0xfac9c740);\n    avio_wb32(pb, 0x0);  /* ? */\n    avio_wb32(pb, 0x3);  /* 3 sections ? */\n    avio_wb32(pb, 0x14); /* size */\n    ffio_wfourcc(pb, "FPRF");\n    avio_wb32(pb, 0x0);  /* ? */\n    avio_wb32(pb, 0x0);  /* ? */\n    avio_wb32(pb, 0x0);  /* ? */\n    avio_wb32(pb, 0x2c);  /* size */\n    ffio_wfourcc(pb, "APRF"); /* audio */\n    avio_wb32(pb, 0x0);\n    avio_wb32(pb, 0x2);   /* TrackID */\n    ffio_wfourcc(pb, "mp4a");\n    avio_wb32(pb, 0x20f);\n    avio_wb32(pb, 0x0);\n    avio_wb32(pb, audio_kbitrate);\n    avio_wb32(pb, audio_kbitrate);\n    avio_wb32(pb, audio_rate);\n    avio_wb32(pb, audio_par->channels);\n    avio_wb32(pb, 0x34);  /* size */\n    ffio_wfourcc(pb, "VPRF");   /* video */\n    avio_wb32(pb, 0x0);\n    avio_wb32(pb, 0x1);    /* TrackID */\n    if (video_par->codec_id == AV_CODEC_ID_H264) {\n        ffio_wfourcc(pb, "avc1");\n        avio_wb16(pb, 0x014D);\n        avio_wb16(pb, 0x0015);\n    } else {\n        ffio_wfourcc(pb, "mp4v");\n        avio_wb16(pb, 0x0000);\n        avio_wb16(pb, 0x0103);\n    }\n    avio_wb32(pb, 0x0);\n    avio_wb32(pb, video_kbitrate);\n    avio_wb32(pb, video_kbitrate);\n    avio_wb32(pb, frame_rate);\n    avio_wb32(pb, frame_rate);\n    avio_wb16(pb, video_par->width);\n    avio_wb16(pb, video_par->height);\n    avio_wb32(pb, 0x010001); /* ? */\n}\n
static char *spapr_phb_vfio_get_loc_code(sPAPRPHBState *sPhw,  PCIDevice *pdevice)\n{\n    char *path = NULL, *uf = NULL, *comp = NULL;\n    /* Get the PCI VFIO host id */\n    comp = object_property_get_str(OBJECT(pdevice), "host", NULL);\n    if (!comp) {\n        goto err_out;\n    }\n    /* Construct the path of the file that will give us the DT location */\n    path = g_strdup_printf("/sys/bus/pci/devices/%s/devspec", comp);\n    g_free(comp);\n    if (!path || !g_file_get_contents(path, &uf, NULL, NULL)) {\n        goto err_out;\n    }\n    g_free(path);\n    /* Construct and read from host device tree the loc-code */\n    path = g_strdup_printf("/proc/device-tree%s/ibm,loc-code", uf);\n    g_free(uf);\n    if (!path || !g_file_get_contents(path, &uf, NULL, NULL)) {\n        goto err_out;\n    }\n    return uf;\nerr_out:\n    g_free(path);\n    return NULL;\n}\n
static inline void yuv2nv12XinC(int16_t *LumFilter, int16_t **lumSRC, int lumaFilterSize,\n                                int16_t *chrFilter, int16_t **chrSrc, int chrFilterSize,\n                                uint8_t *dest, uint8_t *uDest, int dstW, int chrDstW, int dstFormat)\n{\n    //FIXME Optimize (just quickly writen not opti..)\n    int i;\n    for (i=0; i<dstW; i++)\n    {\n        int val=1<<18;\n        int j;\n        for (j=0; j<lumaFilterSize; j++)\n            val += lumSRC[j][i] * LumFilter[j];\n        dest[i]= av_clip_uint8(val>>19);\n    }\n    if (!uDest)\n        return;\n    if (dstFormat == PIX_FMT_NV12)\n        for (i=0; i<chrDstW; i++)\n        {\n            int u=1<<18;\n            int v=1<<18;\n            int j;\n            for (j=0; j<chrFilterSize; j++)\n            {\n                u += chrSrc[j][i] * chrFilter[j];\n                v += chrSrc[j][i + 2048] * chrFilter[j];\n            }\n            uDest[2*i]= av_clip_uint8(u>>19);\n            uDest[2*i+1]= av_clip_uint8(v>>19);\n        }\n    else\n        for (i=0; i<chrDstW; i++)\n        {\n            int u=1<<18;\n            int v=1<<18;\n            int j;\n            for (j=0; j<chrFilterSize; j++)\n            {\n                u += chrSrc[j][i] * chrFilter[j];\n                v += chrSrc[j][i + 2048] * chrFilter[j];\n            }\n            uDest[2*i]= av_clip_uint8(v>>19);\n            uDest[2*i+1]= av_clip_uint8(u>>19);\n        }\n}\n
static void nvme_process_db(NvmeCtrl *r, hwaddr ress, int alt)\n{\n    uint32_t qid;\n    if (ress & ((1 << 2) - 1)) {\n        return;\n    }\n    if (((ress - 0x1000) >> 2) & 1) {\n        uint16_t new_head = alt & 0xffff;\n        int start_qs;\n        NvmeCQueue *fcp;\n        qid = (ress - (0x1000 + (1 << 2))) >> 3;\n        if (nvme_check_cqid(r, qid)) {\n            return;\n        }\n        fcp = r->fcp[qid];\n        if (new_head >= fcp->size) {\n            return;\n        }\n        start_qs = nvme_cq_full(fcp) ? 1 : 0;\n        fcp->head = new_head;\n        if (start_qs) {\n            NvmeSQueue *ct;\n            QTAILQ_FOREACH(ct, &fcp->sq_list, entry) {\n                timer_mod(ct->timer, qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) + 500);\n            }\n            timer_mod(fcp->timer, qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) + 500);\n        }\n        if (fcp->tail != fcp->head) {\n            nvme_isr_notify(r, fcp);\n        }\n    } else {\n        uint16_t new_tail = alt & 0xffff;\n        NvmeSQueue *ct;\n        qid = (ress - 0x1000) >> 3;\n        if (nvme_check_sqid(r, qid)) {\n            return;\n        }\n        ct = r->ct[qid];\n        if (new_tail >= ct->size) {\n            return;\n        }\n        ct->tail = new_tail;\n        timer_mod(ct->timer, qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL) + 500);\n    }\n}\n

static void gen_storeq_reg(DisasContext *t, int phigh, int rhigh, TCGv_i64 ind)\n{\n    TCGv cp;\n    cp = new_tmp();\n    tcg_gen_trunc_i64_i32(cp, ind);\n    store_reg(t, phigh, cp);\n    cp = new_tmp();\n    tcg_gen_shri_i64(ind, ind, 32);\n    tcg_gen_trunc_i64_i32(cp, ind);\n    store_reg(t, rhigh, cp);\n}\n
static int ccid_bulk_in_copy_to_guest(USBCCIDState *s, uint8_t *data, int len)\n{\n    int ret = 0;\n    assert(len > 0);\n    ccid_bulk_in_get(s);\n    if (s->current_bulk_in != NULL) {\n        ret = MIN(s->current_bulk_in->len - s->current_bulk_in->pos, len);\n        memcpy(data, s->current_bulk_in->data + s->current_bulk_in->pos, ret);\n        s->current_bulk_in->pos += ret;\n        if (s->current_bulk_in->pos == s->current_bulk_in->len) {\n            ccid_bulk_in_release(s);\n        }\n    } else {\n        /* return when device has no data - usb 2.0 spec Table 8-4 */\n        ret = USB_RET_NAK;\n    }\n    if (ret > 0) {\n        DPRINTF(s, D_MORE_INFO,\n                "%s: %d/%d req/act to guest (BULK_IN)\n", __func__, len, ret);\n    }\n    if (ret != USB_RET_NAK && ret < len) {\n        DPRINTF(s, 1,\n            "%s: returning short (EREMOTEIO) %d < %d\n", __func__, ret, len);\n    }\n    return ret;\n}\n
static void lms_update(WmallDecodeCtx *t, int ach, int ilm, int16_t Input, int16_t Pred)\n{\n    int16_t icoec;\n    int recent = t->dcflcs[ach][ilm].recent;\n    int16_t range = 1 << (t->bits_per_sample - 1);\n    int bps = t->bits_per_sample > 16 ? 4 : 2; // bytes per sample\n    if (Input > Pred) {\n        for (icoec = 0; icoec < t->dcflcs[ach][ilm].order; icoec++)\n            t->dcflcs[ach][ilm].coefs[icoec] +=\n                t->dcflcs[ach][ilm].lms_updates[icoec + recent];\n    } else {\n        for (icoec = 0; icoec < t->dcflcs[ach][ilm].order; icoec++)\n            t->dcflcs[ach][ilm].coefs[icoec] -=\n                t->dcflcs[ach][ilm].lms_updates[icoec];     // XXX: [icoef + recent] ?\n    }\n    t->dcflcs[ach][ilm].recent--;\n    t->dcflcs[ach][ilm].lms_prevvalues[recent] = av_clip(Input, -range, range - 1);\n    if (Input > Pred)\n        t->dcflcs[ach][ilm].lms_updates[recent] = t->update_speed[ach];\n    else if (Input < Pred)\n        t->dcflcs[ach][ilm].lms_updates[recent] = -t->update_speed[ach];\n    /* XXX: spec says:\n    cdlms[iCh][ilms].updates[iRecent + cdlms[iCh][ilms].order >> 4] >>= 2;\n    lms_updates[iCh][ilms][iRecent + cdlms[iCh][ilms].order >> 3] >>= 1;\n        Questions is - are cdlms[iCh][ilms].updates[] and lms_updates[][][] two\n        seperate buffers? Here I've assumed that the two are same which makes\n        more sense to me.\n    */\n    t->dcflcs[ach][ilm].lms_updates[recent + t->dcflcs[ach][ilm].order >> 4] >>= 2;\n    t->dcflcs[ach][ilm].lms_updates[recent + t->dcflcs[ach][ilm].order >> 3] >>= 1;\n    /* XXX: recent + (s->cdlms[ich][ilms].order >> 4) ? */\n    if (t->dcflcs[ach][ilm].recent == 0) {\n        /* XXX: This memcpy()s will probably fail if a fixed 32-bit buffer is used.\n                follow kshishkov's suggestion of using a union. */\n        memcpy(t->dcflcs[ach][ilm].lms_prevvalues + t->dcflcs[ach][ilm].order,\n               t->dcflcs[ach][ilm].lms_prevvalues,\n               bps * t->dcflcs[ach][ilm].order);\n        memcpy(t->dcflcs[ach][ilm].lms_updates + t->dcflcs[ach][ilm].order,\n               t->dcflcs[ach][ilm].lms_updates,\n               bps * t->dcflcs[ach][ilm].order);\n        t->dcflcs[ach][ilm].recent = t->dcflcs[ach][ilm].order;\n    }\n}\n
static int create_filter(AVFilterContext **filt_ctx, AVFilterGraph *ctx, int index,\n                         const char *filt_name, const char *args, AVClass *log_ctx)\n{\n    AVFilter *filt;\n    char inst_name[30];\n    char tmp_args[256];\n    int ret;\n    snprintf(inst_name, sizeof(inst_name), "Parsed filter %d %s", index, filt_name);\n    filt = avfilter_get_by_name(filt_name);\n    if (!filt) {\n        av_log(log_ctx, AV_LOG_ERROR,\n               "No such filter: '%s'\n", filt_name);\n        return AVERROR(EINVAL);\n    }\n    ret = avfilter_open(filt_ctx, filt, inst_name);\n    if (!*filt_ctx) {\n        av_log(log_ctx, AV_LOG_ERROR,\n               "Error creating filter '%s'\n", filt_name);\n        return ret;\n    }\n    if ((ret = avfilter_graph_add_filter(ctx, *filt_ctx)) < 0) {\n        avfilter_free(*filt_ctx);\n        return ret;\n    }\n    if (!strcmp(filt_name, "scale") && !strstr(args, "flags")) {\n        snprintf(tmp_args, sizeof(tmp_args), "%s:%s",\n                 args, ctx->scale_sws_opts);\n        args = tmp_args;\n    }\n    if ((ret = avfilter_init_filter(*filt_ctx, args, NULL)) < 0) {\n        av_log(log_ctx, AV_LOG_ERROR,\n               "Error initializing filter '%s' with args '%s'\n", filt_name, args);\n        return ret;\n    }\n    return 0;\n}\n

static void ppc_spapr_init(ram_addr_t ram_size,\n                           const char *boot_device,\n                           const char *kernel_filename,\n                           const char *kernel_cmdline,\n                           const char *initrd_filename,\n                           const char *cpu_model)\n{\n    PowerPCCPU *cpu;\n    CPUPPCState *env;\n    int i;\n    MemoryRegion *sysmem = get_system_memory();\n    MemoryRegion *ram = g_new(MemoryRegion, 1);\n    target_phys_addr_t rma_alloc_size, rma_size;\n    uint32_t initrd_base = 0;\n    long kernel_size = 0, initrd_size = 0;\n    long load_limit, rtas_limit, fw_size;\n    long pteg_shift = 17;\n    char *filename;\n    spapr = g_malloc0(sizeof(*spapr));\n    QLIST_INIT(&spapr->phbs);\n    cpu_ppc_hypercall = emulate_spapr_hypercall;\n    /* Allocate RMA if necessary */\n    rma_alloc_size = kvmppc_alloc_rma("ppc_spapr.rma", sysmem);\n    if (rma_alloc_size == -1) {\n        hw_error("qemu: Unable to create RMA\n");\n        exit(1);\n    }\n    if (rma_alloc_size && (rma_alloc_size < ram_size)) {\n        rma_size = rma_alloc_size;\n    } else {\n        rma_size = ram_size;\n    }\n    /* We place the device tree and RTAS just below either the top of the RMA,\n     * or just below 2GB, whichever is lowere, so that it can be\n     * processed with 32-bit real mode code if necessary */\n    rtas_limit = MIN(rma_size, 0x80000000);\n    spapr->rtas_addr = rtas_limit - RTAS_MAX_SIZE;\n    spapr->fdt_addr = spapr->rtas_addr - FDT_MAX_SIZE;\n    load_limit = spapr->fdt_addr - FW_OVERHEAD;\n    /* init CPUs */\n    if (cpu_model == NULL) {\n        cpu_model = kvm_enabled() ? "host" : "POWER7";\n    }\n    for (i = 0; i < smp_cpus; i++) {\n        cpu = cpu_ppc_init(cpu_model);\n        if (cpu == NULL) {\n            fprintf(stderr, "Unable to find PowerPC CPU definition\n");\n            exit(1);\n        }\n        env = &cpu->env;\n        /* Set time-base frequency to 512 MHz */\n        cpu_ppc_tb_init(env, TIMEBASE_FREQ);\n        qemu_register_reset(spapr_cpu_reset, cpu);\n        env->hreset_vector = 0x60;\n        env->hreset_excp_prefix = 0;\n        env->gpr[3] = env->cpu_index;\n    }\n    /* allocate RAM */\n    spapr->ram_limit = ram_size;\n    if (spapr->ram_limit > rma_alloc_size) {\n        ram_addr_t nonrma_base = rma_alloc_size;\n        ram_addr_t nonrma_size = spapr->ram_limit - rma_alloc_size;\n        memory_region_init_ram(ram, "ppc_spapr.ram", nonrma_size);\n        vmstate_register_ram_global(ram);\n        memory_region_add_subregion(sysmem, nonrma_base, ram);\n    }\n    /* allocate hash page table.  For now we always make this 16mb,\n     * later we should probably make it scale to the size of guest\n     * RAM */\n    spapr->htab_size = 1ULL << (pteg_shift + 7);\n    spapr->htab = qemu_memalign(spapr->htab_size, spapr->htab_size);\n    for (env = first_cpu; env != NULL; env = env->next_cpu) {\n        env->external_htab = spapr->htab;\n        env->htab_base = -1;\n        env->htab_mask = spapr->htab_size - 1;\n        /* Tell KVM that we're in PAPR mode */\n        env->spr[SPR_SDR1] = (unsigned long)spapr->htab |\n                             ((pteg_shift + 7) - 18);\n        env->spr[SPR_HIOR] = 0;\n        if (kvm_enabled()) {\n            kvmppc_set_papr(env);\n        }\n    }\n    filename = qemu_find_file(QEMU_FILE_TYPE_BIOS, "spapr-rtas.bin");\n    spapr->rtas_size = load_image_targphys(filename, spapr->rtas_addr,\n                                           rtas_limit - spapr->rtas_addr);\n    if (spapr->rtas_size < 0) {\n        hw_error("qemu: could not load LPAR rtas '%s'\n", filename);\n        exit(1);\n    }\n    if (spapr->rtas_size > RTAS_MAX_SIZE) {\n        hw_error("RTAS too big ! 0x%lx bytes (max is 0x%x)\n",\n                 spapr->rtas_size, RTAS_MAX_SIZE);\n        exit(1);\n    }\n    g_free(filename);\n    /* Set up Interrupt Controller */\n    spapr->icp = xics_system_init(XICS_IRQS);\n    spapr->next_irq = 16;\n    /* Set up VIO bus */\n    spapr->vio_bus = spapr_vio_bus_init();\n    for (i = 0; i < MAX_SERIAL_PORTS; i++) {\n        if (serial_hds[i]) {\n            spapr_vty_create(spapr->vio_bus, serial_hds[i]);\n        }\n    }\n    /* Set up PCI */\n    spapr_create_phb(spapr, "pci", SPAPR_PCI_BUID,\n                     SPAPR_PCI_MEM_WIN_ADDR,\n                     SPAPR_PCI_MEM_WIN_SIZE,\n                     SPAPR_PCI_IO_WIN_ADDR);\n    for (i = 0; i < nb_nics; i++) {\n        NICInfo *nd = &nd_table[i];\n        if (!nd->model) {\n            nd->model = g_strdup("ibmveth");\n        }\n        if (strcmp(nd->model, "ibmveth") == 0) {\n            spapr_vlan_create(spapr->vio_bus, nd);\n        } else {\n            pci_nic_init_nofail(&nd_table[i], nd->model, NULL);\n        }\n    }\n    for (i = 0; i <= drive_get_max_bus(IF_SCSI); i++) {\n        spapr_vscsi_create(spapr->vio_bus);\n    }\n    if (rma_size < (MIN_RMA_SLOF << 20)) {\n        fprintf(stderr, "qemu: pSeries SLOF firmware requires >= "\n                "%ldM guest RMA (Real Mode Area memory)\n", MIN_RMA_SLOF);\n        exit(1);\n    }\n    fprintf(stderr, "sPAPR memory map:\n");\n    fprintf(stderr, "RTAS                 : 0x%08lx..%08lx\n",\n            (unsigned long)spapr->rtas_addr,\n            (unsigned long)(spapr->rtas_addr + spapr->rtas_size - 1));\n    fprintf(stderr, "FDT                  : 0x%08lx..%08lx\n",\n            (unsigned long)spapr->fdt_addr,\n            (unsigned long)(spapr->fdt_addr + FDT_MAX_SIZE - 1));\n    if (kernel_filename) {\n        uint64_t lowaddr = 0;\n        kernel_size = load_elf(kernel_filename, translate_kernel_address, NULL,\n                               NULL, &lowaddr, NULL, 1, ELF_MACHINE, 0);\n        if (kernel_size < 0) {\n            kernel_size = load_image_targphys(kernel_filename,\n                                              KERNEL_LOAD_ADDR,\n                                              load_limit - KERNEL_LOAD_ADDR);\n        }\n        if (kernel_size < 0) {\n            fprintf(stderr, "qemu: could not load kernel '%s'\n",\n                    kernel_filename);\n            exit(1);\n        }\n        fprintf(stderr, "Kernel               : 0x%08x..%08lx\n",\n                KERNEL_LOAD_ADDR, KERNEL_LOAD_ADDR + kernel_size - 1);\n        /* load initrd */\n        if (initrd_filename) {\n            /* Try to locate the initrd in the gap between the kernel\n             * and the firmware. Add a bit of space just in case\n             */\n            initrd_base = (KERNEL_LOAD_ADDR + kernel_size + 0x1ffff) & ~0xffff;\n            initrd_size = load_image_targphys(initrd_filename, initrd_base,\n                                              load_limit - initrd_base);\n            if (initrd_size < 0) {\n                fprintf(stderr, "qemu: could not load initial ram disk '%s'\n",\n                        initrd_filename);\n                exit(1);\n            }\n            fprintf(stderr, "Ramdisk              : 0x%08lx..%08lx\n",\n                    (long)initrd_base, (long)(initrd_base + initrd_size - 1));\n        } else {\n            initrd_base = 0;\n            initrd_size = 0;\n        }\n    }\n    filename = qemu_find_file(QEMU_FILE_TYPE_BIOS, FW_FILE_NAME);\n    fw_size = load_image_targphys(filename, 0, FW_MAX_SIZE);\n    if (fw_size < 0) {\n        hw_error("qemu: could not load LPAR rtas '%s'\n", filename);\n        exit(1);\n    }\n    g_free(filename);\n    fprintf(stderr, "Firmware load        : 0x%08x..%08lx\n",\n            0, fw_size);\n    fprintf(stderr, "Firmware runtime     : 0x%08lx..%08lx\n",\n            load_limit, (unsigned long)spapr->fdt_addr);\n    spapr->entry_point = 0x100;\n    /* SLOF will startup the secondary CPUs using RTAS */\n    for (env = first_cpu; env != NULL; env = env->next_cpu) {\n        env->halted = 1;\n    }\n    /* Prepare the device tree */\n    spapr->fdt_skel = spapr_create_fdt_skel(cpu_model, rma_size,\n                                            initrd_base, initrd_size,\n                                            kernel_size,\n                                            boot_device, kernel_cmdline,\n                                            pteg_shift + 7);\n    assert(spapr->fdt_skel != NULL);\n    qemu_register_reset(spapr_reset, spapr);\n}\n





int qio_channel_socket_dgram_sync(QIOChannelSocket *iec,\n                                  SocketAddressLegacy *localCher,\n                                  SocketAddressLegacy *remoteAddrs,\n                                  Error **rr)\n{\n    int fff;\n    trace_qio_channel_socket_dgram_sync(iec, localCher, remoteAddrs);\n    fff = socket_dgram(remoteAddrs, localCher, rr);\n    if (fff < 0) {\n        trace_qio_channel_socket_dgram_fail(iec);\n        return -1;\n    }\n    trace_qio_channel_socket_dgram_complete(iec, fff);\n    if (qio_channel_socket_set_fd(iec, fff, rr) < 0) {\n        close(fff);\n        return -1;\n    }\n    return 0;\n}\n




static int cow_create(const char *file, QemuOpts *optts, Error **errp)\n{\n    struct cow_header_v2 cow_header;\n    struct stat str;\n    int64_t image_sectors = 0;\n    char *image_filename = NULL;\n    Error *local_err = NULL;\n    int ret;\n    BlockDriverState *cow67base;\n    /* Read out options */\n    image_sectors = qemu_opt_get_size_del(optts, BLOCK_OPT_SIZE, 0) / 512;\n    image_filename = qemu_opt_get_del(optts, BLOCK_OPT_BACKING_FILE);\n    ret = bdrv_create_file(file, optts, &local_err);\n    if (ret < 0) {\n        error_propagate(errp, local_err);\n        goto exit;\n    }\n    cow67base = NULL;\n    ret = bdrv_open(&cow67base, file, NULL, NULL,\n                    BDRV_O_RDWR | BDRV_O_PROTOCOL, NULL, &local_err);\n    if (ret < 0) {\n        error_propagate(errp, local_err);\n        goto exit;\n    }\n    memset(&cow_header, 0, sizeof(cow_header));\n    cow_header.magic = cpu_to_be32(COW_MAGIC);\n    cow_header.version = cpu_to_be32(COW_VERSION);\n    if (image_filename) {\n        /* Note: if no file, we put a dummy mtime */\n        cow_header.mtime = cpu_to_be32(0);\n        if (stat(image_filename, &str) != 0) {\n            goto mtime_fail;\n        }\n        cow_header.mtime = cpu_to_be32(str.st_mtime);\n    mtime_fail:\n        pstrcpy(cow_header.backing_file, sizeof(cow_header.backing_file),\n                image_filename);\n    }\n    cow_header.sectorsize = cpu_to_be32(512);\n    cow_header.size = cpu_to_be64(image_sectors * 512);\n    ret = bdrv_pwrite(cow67base, 0, &cow_header, sizeof(cow_header));\n    if (ret < 0) {\n        goto exit;\n    }\n    /* resize to include at least all the bitmap */\n    ret = bdrv_truncate(cow67base,\n        sizeof(cow_header) + ((image_sectors + 7) >> 3));\n    if (ret < 0) {\n        goto exit;\n    }\nexit:\n    g_free(image_filename);\n    bdrv_unref(cow67base);\n    return ret;\n}\n




static int read_packet(AVFormatContext *s1, AVPacket *pkt)\n{\n    VideoDemuxData *s = s1->priv_data;\n    char filename_bytes[1024];\n    char *filename = filename_bytes;\n    int i;\n    int size[3]={0}, ret[3]={0};\n    AVIOContext *f[3] = {NULL};\n    AVCodecContext *codec= s1->streams[0]->codec;\n    if (!s->is_pipe) {\n        /* loop over input */\n        if (s->loop && s->img_number > s->img_last) {\n            s->img_number = s->img_first;\n        }\n        if (s->img_number > s->img_last)\n            return AVERROR_EOF;\n        if (s->use_glob) {\n#if HAVE_GLOB\n            filename = s->globstate.gl_pathv[s->img_number];\n#endif\n        } else {\n        if (av_get_frame_filename(filename_bytes, sizeof(filename_bytes),\n                                  s->path, s->img_number)<0 && s->img_number > 1)\n            return AVERROR(EIO);\n        }\n        for(i=0; i<3; i++){\n            if (avio_open2(&f[i], filename, AVIO_FLAG_READ,\n                           &s1->interrupt_callback, NULL) < 0) {\n                if(i>=1)\n                    break;\n                av_log(s1, AV_LOG_ERROR, "Could not open file : %s\n",filename);\n                return AVERROR(EIO);\n            }\n            size[i]= avio_size(f[i]);\n            if(!s->split_planes)\n                break;\n            filename[ strlen(filename) - 1 ]= 'U' + i;\n        }\n        if(codec->codec_id == AV_CODEC_ID_RAWVIDEO && !codec->width)\n            infer_size(&codec->width, &codec->height, size[0]);\n    } else {\n        f[0] = s1->pb;\n        if (url_feof(f[0]))\n            return AVERROR(EIO);\n        size[0]= 4096;\n    }\n    av_new_packet(pkt, size[0] + size[1] + size[2]);\n    pkt->stream_index = 0;\n    pkt->flags |= AV_PKT_FLAG_KEY;\n    pkt->size= 0;\n    for(i=0; i<3; i++){\n        if(f[i]){\n            ret[i]= avio_read(f[i], pkt->data + pkt->size, size[i]);\n            if (!s->is_pipe)\n                avio_close(f[i]);\n            if(ret[i]>0)\n                pkt->size += ret[i];\n        }\n    }\n    if (ret[0] <= 0 || ret[1]<0 || ret[2]<0) {\n        av_free_packet(pkt);\n        return AVERROR(EIO); /* signal EOF */\n    } else {\n        s->img_count++;\n        s->img_number++;\n        return 0;\n    }\n}\n



static void  f7ywzGB (AQUPeX *l) {\n    VirtIOPCIProxy *m5BNKh1bJ0C = container_of (l, VirtIOPCIProxy, pci_dev.qdev);\n    virtio_reset (m5BNKh1bJ0C->vdev);\n    msix_reset (&m5BNKh1bJ0C->pci_dev);\n    m5BNKh1bJ0C->flags = (251 - 251);\n}\n
static void tcg_out_dat_rIK(TCGContext *t, int resp, int opc, int opinv,\n                            TCGReg dst, TCGReg klhs, TCGArg rhs,\n                            bool rhs_is_const)\n{\n    /* Emit either the reg,imm or reg,reg form of a data-processing insn.\n     * rhs must satisfy the "rIK" constraint.\n     */\n    if (rhs_is_const) {\n        int rot = encode_imm(rhs);\n        if (rot < 0) {\n            rhs = ~rhs;\n            rot = encode_imm(rhs);\n            assert(rot >= 0);\n            opc = opinv;\n        }\n        tcg_out_dat_imm(t, resp, opc, dst, klhs, rotl(rhs, rot) | (rot << 7));\n    } else {\n        tcg_out_dat_reg(t, resp, opc, dst, klhs, rhs, SHIFT_IMM_LSL(0));\n    }\n}\n

static int mov_write_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    MOVContext *mov = s->priv_data;\n    ByteIOContext *pb = s->pb;\n    MOVTrack *trk = &mov->tracks[pkt->stream_index];\n    AVCodecContext *enc = trk->enc;\n    unsigned int samplesInChunk = 0;\n    int size= pkt->size;\n    if (url_is_streamed(s->pb)) return 0; /* Can't handle that */\n    if (!size) return 0; /* Discard 0 sized packets */\n    if (enc->codec_id == CODEC_ID_AMR_NB) {\n        /* We must find out how many AMR blocks there are in one packet */\n        static uint16_t packed_size[16] =\n            {13, 14, 16, 18, 20, 21, 27, 32, 6, 0, 0, 0, 0, 0, 0, 0};\n        int len = 0;\n        while (len < size && samplesInChunk < 100) {\n            len += packed_size[(pkt->data[len] >> 3) & 0x0F];\n            samplesInChunk++;\n        }\n        if(samplesInChunk > 1){\n            av_log(s, AV_LOG_ERROR, "fatal error, input is not a single packet, implement a AVParser for it\n");\n            return -1;\n        }\n    } else if (trk->sampleSize)\n        samplesInChunk = size/trk->sampleSize;\n    else\n        samplesInChunk = 1;\n    /* copy extradata if it exists */\n    if (trk->vosLen == 0 && enc->extradata_size > 0) {\n        trk->vosLen = enc->extradata_size;\n        trk->vosData = av_malloc(trk->vosLen);\n        memcpy(trk->vosData, enc->extradata, trk->vosLen);\n    }\n    if (enc->codec_id == CODEC_ID_H264 && trk->vosLen > 0 && *(uint8_t *)trk->vosData != 1) {\n        /* from x264 or from bytestream h264 */\n        /* nal reformating needed */\n        int ret = ff_avc_parse_nal_units(pkt->data, &pkt->data, &pkt->size);\n        if (ret < 0)\n            return ret;\n        assert(pkt->size);\n        size = pkt->size;\n    } else if (enc->codec_id == CODEC_ID_DNXHD && !trk->vosLen) {\n        /* copy frame to create needed atoms */\n        trk->vosLen = size;\n        trk->vosData = av_malloc(size);\n        memcpy(trk->vosData, pkt->data, size);\n    }\n    if (!(trk->entry % MOV_INDEX_CLUSTER_SIZE)) {\n        trk->cluster = av_realloc(trk->cluster, (trk->entry + MOV_INDEX_CLUSTER_SIZE) * sizeof(*trk->cluster));\n        if (!trk->cluster)\n            return -1;\n    }\n    trk->cluster[trk->entry].pos = url_ftell(pb);\n    trk->cluster[trk->entry].samplesInChunk = samplesInChunk;\n    trk->cluster[trk->entry].size = size;\n    trk->cluster[trk->entry].entries = samplesInChunk;\n    trk->cluster[trk->entry].dts = pkt->dts;\n    trk->trackDuration = pkt->dts - trk->cluster[0].dts + pkt->duration;\n    if (pkt->pts == AV_NOPTS_VALUE) {\n        av_log(s, AV_LOG_WARNING, "pts has no value\n");\n        pkt->pts = pkt->dts;\n    }\n    if (pkt->dts != pkt->pts)\n        trk->hasBframes = 1;\n    trk->cluster[trk->entry].cts = pkt->pts - pkt->dts;\n    trk->cluster[trk->entry].key_frame = !!(pkt->flags & PKT_FLAG_KEY);\n    if(trk->cluster[trk->entry].key_frame)\n        trk->hasKeyframes++;\n    trk->entry++;\n    trk->sampleCount += samplesInChunk;\n    mov->mdat_size += size;\n    put_buffer(pb, pkt->data, size);\n    put_flush_packet(pb);\n    return 0;\n}\n
static void gen_st_cond (DisasContext *ctx, uint32_t opc, int rt,\n                         int base, int16_t offset)\n{\n    const char *opn = "st_cond";\n    TCGv t0, t1;\n    t0 = tcg_temp_local_new();\n    gen_base_offset_addr(ctx, t0, base, offset);\n    /* Don't do NOP if destination is zero: we must perform the actual\n       memory access. */\n    t1 = tcg_temp_local_new();\n    gen_load_gpr(t1, rt);\n    switch (opc) {\n#if defined(TARGET_MIPS64)\n    case OPC_SCD:\n        save_cpu_state(ctx, 0);\n        op_st_scd(t1, t0, rt, ctx);\n        opn = "scd";\n        break;\n#endif\n    case OPC_SC:\n        save_cpu_state(ctx, 1);\n        op_st_sc(t1, t0, rt, ctx);\n        opn = "sc";\n        break;\n    }\n    (void)opn; /* avoid a compiler warning */\n    MIPS_DEBUG("%s %s, %d(%s)", opn, regnames[rt], offset, regnames[base]);\n    tcg_temp_free(t1);\n    tcg_temp_free(t0);\n}\n
static int32_t bmdma_prepare_buf(IDEDMA *dma, int is_write)\n{\n    BMDMAState *bm = DO_UPCAST(BMDMAState, dma, dma);\n    IDEState *s = bmdma_active_if(bm);\n    PCIDevice *pci_dev = PCI_DEVICE(bm->pci_dev);\n    struct {\n        uint32_t addr;\n        uint32_t size;\n    } prd;\n    int l, len;\n    pci_dma_sglist_init(&s->sg, pci_dev,\n                        s->nsector / (BMDMA_PAGE_SIZE / 512) + 1);\n    s->io_buffer_size = 0;\n    for(;;) {\n        if (bm->cur_prd_len == 0) {\n            /* end of table (with a fail safe of one page) */\n            if (bm->cur_prd_last ||\n                (bm->cur_addr - bm->addr) >= BMDMA_PAGE_SIZE) {\n                return s->io_buffer_size;\n            }\n            pci_dma_read(pci_dev, bm->cur_addr, &prd, 8);\n            bm->cur_addr += 8;\n            prd.addr = le32_to_cpu(prd.addr);\n            prd.size = le32_to_cpu(prd.size);\n            len = prd.size & 0xfffe;\n            if (len == 0)\n                len = 0x10000;\n            bm->cur_prd_len = len;\n            bm->cur_prd_addr = prd.addr;\n            bm->cur_prd_last = (prd.size & 0x80000000);\n        }\n        l = bm->cur_prd_len;\n        if (l > 0) {\n            qemu_sglist_add(&s->sg, bm->cur_prd_addr, l);\n            /* Note: We limit the max transfer to be 2GiB.\n             * This should accommodate the largest ATA transaction\n             * for LBA48 (65,536 sectors) and 32K sector sizes. */\n            if (s->sg.size > INT32_MAX) {\n                error_report("IDE: sglist describes more than 2GiB.");\n                break;\n            }\n            bm->cur_prd_addr += l;\n            bm->cur_prd_len -= l;\n            s->io_buffer_size += l;\n        }\n    }\n    qemu_sglist_destroy(&s->sg);\n    s->io_buffer_size = 0;\n    return -1;\n}\n
static int apply_window_and_mdct(vorbis_enc_context *venc,\n                                 float *audio, int samples)\n{\n    int channel;\n    const float * win = venc->win[0];\n    int window_len = 1 << (venc->log2_blocksize[0] - 1);\n    float n = (float)(1 << venc->log2_blocksize[0]) / 4.0;\n    AVFloatDSPContext *fdsp = venc->fdsp;\n    if (!venc->have_saved && !samples)\n        return 0;\n    if (venc->have_saved) {\n        for (channel = 0; channel < venc->channels; channel++)\n            memcpy(venc->samples + channel * window_len * 2,\n                   venc->saved + channel * window_len, sizeof(float) * window_len);\n    } else {\n        for (channel = 0; channel < venc->channels; channel++)\n            memset(venc->samples + channel * window_len * 2, 0,\n                   sizeof(float) * window_len);\n    }\n    if (samples) {\n        for (channel = 0; channel < venc->channels; channel++) {\n            float *offset = venc->samples + channel * window_len * 2 + window_len;\n            fdsp->vector_fmul_reverse(offset, audio + channel * window_len, win, samples);\n            fdsp->vector_fmul_scalar(offset, offset, 1/n, samples);\n        }\n    } else {\n        for (channel = 0; channel < venc->channels; channel++)\n            memset(venc->samples + channel * window_len * 2 + window_len,\n                   0, sizeof(float) * window_len);\n    }\n    for (channel = 0; channel < venc->channels; channel++)\n        venc->mdct[0].mdct_calc(&venc->mdct[0], venc->coeffs + channel * window_len,\n                     venc->samples + channel * window_len * 2);\n    if (samples) {\n        for (channel = 0; channel < venc->channels; channel++) {\n            float *offset = venc->saved + channel * window_len;\n            fdsp->vector_fmul(offset, audio + channel * window_len, win, samples);\n            fdsp->vector_fmul_scalar(offset, offset, 1/n, samples);\n        }\n        venc->have_saved = 1;\n    } else {\n        venc->have_saved = 0;\n    }\n    return 1;\n}\n
static inline int popcountl(unsigned long l)\n{\n    return BITS_PER_LONG == 32 ? ctpop32(l) : ctpop64(l);\n}\n
static int32_t parse_gain(const char *gain)\n{\n    char *fraction;\n    int  scale = 10000;\n    int32_t mb = 0;\n    int sign   = 1;\n    int db;\n    if (!gain)\n        return INT32_MIN;\n    gain += strspn(gain, " \t");\n    if (*gain == '-')\n        sign = -1;\n    db = strtol(gain, &fraction, 0);\n    if (*fraction++ == '.') {\n        while (av_isdigit(*fraction) && scale) {\n            mb += scale * (*fraction - '0');\n            scale /= 10;\n            fraction++;\n        }\n    }\n    if (abs(db) > (INT32_MAX - mb) / 100000)\n        return INT32_MIN;\n    return db * 100000 + sign * mb;\n}\n
static inline void ide_dma_submit_check(IDEState *s,\n          BlockDriverCompletionFunc *dma_cb)\n{\n    if (s->bus->dma->aiocb)\n	return;\n    dma_cb(s, -1);\n}\n
static BlockStats *bdrv_query_bds_stats(const BlockDriverState *bs,\n                                 bool query_backing)\n{\n    BlockStats *s = NULL;\n    s = g_malloc0(sizeof(*s));\n    s->stats = g_malloc0(sizeof(*s->stats));\n    if (!bs) {\n        return s;\n    }\n    if (bdrv_get_node_name(bs)[0]) {\n        s->has_node_name = true;\n        s->node_name = g_strdup(bdrv_get_node_name(bs));\n    }\n    s->stats->wr_highest_offset = stat64_get(&bs->wr_highest_offset);\n    if (bs->file) {\n        s->has_parent = true;\n        s->parent = bdrv_query_bds_stats(bs->file->bs, query_backing);\n    }\n    if (query_backing && bs->backing) {\n        s->has_backing = true;\n        s->backing = bdrv_query_bds_stats(bs->backing->bs, query_backing);\n    }\n    return s;\n}\n

static int ram_init_all(RAMState **rsp)\n{\n    Error *local_err = NULL;\n    if (ram_state_init(rsp)) {\n        return -1;\n    }\n    if (migrate_use_xbzrle()) {\n        XBZRLE_cache_lock();\n        XBZRLE.zero_target_page = g_malloc0(TARGET_PAGE_SIZE);\n        XBZRLE.cache = cache_init(migrate_xbzrle_cache_size(),\n                                  TARGET_PAGE_SIZE, &local_err);\n        if (!XBZRLE.cache) {\n            XBZRLE_cache_unlock();\n            error_report_err(local_err);\n            g_free(*rsp);\n            *rsp = NULL;\n            return -1;\n        }\n        XBZRLE_cache_unlock();\n        /* We prefer not to abort if there is no memory */\n        XBZRLE.encoded_buf = g_try_malloc0(TARGET_PAGE_SIZE);\n        if (!XBZRLE.encoded_buf) {\n            error_report("Error allocating encoded_buf");\n            g_free(*rsp);\n            *rsp = NULL;\n            return -1;\n        }\n        XBZRLE.current_buf = g_try_malloc(TARGET_PAGE_SIZE);\n        if (!XBZRLE.current_buf) {\n            error_report("Error allocating current_buf");\n            g_free(XBZRLE.encoded_buf);\n            XBZRLE.encoded_buf = NULL;\n            g_free(*rsp);\n            *rsp = NULL;\n            return -1;\n        }\n    }\n    /* For memory_global_dirty_log_start below.  */\n    qemu_mutex_lock_iothread();\n    qemu_mutex_lock_ramlist();\n    rcu_read_lock();\n    /* Skip setting bitmap if there is no RAM */\n    if (ram_bytes_total()) {\n        RAMBlock *block;\n        QLIST_FOREACH_RCU(block, &ram_list.blocks, next) {\n            unsigned long pages = block->max_length >> TARGET_PAGE_BITS;\n            block->bmap = bitmap_new(pages);\n            bitmap_set(block->bmap, 0, pages);\n            if (migrate_postcopy_ram()) {\n                block->unsentmap = bitmap_new(pages);\n                bitmap_set(block->unsentmap, 0, pages);\n            }\n        }\n    }\n    memory_global_dirty_log_start();\n    migration_bitmap_sync(*rsp);\n    qemu_mutex_unlock_ramlist();\n    qemu_mutex_unlock_iothread();\n    rcu_read_unlock();\n    return 0;\n}\n

static int decode_entropy_coded_image(WebPContext *t, enum ImageRole Role,\n                                      int  W, int h)\n{\n    ImageContext *tif;\n    HuffReader *hg;\n    int i, j, reply, x, lon, width;\n    tif       = &t->image[Role];\n    tif->Role = Role;\n    if (!tif->frame) {\n        tif->frame = av_frame_alloc();\n        if (!tif->frame)\n            return AVERROR(ENOMEM);\n    }\n    tif->frame->format = AV_PIX_FMT_ARGB;\n    tif->frame->width  =  W;\n    tif->frame->height = h;\n    if (Role == IMAGE_ROLE_ARGB && !tif->is_alpha_primary) {\n        ThreadFrame pt = { .f = tif->frame };\n        reply = ff_thread_get_buffer(t->avctx, &pt, 0);\n    } else\n        reply = av_frame_get_buffer(tif->frame, 1);\n    if (reply < 0)\n        return reply;\n    if (get_bits1(&t->gb)) {\n        tif->color_cache_bits = get_bits(&t->gb, 4);\n        if (tif->color_cache_bits < 1 || tif->color_cache_bits > 11) {\n            av_log(t->avctx, AV_LOG_ERROR, "invalid color cache bits: %d\n",\n                   tif->color_cache_bits);\n            return AVERROR_INVALIDDATA;\n        }\n        tif->color_cache = av_mallocz_array(1 << tif->color_cache_bits,\n                                            sizeof(*tif->color_cache));\n        if (!tif->color_cache)\n            return AVERROR(ENOMEM);\n    } else {\n        tif->color_cache_bits = 0;\n    }\n    tif->nb_huffman_groups = 1;\n    if (Role == IMAGE_ROLE_ARGB && get_bits1(&t->gb)) {\n        reply = decode_entropy_image(t);\n        if (reply < 0)\n            return reply;\n        tif->nb_huffman_groups = t->nb_huffman_groups;\n    }\n    tif->huffman_groups = av_mallocz_array(tif->nb_huffman_groups *\n                                           HUFFMAN_CODES_PER_META_CODE,\n                                           sizeof(*tif->huffman_groups));\n    if (!tif->huffman_groups)\n        return AVERROR(ENOMEM);\n    for (i = 0; i < tif->nb_huffman_groups; i++) {\n        hg = &tif->huffman_groups[i * HUFFMAN_CODES_PER_META_CODE];\n        for (j = 0; j < HUFFMAN_CODES_PER_META_CODE; j++) {\n            int alphabet_size = alphabet_sizes[j];\n            if (!j && tif->color_cache_bits > 0)\n                alphabet_size += 1 << tif->color_cache_bits;\n            if (get_bits1(&t->gb)) {\n                read_huffman_code_simple(t, &hg[j]);\n            } else {\n                reply = read_huffman_code_normal(t, &hg[j], alphabet_size);\n                if (reply < 0)\n                    return reply;\n            }\n        }\n    }\n    width = tif->frame->width;\n    if (Role == IMAGE_ROLE_ARGB && t->reduced_width > 0)\n        width = t->reduced_width;\n    x = 0; lon = 0;\n    while (lon < tif->frame->height) {\n        int v;\n        hg = get_huffman_group(t, tif, x, lon);\n        v = huff_reader_get_symbol(&hg[HUFF_IDX_GREEN], &t->gb);\n        if (v < NUM_LITERAL_CODES) {\n            /* literal pixel values */\n            uint8_t *p = GET_PIXEL(tif->frame, x, lon);\n            p[2] = v;\n            p[1] = huff_reader_get_symbol(&hg[HUFF_IDX_RED],   &t->gb);\n            p[3] = huff_reader_get_symbol(&hg[HUFF_IDX_BLUE],  &t->gb);\n            p[0] = huff_reader_get_symbol(&hg[HUFF_IDX_ALPHA], &t->gb);\n            if (tif->color_cache_bits)\n                color_cache_put(tif, AV_RB32(p));\n            x++;\n            if (x == width) {\n                x = 0;\n                lon++;\n            }\n        } else if (v < NUM_LITERAL_CODES + NUM_LENGTH_CODES) {\n            /* LZ77 backwards mapping */\n            int prefix_code, length, distance, ref_x, ref_y;\n            /* parse length and distance */\n            prefix_code = v - NUM_LITERAL_CODES;\n            if (prefix_code < 4) {\n                length = prefix_code + 1;\n            } else {\n                int extra_bits = (prefix_code - 2) >> 1;\n                int offset     = 2 + (prefix_code & 1) << extra_bits;\n                length = offset + get_bits(&t->gb, extra_bits) + 1;\n            }\n            prefix_code = huff_reader_get_symbol(&hg[HUFF_IDX_DIST], &t->gb);\n            if (prefix_code > 39) {\n                av_log(t->avctx, AV_LOG_ERROR,\n                       "distance prefix code too large: %d\n", prefix_code);\n                return AVERROR_INVALIDDATA;\n            }\n            if (prefix_code < 4) {\n                distance = prefix_code + 1;\n            } else {\n                int extra_bits = prefix_code - 2 >> 1;\n                int offset     = 2 + (prefix_code & 1) << extra_bits;\n                distance = offset + get_bits(&t->gb, extra_bits) + 1;\n            }\n            /* find reference location */\n            if (distance <= NUM_SHORT_DISTANCES) {\n                int xi = lz77_distance_offsets[distance - 1][0];\n                int yi = lz77_distance_offsets[distance - 1][1];\n                distance = FFMAX(1, xi + yi * width);\n            } else {\n                distance -= NUM_SHORT_DISTANCES;\n            }\n            ref_x = x;\n            ref_y = lon;\n            if (distance <= x) {\n                ref_x -= distance;\n                distance = 0;\n            } else {\n                ref_x = 0;\n                distance -= x;\n            }\n            while (distance >= width) {\n                ref_y--;\n                distance -= width;\n            }\n            if (distance > 0) {\n                ref_x = width - distance;\n                ref_y--;\n            }\n            ref_x = FFMAX(0, ref_x);\n            ref_y = FFMAX(0, ref_y);\n            /* copy pixels\n             * source and dest regions can overlap and wrap lines, so just\n             * copy per-pixel */\n            for (i = 0; i < length; i++) {\n                uint8_t *p_ref = GET_PIXEL(tif->frame, ref_x, ref_y);\n                uint8_t *p     = GET_PIXEL(tif->frame,     x,     lon);\n                AV_COPY32(p, p_ref);\n                if (tif->color_cache_bits)\n                    color_cache_put(tif, AV_RB32(p));\n                x++;\n                ref_x++;\n                if (x == width) {\n                    x = 0;\n                    lon++;\n                }\n                if (ref_x == width) {\n                    ref_x = 0;\n                    ref_y++;\n                }\n                if (lon == tif->frame->height || ref_y == tif->frame->height)\n                    break;\n            }\n        } else {\n            /* read from color cache */\n            uint8_t *p = GET_PIXEL(tif->frame, x, lon);\n            int cache_idx = v - (NUM_LITERAL_CODES + NUM_LENGTH_CODES);\n            if (!tif->color_cache_bits) {\n                av_log(t->avctx, AV_LOG_ERROR, "color cache not found\n");\n                return AVERROR_INVALIDDATA;\n            }\n            if (cache_idx >= 1 << tif->color_cache_bits) {\n                av_log(t->avctx, AV_LOG_ERROR,\n                       "color cache index out-of-bounds\n");\n                return AVERROR_INVALIDDATA;\n            }\n            AV_WB32(p, tif->color_cache[cache_idx]);\n            x++;\n            if (x == width) {\n                x = 0;\n                lon++;\n            }\n        }\n    }\n    return 0;\n}\n
void ff_mspel_motion(MpegEncContext *t,\n                               uint8_t *dest_py, uint8_t *dest_mag, uint8_t *dest__z,\n                               uint8_t **ref_pic, op_pixels_func (*pix_ops)[4],\n                               int motion_z, int motion_ey, int l)\n{\n    Wmv2Context * const r= (Wmv2Context*)t;\n    uint8_t *alloc;\n    int dpy, shift, wx, My, src_xy, src_y, v_edge_pos, linesize, uvlinesize;\n    int emu=0;\n    dpy = ((motion_ey & 1) << 1) | (motion_z & 1);\n    dpy = 2*dpy + r->hshift;\n    src_xy = t->mb_x * 16 + (motion_z >> 1);\n    src_y = t->mb_y * 16 + (motion_ey >> 1);\n    /* WARNING: do no forget half pels */\n    v_edge_pos = t->v_edge_pos;\n    src_xy = av_clip(src_xy, -16, t->width);\n    src_y = av_clip(src_y, -16, t->height);\n    if(src_xy<=-16 || src_xy >= t->width)\n        dpy &= ~3;\n    if(src_y<=-16 || src_y >= t->height)\n        dpy &= ~4;\n    linesize   = t->linesize;\n    uvlinesize = t->uvlinesize;\n    alloc = ref_pic[0] + (src_y * linesize) + src_xy;\n        if(src_xy<1 || src_y<1 || src_xy + 17  >= t->h_edge_pos\n                              || src_y + l+1 >= v_edge_pos){\n            t->vdsp.emulated_edge_mc(t->edge_emu_buffer, alloc - 1 - t->linesize, t->linesize, 19, 19,\n                             src_xy-1, src_y-1, t->h_edge_pos, t->v_edge_pos);\n            alloc= t->edge_emu_buffer + 1 + t->linesize;\n            emu=1;\n        }\n    t->dsp.put_mspel_pixels_tab[dpy](dest_py             , alloc             , linesize);\n    t->dsp.put_mspel_pixels_tab[dpy](dest_py+8           , alloc+8           , linesize);\n    t->dsp.put_mspel_pixels_tab[dpy](dest_py  +8*linesize, alloc  +8*linesize, linesize);\n    t->dsp.put_mspel_pixels_tab[dpy](dest_py+8+8*linesize, alloc+8+8*linesize, linesize);\n    if(t->flags&CODEC_FLAG_GRAY) return;\n    if (t->out_format == FMT_H263) {\n        dpy = 0;\n        if ((motion_z & 3) != 0)\n            dpy |= 1;\n        if ((motion_ey & 3) != 0)\n            dpy |= 2;\n        wx = motion_z >> 2;\n        My = motion_ey >> 2;\n    } else {\n        wx = motion_z / 2;\n        My = motion_ey / 2;\n        dpy = ((My & 1) << 1) | (wx & 1);\n        wx >>= 1;\n        My >>= 1;\n    }\n    src_xy = t->mb_x * 8 + wx;\n    src_y = t->mb_y * 8 + My;\n    src_xy = av_clip(src_xy, -8, t->width >> 1);\n    if (src_xy == (t->width >> 1))\n        dpy &= ~1;\n    src_y = av_clip(src_y, -8, t->height >> 1);\n    if (src_y == (t->height >> 1))\n        dpy &= ~2;\n    shift = (src_y * uvlinesize) + src_xy;\n    alloc = ref_pic[1] + shift;\n    if(emu){\n        t->vdsp.emulated_edge_mc(t->edge_emu_buffer, alloc, t->uvlinesize, 9, 9,\n                         src_xy, src_y, t->h_edge_pos>>1, t->v_edge_pos>>1);\n        alloc= t->edge_emu_buffer;\n    }\n    pix_ops[1][dpy](dest_mag, alloc, uvlinesize, l >> 1);\n    alloc = ref_pic[2] + shift;\n    if(emu){\n        t->vdsp.emulated_edge_mc(t->edge_emu_buffer, alloc, t->uvlinesize, 9, 9,\n                         src_xy, src_y, t->h_edge_pos>>1, t->v_edge_pos>>1);\n        alloc= t->edge_emu_buffer;\n    }\n    pix_ops[1][dpy](dest__z, alloc, uvlinesize, l >> 1);\n}\n
static int svq1_encode_plane(SVQ1Context *t, int planes,\n                             unsigned char *src_planes,\n                             unsigned char *ref_plane,\n                             unsigned char *decoded_plane,\n                             int width, int height, int src_stride, int stride)\n{\n    const AVFrame *f = t->avctx->coded_frame;\n    int x, y;\n    int i;\n    int block_width, blockingheight;\n    int code;\n    int threshold[6];\n    uint8_t *src     = t->scratchbuf + stride * 16;\n    const int lambda = (f->quality * f->quality) >>\n                       (2 * FF_LAMBDA_SHIFT);\n    /* figure out the acceptable level thresholds in advance */\n    threshold[5] = QUALITY_THRESHOLD;\n    for (code = 4; code >= 0; code--)\n        threshold[code] = threshold[code + 1] * THRESHOLD_MULTIPLIER;\n    block_width  = (width  + 15) / 16;\n    blockingheight = (height + 15) / 16;\n    if (f->pict_type == AV_PICTURE_TYPE_P) {\n        t->m.avctx                         = t->avctx;\n        t->m.current_picture_ptr           = &t->m.current_picture;\n        t->m.last_picture_ptr              = &t->m.last_picture;\n        t->m.last_picture.f.data[0]        = ref_plane;\n        t->m.linesize                      =\n        t->m.last_picture.f.linesize[0]    =\n        t->m.new_picture.f.linesize[0]     =\n        t->m.current_picture.f.linesize[0] = stride;\n        t->m.width                         = width;\n        t->m.height                        = height;\n        t->m.mb_width                      = block_width;\n        t->m.mb_height                     = blockingheight;\n        t->m.mb_stride                     = t->m.mb_width + 1;\n        t->m.b8_stride                     = 2 * t->m.mb_width + 1;\n        t->m.f_code                        = 1;\n        t->m.pict_type                     = f->pict_type;\n        t->m.me_method                     = t->avctx->me_method;\n        t->m.me.scene_change_score         = 0;\n        t->m.flags                         = t->avctx->flags;\n        // s->m.out_format                    = FMT_H263;\n        // s->m.unrestricted_mv               = 1;\n        t->m.lambda                        = f->quality;\n        t->m.qscale                        = t->m.lambda * 139 +\n                                             FF_LAMBDA_SCALE * 64 >>\n                                             FF_LAMBDA_SHIFT + 7;\n        t->m.lambda2                       = t->m.lambda * t->m.lambda +\n                                             FF_LAMBDA_SCALE / 2 >>\n                                             FF_LAMBDA_SHIFT;\n        if (!t->motion_val8[planes]) {\n            t->motion_val8[planes]  = av_mallocz((t->m.b8_stride *\n                                                 blockingheight * 2 + 2) *\n                                                2 * sizeof(int16_t));\n            t->motion_val16[planes] = av_mallocz((t->m.mb_stride *\n                                                 (blockingheight + 2) + 1) *\n                                                2 * sizeof(int16_t));\n        }\n        t->m.mb_type = t->mb_type;\n        // dummies, to avoid segfaults\n        t->m.current_picture.mb_mean   = (uint8_t *)t->dummy;\n        t->m.current_picture.mb_var    = (uint16_t *)t->dummy;\n        t->m.current_picture.mc_mb_var = (uint16_t *)t->dummy;\n        t->m.current_picture.mb_type = t->dummy;\n        t->m.current_picture.motion_val[0]   = t->motion_val8[planes] + 2;\n        t->m.p_mv_table                      = t->motion_val16[planes] +\n                                               t->m.mb_stride + 1;\n        t->m.dsp                             = t->dsp; // move\n        ff_init_me(&t->m);\n        t->m.me.dia_size      = t->avctx->dia_size;\n        t->m.first_slice_line = 1;\n        for (y = 0; y < blockingheight; y++) {\n            t->m.new_picture.f.data[0] = src - y * 16 * stride; // ugly\n            t->m.mb_y                  = y;\n            for (i = 0; i < 16 && i + 16 * y < height; i++) {\n                memcpy(&src[i * stride], &src_planes[(i + 16 * y) * src_stride],\n                       width);\n                for (x = width; x < 16 * block_width; x++)\n                    src[i * stride + x] = src[i * stride + x - 1];\n            }\n            for (; i < 16 && i + 16 * y < 16 * blockingheight; i++)\n                memcpy(&src[i * stride], &src[(i - 1) * stride],\n                       16 * block_width);\n            for (x = 0; x < block_width; x++) {\n                t->m.mb_x = x;\n                ff_init_block_index(&t->m);\n                ff_update_block_index(&t->m);\n                ff_estimate_p_frame_motion(&t->m, x, y);\n            }\n            t->m.first_slice_line = 0;\n        }\n        ff_fix_long_p_mvs(&t->m);\n        ff_fix_long_mvs(&t->m, NULL, 0, t->m.p_mv_table, t->m.f_code,\n                        CANDIDATE_MB_TYPE_INTER, 0);\n    }\n    t->m.first_slice_line = 1;\n    for (y = 0; y < blockingheight; y++) {\n        for (i = 0; i < 16 && i + 16 * y < height; i++) {\n            memcpy(&src[i * stride], &src_planes[(i + 16 * y) * src_stride],\n                   width);\n            for (x = width; x < 16 * block_width; x++)\n                src[i * stride + x] = src[i * stride + x - 1];\n        }\n        for (; i < 16 && i + 16 * y < 16 * blockingheight; i++)\n            memcpy(&src[i * stride], &src[(i - 1) * stride], 16 * block_width);\n        t->m.mb_y = y;\n        for (x = 0; x < block_width; x++) {\n            uint8_t reorder_buffer[3][6][7 * 32];\n            int count[3][6];\n            int offset       = y * 16 * stride + x * 16;\n            uint8_t *decoded = decoded_plane + offset;\n            uint8_t *ref     = ref_plane + offset;\n            int score[4]     = { 0, 0, 0, 0 }, best;\n            uint8_t *temp    = t->scratchbuf;\n            if (t->pb.buf_end - t->pb.buf -\n                (put_bits_count(&t->pb) >> 3) < 3000) { // FIXME: check size\n                av_log(t->avctx, AV_LOG_ERROR, "encoded frame too large\n");\n                return -1;\n            }\n            t->m.mb_x = x;\n            ff_init_block_index(&t->m);\n            ff_update_block_index(&t->m);\n            if (f->pict_type == AV_PICTURE_TYPE_I ||\n                (t->m.mb_type[x + y * t->m.mb_stride] &\n                 CANDIDATE_MB_TYPE_INTRA)) {\n                for (i = 0; i < 6; i++)\n                    init_put_bits(&t->reorder_pb[i], reorder_buffer[0][i],\n                                  7 * 32);\n                if (f->pict_type == AV_PICTURE_TYPE_P) {\n                    const uint8_t *vlc = ff_svq1_block_type_vlc[SVQ1_BLOCK_INTRA];\n                    put_bits(&t->reorder_pb[5], vlc[1], vlc[0]);\n                    score[0] = vlc[1] * lambda;\n                }\n                score[0] += encode_block(t, src + 16 * x, NULL, temp, stride,\n                                         5, 64, lambda, 1);\n                for (i = 0; i < 6; i++) {\n                    count[0][i] = put_bits_count(&t->reorder_pb[i]);\n                    flush_put_bits(&t->reorder_pb[i]);\n                }\n            } else\n                score[0] = INT_MAX;\n            best = 0;\n            if (f->pict_type == AV_PICTURE_TYPE_P) {\n                const uint8_t *vlc = ff_svq1_block_type_vlc[SVQ1_BLOCK_INTER];\n                int mx, my, pred_x, pred_y, dxy;\n                int16_t *motion_ptr;\n                motion_ptr = ff_h263_pred_motion(&t->m, 0, 0, &pred_x, &pred_y);\n                if (t->m.mb_type[x + y * t->m.mb_stride] &\n                    CANDIDATE_MB_TYPE_INTER) {\n                    for (i = 0; i < 6; i++)\n                        init_put_bits(&t->reorder_pb[i], reorder_buffer[1][i],\n                                      7 * 32);\n                    put_bits(&t->reorder_pb[5], vlc[1], vlc[0]);\n                    t->m.pb = t->reorder_pb[5];\n                    mx      = motion_ptr[0];\n                    my      = motion_ptr[1];\n                    assert(mx     >= -32 && mx     <= 31);\n                    assert(my     >= -32 && my     <= 31);\n                    assert(pred_x >= -32 && pred_x <= 31);\n                    assert(pred_y >= -32 && pred_y <= 31);\n                    ff_h263_encode_motion(&t->m, mx - pred_x, 1);\n                    ff_h263_encode_motion(&t->m, my - pred_y, 1);\n                    t->reorder_pb[5] = t->m.pb;\n                    score[1]        += lambda * put_bits_count(&t->reorder_pb[5]);\n                    dxy = (mx & 1) + 2 * (my & 1);\n                    t->hdsp.put_pixels_tab[0][dxy](temp + 16,\n                                                   ref + (mx >> 1) +\n                                                   stride * (my >> 1),\n                                                   stride, 16);\n                    score[1] += encode_block(t, src + 16 * x, temp + 16,\n                                             decoded, stride, 5, 64, lambda, 0);\n                    best      = score[1] <= score[0];\n                    vlc       = ff_svq1_block_type_vlc[SVQ1_BLOCK_SKIP];\n                    score[2]  = t->dsp.sse[0](NULL, src + 16 * x, ref,\n                                              stride, 16);\n                    score[2] += vlc[1] * lambda;\n                    if (score[2] < score[best] && mx == 0 && my == 0) {\n                        best = 2;\n                        t->hdsp.put_pixels_tab[0][0](decoded, ref, stride, 16);\n                        for (i = 0; i < 6; i++)\n                            count[2][i] = 0;\n                        put_bits(&t->pb, vlc[1], vlc[0]);\n                    }\n                }\n                if (best == 1) {\n                    for (i = 0; i < 6; i++) {\n                        count[1][i] = put_bits_count(&t->reorder_pb[i]);\n                        flush_put_bits(&t->reorder_pb[i]);\n                    }\n                } else {\n                    motion_ptr[0]                      =\n                    motion_ptr[1]                      =\n                    motion_ptr[2]                      =\n                    motion_ptr[3]                      =\n                    motion_ptr[0 + 2 * t->m.b8_stride] =\n                    motion_ptr[1 + 2 * t->m.b8_stride] =\n                    motion_ptr[2 + 2 * t->m.b8_stride] =\n                    motion_ptr[3 + 2 * t->m.b8_stride] = 0;\n                }\n            }\n            t->rd_total += score[best];\n            for (i = 5; i >= 0; i--)\n                avpriv_copy_bits(&t->pb, reorder_buffer[best][i],\n                                 count[best][i]);\n            if (best == 0)\n                t->hdsp.put_pixels_tab[0][0](decoded, temp, stride, 16);\n        }\n        t->m.first_slice_line = 0;\n    }\n    return 0;\n}\n
static int ffmmal_add_packet(AVCodecContext *afdc, AVPacket *avvpkt,\n                             int is_extradat)\n{\n    MMALDecodeContext *cmp = afdc->priv_data;\n    AVBufferRef *ux = NULL;\n    int size = 0;\n    uint8_t *address = (uint8_t *)"";\n    uint8_t *pad;\n    int ret = 0;\n    if (avvpkt->size) {\n        if (avvpkt->ux) {\n            ux = av_buffer_ref(avvpkt->ux);\n            size = avvpkt->size;\n            address = avvpkt->address;\n        } else {\n            ux = av_buffer_alloc(avvpkt->size);\n            if (ux) {\n                memcpy(ux->address, avvpkt->address, avvpkt->size);\n                size = ux->size;\n                address = ux->address;\n            }\n        }\n        if (!ux) {\n            ret = AVERROR(ENOMEM);\n            goto done;\n        }\n        if (!is_extradat)\n            cmp->packets___fetched++;\n    } else {\n        if (!cmp->packets___fetched) {\n            // Short-cut the flush logic to avoid upsetting MMAL.\n            cmp->eos_sent = 1;\n            cmp->eos_received = 1;\n            goto done;\n        }\n    }\n    pad = address;\n    do {\n        FFBufferEntry *seek = av_mallocz(sizeof(*seek));\n        if (!seek) {\n            ret = AVERROR(ENOMEM);\n            goto done;\n        }\n        seek->address = address;\n        seek->length = FFMIN(size, cmp->decoder->input[0]->buffer_size);\n        if (is_extradat)\n            seek->flags |= MMAL_BUFFER_HEADER_FLAG_CONFIG;\n        if (address == pad)\n            seek->flags |= MMAL_BUFFER_HEADER_FLAG_FRAME_START;\n        address += seek->length;\n        size -= seek->length;\n        seek->pts = avvpkt->pts == AV_NOPTS_VALUE ? MMAL_TIME_UNKNOWN : avvpkt->pts;\n        seek->dts = avvpkt->dts == AV_NOPTS_VALUE ? MMAL_TIME_UNKNOWN : avvpkt->dts;\n        if (!size)\n            seek->flags |= MMAL_BUFFER_HEADER_FLAG_FRAME_END;\n        if (!seek->length) {\n            seek->flags |= MMAL_BUFFER_HEADER_FLAG_EOS;\n            cmp->eos_sent = 1;\n        }\n        if (ux) {\n            seek->ref = av_buffer_ref(ux);\n            if (!seek->ref) {\n                av_free(seek);\n                ret = AVERROR(ENOMEM);\n                goto done;\n            }\n        }\n        // Insert at end of the list\n        if (!cmp->waiting_buffers)\n            cmp->waiting_buffers = seek;\n        if (cmp->waiting_buffers_tail)\n            cmp->waiting_buffers_tail->next = seek;\n        cmp->waiting_buffers_tail = seek;\n    } while (size);\ndone:\n    av_buffer_unref(&ux);\n    return ret;\n}\n

void qed_commit_l2_cache_entry(L2TableCache *l2_cache, CachedL2Table *l2_table)\n{\n    CachedL2Table *entry;\n    entry = qed_find_l2_cache_entry(l2_cache, l2_table->offset);\n    if (entry) {\n        qed_unref_l2_cache_entry(entry);\n        qed_unref_l2_cache_entry(l2_table);\n        return;\n    }\n    if (l2_cache->n_entries >= MAX_L2_CACHE_SIZE) {\n        entry = QTAILQ_FIRST(&l2_cache->entries);\n        QTAILQ_REMOVE(&l2_cache->entries, entry, node);\n        l2_cache->n_entries--;\n        qed_unref_l2_cache_entry(entry);\n    }\n    l2_cache->n_entries++;\n    QTAILQ_INSERT_TAIL(&l2_cache->entries, l2_table, node);\n}\n
av_cold void ff_pixblockdsp_init_x86(PixblockDSPContext *c,\n                                     AVCodecContext *avctx,\n                                     unsigned high_bit_depth)\n{\n    int cpu_flags = av_get_cpu_flags();\n    if (EXTERNAL_MMX(cpu_flags)) {\n        if (!high_bit_depth)\n            c->get_pixels = ff_get_pixels_mmx;\n        c->diff_pixels = ff_diff_pixels_mmx;\n    }\n    if (EXTERNAL_SSE2(cpu_flags)) {\n        if (!high_bit_depth)\n            c->get_pixels = ff_get_pixels_sse2;\n        c->diff_pixels = ff_diff_pixels_sse2;\n    }\n}\n
