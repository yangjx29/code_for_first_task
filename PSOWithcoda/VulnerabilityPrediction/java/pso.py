import sys

import logging
import random
import numpy as np
import torch
import pandas as pd
import copy
sys.path.append("../../")
sys.path.append("../../python_parser")
import subprocess

from run_parser import get_identifiers,extract_dataflow,remove_comments_and_docstrings,get_example,get_example_batch,remove_strings
import logging
import numpy as np
import pandas as pd
from utils import get_identifier_posistions_from_code,get_masked_code_by_position,CodeDataset, _tokenize,GraphCodeDataset,CodeT5Dataset,isUID
import os
import time
import torch.nn as nn
import copy
import utils
from scipy.spatial.distance import cosine as cosine_distance
from run import CodeBertInputFeatures, GraphCodeBertInputFeatures, CodeT5InputFeatures
from Transform import GenRandomChange
import re

logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
    datefmt="%m/%d/%Y %H:%M:%S",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)

def codebert_convert_code_to_features(code, tokenizer, label, args):
    code = ' '.join(code.split())
    code_tokens = tokenizer.tokenize(code)[:args.block_size-2]
    source_tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]
    source_ids = tokenizer.convert_tokens_to_ids(source_tokens)
    padding_length = args.block_size - len(source_ids)
    source_ids += [tokenizer.pad_token_id] * padding_length

    return CodeBertInputFeatures(source_tokens, source_ids, 0, label)


def graphcodebert_convert_code_to_features(code, tokenizer, label, args):
    code = ' '.join(code.split())
    dfg, index_table, code_tokens = extract_dataflow(code, "java")
    code_tokens = [tokenizer.tokenize('@ ' + x)[1:] if idx != 0 else tokenizer.tokenize(x) for idx, x in enumerate(code_tokens)]
    ori2cur_pos = {}
    ori2cur_pos[-1] = (0, 0)
    for i in range(len(code_tokens)):
        ori2cur_pos[i] = (ori2cur_pos[i - 1][1], ori2cur_pos[i - 1][1] + len(code_tokens[i]))
    code_tokens = [y for x in code_tokens for y in x]

    code_tokens = code_tokens[:args.code_length + args.data_flow_length - 2 - min(len(dfg), args.data_flow_length)]
    source_tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]
    source_ids = tokenizer.convert_tokens_to_ids(source_tokens)
    position_idx = [i + tokenizer.pad_token_id + 1 for i in range(len(source_tokens))]
    dfg = dfg[:args.code_length + args.data_flow_length - len(source_tokens)]
    source_tokens += [x[0] for x in dfg]
    position_idx += [0 for x in dfg]
    source_ids += [tokenizer.unk_token_id for x in dfg]
    padding_length = args.code_length + args.data_flow_length - len(source_ids)
    position_idx += [tokenizer.pad_token_id] * padding_length
    source_ids += [tokenizer.pad_token_id] * padding_length

    reverse_index = {}
    for idx, x in enumerate(dfg):
        reverse_index[x[1]] = idx
    for idx, x in enumerate(dfg):
        dfg[idx] = x[:-1] + ([reverse_index[i] for i in x[-1] if i in reverse_index],)
    dfg_to_dfg = [x[-1] for x in dfg]
    dfg_to_code = [ori2cur_pos[x[1]] for x in dfg]
    length = len([tokenizer.cls_token])
    dfg_to_code = [(x[0] + length, x[1] + length) for x in dfg_to_code]

    return GraphCodeBertInputFeatures(source_tokens, source_ids, position_idx, dfg_to_code, dfg_to_dfg, 0, label)


def codet5_convert_code_to_features(code, tokenizer, label, args):
    code = ' '.join(code.split())
    code_tokens = tokenizer.tokenize(code)[:args.block_size-2]
    source_tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]
    source_ids = tokenizer.convert_tokens_to_ids(source_tokens)
    padding_length = args.block_size - len(source_ids)
    source_ids += [tokenizer.pad_token_id] * padding_length

    return CodeT5InputFeatures(source_tokens, source_ids, 0, label)


def get_embeddings(code, variables, tokenizer_mlm, codebert_mlm):
    new_code = copy.deepcopy(code)
    chromesome = {}
    for i in variables:
        chromesome[i] = '<unk>'
    new_code = get_example_batch(new_code, chromesome, "java")
    _, _, code_tokens = get_identifiers(remove_comments_and_docstrings(new_code, "java"), "java")
    processed_code = " ".join(code_tokens)
    words, sub_words, keys = _tokenize(processed_code, tokenizer_mlm)
    sub_words = [tokenizer_mlm.cls_token] + sub_words[:512 - 2] + [tokenizer_mlm.sep_token]
    input_ids_ = torch.tensor([tokenizer_mlm.convert_tokens_to_ids(sub_words)])
    with torch.no_grad():
        embeddings = codebert_mlm.roberta(input_ids_.to('cuda'))[0]

    return embeddings

NONREACHABLECODE = ["if(false){String input;char[] buffer = new char[64];System.arraycopy(input.toCharArray(), 0, buffer, 0, input.length()); }", 
"int x=0; if(!(x*(x-1) % 2 == 0)) { x = (x+3)/x; }", 
"int x=0,y; boolean flag_is_true = false; if(flag_is_true) { char[] dest = new char[64]; String user_input = new String(dest); }", 
"int x=0,y; if(!(x*(x-1) % 2 == 0)) { double n=0.0; if(n>10) { char[] dest = new char[64]; String user_input = \"input\"; System.arraycopy(user_input.toCharArray(), 0, dest, 0, user_input.length()); } else n=0; }", 
"int x=0,y; if(!(x*(x-1) % 2 == 0)) { int temp=0; int[] asdfwq = new int[10]; while(temp<10) { temp=temp+1; if(temp==9) asdfwq[temp] = temp; break; }}", 
"int x=0,y; if(!(x*(x+1) % 2 == 0)){ double temp=0.0; if(temp==3) { String str; { String temp = \"Hello, World!\"; String tr = temp; } } return 0; }"]


def loss(embedding_a, embedding_b):
        '''
        compute the squared distance between embedding_a and embedding_b
        '''        
        return nn.MSELoss()(embedding_a.to('cuda'), embedding_b.to('cuda')).item()

def get_insert_masked_code(code, pos):
            splited_code = code.split('\n')
            splited_code.insert(pos, '<mask>')
            inserted_code_str = ''
            for line in splited_code:
                inserted_code_str += (line + '; ')
            return inserted_code_str

def get_inserted_code(code, pos, print_statement):
            splited_code = code.split(';')
            splited_code.insert(pos, '{}'.format(print_statement))
            inserted_code_str = ''
            for line in splited_code:
                inserted_code_str += (line + ';')
            return inserted_code_str

def get_input_ids(processed_masked_code,tokenizer_mlm, codebert_mlm,args):
    code_tokens=tokenizer_mlm.tokenize(processed_masked_code)[:args.block_size-2]
    source_tokens =[tokenizer_mlm.cls_token]+code_tokens+[tokenizer_mlm.sep_token]
    source_ids =  tokenizer_mlm.convert_tokens_to_ids(source_tokens)
    padding_length = args.block_size - len(source_ids)
    source_ids+=[tokenizer_mlm.pad_token_id]*padding_length
    return source_ids

def find_important_positions(ori_code,adv_code, tokenizer_mlm, codebert_mlm,args,idx):
    insert_pos_nums = len(re.findall(';', adv_code))
    importance_score = []
    ori_feature = get_input_ids(ori_code,tokenizer_mlm, codebert_mlm,args)
    orig_embeddings = codebert_mlm(torch.tensor(ori_feature).unsqueeze(0).to(args.device))[0].detach().cpu()
    for i in range(insert_pos_nums):
        masked_code = get_insert_masked_code(adv_code, i)
        processed_masked_code = ' ' + masked_code
        masked_feature = get_input_ids(processed_masked_code,tokenizer_mlm, codebert_mlm,args)
        masked_embeddings = codebert_mlm(torch.tensor(masked_feature).unsqueeze(0).to(args.device))[0].detach().cpu()
        importance_score.append(loss(orig_embeddings, masked_embeddings))
    sorted_id = sorted(range(len(importance_score)), key=lambda k: importance_score[k],reverse=True)
    # print("sorted_id:", sorted_id)
    return sorted_id[idx % len(sorted_id) if len(sorted_id) > 0 else 0]
    

def changeCodeStructure(code, tokenizer_mlm, codebert_mlm,args,now_iter):
    with open ("tmpcode.c", 'w') as wf:
        wf.write(code)
    # TODO 1首先判断代码中每种结构的数量,根据数量进行概率分布,进一步决定进行何种变换
    result = subprocess.run(["bash", "./Transform/AnalysisStructure.sh","/data/yjx/code_for_first_task/PSOWithcoda/VulnerabilityPrediction/code/tmpcode.c"], capture_output=True, text=True)
    # print("result1:", result)
    # TODO 2确定进行何种变换
    action = GenRandomChange.getAction()

    # TODO 3确定好action之后,根据action进行变换 变换后的代码在Mutete.c中
    if not action == 13:
        result = subprocess.run(["bash", "./Transform/changeStructure.sh","/data/yjx/code_for_first_task/PSOWithcoda/VulnerabilityPrediction/code/tmpcode.c",str(action)], capture_output=True, text=True)
        # print("result2:", result)
        # TODO 返回代码
        with open ("Mutated.c", 'r') as rf:
            code = rf.read()
    else:
        # 如果是插入垃圾代码,不用txl的逻辑
        pos = find_important_positions(code,code, tokenizer_mlm, codebert_mlm,args,now_iter)
        now_iter += 1
        # 随机选择一个垃圾代码插入
        junk_code_id = random.randint(0, len(NONREACHABLECODE)-1)
        # 找到最佳位置进行插入
        code = get_inserted_code(code, pos, NONREACHABLECODE[junk_code_id])
        
    return code,now_iter

class PSOAttack(object):
    def __init__(self, args, model_tgt, tokenizer_tgt, tokenizer_mlm, codebert_mlm, fasttext_model,t5_model,t5_tokenizer, generated_substitutions, pop_size,max_iters) -> None:
        self.args = args
        self.model_tgt = model_tgt
        self.tokenizer_tgt = tokenizer_tgt
        self.tokenizer_mlm = tokenizer_mlm
        self.codebert_mlm = codebert_mlm
        self.fasttext_model = fasttext_model
        self.t5_model = t5_model
        self.t5_tokenizer = t5_tokenizer
        self.substitutions = generated_substitutions
        self.pop_size = pop_size
        self.max_iters = max_iters

    
    def do_replace(self, adv_code, tgt_word, subsitute_word):
        """
        将代码 adv_code 的 tgt_word 替换为新词 subsitute_word,返回修改后的代码
        """
        new_code = copy.deepcopy(adv_code)
        new_code = get_example(new_code, tgt_word,subsitute_word, "java")
        return new_code
    
    def predict_batch(self,code_batch, labels):
        replace_examples = []
        for idx, code in enumerate(code_batch):
            replace_examples.append(self.get_feature(code, labels[idx]))

        # 评估新生成的对抗样本
        if self.args.model_name == 'codebert':
            new_dataset = CodeDataset(replace_examples)
        elif self.args.model_name == 'graphcodebert':
            new_dataset = GraphCodeDataset(replace_examples, self.args)
        elif self.args.model_name == 'codet5':
            new_dataset = CodeT5Dataset(replace_examples)
        logits, preds = self.model_tgt.get_results(new_dataset, self.args.eval_batch_size)
       
        return logits, preds

    
    def get_feature(self,temp_code,label):
        replace_examples = []
        if self.args.model_name == 'codebert':
            new_feature = codebert_convert_code_to_features(temp_code, self.tokenizer_tgt,label, self.args)
        elif self.args.model_name == 'graphcodebert':
            new_feature = graphcodebert_convert_code_to_features(temp_code, self.tokenizer_tgt,label, self.args)
        elif self.args.model_name == 'codet5':
            new_feature = codet5_convert_code_to_features(temp_code, self.tokenizer_tgt,label, self.args)
        
        return new_feature


    def select_best_replacement(self,  cur_code, tgt_name, label, replace_list,current_prob):
        """ Select the most effective replacement to word at pos (pos)
        in (cur_code) between the words in replace_list 
        候选替换词 replace_list 中找到最能改变目标模型预测的词
        过比较修改后的预测与原始预测，选择最有效的替换词
        """
        # TODO min_prob的需要优化,代码中重复太多
        min_prob = current_prob
        new_code_list = [self.do_replace(cur_code,tgt_name,sub_name) for sub_name in replace_list]
        labels = [label for _ in range(len(new_code_list))]
        # [[logits, preds], [logits, preds], ...]
        # print("new_code_list", new_code_list)
        logits, preds = self.predict_batch(new_code_list,labels)
        dim = 0
        final_code = cur_code
        for index, temp_prob in enumerate(logits):
            temp_label = preds[index]
            if temp_label != labels[index]:
                # print("rename in select_best_replacement %s SUCCESS! (%.5f => %.5f)" % ('>>', current_prob, temp_prob[labels[index]]), flush=True)
                print("select_best_replacement SUCCESS!")
                return 1, new_code_list[index], current_prob - temp_prob[labels[index]],dim
            else:
                if min_prob > temp_prob[label]:
                    min_prob = temp_prob[label]
                    final_code = new_code_list[index]
                    dim = index
        return -1, final_code, current_prob - min_prob, dim


    def perturb(self, cur_code, orig_code, substituions, sorted_list_of_names, label,current_prob,particles,id):
        """
        选择一个词位置，并根据选择的概率 sorted_list_of_names 选取一个候选词，将原始词替换为该候选词
        返回修改后的代码及其预测结果
        """
        scores = []
        # print(f"sorted_list_of_names:{sorted_list_of_names}") # {'name1': [['sub_name1', 0.9], ['sub_name2', 0.8]], 'name2': [['sub_name1', 0.9], ['sub_name2', 0.8]]}
        # 计算每个变量替换的总得分
        for name, replacements in sorted_list_of_names.items():
            sub_scores = []
            for sub_name, score in replacements:
                sub_scores.append(score)
            sub_scores = np.array(sub_scores,dtype=np.float64)
            scores.append([name,sub_scores.sum()])
        # 确保得分归一化为概率分布
        scores = np.array(scores)
        # print(f"测试scores:{scores}")
        scores = np.array([score[1] for score in scores], dtype=np.float64)
        scores = np.maximum(scores, 0)
        # print(f"转换之后scores:{scores}")
        if np.any(np.isnan(scores)) or np.any(np.isinf(scores)):
            # print("Warning: scores contain NaN or inf values!")
            # 处理 NaN 或 inf
            scores = np.nan_to_num(scores, nan=np.random.uniform(0,20), posinf=0.99, neginf=0)
            # print(f"处理之后scores:{scores}")
        probabilities = scores / scores.sum()
        rand_idx = np.random.choice(len(scores), 1, p=probabilities)[0]
        # chosen_name, chosen_score = None, None
        replace_list=[]
        cumulative_idx = 0
        tgt_name = None
        for name, replacements in sorted_list_of_names.items():
            if cumulative_idx == rand_idx:
                tgt_name = name
                for sub_name, score in replacements:
                    replace_list.append(sub_name)
                break
            cumulative_idx += 1
        # print(f'cur_code:{cur_code},rand_idx:{rand_idx},cumulative_idx:{cumulative_idx}')
        is_success, final_code, gap_prob, dim = self.select_best_replacement(cur_code, tgt_name, label, replace_list,current_prob)
        particles[id][cumulative_idx] = replace_list[dim]
        return is_success, final_code, gap_prob

        

    def perturb_init(self, adv_code, orig_code, substituions, sorted_list_of_names, label, idx,current_prob,variable_names,particles):
        """
        选择一个词位置，并根据选择的概率 sorted_list_of_names 选取一个候选词，将原始词替换为该候选词
        返回修改后的代码及其预测结果
        """

        # 按照idx选择
        # print(f"sorted_list_of_names:{sorted_list_of_names}")
        tgt_word = variable_names[idx % len(variable_names)]
        # 选择对应的相似度最高的替换词 # TODOsolved 处理替换量太少case
        replace_word = sorted_list_of_names[tgt_word][idx // len(variable_names) if idx // len(variable_names) < len(substituions) else len(substituions)-1][0]
        particles[idx][idx % len(variable_names)] = replace_word
        # print(f"tgt_word:{tgt_word} |init| replace_word:{replace_word}") 
        tmp_code=self.do_replace(adv_code, tgt_word, replace_word)
        logits, preds=self.predict_batch([tmp_code], [label])
        # print(f"logits:{logits}, preds:{preds}")
        # 获得预测的标签
        temp_label = preds[0]
        temp_prob = logits[0]
        if temp_label != label:
            # print("rename in init %s SUCCESS! (%.5f => %.5f)" % ('>>', current_prob, temp_prob[label]), flush=True)
            print("init SUCCESS!")
            is_success = 1
        else:
            is_success = -1
       
        return is_success, tmp_code, current_prob - temp_prob[label]

    def generate_population(self, code, substituions, sorted_list_of_names, label, pop_size,current_prob,variable_names,particles):
        """
        每个种群个体都是通过对原始文本 code 进行扰动得到的，扰动通过 perturb 方法实现
        返回扰动后的代码及其预测结果
        """
        pop = []
        pop_scores=[]
        adv_code = code
        for idx in range(pop_size):
            # 需要保证sort_list_of_names中的每个变量名都在variable_names中
            is_success, adv_code, max_gap_prob = self.perturb_init(adv_code, code, substituions, sorted_list_of_names, label,idx,current_prob,variable_names,particles)
            if is_success == 1:
                return is_success, adv_code, max_gap_prob
            else:
                # 存储下降的分数,越大越好
                pop_scores.append(max_gap_prob)
                # 存储初始化的例子
                pop.append(adv_code)
        return is_success,pop,pop_scores

    def crossover(self, tmp_code,tgt_word,subsitute_word, prob, i):
        """
        根据给定的概率 prob,将文本 x1 的一些词替换到 x2 中，生成新的文本
        """
        # TODO 只能修改变量
        new_code = copy.deepcopy(tmp_code)
        if np.random.uniform() < prob[i]:
            new_code = get_example(new_code, tgt_word,subsitute_word, "java")
            return new_code,True
        return new_code,False

    def equal(self, a, b):
        """
        判断两个元素是否相等，相等返回-3，不相等返回3
        """
        if a == b:
            return -5
        else:
            return 5

    def sigmod(self, n):
        return 1 / (1 + np.exp(-n))

    def count_change_ratio(self, adv_code_tokens, orig_code_tokens, identifiers_len):
        """
        计算对抗样本与原始样本之间的修改比例
        """
        change_ratio = float(np.sum(adv_code_tokens != orig_code_tokens)) / float(identifiers_len)
        return change_ratio
    
    def mutate(self,code,substituions,variable_names,t5_model,t5_tokenizer):
        # _,code_tokens = get_identifiers(code, "java")
        # 随机选择变量 identifiers是从substituions中提取的变量名
        index = random.choice(range(len(variable_names)))
        name = variable_names[index]
        while name not in substituions.keys():
            index = random.choice(range(len(variable_names)))
            name = variable_names[index]
        
        if code.find(name) == -1:
            is_find = False
            while is_find == False:
                if code.find(name) != -1:
                    is_find = True
                    # print(f"find name here:{name}")
                    break
                for tgt_name in substituions[name]:
                    if code.find(tgt_name) != -1:
                        # print(f"find tgt_name:{tgt_name}")
                        name = tgt_name
                        is_find = True
                        break
                if is_find:
                    break
                index = (index + 1) % len(variable_names)
                name = variable_names[index]
                # print(f'index in mutate:{index},name:{name}')

        # positions = names_positions_dict[name]
        # print(f"mutate中选择的 name:{name}, 位置positions:{positions}")
        # for t in positions:
        #     if t >= len(code_tokens):
        #         continue
        #     code_tokens[t] = "<extra_id_0>"
        new_code = get_example(code, name, "<extra_id_0>", "java")
        # print(f"name:{name}\ncode:{code}\nnew_code:{new_code}")
        # token -> id
        source_ids = t5_tokenizer.encode(
            new_code,
            max_length=512,
            padding="max_length",
            truncation=True,
        )
        source_ids = torch.tensor([source_ids], dtype=torch.long).to("cuda")
        # not equal to pad token
        source_mask = source_ids.ne(t5_tokenizer.pad_token_id)
        # 生成 40 个候选标识符
        preds = t5_model.generate(
            input_ids=source_ids,
            attention_mask=source_mask,
            max_length=25,
            num_return_sequences=40,
            use_cache=True,
            num_beams=40,
        )
        # logger.info("T5生成标识符时间:{}".format(time.time() - t5startTime))
        # 解码得到标识符
        pred_nls = [
            t5_tokenizer.decode(id, skip_special_tokens=True) for id in preds
        ]
        # print(f"pred_nls:{pred_nls}")

        # 随机选择符合条件的标识符,将index位置的标识符替换为选择的标识符
        cnt = 0
        subs = []
        # while cnt < 20:
        #     i = np.random.randint(0, 40)
        #     if isUID(pred_nls[i]):
        #         # identifiers[index] = pred_nls[i]
        #         for j in positions:
        #             code_tokens[j] = pred_nls[i]
        #         break
        #     cnt += 1
        while cnt < 40:
            if isUID(pred_nls[cnt]):
                # identifiers[index] = pred_nls[i]
                subs.append(pred_nls[cnt])
            cnt += 1
        if len(subs) == 0:
            # print("No valid substitutions found in mutate.")
            return code
        idx = random.choice(range(len(subs)))
        # for j in positions:
        new_code = get_example(new_code,"<extra_id_0>",subs[idx], "java")
        return new_code

    def attack(self, idx, example, orig_code, pos_tags=None):
        
        # 先预测
        logits, preds = self.model_tgt.get_results([example], self.args.eval_batch_size)
        orig_prob = logits[0]
        orig_label = preds[0]
        current_prob = max(orig_prob)
        if self.args.model_name == 'codebert':
            true_label = example[1].item()
        elif self.args.model_name == 'graphcodebert':
            true_label = example[3].item()
        elif self.args.model_name == 'codet5':
            true_label = example[1].item()
        query_times = 0
        flag_success = False  # whether we have found the first adversarial example in our algorithm
        is_success = 0

        # 对应代码的变量名替换
        substituions = self.substitutions[idx]
        # 第一次是正确的
        # variable_names, function_names, code_tokens = get_identifiers(orig_code, "java")
        # variable_names = variable_names + function_names
        identifiers,code_tokens = get_identifiers(orig_code, "java")
        variable_names = list(substituions.keys())
        processed_code = " ".join(code_tokens)
        # 分别是代码中的分词，分词的token，位置
        words, sub_words, keys = _tokenize(processed_code, self.tokenizer_mlm)
        # print(f"words:{words}\nsub_words:{sub_words}\nkeys:{keys}")

        if orig_label != true_label:  # the original code is misclassified
            print("The original code is misclassified.")
            is_success = -4
            return is_success, orig_code, 0
        elif len(variable_names) == 0:  # no identifier in the code
            print("No variable_names in the code.")
            is_success = -3
            return is_success, orig_code, 0
        
        # 进行代码结构转换
        min_prob = current_prob
        names_positions_dict = get_identifier_posistions_from_code(
            words, variable_names
        )
        if len(names_positions_dict) == 0:
            print("No identifiers in the code.")
            is_success = -3
            return is_success, orig_code, 0
        # print(f"code_tokens:{code_tokens}\nwords:{words}\n")
        # print(f"names_positions_dict:{names_positions_dict}, variable_names:{variable_names}")
        # 存储所有变量的位置信息
        pos_dict = []
        for i in variable_names:
            if i not in names_positions_dict.keys():
                continue
            pos_dict.append(names_positions_dict[i])
        
        print("Number of variable_names extracted: ", len(variable_names))
        # 初始化时,每个粒子依次替换一个变量名。怎么替换呢，用fasttext计算变量和他所有替换的相似度，然后选择最相似的替换
        temp_subs_variable_name = {}
        substituions_len = 0
        # TODO substituions中变量少于variable_names
        # print(f"substituions:{substituions}")
        
        for name, subs in substituions.items():
            substituions_len = substituions_len+1
            temp_subs_variable_name[name] = []
            for sub in subs:
            # temp_subs_variable_name.update(subs)
                temp_subs_variable_name[name].append([sub, self.fasttext_model.get_word_vector(sub)])

        # print(f"temp_subs_variable_name in {idx}轮:{temp_subs_variable_name}")

        if substituions_len == 0:
            print("substituions_len == 0")
            return -4, orig_code, 0

        variable_substitue_dict = {}   
        for name, subs in temp_subs_variable_name.items():
            variable_substitue_dict[name] =[]
            name_vec = self.fasttext_model.get_word_vector(name)
            for j in subs:
                variable_substitue_dict[name].append([j[0], 1-cosine_distance(name_vec, j[1])])

            variable_substitue_dict[name] = sorted(variable_substitue_dict[name], key=lambda x: x[1], reverse=True)
        
        # print(f"variable_substitue_dict:{variable_substitue_dict}") # 存储了每个变量对应余弦距离最大的替换词
        # 存储每个粒子初始的变量替换
        particles = [[] for _ in range(self.pop_size)]
        for i in range(self.pop_size):
            for name in variable_names:
                particles[i].append(name)
        # print("生成前的particles:",particles)
        print(f"Generating population{idx}...")
        final_words = copy.deepcopy(words)
        final_code = copy.deepcopy(orig_code)
        is_success,pop,pop_scores = self.generate_population(final_code, substituions, variable_substitue_dict, true_label,self.pop_size,current_prob,variable_names,particles)
        # print("生成之后particles:",particles)
        # print(f"adv_codes: {pop}\n origin_code:{orig_code}\n")
        if is_success==1:
            return is_success,pop,pop_scores
        
        # 粒子群体 注意,存储的代码而不是代码片段
        part_elites = copy.deepcopy(pop)
        # 粒子群对应的gap分数 越大越好
        part_elites_scores = pop_scores
        # 最优最大的粒子的gap分数
        all_elite_score = np.max(pop_scores)
        pop_ranks = np.argsort(pop_scores) 

        top_attack = pop_ranks[-1]# 找到最优的粒子的下标
        # 最优对抗性代码
        part_elites_code = part_elites[top_attack]
        part_elites_subs = particles[top_attack]
        all_elite_code = pop[top_attack]
        all_elite_subs = particles[top_attack]
        # logger.info(f"{idx}轮初始的最优对抗性代码,all_elite:{all_elite}\n")
        most_gap = part_elites_scores[top_attack]
        variabel_len = len(variable_names)

        # print(f"{idx}轮初始的最优对抗性代码,all_elite_code:{all_elite_code}\n")
        # PSO超参数
        # Omega_1 和 Omega_2:惯性权重的最大值和最小值
        Omega_1 = 0.8
        Omega_2 = 0.2
        # C1_origin 和 C2_origin:个体学习因子和社会学习因子
        C1_origin = 0.8
        C2_origin = 0.2
        # 速度初始化为随机值
        V = [np.random.uniform(-3, 3) for rrr in range(self.pop_size)]
        
        # V_P[粒子群个数][可替换变量数]
        V_P = np.array([[V[t] for rrr in range(variabel_len)] for t in range(self.pop_size)])
        V_P[:] = -np.inf
        
        # 最优对抗性代码的prob
        iter_same_num = 0
        last_best_score = all_elite_score
        for i in range(self.max_iters):
            # 逐步调整速度和位置，以寻找最优对抗样本
            Omega = (Omega_1 - Omega_2) * (self.max_iters - i) / self.max_iters + Omega_2
            C1 = C1_origin - i / self.max_iters * (C1_origin - C2_origin)
            C2 = C2_origin + i / self.max_iters * (C1_origin - C2_origin)

            # 粒子更新,根据其当前速度和最优个体（粒子自身和全局最优个体）更新位置（对抗代码）
            for id in range(self.pop_size):
                
                tmp_code = pop[id]
                
                for dim, tgt_name in enumerate(names_positions_dict.keys()):
                    # 判断该变量是否一样
                    V_P[id][dim] = Omega * V_P[id][dim] + (1 - Omega) * (self.equal(particles[id][dim], part_elites_subs[dim]) + self.equal(particles[id][dim],all_elite_subs[dim]))

                # 根据粒子的速度决定每个位置对应的变量是否进行修改
                turn_prob = [self.sigmod(V_P[id][d]) for d in range(variabel_len)]

                # 通过调整局部搜索和全局搜索之间的平衡来提高搜索效率,在早期阶段围绕各自的最佳位置进行空间搜索，在最后阶段围绕全局最佳位置进行更好的位置搜索
                P1 = C1 # 通过P1判断粒子是否整体移动到其个体的最佳位置,一旦一个粒子决定移动，其位置的每个维度的变化取决于其速度的相同维度，特别是与sigmoid的概率有关
                P2 = C2 # 以P2来决定是否移动到全局最佳位置,每个位置维度的变化也依赖于sigmoid
                # P1=self.sigmod(P1)
                # P2=self.sigmod(P2)

                # TODO 这里的逻辑使用的是crossover,可以进一步创新
                # 为了加强在未探索空间中的搜索，在更新步骤后对每个粒子进行变异。为避免过度修改，以turn_prob概率进行变异,分成两步执行
                # TODO 这里初步想法是变异,如果只是进行普通的交换,本质上还是在替换词里面选来选去
                new_code = None
                if np.random.uniform() < P1:
                    
                    new_code, is_change = self.crossover(tmp_code,particles[id][dim], part_elites_subs[dim],  turn_prob, dim)
                    if is_change:
                        particles[id][dim] = part_elites_subs[dim]
                    

                if np.random.uniform() < P2:
                    new_code, is_change = self.crossover(tmp_code,particles[id][dim],all_elite_subs[dim], turn_prob, dim)
                    if is_change:
                        particles[id][dim] = all_elite_subs[dim]
                pop[id] = new_code if new_code is not None else tmp_code
                # part_elites_subs = particles[id] if new_code is not None else part_elites_subs
            # 评估
            pop_scores = []

            # TODO 可能会出现到某次迭代之后的优化值不再变化的情况
            logits, preds = self.predict_batch(pop, [true_label for _ in range(self.pop_size)])
            # print(f"优化时的logits:{logits}\n preds:{preds}")
            for index, temp_prob in enumerate(logits):
                temp_label = preds[index]
                if temp_label != orig_label:
                    # print("rename in evaluate %s SUCCESS! (%.5f => %.5f)" % ('>>', current_prob, temp_prob[orig_label]), flush=True)
                    print("evaluate SUCCESS!")
                    return 1, pop[index], current_prob - temp_prob[orig_label]
                else:
                    # if part_elites_scores[index] < current_prob - temp_prob[orig_label]:
                    #     part_elites[index] = pop[index]
                    #     part_elites_scores[index] = current_prob - temp_prob[orig_label]
                    pop_scores.append(current_prob-temp_prob[orig_label])

                    if most_gap < current_prob-temp_prob[orig_label]:
                        # 更新全局最优对抗性代码
                        most_gap = current_prob-temp_prob[orig_label]

                        # all_elite = pop[index]

            # 从小到大排序,返回的是索引
            pop_ranks = np.argsort(pop_scores)
            top_attack = pop_ranks[-1]
            assert most_gap >= pop_scores[top_attack]

            # TODO 
            print('\t', i, ' --most gap', most_gap)
            # TODO 如果粒子在两代内未更新，我们认定他可能陷入了局部最优，执行额外的变异操作以跳出局部最优
            if most_gap == last_best_score:
                iter_same_num += 1
            else:
                last_best_score = most_gap
                iter_same_num = 0
            if iter_same_num > 2:
                # TODO 变异操作 variable_names_tmp
                # print(f"PSO迭代第{i}轮进行muteted...")
                print("两轮结果未更新,进行muteted...")
                muteted_code = self.mutate(pop[top_attack],substituions,variable_names,self.t5_model,self.t5_tokenizer)
                iter_same_num = 0
                part_elites[top_attack] = muteted_code
                # pop_scores[top_attack] = current_prob - temp_prob[orig_label]
            # logger.info(f"PSO迭代第{i}轮,更新...")
            # 更新种群和最优个体
            new_pop = []
            new_pop_scores=[]
            # _,ttt_code = get_identifiers(pop[0], "java")
            # print(f'先在这里测试:{len(ttt_code)}\ncode:{pop[0]}')
            for id in range(self.pop_size):
                _,adv_code_tokens = get_identifiers(pop[id], "java")
                # print(f"第{i}轮 第{id}各粒子优化前 adv_code_tokens:{len(adv_code_tokens)}")
                change_ratio = self.count_change_ratio(adv_code_tokens, code_tokens, len(identifiers))
                p_change = 1 - 2*change_ratio
                if np.random.uniform() < p_change:
                    tmp_part_elites = particles[id]
                    is_success, adv_code, gap_prob = self.perturb(pop[id], orig_code, substituions, variable_substitue_dict, true_label,current_prob,particles,id)
                    if is_success == 1:
                        # print("rename in update %s SUCCESS! (%.5f => %.5f)" % ('>>', current_prob, temp_prob[orig_label]), flush=True)
                        print("update SUCCESS!")
                        return is_success, adv_code, gap_prob
                    else:
                        if gap_prob > most_gap:
                            most_gap = gap_prob
                            new_pop_scores.append(gap_prob)
                            new_pop.append(adv_code)
                        elif gap_prob > pop_scores[id]:
                            new_pop_scores.append(gap_prob)
                            new_pop.append(adv_code)
                        else:
                            new_pop_scores.append(pop_scores[id])
                            new_pop.append(pop[id])
                            particles[id] = tmp_part_elites
                else:
                    new_pop_scores.append(pop_scores[id])
                    new_pop.append(pop[id])
            # logger.info(f"PSO迭代第{i}轮,更新最优个体...")
            pop = new_pop

            pop_scores = new_pop_scores
            # 升序之后的索引
            pop_ranks = np.argsort(pop_scores)
            top_attack = pop_ranks[-1]
            if most_gap < pop_scores[top_attack]:
                logger.info(f"第{idx}轮:warnning: most_gap:{most_gap} < pop_scores[top_attack]:{pop_scores[top_attack]}")
            for k in range(self.pop_size):
                if pop_scores[k] > part_elites_scores[k]:
                    part_elites[k] = pop[k]
                    part_elites_scores[k] = pop_scores[k]
            elite = pop[top_attack]
            if np.max(pop_scores) > all_elite_score:
                all_elite_code = elite
                all_elite_score = np.max(pop_scores)
                all_elite_subs = particles[top_attack]
        print("Changing code structure...")
        # logger.info("Changing code structure...")
        now_iter = 0
        for i in range(25):
            adv_code,now_iter = changeCodeStructure(all_elite_code, self.tokenizer_mlm, self.codebert_mlm,self.args,now_iter)
            logits, preds = self.predict_batch([adv_code], [true_label])
            # print(f"logits:{logits}\npreds:{preds}")
            for index, temp_prob in enumerate(logits):
                temp_label = preds[index]
                if temp_label != true_label:
                    print("changeCodeStructure SUCCESS!")
                    # print("changeCodeStructure %s SUCCESS! (%.5f => %.5f)" % ('>>', current_prob, temp_prob[true_label]), flush=True)
                    return 1, adv_code, current_prob - temp_prob[true_label]
                else:
                    if current_prob > temp_prob[true_label]:
                        all_elite_code = adv_code
        return -1,all_elite_code, all_elite_score
    
if __name__ == '__main__':
    with open('codeinc.c', 'r') as rf:
        code = rf.read()
    print(changeCodeStructure(code))