12/10/2024 19:40:36 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/10/2024 19:40:37 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../preprocess/dataset/train.jsonl', output_dir='./saved_models', eval_data_file='../preprocess/dataset/valid.jsonl', test_data_file='../preprocess/dataset/test.jsonl', adv_data_file=None, model_type='t5', model_name_or_path='Salesforce/codet5-base-multi-sum', mlm=False, mlm_probability=0.15, config_name='Salesforce/codet5-base-multi-sum', tokenizer_name='Salesforce/codet5-base-multi-sum', cache_dir='', block_size=510, do_train=True, do_eval=False, do_test=True, do_asr=False, do_sim=False, evaluate_during_training=True, do_lower_case=False, train_batch_size=24, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=5, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'), per_gpu_train_batch_size=24, per_gpu_eval_batch_size=64, start_epoch=0, start_step=0)
/data/yjx/code_for_first_task/CodeTAE/CodeT5/Defect-detection/code/run.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.examples = torch.load(cache_file_path)
12/10/2024 19:40:40 - INFO - __main__ -   Loading features from cached file ../preprocess/dataset/cached_train
12/10/2024 19:40:40 - INFO - __main__ -   *** Example ***
12/10/2024 19:40:40 - INFO - __main__ -   idx: 0
12/10/2024 19:40:40 - INFO - __main__ -   label: 0
12/10/2024 19:40:40 - INFO - __main__ -   input_tokens: ['<s>', 'static', '_av', '_', 'col', 'd', '_int', '_v', 'da', 'dec', '_', 'init', '(', 'AV', 'Codec', 'Context', '_*', 'av', 'ctx', ')', '_{', '_V', 'DA', 'Decoder', 'Context', '_*', 'ctx', '_=', '_av', 'ctx', '->', 'priv', '_', 'data', ';', '_struct', '_v', 'da', '_', 'context', '_*', 'v', 'da', '_', 'ctx', '_=', '_&', 'ctx', '->', 'v', 'da', '_', 'ctx', ';', '_OS', 'Status', '_status', ';', '_int', '_ret', ';', '_ctx', '->', 'h', '264', '_', 'initialized', '_=', '_0', ';', '_/*', '_init', '_pix', '_', 'fmt', 's', '_of', '_codec', '_*/', '_if', '_(!', 'ff', '_', 'h', '264', '_', 'v', 'da', '_', 'decoder', '.', 'pix', '_', 'fmt', 's', ')', '_{', '_if', '_(', 'k', 'C', 'FC', 'ore', 'Foundation', 'Version', 'Number', '_<', '_k', 'C', 'FC', 'ore', 'Foundation', 'Version', 'Number', '10', '_', '7', ')', '_ff', '_', 'h', '264', '_', 'v', 'da', '_', 'decoder', '.', 'pix', '_', 'fmt', 's', '_=', '_v', 'da', '_', 'pix', 'fmt', 's', '_', 'prior', '_', '10', '_', '7', ';', '_else', '_ff', '_', 'h', '264', '_', 'v', 'da', '_', 'decoder', '.', 'pix', '_', 'fmt', 's', '_=', '_v', 'da', '_', 'pix', 'fmt', 's', ';', '_}', '_/*', '_init', '_v', 'da', '_*/', '_mem', 'set', '(', 'v', 'da', '_', 'ctx', ',', '_0', ',', '_sizeof', '(', 'struct', '_v', 'da', '_', 'context', '));', '_v', 'da', '_', 'ctx', '->', 'width', '_=', '_av', 'ctx', '->', 'width', ';', '_v', 'da', '_', 'ctx', '->', 'height', '_=', '_av', 'ctx', '->', 'height', ';', '_v', 'da', '_', 'ctx', '->', 'format', '_=', "_'", 'av', 'c', '1', "';", '_v', 'da', '_', 'ctx', '->', 'use', '_', 'sync', '_', 'de', 'coding', '_=', '_1', ';', '_v', 'da', '_', 'ctx', '->', 'use', '_', 'ref', '_', 'buffer', '_=', '_1', ';', '_ctx', '->', 'pix', '_', 'fmt', '_=', '_av', 'ctx', '->', 'get', '_', 'format', '(', 'av', 'ctx', ',', '_av', 'ctx', '->', 'codec', '->', 'pix', '_', 'fmt', 's', ');', '_switch', '_(', 'ctx', '->', 'pix', '_', 'fmt', ')', '_{', '_case', '_AV', '_', 'PIX', '_', 'F', 'MT', '_', 'U', 'Y', 'V', 'Y', '4', '22', ':', '_v', 'da', '_', 'ctx', '->', 'cv', '_', 'pix', '_', 'fmt', '_', 'type', '_=', "_'", '2', 'v', 'uy', "';", '_break', ';', '_case', '_AV', '_', 'PIX', '_', 'F', 'MT', '_', 'Y', 'U', 'Y', 'V', '4', '22', ':', '_v', 'da', '_', 'ctx', '->', 'cv', '_', 'pix', '_', 'fmt', '_', 'type', '_=', "_'", 'y', 'u', 'vs', "';", '_break', ';', '_case', '_AV', '_', 'PIX', '_', 'F', 'MT', '_', 'NV', '12', ':', '_v', 'da', '_', 'ctx', '->', 'cv', '_', 'pix', '_', 'fmt', '_', 'type', '_=', "_'", '4', '20', 'v', "';", '_break', ';', '_case', '_AV', '_', 'PIX', '_', 'F', 'MT', '_', 'Y', 'UV', '4', '20', 'P', ':', '_v', 'da', '_', 'ctx', '->', 'cv', '_', 'pix', '_', 'fmt', '_', 'type', '_=', "_'", 'y', '4', '20', "';", '_break', ';', '_default', ':', '_av', '_', 'log', '(', 'av', 'ctx', ',', '_AV', '_', 'LOG', '_', 'ERROR', ',', '_"', 'Unsupported', '_pixel', '_format', ':', '_%', 'd', '\\', 'n', '",', '_av', 'ctx', '->', 'pix', '_', 'fmt', ');', '_goto', '_failed', ';', '_}', '_status', '_=', '_ff', '_', 'v', 'da', '_', 'create', '_', 'decoder', '(', 'v', 'da', '_', 'ctx', ',', '_av', 'ctx', '->', 'extr', 'ad', 'ata', ',', '_av', 'ctx', '->', 'extr', 'ad', 'ata', '_', 'size', ');', '_if', '_(', 'status', '_!=', '_k', 'V', 'DA', 'Decoder', 'No', 'Err', ')', '_{', '_av', '_', 'log', '</s>']
12/10/2024 19:40:40 - INFO - __main__ -   input_ids: 1 3845 1712 67 1293 72 509 331 2414 4924 67 2738 12 5856 11008 1042 380 842 5900 13 288 776 9793 7975 1042 380 5900 273 1712 5900 2122 11365 67 892 31 1958 331 2414 67 2472 380 90 2414 67 5900 273 473 5900 2122 90 2414 67 5900 31 5932 1482 1267 31 509 325 31 1103 2122 76 23728 67 13227 273 374 31 1748 1208 11871 67 8666 87 434 9196 1195 309 16051 1403 67 76 23728 67 90 2414 67 21070 18 14861 67 8666 87 13 288 309 261 79 39 4488 479 27788 1444 1854 411 417 39 4488 479 27788 1444 1854 2163 67 27 13 6875 67 76 23728 67 90 2414 67 21070 18 14861 67 8666 87 273 331 2414 67 14861 8666 87 67 17927 67 2163 67 27 31 469 6875 67 76 23728 67 90 2414 67 21070 18 14861 67 8666 87 273 331 2414 67 14861 8666 87 31 289 1748 1208 331 2414 1195 1663 542 12 90 2414 67 5900 16 374 16 13726 12 1697 331 2414 67 2472 10019 331 2414 67 5900 2122 2819 273 1712 5900 2122 2819 31 331 2414 67 5900 2122 4210 273 1712 5900 2122 4210 31 331 2414 67 5900 2122 2139 273 296 842 71 21 13506 331 2414 67 5900 2122 1202 67 8389 67 323 2014 273 404 31 331 2414 67 5900 2122 1202 67 1734 67 4106 273 404 31 1103 2122 14861 67 8666 273 1712 5900 2122 588 67 2139 12 842 5900 16 1712 5900 2122 21059 2122 14861 67 8666 87 1769 1620 261 5900 2122 14861 67 8666 13 288 648 15068 67 27381 67 42 6152 67 57 61 58 61 24 3787 30 331 2414 67 5900 2122 19774 67 14861 67 8666 67 723 273 296 22 90 9835 13506 898 31 648 15068 67 27381 67 42 6152 67 61 57 61 58 24 3787 30 331 2414 67 5900 2122 19774 67 14861 67 8666 67 723 273 296 93 89 6904 13506 898 31 648 15068 67 27381 67 42 6152 67 11679 2138 30 331 2414 67 5900 2122 19774 67 14861 67 8666 67 723 273 296 24 3462 90 13506 898 31 648 15068 67 27381 67 42 6152 67 61 20147 24 3462 52 30 331 2414 67 5900 2122 19774 67 14861 67 8666 67 723 273 296 93 24 3462 13506 898 31 805 30 1712 67 1330 12 842 5900 16 15068 67 4842 67 3589 16 315 8544 4957 740 30 738 72 64 82 3113 1712 5900 2122 14861 67 8666 1769 2897 2535 31 289 1267 273 6875 67 90 2414 67 2640 67 21070 12 90 2414 67 5900 16 1712 5900 2122 14523 361 396 16 1712 5900 2122 14523 361 396 67 1467 1769 309 261 2327 480 417 58 9793 7975 2279 2524 13 288 1712 67 1330 2
12/10/2024 19:40:40 - INFO - __main__ -   *** Example ***
12/10/2024 19:40:40 - INFO - __main__ -   idx: 1
12/10/2024 19:40:40 - INFO - __main__ -   label: 0
12/10/2024 19:40:40 - INFO - __main__ -   input_tokens: ['<s>', 'static', '_int', '_trans', 'code', '(', 'AV', 'Format', 'Context', '_**', 'output', '_', 'files', ',', '_int', '_nb', '_', 'output', '_', 'files', ',', '_Input', 'File', '_*', 'input', '_', 'files', ',', '_int', '_nb', '_', 'input', '_', 'files', ',', '_Stream', 'Map', '_*', 'stream', '_', 'maps', ',', '_int', '_nb', '_', 'stream', '_', 'maps', ')', '_{', '_int', '_ret', '_=', '_0', ',', '_i', ',', '_j', ',', '_k', ',', '_n', ',', '_nb', '_', 'ost', 'ream', 's', '_=', '_0', ',', '_step', ';', '_AV', 'Format', 'Context', '_*', 'is', ',', '_*', 'os', ';', '_AV', 'Codec', 'Context', '_*', 'codec', ',', '_*', 'icode', 'c', ';', '_OutputStream', '_*', 'ost', ',', '_**', 'ost', '_', 'table', '_=', '_NULL', ';', '_InputStream', '_*', 'ist', ';', '_char', '_error', '[', '10', '24', '];', '_int', '_key', ';', '_int', '_want', '_', 'sd', 'p', '_=', '_1', ';', '_uint', '8', '_', 't', '_no', '_', 'packet', '[', 'MAX', '_', 'FILES', ']', '={', '0', '};', '_int', '_no', '_', 'packet', '_', 'count', '=', '0', ';', '_int', '_nb', '_', 'frame', '_', 'threshold', '[', 'AV', 'MEDIA', '_', 'TYPE', '_', 'NB', ']', '={', '0', '};', '_int', '_nb', '_', 'streams', '[', 'AV', 'MEDIA', '_', 'TYPE', '_', 'NB', ']', '={', '0', '};', '_if', '_(', 'rate', '_', 'emu', ')', '_for', '_(', 'i', '_=', '_0', ';', '_i', '_<', '_nb', '_', 'input', '_', 'streams', ';', '_i', '++)', '_input', '_', 'streams', '[', 'i', '].', 'start', '_=', '_av', '_', 'get', 'time', '();', '_/*', '_output', '_stream', '_init', '_*/', '_nb', '_', 'ost', 'ream', 's', '_=', '_0', ';', '_for', '(', 'i', '=', '0', ';', 'i', '<', 'nb', '_', 'output', '_', 'files', ';', 'i', '++)', '_{', '_os', '_=', '_output', '_', 'files', '[', 'i', '];', '_if', '_(!', 'os', '->', 'nb', '_', 'streams', '_&&', '_!', '(', 'os', '->', 'o', 'format', '->', 'flags', '_&', '_AV', 'F', 'MT', '_', 'NO', 'STREAM', 'S', '))', '_{', '_av', '_', 'dump', '_', 'format', '(', 'output', '_', 'files', '[', 'i', '],', '_i', ',', '_output', '_', 'files', '[', 'i', ']', '->', 'filename', ',', '_1', ');', '_f', 'printf', '(', 'stderr', ',', '_"', 'Output', '_file', '_#%', 'd', '_does', '_not', '_contain', '_any', '_stream', '\\', 'n', '",', '_i', ');', '_ret', '_=', '_A', 'VER', 'ROR', '(', 'E', 'IN', 'VAL', ');', '_goto', '_fail', ';', '_}', '_nb', '_', 'ost', 'ream', 's', '_+=', '_os', '->', 'nb', '_', 'streams', ';', '_}', '_if', '_(', 'nb', '_', 'stream', '_', 'maps', '_>', '_0', '_&&', '_nb', '_', 'stream', '_', 'maps', '_!=', '_nb', '_', 'ost', 'ream', 's', ')', '_{', '_f', 'printf', '(', 'stderr', ',', '_"', 'Number', '_of', '_stream', '_maps', '_must', '_match', '_number', '_of', '_output', '_streams', '\\', 'n', '");', '_ret', '_=', '_A', 'VER', 'ROR', '(', 'E', 'IN', 'VAL', ');', '_goto', '_fail', ';', '_}', '_/*', '_Sanity', '_check', '_the', '_mapping', '_args', '_--', '_do', '_the', '_input', '_files', '_&', '_streams', '_exist', '?', '_*/', '_for', '(', 'i', '=', '0', ';', 'i', '<', 'nb', '_', 'stream', '_', 'maps', ';', 'i', '++)', '_{', '_int', '_fi', '_=', '_stream', '_', 'maps', '[', 'i', '].', 'file', '_', 'index', ';', '_int', '_si', '_=', '_stream', '_', 'maps', '[', 'i', '].', 'stream', '_', 'index', ';', '_if', '_(', 'fi', '_<', '_0', '_||', '_fi', '_>', '_nb', '_', 'input', '_', 'files', '_-', '_1', '_||', '_si', '_<', '_0', '_||', '_si', '_>', '_input', '_', 'files', '[', 'fi', '].', 'ctx', '->', 'nb', '_', 'streams', '_-', '_1', ')', '_{', '_f', 'printf', '(', 'stderr', ',"', 'Could', '</s>']
12/10/2024 19:40:40 - INFO - __main__ -   input_ids: 1 3845 509 906 710 12 5856 1630 1042 2826 2844 67 2354 16 509 4264 67 2844 67 2354 16 2741 812 380 2630 67 2354 16 509 4264 67 2630 67 2354 16 3961 863 380 3256 67 10711 16 509 4264 67 3256 67 10711 13 288 509 325 273 374 16 277 16 525 16 417 16 290 16 4264 67 669 793 87 273 374 16 2235 31 15068 1630 1042 380 291 16 380 538 31 15068 11008 1042 380 21059 16 380 3487 71 31 8962 380 669 16 2826 669 67 2121 273 3206 31 5037 380 376 31 1149 555 63 2163 3247 15533 509 498 31 509 2545 67 6427 84 273 404 31 2254 28 67 88 1158 67 11482 63 6694 67 12669 65 5899 20 20451 509 1158 67 11482 67 1883 33 20 31 509 4264 67 3789 67 8699 63 5856 26368 67 2399 67 20626 65 5899 20 20451 509 4264 67 16320 63 5856 26368 67 2399 67 20626 65 5899 20 20451 309 261 5141 67 24995 13 364 261 77 273 374 31 277 411 4264 67 2630 67 16320 31 277 27245 810 67 16320 63 77 8009 1937 273 1712 67 588 957 5621 1748 876 1407 1208 1195 4264 67 669 793 87 273 374 31 364 12 77 33 20 31 77 32 6423 67 2844 67 2354 31 77 27245 288 1140 273 876 67 2354 63 77 15533 309 16051 538 2122 6423 67 16320 597 401 12 538 2122 83 2139 2122 7133 473 15068 42 6152 67 3417 13693 55 3719 288 1712 67 8481 67 2139 12 2844 67 2354 63 77 6487 277 16 876 67 2354 63 77 65 2122 3459 16 404 1769 284 1461 12 11241 16 315 1447 585 31974 72 1552 486 912 1281 1407 64 82 3113 277 1769 325 273 432 2204 2784 12 41 706 2669 1769 2897 2321 31 289 4264 67 669 793 87 1011 1140 2122 6423 67 16320 31 289 309 261 6423 67 3256 67 10711 405 374 597 4264 67 3256 67 10711 480 4264 67 669 793 87 13 288 284 1461 12 11241 16 315 1854 434 1407 7565 1297 845 1300 434 876 8205 64 82 8863 325 273 432 2204 2784 12 41 706 2669 1769 2897 2321 31 289 1748 23123 866 326 2874 833 1493 741 326 810 1390 473 8205 1005 35 1195 364 12 77 33 20 31 77 32 6423 67 3256 67 10711 31 77 27245 288 509 7314 273 1407 67 10711 63 77 8009 768 67 1615 31 509 7533 273 1407 67 10711 63 77 8009 3256 67 1615 31 309 261 22056 411 374 747 7314 405 4264 67 2630 67 2354 300 404 747 7533 411 374 747 7533 405 810 67 2354 63 22056 8009 5900 2122 6423 67 16320 300 404 13 288 284 1461 12 11241 10837 4445 2
12/10/2024 19:40:40 - INFO - __main__ -   *** Example ***
12/10/2024 19:40:40 - INFO - __main__ -   idx: 2
12/10/2024 19:40:40 - INFO - __main__ -   label: 0
12/10/2024 19:40:40 - INFO - __main__ -   input_tokens: ['<s>', 'static', '_void', '_v', '4', 'l', '2', '_', 'free', '_', 'buffer', '(', 'void', '_*', 'op', 'aque', ',', '_uint', '8', '_', 't', '_*', 'unused', ')', '_{', '_V', '4', 'L', '2', 'Buffer', '*', '_av', 'buf', '_=', '_opaque', ';', '_V', '4', 'L', '2', 'm', '2', 'm', 'Context', '_*', 's', '_=', '_buf', '_', 'to', '_', 'm', '2', 'm', 'ctx', '(', 'av', 'buf', ');', '_if', '_(', 'atomic', '_', 'fetch', '_', 'sub', '(', '&', 'av', 'buf', '->', 'context', '_', 'ref', 'count', ',', '_1', ')', '_==', '_1', ')', '_{', '_atomic', '_', 'fetch', '_', 'sub', '_', 'explicit', '(', '&', 's', '->', 'ref', 'count', ',', '_1', ',', '_memory', '_', 'order', '_', 'ac', 'q', '_', 'rel', ');', '_if', '_(', 's', '->', 're', 'init', ')', '_{', '_if', '_(!', 'atomic', '_', 'load', '(', '&', 's', '->', 'ref', 'count', '))', '_sem', '_', 'post', '(', '&', 's', '->', 'ref', 'sync', ');', '_}', '_else', '_if', '_(', 'av', 'buf', '->', 'context', '->', 'stream', 'on', ')', '_ff', '_', 'v', '4', 'l', '2', '_', 'buffer', '_', 'enqueue', '(', 'av', 'buf', ');', '_av', '_', 'buffer', '_', 'un', 'ref', '(', '&', 'av', 'buf', '->', 'context', '_', 'ref', ');', '_}', '_}', '</s>']
12/10/2024 19:40:40 - INFO - __main__ -   input_ids: 1 3845 918 331 24 80 22 67 9156 67 4106 12 6459 380 556 14886 16 2254 28 67 88 380 14375 13 288 776 24 48 22 1892 14 1712 4385 273 22519 31 776 24 48 22 81 22 81 1042 380 87 273 1681 67 869 67 81 22 81 5900 12 842 4385 1769 309 261 27718 67 5754 67 1717 12 10 842 4385 2122 2472 67 1734 1883 16 404 13 422 404 13 288 7960 67 5754 67 1717 67 16511 12 10 87 2122 1734 1883 16 404 16 3778 67 1019 67 1077 85 67 2878 1769 309 261 87 2122 266 2738 13 288 309 16051 27718 67 945 12 10 87 2122 1734 1883 3719 6111 67 2767 12 10 87 2122 1734 8389 1769 289 469 309 261 842 4385 2122 2472 2122 3256 265 13 6875 67 90 24 80 22 67 4106 67 21798 12 842 4385 1769 1712 67 4106 67 318 1734 12 10 842 4385 2122 2472 67 1734 1769 289 289 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
/data/yjx/cache/conda/envs/week1/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
12/10/2024 19:40:40 - INFO - __main__ -   ***** Running training *****
12/10/2024 19:40:40 - INFO - __main__ -     Num examples = 21854
12/10/2024 19:40:40 - INFO - __main__ -     Num Epochs = 5
12/10/2024 19:40:40 - INFO - __main__ -     Instantaneous batch size per GPU = 24
12/10/2024 19:40:40 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 24
12/10/2024 19:40:40 - INFO - __main__ -     Gradient Accumulation steps = 1
12/10/2024 19:40:40 - INFO - __main__ -     Total optimization steps = 4555

 cached_features_file:  ../preprocess/dataset/cached_train
  0%|          | 0/911 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.
  0%|          | 0/911 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/data/yjx/code_for_first_task/CodeTAE/CodeT5/Defect-detection/code/run.py", line 723, in <module>
    main()
  File "/data/yjx/code_for_first_task/CodeTAE/CodeT5/Defect-detection/code/run.py", line 678, in main
    train(args, train_dataset, model, tokenizer)
  File "/data/yjx/code_for_first_task/CodeTAE/CodeT5/Defect-detection/code/run.py", line 212, in train
    loss,logits = model(inputs,labels)
  File "/data/yjx/cache/conda/envs/week1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/yjx/cache/conda/envs/week1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/yjx/code_for_first_task/CodeTAE/CodeT5/Defect-detection/code/model.py", line 184, in forward
    outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask,
  File "/data/yjx/cache/conda/envs/week1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/yjx/cache/conda/envs/week1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/yjx/cache/conda/envs/week1/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py", line 1920, in forward
    lm_logits = self.lm_head(sequence_output)
  File "/data/yjx/cache/conda/envs/week1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data/yjx/cache/conda/envs/week1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/yjx/cache/conda/envs/week1/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.46 GiB. GPU 0 has a total capacity of 47.43 GiB of which 1.33 GiB is free. Including non-PyTorch memory, this process has 46.08 GiB memory in use. Of the allocated memory 44.93 GiB is allocated by PyTorch, and 863.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
